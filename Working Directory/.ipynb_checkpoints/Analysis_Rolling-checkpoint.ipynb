{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width: 98% !important }<style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 98% !important }<style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_file = \"../Data/pin.csv\"\n",
    "\n",
    "pin = read_pin(pin_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All beacons: ['0117C55D14E4']\n",
      "Selecting 0117C55D14E4\n"
     ]
    }
   ],
   "source": [
    "filename = \"../Data/rssi3.csv\"\n",
    "B1 = \"0117C55D14E4\"\n",
    "\n",
    "data = read_data(filename, B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Validation Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = train_validation_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14582, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4861, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(\"time\", inplace=True)\n",
    "validation.sort_values(\"time\", inplace=True)\n",
    "test.sort_values(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rolled = train.groupby(\"location\").rolling(15, min_periods=1).mean().reset_index()\n",
    "validation_rolled = validation.groupby(\"location\").rolling(15, min_periods=1).mean().reset_index()\n",
    "test_rolled = test.groupby(\"location\").rolling(15, min_periods=1).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>level_1</th>\n",
       "      <th>C400A2E19293</th>\n",
       "      <th>CD4533FFC0E1</th>\n",
       "      <th>D2B6503554D7</th>\n",
       "      <th>DB8B36A69C56</th>\n",
       "      <th>DD697EA75B68</th>\n",
       "      <th>DF231643E227</th>\n",
       "      <th>E13B805C6CB0</th>\n",
       "      <th>E43355CA8B96</th>\n",
       "      <th>E6D9D20DD197</th>\n",
       "      <th>E8FD0B453DC4</th>\n",
       "      <th>E96AF2C858BA</th>\n",
       "      <th>EC72840D9AD3</th>\n",
       "      <th>F1307ECB3B90</th>\n",
       "      <th>F1EDAF28E08A</th>\n",
       "      <th>F69A86823B96</th>\n",
       "      <th>FB2EE01C18CE</th>\n",
       "      <th>FDAE5980F28C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1_12</td>\n",
       "      <td>5283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V1_12</td>\n",
       "      <td>5284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1_12</td>\n",
       "      <td>5285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V1_12</td>\n",
       "      <td>5286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V1_12</td>\n",
       "      <td>5287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-74.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14577</th>\n",
       "      <td>V1_32</td>\n",
       "      <td>22545</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.5</td>\n",
       "      <td>-70.666667</td>\n",
       "      <td>-86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14578</th>\n",
       "      <td>V1_32</td>\n",
       "      <td>22551</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.5</td>\n",
       "      <td>-70.666667</td>\n",
       "      <td>-86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14579</th>\n",
       "      <td>V1_32</td>\n",
       "      <td>22552</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-60.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.5</td>\n",
       "      <td>-68.500000</td>\n",
       "      <td>-86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14580</th>\n",
       "      <td>V1_32</td>\n",
       "      <td>22553</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-60.5</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.5</td>\n",
       "      <td>-68.500000</td>\n",
       "      <td>-86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14581</th>\n",
       "      <td>V1_32</td>\n",
       "      <td>22554</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-60.5</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.5</td>\n",
       "      <td>-68.500000</td>\n",
       "      <td>-86.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14582 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      location  level_1  C400A2E19293  CD4533FFC0E1  D2B6503554D7  \\\n",
       "0        V1_12     5283           NaN           NaN           NaN   \n",
       "1        V1_12     5284           NaN         -67.0           NaN   \n",
       "2        V1_12     5285           NaN         -67.0           NaN   \n",
       "3        V1_12     5286           NaN         -66.0           NaN   \n",
       "4        V1_12     5287           NaN         -66.0           NaN   \n",
       "...        ...      ...           ...           ...           ...   \n",
       "14577    V1_32    22545         -89.0           NaN         -80.0   \n",
       "14578    V1_32    22551         -89.0           NaN         -80.0   \n",
       "14579    V1_32    22552         -89.0           NaN         -80.0   \n",
       "14580    V1_32    22553         -89.0           NaN         -80.0   \n",
       "14581    V1_32    22554         -89.0           NaN         -80.0   \n",
       "\n",
       "       DB8B36A69C56  DD697EA75B68  DF231643E227  E13B805C6CB0  E43355CA8B96  \\\n",
       "0               NaN           NaN           NaN           NaN           NaN   \n",
       "1               NaN           NaN           NaN           NaN           NaN   \n",
       "2               NaN           NaN         -71.0           NaN           NaN   \n",
       "3               NaN           NaN         -71.0           NaN           NaN   \n",
       "4               NaN           NaN         -74.5           NaN           NaN   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "14577           NaN           NaN         -80.0         -74.0           NaN   \n",
       "14578           NaN           NaN         -80.0         -74.0           NaN   \n",
       "14579           NaN           NaN         -80.0         -74.0           NaN   \n",
       "14580           NaN           NaN           NaN         -74.0           NaN   \n",
       "14581           NaN           NaN           NaN         -76.0           NaN   \n",
       "\n",
       "       E6D9D20DD197  E8FD0B453DC4  E96AF2C858BA  EC72840D9AD3  F1307ECB3B90  \\\n",
       "0               NaN           NaN           NaN         -58.0           NaN   \n",
       "1               NaN           NaN           NaN         -58.0           NaN   \n",
       "2               NaN           NaN           NaN         -58.0           NaN   \n",
       "3               NaN           NaN           NaN         -58.0           NaN   \n",
       "4               NaN           NaN           NaN         -58.0           NaN   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "14577         -66.0           NaN         -58.0           NaN           NaN   \n",
       "14578         -67.0           NaN         -58.0           NaN           NaN   \n",
       "14579         -67.0           NaN         -60.5           NaN           NaN   \n",
       "14580         -67.0           NaN         -60.5         -84.0           NaN   \n",
       "14581         -67.0           NaN         -60.5         -84.0           NaN   \n",
       "\n",
       "       F1EDAF28E08A  F69A86823B96  FB2EE01C18CE  FDAE5980F28C  \n",
       "0               NaN           NaN           NaN           NaN  \n",
       "1             -84.0           NaN           NaN           NaN  \n",
       "2             -84.0           NaN           NaN           NaN  \n",
       "3             -84.0           NaN           NaN           NaN  \n",
       "4             -84.0           NaN           NaN           NaN  \n",
       "...             ...           ...           ...           ...  \n",
       "14577           NaN         -84.5    -70.666667         -86.0  \n",
       "14578           NaN         -84.5    -70.666667         -86.0  \n",
       "14579           NaN         -84.5    -68.500000         -86.0  \n",
       "14580           NaN         -84.5    -68.500000         -86.0  \n",
       "14581           NaN         -84.5    -68.500000         -86.0  \n",
       "\n",
       "[14582 rows x 19 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rolled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "1. Forward fill\n",
    "2. Fill NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imputed = train_rolled.set_index(\"location\").groupby(\"location\").ffill()\n",
    "train_imputed.fillna(0, inplace=True)\n",
    "train_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_imputed = validation_rolled.set_index(\"location\").groupby(\"location\").ffill()\n",
    "validation_imputed.fillna(0, inplace=True)\n",
    "validation_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imputed = test_rolled.set_index(\"location\").groupby(\"location\").ffill()\n",
    "test_imputed.fillna(0, inplace=True)\n",
    "test_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Location to Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imputed[\"X\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "train_imputed[\"Y\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_imputed[\"X\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "validation_imputed[\"Y\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imputed[\"X\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "test_imputed[\"Y\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_imputed[scanners].values, train_imputed[[\"X\", \"Y\"]].values\n",
    "X_validation, y_validation = validation_imputed[scanners].values, validation_imputed[[\"X\", \"Y\"]].values\n",
    "X_test, y_test = test_imputed[scanners].values, test_imputed[[\"X\", \"Y\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14582 samples, validate on 4861 samples\n",
      "Epoch 1/500\n",
      "14582/14582 [==============================] - 1s 74us/sample - loss: 56.8717 - mae: 4.6832 - mse: 56.8718 - val_loss: 24.5229 - val_mae: 3.3552 - val_mse: 24.5229\n",
      "Epoch 2/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 14.6178 - mae: 2.8188 - mse: 14.6178 - val_loss: 21.5947 - val_mae: 3.3993 - val_mse: 21.5947\n",
      "Epoch 3/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 10.9515 - mae: 2.5382 - mse: 10.9515 - val_loss: 13.5220 - val_mae: 2.4425 - val_mse: 13.5220\n",
      "Epoch 4/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 9.2145 - mae: 2.3522 - mse: 9.2145 - val_loss: 11.3982 - val_mae: 2.1458 - val_mse: 11.3982\n",
      "Epoch 5/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 8.1928 - mae: 2.2585 - mse: 8.1927 - val_loss: 9.8435 - val_mae: 1.9166 - val_mse: 9.8435\n",
      "Epoch 6/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 7.5214 - mae: 2.1933 - mse: 7.5214 - val_loss: 10.3505 - val_mae: 2.0462 - val_mse: 10.3505\n",
      "Epoch 7/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 6.9192 - mae: 2.0986 - mse: 6.9192 - val_loss: 10.7550 - val_mae: 2.2927 - val_mse: 10.7550\n",
      "Epoch 8/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 6.3143 - mae: 1.9939 - mse: 6.3143 - val_loss: 13.4127 - val_mae: 2.8280 - val_mse: 13.4127\n",
      "Epoch 9/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 6.0371 - mae: 1.9629 - mse: 6.0371 - val_loss: 10.4558 - val_mae: 2.2939 - val_mse: 10.4558\n",
      "Epoch 10/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 5.6239 - mae: 1.9120 - mse: 5.6239 - val_loss: 10.1593 - val_mae: 2.1288 - val_mse: 10.1593\n",
      "Epoch 11/500\n",
      "14582/14582 [==============================] - 1s 49us/sample - loss: 5.4089 - mae: 1.8567 - mse: 5.4089 - val_loss: 9.8288 - val_mae: 2.0799 - val_mse: 9.8288\n",
      "Epoch 12/500\n",
      "14582/14582 [==============================] - 1s 47us/sample - loss: 5.1555 - mae: 1.8144 - mse: 5.1555 - val_loss: 9.2327 - val_mae: 2.0202 - val_mse: 9.2327\n",
      "Epoch 13/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 4.9675 - mae: 1.7901 - mse: 4.9675 - val_loss: 18.5840 - val_mae: 3.3127 - val_mse: 18.5840\n",
      "Epoch 14/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 4.7082 - mae: 1.7381 - mse: 4.7082 - val_loss: 8.5466 - val_mae: 1.8165 - val_mse: 8.5466\n",
      "Epoch 15/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 4.5278 - mae: 1.6965 - mse: 4.5278 - val_loss: 10.4151 - val_mae: 2.2752 - val_mse: 10.4151\n",
      "Epoch 16/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 4.3426 - mae: 1.6622 - mse: 4.3426 - val_loss: 10.5773 - val_mae: 2.3109 - val_mse: 10.5773\n",
      "Epoch 17/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 4.1687 - mae: 1.6238 - mse: 4.1687 - val_loss: 8.9045 - val_mae: 1.9754 - val_mse: 8.9045\n",
      "Epoch 18/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 4.0150 - mae: 1.5996 - mse: 4.0150 - val_loss: 9.3486 - val_mae: 2.0780 - val_mse: 9.3486\n",
      "Epoch 19/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 3.8114 - mae: 1.5580 - mse: 3.8114 - val_loss: 7.2514 - val_mae: 1.6428 - val_mse: 7.2514\n",
      "Epoch 20/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 3.6026 - mae: 1.5124 - mse: 3.6026 - val_loss: 9.5702 - val_mae: 2.2938 - val_mse: 9.5702\n",
      "Epoch 21/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 3.3509 - mae: 1.4545 - mse: 3.3509 - val_loss: 8.1700 - val_mae: 1.8653 - val_mse: 8.1700\n",
      "Epoch 22/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 3.2529 - mae: 1.4347 - mse: 3.2529 - val_loss: 7.1153 - val_mae: 1.6492 - val_mse: 7.1153\n",
      "Epoch 23/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 3.1245 - mae: 1.4064 - mse: 3.1245 - val_loss: 7.0777 - val_mae: 1.6043 - val_mse: 7.0777\n",
      "Epoch 24/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 3.0728 - mae: 1.3961 - mse: 3.0728 - val_loss: 8.4577 - val_mae: 2.0617 - val_mse: 8.4577\n",
      "Epoch 25/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 2.8914 - mae: 1.3467 - mse: 2.8914 - val_loss: 6.8916 - val_mae: 1.6543 - val_mse: 6.8916\n",
      "Epoch 26/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 2.8385 - mae: 1.3418 - mse: 2.8385 - val_loss: 6.3670 - val_mae: 1.5498 - val_mse: 6.3670\n",
      "Epoch 27/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 2.7421 - mae: 1.3175 - mse: 2.7421 - val_loss: 7.8529 - val_mae: 1.9710 - val_mse: 7.8529\n",
      "Epoch 28/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 2.6516 - mae: 1.2904 - mse: 2.6516 - val_loss: 7.0211 - val_mae: 1.7931 - val_mse: 7.0211\n",
      "Epoch 29/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 2.5672 - mae: 1.2736 - mse: 2.5672 - val_loss: 6.9406 - val_mae: 1.7465 - val_mse: 6.9406\n",
      "Epoch 30/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 2.4528 - mae: 1.2429 - mse: 2.4527 - val_loss: 5.9700 - val_mae: 1.5001 - val_mse: 5.9700\n",
      "Epoch 31/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 2.3968 - mae: 1.2189 - mse: 2.3968 - val_loss: 6.3941 - val_mae: 1.5766 - val_mse: 6.3941\n",
      "Epoch 32/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 2.3099 - mae: 1.2015 - mse: 2.3099 - val_loss: 6.3088 - val_mae: 1.5770 - val_mse: 6.3088\n",
      "Epoch 33/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 2.2285 - mae: 1.1738 - mse: 2.2285 - val_loss: 5.8576 - val_mae: 1.5309 - val_mse: 5.8576\n",
      "Epoch 34/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 2.1672 - mae: 1.1577 - mse: 2.1672 - val_loss: 6.1900 - val_mae: 1.5870 - val_mse: 6.1900\n",
      "Epoch 35/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 2.0931 - mae: 1.1392 - mse: 2.0931 - val_loss: 5.8981 - val_mae: 1.4984 - val_mse: 5.8981\n",
      "Epoch 36/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 2.0513 - mae: 1.1276 - mse: 2.0513 - val_loss: 5.7391 - val_mae: 1.4690 - val_mse: 5.7391\n",
      "Epoch 37/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.9991 - mae: 1.1097 - mse: 1.9991 - val_loss: 5.9971 - val_mae: 1.5920 - val_mse: 5.9971\n",
      "Epoch 38/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.9460 - mae: 1.0949 - mse: 1.9460 - val_loss: 5.6445 - val_mae: 1.4847 - val_mse: 5.6445\n",
      "Epoch 39/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.9383 - mae: 1.0973 - mse: 1.9383 - val_loss: 5.7963 - val_mae: 1.5801 - val_mse: 5.7963\n",
      "Epoch 40/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.8675 - mae: 1.0727 - mse: 1.8675 - val_loss: 6.1171 - val_mae: 1.6220 - val_mse: 6.1171\n",
      "Epoch 41/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.8125 - mae: 1.0535 - mse: 1.8125 - val_loss: 5.8814 - val_mae: 1.5192 - val_mse: 5.8814\n",
      "Epoch 42/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.7974 - mae: 1.0490 - mse: 1.7974 - val_loss: 5.7058 - val_mae: 1.5116 - val_mse: 5.7058\n",
      "Epoch 43/500\n",
      "14582/14582 [==============================] - 1s 47us/sample - loss: 1.7470 - mae: 1.0340 - mse: 1.7470 - val_loss: 5.8128 - val_mae: 1.5558 - val_mse: 5.8128\n",
      "Epoch 44/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.7210 - mae: 1.0249 - mse: 1.7210 - val_loss: 5.4086 - val_mae: 1.4438 - val_mse: 5.4086\n",
      "Epoch 45/500\n",
      "14582/14582 [==============================] - 1s 41us/sample - loss: 1.6737 - mae: 1.0080 - mse: 1.6737 - val_loss: 5.5175 - val_mae: 1.4702 - val_mse: 5.5175\n",
      "Epoch 46/500\n",
      "14582/14582 [==============================] - 1s 47us/sample - loss: 1.6734 - mae: 1.0057 - mse: 1.6734 - val_loss: 5.4967 - val_mae: 1.4469 - val_mse: 5.4967\n",
      "Epoch 47/500\n",
      "14582/14582 [==============================] - 1s 40us/sample - loss: 1.6311 - mae: 0.9930 - mse: 1.6311 - val_loss: 5.4207 - val_mae: 1.4195 - val_mse: 5.4207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/500\n",
      "14582/14582 [==============================] - 1s 42us/sample - loss: 1.6024 - mae: 0.9834 - mse: 1.6024 - val_loss: 5.3108 - val_mae: 1.3994 - val_mse: 5.3108\n",
      "Epoch 49/500\n",
      "14582/14582 [==============================] - 1s 40us/sample - loss: 1.5780 - mae: 0.9728 - mse: 1.5780 - val_loss: 7.0305 - val_mae: 1.8279 - val_mse: 7.0305\n",
      "Epoch 50/500\n",
      "14582/14582 [==============================] - 1s 41us/sample - loss: 1.5545 - mae: 0.9678 - mse: 1.5545 - val_loss: 5.3318 - val_mae: 1.4242 - val_mse: 5.3318\n",
      "Epoch 51/500\n",
      "14582/14582 [==============================] - 1s 43us/sample - loss: 1.5362 - mae: 0.9601 - mse: 1.5362 - val_loss: 5.9408 - val_mae: 1.5817 - val_mse: 5.9408\n",
      "Epoch 52/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.5043 - mae: 0.9518 - mse: 1.5043 - val_loss: 5.3024 - val_mae: 1.3873 - val_mse: 5.3024\n",
      "Epoch 53/500\n",
      "14582/14582 [==============================] - 1s 40us/sample - loss: 1.5198 - mae: 0.9581 - mse: 1.5198 - val_loss: 5.4612 - val_mae: 1.4204 - val_mse: 5.4612\n",
      "Epoch 54/500\n",
      "14582/14582 [==============================] - 1s 41us/sample - loss: 1.4878 - mae: 0.9462 - mse: 1.4878 - val_loss: 5.4912 - val_mae: 1.4452 - val_mse: 5.4912\n",
      "Epoch 55/500\n",
      "14582/14582 [==============================] - 1s 40us/sample - loss: 1.4697 - mae: 0.9384 - mse: 1.4697 - val_loss: 5.6358 - val_mae: 1.4516 - val_mse: 5.6358\n",
      "Epoch 56/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.4581 - mae: 0.9348 - mse: 1.4581 - val_loss: 6.2395 - val_mae: 1.6298 - val_mse: 6.2395\n",
      "Epoch 57/500\n",
      "14582/14582 [==============================] - 1s 45us/sample - loss: 1.4390 - mae: 0.9288 - mse: 1.4390 - val_loss: 5.7940 - val_mae: 1.4756 - val_mse: 5.7940\n",
      "Epoch 58/500\n",
      "14582/14582 [==============================] - 1s 43us/sample - loss: 1.4334 - mae: 0.9274 - mse: 1.4334 - val_loss: 5.8154 - val_mae: 1.4537 - val_mse: 5.8154\n",
      "Epoch 59/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.4196 - mae: 0.9218 - mse: 1.4196 - val_loss: 5.6764 - val_mae: 1.4166 - val_mse: 5.6764\n",
      "Epoch 60/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.3922 - mae: 0.9111 - mse: 1.3922 - val_loss: 6.0946 - val_mae: 1.5200 - val_mse: 6.0946\n",
      "Epoch 61/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.3836 - mae: 0.9098 - mse: 1.3836 - val_loss: 5.6317 - val_mae: 1.4244 - val_mse: 5.6317\n",
      "Epoch 62/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.3611 - mae: 0.9027 - mse: 1.3611 - val_loss: 5.5147 - val_mae: 1.3735 - val_mse: 5.5147\n",
      "Epoch 63/500\n",
      "14582/14582 [==============================] - 1s 41us/sample - loss: 1.3643 - mae: 0.9031 - mse: 1.3643 - val_loss: 6.0262 - val_mae: 1.5026 - val_mse: 6.0262\n",
      "Epoch 64/500\n",
      "14582/14582 [==============================] - 1s 42us/sample - loss: 1.3324 - mae: 0.8943 - mse: 1.3324 - val_loss: 5.8323 - val_mae: 1.4938 - val_mse: 5.8323\n",
      "Epoch 65/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.3348 - mae: 0.8923 - mse: 1.3348 - val_loss: 5.8602 - val_mae: 1.4114 - val_mse: 5.8602\n",
      "Epoch 66/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.3214 - mae: 0.8868 - mse: 1.3214 - val_loss: 6.3781 - val_mae: 1.5805 - val_mse: 6.3781\n",
      "Epoch 67/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.3101 - mae: 0.8853 - mse: 1.3101 - val_loss: 6.0035 - val_mae: 1.4347 - val_mse: 6.0035\n",
      "Epoch 68/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.2995 - mae: 0.8781 - mse: 1.2995 - val_loss: 6.2894 - val_mae: 1.5026 - val_mse: 6.2894\n",
      "Epoch 69/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.2837 - mae: 0.8756 - mse: 1.2837 - val_loss: 5.7085 - val_mae: 1.3879 - val_mse: 5.7085\n",
      "Epoch 70/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.2703 - mae: 0.8674 - mse: 1.2703 - val_loss: 5.7876 - val_mae: 1.4162 - val_mse: 5.7876\n",
      "Epoch 71/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.2591 - mae: 0.8636 - mse: 1.2591 - val_loss: 6.0588 - val_mae: 1.4310 - val_mse: 6.0588\n",
      "Epoch 72/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.2734 - mae: 0.8710 - mse: 1.2734 - val_loss: 6.3736 - val_mae: 1.4897 - val_mse: 6.3736\n",
      "Epoch 73/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.2387 - mae: 0.8559 - mse: 1.2387 - val_loss: 6.4751 - val_mae: 1.5109 - val_mse: 6.4751\n",
      "Epoch 74/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.2340 - mae: 0.8523 - mse: 1.2340 - val_loss: 6.8270 - val_mae: 1.5936 - val_mse: 6.8270\n",
      "Epoch 75/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.2206 - mae: 0.8519 - mse: 1.2206 - val_loss: 5.9350 - val_mae: 1.3881 - val_mse: 5.9350\n",
      "Epoch 76/500\n",
      "14582/14582 [==============================] - 1s 40us/sample - loss: 1.2007 - mae: 0.8419 - mse: 1.2007 - val_loss: 6.4398 - val_mae: 1.4655 - val_mse: 6.4398\n",
      "Epoch 77/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.1924 - mae: 0.8400 - mse: 1.1924 - val_loss: 6.2866 - val_mae: 1.4806 - val_mse: 6.2866\n",
      "Epoch 78/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.1941 - mae: 0.8387 - mse: 1.1941 - val_loss: 6.5669 - val_mae: 1.5001 - val_mse: 6.5669\n",
      "Epoch 79/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.1883 - mae: 0.8376 - mse: 1.1883 - val_loss: 6.2172 - val_mae: 1.4133 - val_mse: 6.2172\n",
      "Epoch 80/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.1761 - mae: 0.8340 - mse: 1.1761 - val_loss: 6.5938 - val_mae: 1.4747 - val_mse: 6.5938\n",
      "Epoch 81/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.1623 - mae: 0.8269 - mse: 1.1623 - val_loss: 6.6503 - val_mae: 1.5364 - val_mse: 6.6503\n",
      "Epoch 82/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.1469 - mae: 0.8252 - mse: 1.1469 - val_loss: 6.4510 - val_mae: 1.4520 - val_mse: 6.4510\n",
      "Epoch 83/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.1578 - mae: 0.8287 - mse: 1.1578 - val_loss: 6.3619 - val_mae: 1.4056 - val_mse: 6.3619\n",
      "Epoch 84/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.1280 - mae: 0.8177 - mse: 1.1280 - val_loss: 7.4034 - val_mae: 1.6782 - val_mse: 7.4034\n",
      "Epoch 85/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.1409 - mae: 0.8193 - mse: 1.1409 - val_loss: 6.5425 - val_mae: 1.4467 - val_mse: 6.5425\n",
      "Epoch 86/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.1273 - mae: 0.8149 - mse: 1.1273 - val_loss: 6.4603 - val_mae: 1.4186 - val_mse: 6.4603\n",
      "Epoch 87/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.1137 - mae: 0.8103 - mse: 1.1137 - val_loss: 6.5522 - val_mae: 1.4358 - val_mse: 6.5522\n",
      "Epoch 88/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.1077 - mae: 0.8093 - mse: 1.1077 - val_loss: 7.3510 - val_mae: 1.6056 - val_mse: 7.3510\n",
      "Epoch 89/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.0976 - mae: 0.8042 - mse: 1.0976 - val_loss: 7.1847 - val_mae: 1.5574 - val_mse: 7.1847\n",
      "Epoch 90/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.1053 - mae: 0.8081 - mse: 1.1053 - val_loss: 6.6374 - val_mae: 1.4385 - val_mse: 6.6374\n",
      "Epoch 91/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.0861 - mae: 0.7984 - mse: 1.0861 - val_loss: 6.6952 - val_mae: 1.4137 - val_mse: 6.6952\n",
      "Epoch 92/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.0888 - mae: 0.7999 - mse: 1.0888 - val_loss: 7.0445 - val_mae: 1.5282 - val_mse: 7.0445\n",
      "Epoch 93/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.0679 - mae: 0.7919 - mse: 1.0679 - val_loss: 7.4122 - val_mae: 1.6465 - val_mse: 7.4122\n",
      "Epoch 94/500\n",
      "14582/14582 [==============================] - 1s 47us/sample - loss: 1.0762 - mae: 0.7963 - mse: 1.0762 - val_loss: 6.9087 - val_mae: 1.4746 - val_mse: 6.9087\n",
      "Epoch 95/500\n",
      "14582/14582 [==============================] - 1s 44us/sample - loss: 1.0596 - mae: 0.7883 - mse: 1.0596 - val_loss: 6.5890 - val_mae: 1.4226 - val_mse: 6.5890\n",
      "Epoch 96/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 1.0487 - mae: 0.7863 - mse: 1.0487 - val_loss: 7.4746 - val_mae: 1.5957 - val_mse: 7.4746\n",
      "Epoch 97/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 1.0506 - mae: 0.7872 - mse: 1.0506 - val_loss: 7.1103 - val_mae: 1.5215 - val_mse: 7.1103\n",
      "Epoch 98/500\n",
      "14582/14582 [==============================] - 1s 36us/sample - loss: 1.0382 - mae: 0.7797 - mse: 1.0382 - val_loss: 8.1789 - val_mae: 1.8007 - val_mse: 8.1789\n",
      "Epoch 99/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 1.0385 - mae: 0.7820 - mse: 1.0385 - val_loss: 7.3862 - val_mae: 1.5710 - val_mse: 7.3862\n",
      "Epoch 100/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 1.0251 - mae: 0.7774 - mse: 1.0251 - val_loss: 6.8453 - val_mae: 1.5092 - val_mse: 6.8453\n",
      "Epoch 101/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 1.0172 - mae: 0.7728 - mse: 1.0172 - val_loss: 6.5842 - val_mae: 1.3900 - val_mse: 6.5842\n",
      "Epoch 102/500\n",
      "14582/14582 [==============================] - 1s 36us/sample - loss: 1.0199 - mae: 0.7740 - mse: 1.0199 - val_loss: 6.9312 - val_mae: 1.4973 - val_mse: 6.9312\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model_validation(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4861/1 - 0s - loss: 6.8050 - mae: 1.9852 - mse: 11.5242\n",
      "Test loss: 11.524167635047958\n",
      "Mean absolute error: 1.9851788\n",
      "Mean squared error: 11.524168\n"
     ]
    }
   ],
   "source": [
    "model.model_testing(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1458 samples, validate on 486 samples\n",
      "Epoch 1/500\n",
      "1458/1458 [==============================] - 0s 335us/sample - loss: 372.6310 - mae: 14.2659 - mse: 372.6310 - val_loss: 625.3759 - val_mae: 17.8116 - val_mse: 625.3758\n",
      "Epoch 2/500\n",
      "1458/1458 [==============================] - 0s 46us/sample - loss: 128.6368 - mae: 8.4705 - mse: 128.6368 - val_loss: 439.2829 - val_mae: 14.6502 - val_mse: 439.2829\n",
      "Epoch 3/500\n",
      "1458/1458 [==============================] - 0s 45us/sample - loss: 72.6002 - mae: 6.4073 - mse: 72.6002 - val_loss: 295.4197 - val_mae: 12.1403 - val_mse: 295.4196\n",
      "Epoch 4/500\n",
      "1458/1458 [==============================] - 0s 46us/sample - loss: 51.8497 - mae: 5.4320 - mse: 51.8497 - val_loss: 238.7605 - val_mae: 10.9035 - val_mse: 238.7605\n",
      "Epoch 5/500\n",
      "1458/1458 [==============================] - 0s 46us/sample - loss: 41.5227 - mae: 4.8730 - mse: 41.5227 - val_loss: 214.1014 - val_mae: 10.4806 - val_mse: 214.1013\n",
      "Epoch 6/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 34.1980 - mae: 4.4223 - mse: 34.1980 - val_loss: 190.4977 - val_mae: 9.9030 - val_mse: 190.4977\n",
      "Epoch 7/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 29.7702 - mae: 4.1608 - mse: 29.7702 - val_loss: 178.5569 - val_mae: 9.5764 - val_mse: 178.5569\n",
      "Epoch 8/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 27.8884 - mae: 4.0320 - mse: 27.8884 - val_loss: 136.5466 - val_mae: 8.3653 - val_mse: 136.5466\n",
      "Epoch 9/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 24.1049 - mae: 3.7748 - mse: 24.1049 - val_loss: 124.2885 - val_mae: 7.9622 - val_mse: 124.2885\n",
      "Epoch 10/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 23.0798 - mae: 3.7186 - mse: 23.0798 - val_loss: 118.1245 - val_mae: 7.8763 - val_mse: 118.1245\n",
      "Epoch 11/500\n",
      "1458/1458 [==============================] - 0s 46us/sample - loss: 20.0732 - mae: 3.4669 - mse: 20.0732 - val_loss: 108.0338 - val_mae: 7.4775 - val_mse: 108.0338\n",
      "Epoch 12/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 19.4423 - mae: 3.4044 - mse: 19.4423 - val_loss: 106.2333 - val_mae: 7.6339 - val_mse: 106.2333\n",
      "Epoch 13/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 18.8117 - mae: 3.3636 - mse: 18.8117 - val_loss: 109.9580 - val_mae: 7.6060 - val_mse: 109.9580\n",
      "Epoch 14/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 19.3208 - mae: 3.4703 - mse: 19.3208 - val_loss: 101.2865 - val_mae: 7.1939 - val_mse: 101.2866\n",
      "Epoch 15/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 17.0915 - mae: 3.2160 - mse: 17.0915 - val_loss: 93.5889 - val_mae: 7.1164 - val_mse: 93.5889\n",
      "Epoch 16/500\n",
      "1458/1458 [==============================] - 0s 46us/sample - loss: 16.8612 - mae: 3.2412 - mse: 16.8612 - val_loss: 95.3159 - val_mae: 7.0185 - val_mse: 95.3159\n",
      "Epoch 17/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 16.5759 - mae: 3.2298 - mse: 16.5759 - val_loss: 101.7101 - val_mae: 7.2894 - val_mse: 101.7101\n",
      "Epoch 18/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 16.0543 - mae: 3.1660 - mse: 16.0543 - val_loss: 90.2405 - val_mae: 6.8659 - val_mse: 90.2405\n",
      "Epoch 19/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 15.5345 - mae: 3.1265 - mse: 15.5345 - val_loss: 88.2872 - val_mae: 6.8010 - val_mse: 88.2872\n",
      "Epoch 20/500\n",
      "1458/1458 [==============================] - 0s 49us/sample - loss: 15.6052 - mae: 3.1215 - mse: 15.6052 - val_loss: 89.4729 - val_mae: 6.8836 - val_mse: 89.4729\n",
      "Epoch 21/500\n",
      "1458/1458 [==============================] - 0s 48us/sample - loss: 14.8181 - mae: 3.0049 - mse: 14.8181 - val_loss: 107.7366 - val_mae: 7.7580 - val_mse: 107.7366\n",
      "Epoch 22/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 14.4579 - mae: 2.9877 - mse: 14.4579 - val_loss: 95.7984 - val_mae: 7.2211 - val_mse: 95.7984\n",
      "Epoch 23/500\n",
      "1458/1458 [==============================] - 0s 46us/sample - loss: 14.0746 - mae: 2.9703 - mse: 14.0746 - val_loss: 85.6670 - val_mae: 6.7027 - val_mse: 85.6670\n",
      "Epoch 24/500\n",
      "1458/1458 [==============================] - 0s 46us/sample - loss: 13.7418 - mae: 2.9276 - mse: 13.7418 - val_loss: 102.4914 - val_mae: 7.6526 - val_mse: 102.4914\n",
      "Epoch 25/500\n",
      "1458/1458 [==============================] - 0s 48us/sample - loss: 14.6589 - mae: 3.0721 - mse: 14.6589 - val_loss: 89.1957 - val_mae: 7.1058 - val_mse: 89.1957\n",
      "Epoch 26/500\n",
      "1458/1458 [==============================] - 0s 46us/sample - loss: 13.3170 - mae: 2.8672 - mse: 13.3170 - val_loss: 91.9373 - val_mae: 7.5169 - val_mse: 91.9373\n",
      "Epoch 27/500\n",
      "1458/1458 [==============================] - 0s 45us/sample - loss: 13.5546 - mae: 2.9130 - mse: 13.5546 - val_loss: 85.1762 - val_mae: 6.9384 - val_mse: 85.1762\n",
      "Epoch 28/500\n",
      "1458/1458 [==============================] - 0s 46us/sample - loss: 12.8317 - mae: 2.8297 - mse: 12.8317 - val_loss: 91.4049 - val_mae: 7.1644 - val_mse: 91.4049\n",
      "Epoch 29/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 12.1794 - mae: 2.7638 - mse: 12.1794 - val_loss: 89.7698 - val_mae: 7.3229 - val_mse: 89.7698\n",
      "Epoch 30/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 13.2439 - mae: 2.8598 - mse: 13.2439 - val_loss: 88.3579 - val_mae: 6.8500 - val_mse: 88.3579\n",
      "Epoch 31/500\n",
      "1458/1458 [==============================] - 0s 46us/sample - loss: 12.5304 - mae: 2.7858 - mse: 12.5304 - val_loss: 84.4385 - val_mae: 6.6679 - val_mse: 84.4385\n",
      "Epoch 32/500\n",
      "1458/1458 [==============================] - 0s 51us/sample - loss: 12.5607 - mae: 2.8037 - mse: 12.5607 - val_loss: 86.1504 - val_mae: 6.8415 - val_mse: 86.1504\n",
      "Epoch 33/500\n",
      "1458/1458 [==============================] - 0s 48us/sample - loss: 11.9101 - mae: 2.6860 - mse: 11.9101 - val_loss: 91.5518 - val_mae: 7.0026 - val_mse: 91.5518\n",
      "Epoch 34/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 12.1784 - mae: 2.8272 - mse: 12.1784 - val_loss: 102.7708 - val_mae: 7.8993 - val_mse: 102.7708\n",
      "Epoch 35/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 12.1360 - mae: 2.7944 - mse: 12.1360 - val_loss: 95.4146 - val_mae: 7.2678 - val_mse: 95.4146\n",
      "Epoch 36/500\n",
      "1458/1458 [==============================] - 0s 48us/sample - loss: 12.3236 - mae: 2.8046 - mse: 12.3236 - val_loss: 112.6921 - val_mae: 8.3027 - val_mse: 112.6921\n",
      "Epoch 37/500\n",
      "1458/1458 [==============================] - 0s 48us/sample - loss: 11.9389 - mae: 2.7537 - mse: 11.9389 - val_loss: 97.6167 - val_mae: 7.4138 - val_mse: 97.6167\n",
      "Epoch 38/500\n",
      "1458/1458 [==============================] - 0s 48us/sample - loss: 11.8366 - mae: 2.7437 - mse: 11.8366 - val_loss: 83.2649 - val_mae: 6.6983 - val_mse: 83.2649\n",
      "Epoch 39/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 11.4848 - mae: 2.7287 - mse: 11.4848 - val_loss: 85.1769 - val_mae: 6.7561 - val_mse: 85.1769\n",
      "Epoch 40/500\n",
      "1458/1458 [==============================] - 0s 48us/sample - loss: 11.4806 - mae: 2.6630 - mse: 11.4806 - val_loss: 95.1753 - val_mae: 7.2165 - val_mse: 95.1753\n",
      "Epoch 41/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 11.1580 - mae: 2.6632 - mse: 11.1580 - val_loss: 95.6659 - val_mae: 7.2846 - val_mse: 95.6659\n",
      "Epoch 42/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 10.9765 - mae: 2.6410 - mse: 10.9765 - val_loss: 89.2207 - val_mae: 6.9027 - val_mse: 89.2207\n",
      "Epoch 43/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 11.9372 - mae: 2.7037 - mse: 11.9372 - val_loss: 87.6916 - val_mae: 6.9905 - val_mse: 87.6916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "1458/1458 [==============================] - 0s 49us/sample - loss: 10.7416 - mae: 2.6110 - mse: 10.7416 - val_loss: 113.8312 - val_mae: 8.0512 - val_mse: 113.8312\n",
      "Epoch 45/500\n",
      "1458/1458 [==============================] - 0s 46us/sample - loss: 11.1417 - mae: 2.6022 - mse: 11.1417 - val_loss: 88.3217 - val_mae: 6.8662 - val_mse: 88.3217\n",
      "Epoch 46/500\n",
      "1458/1458 [==============================] - 0s 48us/sample - loss: 10.5698 - mae: 2.5792 - mse: 10.5698 - val_loss: 93.8920 - val_mae: 7.1886 - val_mse: 93.8920\n",
      "Epoch 47/500\n",
      "1458/1458 [==============================] - 0s 45us/sample - loss: 11.2508 - mae: 2.6342 - mse: 11.2508 - val_loss: 92.8694 - val_mae: 7.1523 - val_mse: 92.8694\n",
      "Epoch 48/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 10.7008 - mae: 2.6277 - mse: 10.7008 - val_loss: 85.1710 - val_mae: 6.6879 - val_mse: 85.1710\n",
      "Epoch 49/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 10.9026 - mae: 2.5954 - mse: 10.9026 - val_loss: 98.8194 - val_mae: 7.3086 - val_mse: 98.8194\n",
      "Epoch 50/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 9.4672 - mae: 2.4311 - mse: 9.4672 - val_loss: 87.2949 - val_mae: 7.1564 - val_mse: 87.2949\n",
      "Epoch 51/500\n",
      "1458/1458 [==============================] - 0s 43us/sample - loss: 10.0008 - mae: 2.4947 - mse: 10.0008 - val_loss: 97.4436 - val_mae: 7.5549 - val_mse: 97.4436\n",
      "Epoch 52/500\n",
      "1458/1458 [==============================] - 0s 46us/sample - loss: 10.3573 - mae: 2.5694 - mse: 10.3573 - val_loss: 106.5973 - val_mae: 7.7682 - val_mse: 106.5973\n",
      "Epoch 53/500\n",
      "1458/1458 [==============================] - 0s 43us/sample - loss: 10.2884 - mae: 2.5578 - mse: 10.2884 - val_loss: 135.0074 - val_mae: 9.3563 - val_mse: 135.0074\n",
      "Epoch 54/500\n",
      "1458/1458 [==============================] - 0s 45us/sample - loss: 10.2828 - mae: 2.4864 - mse: 10.2828 - val_loss: 87.5603 - val_mae: 6.8548 - val_mse: 87.5603\n",
      "Epoch 55/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 9.9107 - mae: 2.5133 - mse: 9.9107 - val_loss: 110.3947 - val_mae: 7.8661 - val_mse: 110.3947\n",
      "Epoch 56/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 9.6466 - mae: 2.4806 - mse: 9.6466 - val_loss: 88.5809 - val_mae: 6.8648 - val_mse: 88.5809\n",
      "Epoch 57/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 10.0430 - mae: 2.5467 - mse: 10.0430 - val_loss: 100.5981 - val_mae: 7.4154 - val_mse: 100.5981\n",
      "Epoch 58/500\n",
      "1458/1458 [==============================] - 0s 43us/sample - loss: 8.8405 - mae: 2.3787 - mse: 8.8405 - val_loss: 85.6569 - val_mae: 6.8245 - val_mse: 85.6569\n",
      "Epoch 59/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 10.3047 - mae: 2.5101 - mse: 10.3047 - val_loss: 87.7741 - val_mae: 6.7687 - val_mse: 87.7741\n",
      "Epoch 60/500\n",
      "1458/1458 [==============================] - 0s 45us/sample - loss: 8.9849 - mae: 2.3798 - mse: 8.9849 - val_loss: 100.1559 - val_mae: 7.4074 - val_mse: 100.1559\n",
      "Epoch 61/500\n",
      "1458/1458 [==============================] - 0s 45us/sample - loss: 9.2121 - mae: 2.4165 - mse: 9.2121 - val_loss: 85.4953 - val_mae: 6.6896 - val_mse: 85.4953\n",
      "Epoch 62/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 9.7855 - mae: 2.5176 - mse: 9.7855 - val_loss: 106.9463 - val_mae: 7.8505 - val_mse: 106.9463\n",
      "Epoch 63/500\n",
      "1458/1458 [==============================] - 0s 43us/sample - loss: 9.5823 - mae: 2.4561 - mse: 9.5823 - val_loss: 108.3084 - val_mae: 7.8221 - val_mse: 108.3084\n",
      "Epoch 64/500\n",
      "1458/1458 [==============================] - 0s 45us/sample - loss: 9.2810 - mae: 2.4054 - mse: 9.2810 - val_loss: 97.7078 - val_mae: 7.2372 - val_mse: 97.7078\n",
      "Epoch 65/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 9.0963 - mae: 2.3042 - mse: 9.0963 - val_loss: 121.0894 - val_mae: 8.4843 - val_mse: 121.0894\n",
      "Epoch 66/500\n",
      "1458/1458 [==============================] - 0s 45us/sample - loss: 9.8045 - mae: 2.4561 - mse: 9.8045 - val_loss: 91.4041 - val_mae: 7.0533 - val_mse: 91.4040\n",
      "Epoch 67/500\n",
      "1458/1458 [==============================] - 0s 43us/sample - loss: 9.4739 - mae: 2.4484 - mse: 9.4739 - val_loss: 85.7393 - val_mae: 6.8302 - val_mse: 85.7393\n",
      "Epoch 68/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 9.4769 - mae: 2.4775 - mse: 9.4769 - val_loss: 88.8997 - val_mae: 6.8670 - val_mse: 88.8998\n",
      "Epoch 69/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 8.7993 - mae: 2.3612 - mse: 8.7993 - val_loss: 85.8603 - val_mae: 6.6702 - val_mse: 85.8603\n",
      "Epoch 70/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 9.8366 - mae: 2.4798 - mse: 9.8366 - val_loss: 95.7455 - val_mae: 7.1615 - val_mse: 95.7455\n",
      "Epoch 71/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 8.5324 - mae: 2.3176 - mse: 8.5324 - val_loss: 89.8133 - val_mae: 6.8513 - val_mse: 89.8133\n",
      "Epoch 72/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 9.1272 - mae: 2.4476 - mse: 9.1272 - val_loss: 100.0782 - val_mae: 7.3950 - val_mse: 100.0782\n",
      "Epoch 73/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 8.3489 - mae: 2.2493 - mse: 8.3489 - val_loss: 104.4340 - val_mae: 7.7339 - val_mse: 104.4340\n",
      "Epoch 74/500\n",
      "1458/1458 [==============================] - 0s 45us/sample - loss: 8.8502 - mae: 2.3905 - mse: 8.8502 - val_loss: 99.3920 - val_mae: 7.2882 - val_mse: 99.3920\n",
      "Epoch 75/500\n",
      "1458/1458 [==============================] - 0s 45us/sample - loss: 8.7063 - mae: 2.3230 - mse: 8.7063 - val_loss: 100.0674 - val_mae: 7.5959 - val_mse: 100.0674\n",
      "Epoch 76/500\n",
      "1458/1458 [==============================] - 0s 43us/sample - loss: 8.7469 - mae: 2.2615 - mse: 8.7469 - val_loss: 90.3770 - val_mae: 6.9075 - val_mse: 90.3770\n",
      "Epoch 77/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 8.8451 - mae: 2.3233 - mse: 8.8451 - val_loss: 90.8642 - val_mae: 6.9362 - val_mse: 90.8642\n",
      "Epoch 78/500\n",
      "1458/1458 [==============================] - 0s 45us/sample - loss: 8.6868 - mae: 2.2700 - mse: 8.6868 - val_loss: 104.5900 - val_mae: 7.7630 - val_mse: 104.5900\n",
      "Epoch 79/500\n",
      "1458/1458 [==============================] - 0s 45us/sample - loss: 8.6779 - mae: 2.3321 - mse: 8.6779 - val_loss: 110.7354 - val_mae: 8.0371 - val_mse: 110.7354\n",
      "Epoch 80/500\n",
      "1458/1458 [==============================] - 0s 45us/sample - loss: 8.4130 - mae: 2.2806 - mse: 8.4130 - val_loss: 88.7190 - val_mae: 6.8088 - val_mse: 88.7190\n",
      "Epoch 81/500\n",
      "1458/1458 [==============================] - 0s 47us/sample - loss: 9.5587 - mae: 2.4726 - mse: 9.5587 - val_loss: 85.6825 - val_mae: 6.7540 - val_mse: 85.6825\n",
      "Epoch 82/500\n",
      "1458/1458 [==============================] - ETA: 0s - loss: 10.4760 - mae: 2.7962 - mse: 10.476 - 0s 44us/sample - loss: 8.1521 - mae: 2.2604 - mse: 8.1521 - val_loss: 99.4195 - val_mae: 7.3702 - val_mse: 99.4195\n",
      "Epoch 83/500\n",
      "1458/1458 [==============================] - 0s 43us/sample - loss: 8.1721 - mae: 2.2544 - mse: 8.1721 - val_loss: 99.5227 - val_mae: 7.3640 - val_mse: 99.5227\n",
      "Epoch 84/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 8.9197 - mae: 2.3362 - mse: 8.9197 - val_loss: 87.3978 - val_mae: 6.8361 - val_mse: 87.3978\n",
      "Epoch 85/500\n",
      "1458/1458 [==============================] - 0s 45us/sample - loss: 8.7353 - mae: 2.3439 - mse: 8.7353 - val_loss: 96.8141 - val_mae: 7.2493 - val_mse: 96.8141\n",
      "Epoch 86/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 7.8799 - mae: 2.2080 - mse: 7.8799 - val_loss: 84.7423 - val_mae: 6.9373 - val_mse: 84.7423\n",
      "Epoch 87/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 8.4235 - mae: 2.2480 - mse: 8.4235 - val_loss: 92.1483 - val_mae: 7.1032 - val_mse: 92.1483\n",
      "Epoch 88/500\n",
      "1458/1458 [==============================] - 0s 44us/sample - loss: 8.1827 - mae: 2.2979 - mse: 8.1827 - val_loss: 84.8223 - val_mae: 6.7350 - val_mse: 84.8223\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2916 samples, validate on 972 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2916/2916 [==============================] - 0s 162us/sample - loss: 243.7667 - mae: 8.5056 - mse: 243.7668 - val_loss: 184.5748 - val_mae: 9.5855 - val_mse: 184.5748\n",
      "Epoch 2/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 27.5706 - mae: 3.3649 - mse: 27.5706 - val_loss: 125.0208 - val_mae: 7.9866 - val_mse: 125.0208\n",
      "Epoch 3/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 18.0206 - mae: 2.8399 - mse: 18.0206 - val_loss: 97.7238 - val_mae: 6.9163 - val_mse: 97.7238\n",
      "Epoch 4/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 14.1173 - mae: 2.5695 - mse: 14.1173 - val_loss: 85.9698 - val_mae: 6.5345 - val_mse: 85.9698\n",
      "Epoch 5/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 11.9427 - mae: 2.3829 - mse: 11.9427 - val_loss: 73.7770 - val_mae: 5.9569 - val_mse: 73.7770\n",
      "Epoch 6/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 10.4945 - mae: 2.2690 - mse: 10.4945 - val_loss: 68.7607 - val_mae: 5.6412 - val_mse: 68.7607\n",
      "Epoch 7/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 9.4126 - mae: 2.1644 - mse: 9.4126 - val_loss: 71.6306 - val_mae: 6.0074 - val_mse: 71.6306\n",
      "Epoch 8/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 8.5550 - mae: 2.0514 - mse: 8.5550 - val_loss: 62.1735 - val_mae: 5.5109 - val_mse: 62.1735\n",
      "Epoch 9/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 8.0927 - mae: 2.0238 - mse: 8.0927 - val_loss: 58.7584 - val_mae: 5.3079 - val_mse: 58.7584\n",
      "Epoch 10/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 7.6487 - mae: 1.9839 - mse: 7.6487 - val_loss: 52.9998 - val_mae: 5.1600 - val_mse: 52.9998\n",
      "Epoch 11/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 7.0632 - mae: 1.8825 - mse: 7.0632 - val_loss: 49.5162 - val_mae: 5.1058 - val_mse: 49.5162\n",
      "Epoch 12/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 6.8810 - mae: 1.8906 - mse: 6.8810 - val_loss: 54.1007 - val_mae: 5.1960 - val_mse: 54.1007\n",
      "Epoch 13/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 6.4986 - mae: 1.8468 - mse: 6.4986 - val_loss: 47.9409 - val_mae: 5.0086 - val_mse: 47.9409\n",
      "Epoch 14/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 6.0110 - mae: 1.7720 - mse: 6.0110 - val_loss: 52.1242 - val_mae: 5.1628 - val_mse: 52.1242\n",
      "Epoch 15/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 5.8844 - mae: 1.7630 - mse: 5.8844 - val_loss: 47.0086 - val_mae: 4.8637 - val_mse: 47.0086\n",
      "Epoch 16/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 5.5861 - mae: 1.7349 - mse: 5.5861 - val_loss: 44.1769 - val_mae: 4.5585 - val_mse: 44.1769\n",
      "Epoch 17/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 5.2464 - mae: 1.6622 - mse: 5.2464 - val_loss: 43.8080 - val_mae: 4.5790 - val_mse: 43.8080\n",
      "Epoch 18/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 5.0752 - mae: 1.6555 - mse: 5.0752 - val_loss: 45.6970 - val_mae: 4.8667 - val_mse: 45.6970\n",
      "Epoch 19/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 5.0135 - mae: 1.6551 - mse: 5.0135 - val_loss: 41.6002 - val_mae: 4.4976 - val_mse: 41.6002\n",
      "Epoch 20/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 4.7931 - mae: 1.6123 - mse: 4.7931 - val_loss: 39.3077 - val_mae: 4.4332 - val_mse: 39.3077\n",
      "Epoch 21/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 4.6528 - mae: 1.6020 - mse: 4.6528 - val_loss: 39.3483 - val_mae: 4.3558 - val_mse: 39.3483\n",
      "Epoch 22/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 4.5501 - mae: 1.5895 - mse: 4.5501 - val_loss: 37.3137 - val_mae: 4.4344 - val_mse: 37.3137\n",
      "Epoch 23/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 4.4463 - mae: 1.5787 - mse: 4.4463 - val_loss: 41.2386 - val_mae: 4.6904 - val_mse: 41.2386\n",
      "Epoch 24/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 4.3426 - mae: 1.5516 - mse: 4.3426 - val_loss: 36.7212 - val_mae: 4.4147 - val_mse: 36.7212\n",
      "Epoch 25/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 4.2338 - mae: 1.5364 - mse: 4.2338 - val_loss: 37.4115 - val_mae: 4.3584 - val_mse: 37.4114\n",
      "Epoch 26/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 4.1254 - mae: 1.5370 - mse: 4.1254 - val_loss: 37.2539 - val_mae: 4.2848 - val_mse: 37.2539\n",
      "Epoch 27/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 4.0607 - mae: 1.5203 - mse: 4.0607 - val_loss: 36.6575 - val_mae: 4.2766 - val_mse: 36.6575\n",
      "Epoch 28/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 3.8956 - mae: 1.4833 - mse: 3.8956 - val_loss: 37.3384 - val_mae: 4.3155 - val_mse: 37.3384\n",
      "Epoch 29/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 3.8754 - mae: 1.4905 - mse: 3.8754 - val_loss: 35.1242 - val_mae: 4.3016 - val_mse: 35.1242\n",
      "Epoch 30/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 3.7478 - mae: 1.4538 - mse: 3.7478 - val_loss: 40.1365 - val_mae: 4.6620 - val_mse: 40.1365\n",
      "Epoch 31/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 3.8473 - mae: 1.4926 - mse: 3.8473 - val_loss: 37.9992 - val_mae: 4.3012 - val_mse: 37.9992\n",
      "Epoch 32/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 3.7461 - mae: 1.4633 - mse: 3.7461 - val_loss: 40.7175 - val_mae: 4.5904 - val_mse: 40.7175\n",
      "Epoch 33/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 3.6033 - mae: 1.4537 - mse: 3.6033 - val_loss: 34.9354 - val_mae: 4.1312 - val_mse: 34.9354\n",
      "Epoch 34/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 3.5362 - mae: 1.4141 - mse: 3.5362 - val_loss: 36.6507 - val_mae: 4.2051 - val_mse: 36.6507\n",
      "Epoch 35/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 3.4405 - mae: 1.3981 - mse: 3.4405 - val_loss: 35.1268 - val_mae: 4.1893 - val_mse: 35.1268\n",
      "Epoch 36/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 3.4800 - mae: 1.4271 - mse: 3.4800 - val_loss: 34.5417 - val_mae: 4.1198 - val_mse: 34.5417\n",
      "Epoch 37/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 3.3747 - mae: 1.4045 - mse: 3.3747 - val_loss: 39.6064 - val_mae: 4.6176 - val_mse: 39.6064\n",
      "Epoch 38/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 3.3504 - mae: 1.3945 - mse: 3.3504 - val_loss: 35.8005 - val_mae: 4.3377 - val_mse: 35.8005\n",
      "Epoch 39/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 3.2985 - mae: 1.3990 - mse: 3.2985 - val_loss: 36.5815 - val_mae: 4.4660 - val_mse: 36.5815\n",
      "Epoch 40/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 3.1805 - mae: 1.3637 - mse: 3.1805 - val_loss: 40.9046 - val_mae: 4.5783 - val_mse: 40.9046\n",
      "Epoch 41/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 3.2247 - mae: 1.3834 - mse: 3.2247 - val_loss: 36.3687 - val_mae: 4.3522 - val_mse: 36.3687\n",
      "Epoch 42/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 3.0481 - mae: 1.3258 - mse: 3.0481 - val_loss: 33.7367 - val_mae: 4.2270 - val_mse: 33.7367\n",
      "Epoch 43/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 3.1211 - mae: 1.3597 - mse: 3.1211 - val_loss: 33.4176 - val_mae: 4.0225 - val_mse: 33.4176\n",
      "Epoch 44/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 3.0419 - mae: 1.3383 - mse: 3.0419 - val_loss: 33.4030 - val_mae: 4.1518 - val_mse: 33.4030\n",
      "Epoch 45/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 3.0467 - mae: 1.3310 - mse: 3.0467 - val_loss: 39.8147 - val_mae: 4.5563 - val_mse: 39.8147\n",
      "Epoch 46/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.9367 - mae: 1.3063 - mse: 2.9367 - val_loss: 35.1199 - val_mae: 4.1489 - val_mse: 35.1199\n",
      "Epoch 47/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.9302 - mae: 1.3188 - mse: 2.9302 - val_loss: 33.8546 - val_mae: 4.1809 - val_mse: 33.8546\n",
      "Epoch 48/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.9425 - mae: 1.3163 - mse: 2.9425 - val_loss: 35.0358 - val_mae: 4.1238 - val_mse: 35.0358\n",
      "Epoch 49/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.8321 - mae: 1.2969 - mse: 2.8321 - val_loss: 34.2185 - val_mae: 4.2203 - val_mse: 34.2185\n",
      "Epoch 50/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.7748 - mae: 1.2695 - mse: 2.7748 - val_loss: 34.2967 - val_mae: 4.1358 - val_mse: 34.2967\n",
      "Epoch 51/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.7750 - mae: 1.2718 - mse: 2.7750 - val_loss: 33.5754 - val_mae: 4.2974 - val_mse: 33.5754\n",
      "Epoch 52/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.7472 - mae: 1.2759 - mse: 2.7472 - val_loss: 35.9396 - val_mae: 4.2599 - val_mse: 35.9396\n",
      "Epoch 53/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.7636 - mae: 1.2764 - mse: 2.7636 - val_loss: 33.6406 - val_mae: 4.0951 - val_mse: 33.6406\n",
      "Epoch 54/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.6832 - mae: 1.2607 - mse: 2.6832 - val_loss: 37.8588 - val_mae: 4.3751 - val_mse: 37.8588\n",
      "Epoch 55/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.6085 - mae: 1.2418 - mse: 2.6085 - val_loss: 38.8295 - val_mae: 4.6195 - val_mse: 38.8295\n",
      "Epoch 56/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.6173 - mae: 1.2431 - mse: 2.6173 - val_loss: 36.6044 - val_mae: 4.2909 - val_mse: 36.6044\n",
      "Epoch 57/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.6143 - mae: 1.2428 - mse: 2.6143 - val_loss: 41.2808 - val_mae: 4.7321 - val_mse: 41.2808\n",
      "Epoch 58/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.6386 - mae: 1.2474 - mse: 2.6386 - val_loss: 35.2673 - val_mae: 4.1891 - val_mse: 35.2673\n",
      "Epoch 59/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.5797 - mae: 1.2344 - mse: 2.5797 - val_loss: 37.2349 - val_mae: 4.3055 - val_mse: 37.2349\n",
      "Epoch 60/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.5246 - mae: 1.2133 - mse: 2.5246 - val_loss: 37.3155 - val_mae: 4.5416 - val_mse: 37.3155\n",
      "Epoch 61/500\n",
      "2916/2916 [==============================] - 0s 39us/sample - loss: 2.5192 - mae: 1.2146 - mse: 2.5192 - val_loss: 34.5890 - val_mae: 4.2492 - val_mse: 34.5890\n",
      "Epoch 62/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.4888 - mae: 1.2072 - mse: 2.4888 - val_loss: 34.5768 - val_mae: 4.1435 - val_mse: 34.5768\n",
      "Epoch 63/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.5381 - mae: 1.2186 - mse: 2.5381 - val_loss: 33.9023 - val_mae: 4.1686 - val_mse: 33.9023\n",
      "Epoch 64/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.4072 - mae: 1.1976 - mse: 2.4072 - val_loss: 39.6979 - val_mae: 4.5630 - val_mse: 39.6979\n",
      "Epoch 65/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.3548 - mae: 1.1700 - mse: 2.3548 - val_loss: 35.3503 - val_mae: 4.2465 - val_mse: 35.3503\n",
      "Epoch 66/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.3618 - mae: 1.1787 - mse: 2.3618 - val_loss: 35.0399 - val_mae: 4.2261 - val_mse: 35.0400\n",
      "Epoch 67/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.4004 - mae: 1.1842 - mse: 2.4004 - val_loss: 35.6855 - val_mae: 4.2278 - val_mse: 35.6855\n",
      "Epoch 68/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.3325 - mae: 1.1708 - mse: 2.3325 - val_loss: 34.6671 - val_mae: 4.4113 - val_mse: 34.6671\n",
      "Epoch 69/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.3287 - mae: 1.1652 - mse: 2.3287 - val_loss: 36.5213 - val_mae: 4.3060 - val_mse: 36.5213\n",
      "Epoch 70/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.2703 - mae: 1.1588 - mse: 2.2703 - val_loss: 37.4852 - val_mae: 4.3682 - val_mse: 37.4852\n",
      "Epoch 71/500\n",
      "2916/2916 [==============================] - 0s 42us/sample - loss: 2.2458 - mae: 1.1507 - mse: 2.2458 - val_loss: 32.7748 - val_mae: 4.2771 - val_mse: 32.7748\n",
      "Epoch 72/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.2163 - mae: 1.1282 - mse: 2.2163 - val_loss: 35.0718 - val_mae: 4.3023 - val_mse: 35.0718\n",
      "Epoch 73/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.2457 - mae: 1.1484 - mse: 2.2457 - val_loss: 35.0961 - val_mae: 4.2519 - val_mse: 35.0961\n",
      "Epoch 74/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.1772 - mae: 1.1301 - mse: 2.1772 - val_loss: 37.5777 - val_mae: 4.4783 - val_mse: 37.5777\n",
      "Epoch 75/500\n",
      "2916/2916 [==============================] - 0s 42us/sample - loss: 2.1544 - mae: 1.1128 - mse: 2.1544 - val_loss: 37.6930 - val_mae: 4.3727 - val_mse: 37.6930\n",
      "Epoch 76/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.1293 - mae: 1.1260 - mse: 2.1293 - val_loss: 37.9754 - val_mae: 4.4966 - val_mse: 37.9754\n",
      "Epoch 77/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.0906 - mae: 1.1153 - mse: 2.0906 - val_loss: 35.0767 - val_mae: 4.3219 - val_mse: 35.0767\n",
      "Epoch 78/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.1159 - mae: 1.1166 - mse: 2.1159 - val_loss: 37.9684 - val_mae: 4.4400 - val_mse: 37.9684\n",
      "Epoch 79/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.0764 - mae: 1.1000 - mse: 2.0764 - val_loss: 37.0092 - val_mae: 4.4194 - val_mse: 37.0092\n",
      "Epoch 80/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.0712 - mae: 1.1038 - mse: 2.0712 - val_loss: 36.6734 - val_mae: 4.3487 - val_mse: 36.6734\n",
      "Epoch 81/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 2.0364 - mae: 1.0964 - mse: 2.0364 - val_loss: 35.1816 - val_mae: 4.2407 - val_mse: 35.1815\n",
      "Epoch 82/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.0349 - mae: 1.0944 - mse: 2.0349 - val_loss: 34.5710 - val_mae: 4.2131 - val_mse: 34.5710\n",
      "Epoch 83/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 2.0375 - mae: 1.0971 - mse: 2.0375 - val_loss: 34.8651 - val_mae: 4.2877 - val_mse: 34.8651\n",
      "Epoch 84/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.9319 - mae: 1.0723 - mse: 1.9319 - val_loss: 39.3772 - val_mae: 4.5561 - val_mse: 39.3772\n",
      "Epoch 85/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.9213 - mae: 1.0650 - mse: 1.9213 - val_loss: 37.5560 - val_mae: 4.3672 - val_mse: 37.5560\n",
      "Epoch 86/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.9515 - mae: 1.0773 - mse: 1.9515 - val_loss: 36.0191 - val_mae: 4.3512 - val_mse: 36.0191\n",
      "Epoch 87/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.9357 - mae: 1.0694 - mse: 1.9357 - val_loss: 35.9863 - val_mae: 4.4494 - val_mse: 35.9863\n",
      "Epoch 88/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.9155 - mae: 1.0691 - mse: 1.9155 - val_loss: 40.4578 - val_mae: 4.6663 - val_mse: 40.4578\n",
      "Epoch 89/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.9277 - mae: 1.0767 - mse: 1.9277 - val_loss: 36.0073 - val_mae: 4.4237 - val_mse: 36.0073\n",
      "Epoch 90/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.8061 - mae: 1.0294 - mse: 1.8061 - val_loss: 34.6566 - val_mae: 4.2119 - val_mse: 34.6566\n",
      "Epoch 91/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.8682 - mae: 1.0514 - mse: 1.8682 - val_loss: 36.8185 - val_mae: 4.3910 - val_mse: 36.8185\n",
      "Epoch 92/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.8495 - mae: 1.0446 - mse: 1.8495 - val_loss: 38.9085 - val_mae: 4.5363 - val_mse: 38.9085\n",
      "Epoch 93/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.8099 - mae: 1.0255 - mse: 1.8099 - val_loss: 34.9937 - val_mae: 4.3466 - val_mse: 34.9938\n",
      "Epoch 94/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.8044 - mae: 1.0390 - mse: 1.8044 - val_loss: 33.7647 - val_mae: 4.2161 - val_mse: 33.7647\n",
      "Epoch 95/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.8064 - mae: 1.0337 - mse: 1.8064 - val_loss: 36.1575 - val_mae: 4.3210 - val_mse: 36.1576\n",
      "Epoch 96/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.7464 - mae: 1.0221 - mse: 1.7464 - val_loss: 35.4388 - val_mae: 4.3391 - val_mse: 35.4388\n",
      "Epoch 97/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.7768 - mae: 1.0351 - mse: 1.7768 - val_loss: 36.9439 - val_mae: 4.3518 - val_mse: 36.9439\n",
      "Epoch 98/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.7867 - mae: 1.0316 - mse: 1.7867 - val_loss: 35.6096 - val_mae: 4.2915 - val_mse: 35.6096\n",
      "Epoch 99/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.7059 - mae: 1.0094 - mse: 1.7059 - val_loss: 34.6539 - val_mae: 4.2788 - val_mse: 34.6539\n",
      "Epoch 100/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.7545 - mae: 1.0318 - mse: 1.7545 - val_loss: 35.4372 - val_mae: 4.2964 - val_mse: 35.4372\n",
      "Epoch 101/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.6690 - mae: 0.9959 - mse: 1.6690 - val_loss: 35.9128 - val_mae: 4.2628 - val_mse: 35.9128\n",
      "Epoch 102/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.6674 - mae: 1.0026 - mse: 1.6674 - val_loss: 35.0340 - val_mae: 4.2284 - val_mse: 35.0340\n",
      "Epoch 103/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.7056 - mae: 1.0116 - mse: 1.7056 - val_loss: 39.0190 - val_mae: 4.4645 - val_mse: 39.0190\n",
      "Epoch 104/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.6571 - mae: 0.9964 - mse: 1.6571 - val_loss: 35.5505 - val_mae: 4.2540 - val_mse: 35.5505\n",
      "Epoch 105/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.6658 - mae: 0.9995 - mse: 1.6658 - val_loss: 37.5938 - val_mae: 4.4715 - val_mse: 37.5938\n",
      "Epoch 106/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.6696 - mae: 0.9979 - mse: 1.6696 - val_loss: 38.0031 - val_mae: 4.4408 - val_mse: 38.0031\n",
      "Epoch 107/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.5949 - mae: 0.9730 - mse: 1.5949 - val_loss: 36.5121 - val_mae: 4.2922 - val_mse: 36.5122\n",
      "Epoch 108/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.6528 - mae: 0.9927 - mse: 1.6528 - val_loss: 35.2395 - val_mae: 4.2782 - val_mse: 35.2395\n",
      "Epoch 109/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.5976 - mae: 0.9862 - mse: 1.5976 - val_loss: 35.2901 - val_mae: 4.2525 - val_mse: 35.2901\n",
      "Epoch 110/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.6304 - mae: 0.9926 - mse: 1.6304 - val_loss: 36.1257 - val_mae: 4.2808 - val_mse: 36.1257\n",
      "Epoch 111/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.6239 - mae: 0.9877 - mse: 1.6239 - val_loss: 35.3777 - val_mae: 4.2001 - val_mse: 35.3777\n",
      "Epoch 112/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.6387 - mae: 0.9996 - mse: 1.6387 - val_loss: 33.2757 - val_mae: 4.2589 - val_mse: 33.2757\n",
      "Epoch 113/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.5808 - mae: 0.9767 - mse: 1.5808 - val_loss: 36.5976 - val_mae: 4.3085 - val_mse: 36.5976\n",
      "Epoch 114/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.5840 - mae: 0.9763 - mse: 1.5840 - val_loss: 38.2663 - val_mae: 4.4674 - val_mse: 38.2663\n",
      "Epoch 115/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.5833 - mae: 0.9811 - mse: 1.5833 - val_loss: 36.6195 - val_mae: 4.3083 - val_mse: 36.6195\n",
      "Epoch 116/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.5522 - mae: 0.9664 - mse: 1.5522 - val_loss: 38.3467 - val_mae: 4.4625 - val_mse: 38.3467\n",
      "Epoch 117/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.5831 - mae: 0.9790 - mse: 1.5831 - val_loss: 39.1875 - val_mae: 4.3926 - val_mse: 39.1875\n",
      "Epoch 118/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.5382 - mae: 0.9644 - mse: 1.5382 - val_loss: 36.5709 - val_mae: 4.2860 - val_mse: 36.5709\n",
      "Epoch 119/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.5216 - mae: 0.9577 - mse: 1.5216 - val_loss: 38.2797 - val_mae: 4.3849 - val_mse: 38.2797\n",
      "Epoch 120/500\n",
      "2916/2916 [==============================] - 0s 40us/sample - loss: 1.5393 - mae: 0.9639 - mse: 1.5393 - val_loss: 33.7217 - val_mae: 4.1509 - val_mse: 33.7217\n",
      "Epoch 121/500\n",
      "2916/2916 [==============================] - 0s 41us/sample - loss: 1.5385 - mae: 0.9556 - mse: 1.5385 - val_loss: 38.8096 - val_mae: 4.4069 - val_mse: 38.8096\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4374 samples, validate on 1458 samples\n",
      "Epoch 1/500\n",
      "4374/4374 [==============================] - 1s 117us/sample - loss: 209.0486 - mae: 8.0884 - mse: 209.0486 - val_loss: 132.4803 - val_mae: 8.0836 - val_mse: 132.4803\n",
      "Epoch 2/500\n",
      "4374/4374 [==============================] - 0s 38us/sample - loss: 27.0396 - mae: 3.6547 - mse: 27.0396 - val_loss: 74.0749 - val_mae: 6.0301 - val_mse: 74.0749\n",
      "Epoch 3/500\n",
      "4374/4374 [==============================] - 0s 38us/sample - loss: 16.3915 - mae: 2.9048 - mse: 16.3915 - val_loss: 66.9865 - val_mae: 5.9968 - val_mse: 66.9865\n",
      "Epoch 4/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 13.1548 - mae: 2.6550 - mse: 13.1548 - val_loss: 45.4498 - val_mae: 4.5634 - val_mse: 45.4498\n",
      "Epoch 5/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 11.4057 - mae: 2.4554 - mse: 11.4057 - val_loss: 42.1971 - val_mae: 4.5115 - val_mse: 42.1971\n",
      "Epoch 6/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 10.0198 - mae: 2.3226 - mse: 10.0198 - val_loss: 44.8249 - val_mae: 5.0077 - val_mse: 44.8249\n",
      "Epoch 7/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 9.3009 - mae: 2.2673 - mse: 9.3009 - val_loss: 35.7428 - val_mae: 4.2130 - val_mse: 35.7428\n",
      "Epoch 8/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 8.8918 - mae: 2.2372 - mse: 8.8918 - val_loss: 30.0024 - val_mae: 3.7838 - val_mse: 30.0024\n",
      "Epoch 9/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 8.2446 - mae: 2.1432 - mse: 8.2446 - val_loss: 27.7412 - val_mae: 3.7369 - val_mse: 27.7412\n",
      "Epoch 10/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 7.9312 - mae: 2.1210 - mse: 7.9312 - val_loss: 26.0168 - val_mae: 3.5426 - val_mse: 26.0168\n",
      "Epoch 11/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 7.8141 - mae: 2.1075 - mse: 7.8141 - val_loss: 25.2709 - val_mae: 3.6061 - val_mse: 25.2709\n",
      "Epoch 12/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 6.9137 - mae: 1.9963 - mse: 6.9137 - val_loss: 26.5598 - val_mae: 3.6371 - val_mse: 26.5598\n",
      "Epoch 13/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 6.9946 - mae: 1.9909 - mse: 6.9946 - val_loss: 22.5815 - val_mae: 3.2660 - val_mse: 22.5815\n",
      "Epoch 14/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 6.8646 - mae: 1.9905 - mse: 6.8646 - val_loss: 21.7696 - val_mae: 3.1976 - val_mse: 21.7696\n",
      "Epoch 15/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 6.5401 - mae: 1.9728 - mse: 6.5401 - val_loss: 22.6778 - val_mae: 3.3584 - val_mse: 22.6778\n",
      "Epoch 16/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 6.3461 - mae: 1.9050 - mse: 6.3461 - val_loss: 24.1222 - val_mae: 3.5377 - val_mse: 24.1222\n",
      "Epoch 17/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 6.2426 - mae: 1.9180 - mse: 6.2426 - val_loss: 22.9065 - val_mae: 3.3830 - val_mse: 22.9065\n",
      "Epoch 18/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 6.0988 - mae: 1.8950 - mse: 6.0988 - val_loss: 20.9579 - val_mae: 3.1448 - val_mse: 20.9579\n",
      "Epoch 19/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 5.8725 - mae: 1.8637 - mse: 5.8725 - val_loss: 27.8938 - val_mae: 4.0035 - val_mse: 27.8938\n",
      "Epoch 20/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 5.7999 - mae: 1.8088 - mse: 5.7999 - val_loss: 20.9115 - val_mae: 3.2088 - val_mse: 20.9115\n",
      "Epoch 21/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 5.6340 - mae: 1.8433 - mse: 5.6340 - val_loss: 21.8406 - val_mae: 3.2744 - val_mse: 21.8406\n",
      "Epoch 22/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 5.6483 - mae: 1.8359 - mse: 5.6483 - val_loss: 20.1344 - val_mae: 3.1054 - val_mse: 20.1344\n",
      "Epoch 23/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 5.3483 - mae: 1.7873 - mse: 5.3483 - val_loss: 21.4064 - val_mae: 3.2929 - val_mse: 21.4064\n",
      "Epoch 24/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 5.1444 - mae: 1.7352 - mse: 5.1444 - val_loss: 21.9728 - val_mae: 3.3477 - val_mse: 21.9728\n",
      "Epoch 25/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 5.3129 - mae: 1.7848 - mse: 5.3129 - val_loss: 19.5862 - val_mae: 3.0248 - val_mse: 19.5862\n",
      "Epoch 26/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 5.1185 - mae: 1.7658 - mse: 5.1185 - val_loss: 22.5666 - val_mae: 3.4271 - val_mse: 22.5666\n",
      "Epoch 27/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 4.9988 - mae: 1.7421 - mse: 4.9988 - val_loss: 27.3529 - val_mae: 4.0297 - val_mse: 27.3529\n",
      "Epoch 28/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 5.0546 - mae: 1.7694 - mse: 5.0546 - val_loss: 21.2599 - val_mae: 3.2031 - val_mse: 21.2599\n",
      "Epoch 29/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 4.7961 - mae: 1.6955 - mse: 4.7961 - val_loss: 23.0916 - val_mae: 3.5035 - val_mse: 23.0916\n",
      "Epoch 30/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 4.9309 - mae: 1.7178 - mse: 4.9309 - val_loss: 20.3140 - val_mae: 3.0627 - val_mse: 20.3140\n",
      "Epoch 31/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 4.7499 - mae: 1.6833 - mse: 4.7499 - val_loss: 24.3572 - val_mae: 3.7187 - val_mse: 24.3572\n",
      "Epoch 32/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 4.6839 - mae: 1.6972 - mse: 4.6839 - val_loss: 24.5824 - val_mae: 3.7081 - val_mse: 24.5824\n",
      "Epoch 33/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 4.5339 - mae: 1.6618 - mse: 4.5339 - val_loss: 23.8430 - val_mae: 3.5247 - val_mse: 23.8430\n",
      "Epoch 34/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 4.5361 - mae: 1.6712 - mse: 4.5361 - val_loss: 19.9706 - val_mae: 3.0473 - val_mse: 19.9706\n",
      "Epoch 35/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 4.4337 - mae: 1.6412 - mse: 4.4337 - val_loss: 21.0778 - val_mae: 3.2484 - val_mse: 21.0778\n",
      "Epoch 36/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 4.3082 - mae: 1.6002 - mse: 4.3082 - val_loss: 19.5539 - val_mae: 3.0155 - val_mse: 19.5539\n",
      "Epoch 37/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 4.3140 - mae: 1.6216 - mse: 4.3140 - val_loss: 19.9009 - val_mae: 3.0184 - val_mse: 19.9009\n",
      "Epoch 38/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 4.1913 - mae: 1.6132 - mse: 4.1913 - val_loss: 21.4502 - val_mae: 3.2787 - val_mse: 21.4501\n",
      "Epoch 39/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 4.0903 - mae: 1.5822 - mse: 4.0903 - val_loss: 20.5052 - val_mae: 3.1315 - val_mse: 20.5052\n",
      "Epoch 40/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 3.9987 - mae: 1.5665 - mse: 3.9987 - val_loss: 23.1914 - val_mae: 3.5565 - val_mse: 23.1914\n",
      "Epoch 41/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 3.9519 - mae: 1.5475 - mse: 3.9519 - val_loss: 20.0993 - val_mae: 3.0878 - val_mse: 20.0993\n",
      "Epoch 42/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 3.9918 - mae: 1.5582 - mse: 3.9918 - val_loss: 21.1562 - val_mae: 3.2120 - val_mse: 21.1562\n",
      "Epoch 43/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 3.8524 - mae: 1.5458 - mse: 3.8524 - val_loss: 20.9057 - val_mae: 3.1907 - val_mse: 20.9057\n",
      "Epoch 44/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 3.6943 - mae: 1.4799 - mse: 3.6943 - val_loss: 20.6178 - val_mae: 3.1258 - val_mse: 20.6178\n",
      "Epoch 45/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 3.7465 - mae: 1.5017 - mse: 3.7465 - val_loss: 21.8245 - val_mae: 3.3441 - val_mse: 21.8245\n",
      "Epoch 46/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 3.7031 - mae: 1.5101 - mse: 3.7031 - val_loss: 19.4327 - val_mae: 2.9863 - val_mse: 19.4327\n",
      "Epoch 47/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 3.5803 - mae: 1.4788 - mse: 3.5803 - val_loss: 20.4046 - val_mae: 3.1797 - val_mse: 20.4046\n",
      "Epoch 48/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 3.6976 - mae: 1.5143 - mse: 3.6976 - val_loss: 21.2122 - val_mae: 3.2592 - val_mse: 21.2122\n",
      "Epoch 49/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 3.5906 - mae: 1.4901 - mse: 3.5906 - val_loss: 19.8990 - val_mae: 3.0212 - val_mse: 19.8990\n",
      "Epoch 50/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 3.5361 - mae: 1.4694 - mse: 3.5361 - val_loss: 20.3845 - val_mae: 3.1211 - val_mse: 20.3845\n",
      "Epoch 51/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 3.4281 - mae: 1.4511 - mse: 3.4281 - val_loss: 21.7949 - val_mae: 3.3356 - val_mse: 21.7949\n",
      "Epoch 52/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 3.4131 - mae: 1.4447 - mse: 3.4131 - val_loss: 19.5525 - val_mae: 3.0080 - val_mse: 19.5525\n",
      "Epoch 53/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 3.3619 - mae: 1.4445 - mse: 3.3619 - val_loss: 19.7382 - val_mae: 3.0815 - val_mse: 19.7382\n",
      "Epoch 54/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 3.3301 - mae: 1.4368 - mse: 3.3301 - val_loss: 21.4851 - val_mae: 3.2899 - val_mse: 21.4851\n",
      "Epoch 55/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 3.2118 - mae: 1.3987 - mse: 3.2118 - val_loss: 23.5814 - val_mae: 3.5745 - val_mse: 23.5814\n",
      "Epoch 56/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 3.2185 - mae: 1.3896 - mse: 3.2185 - val_loss: 21.4377 - val_mae: 3.2669 - val_mse: 21.4377\n",
      "Epoch 57/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 3.0991 - mae: 1.3823 - mse: 3.0991 - val_loss: 19.4476 - val_mae: 2.9245 - val_mse: 19.4476\n",
      "Epoch 58/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 3.1253 - mae: 1.3728 - mse: 3.1253 - val_loss: 20.0975 - val_mae: 3.0911 - val_mse: 20.0975\n",
      "Epoch 59/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 3.0794 - mae: 1.3648 - mse: 3.0794 - val_loss: 20.7004 - val_mae: 3.1622 - val_mse: 20.7004\n",
      "Epoch 60/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 2.9934 - mae: 1.3509 - mse: 2.9934 - val_loss: 20.0411 - val_mae: 3.0513 - val_mse: 20.0411\n",
      "Epoch 61/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.9820 - mae: 1.3413 - mse: 2.9820 - val_loss: 20.6071 - val_mae: 3.0511 - val_mse: 20.6071\n",
      "Epoch 62/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.9483 - mae: 1.3501 - mse: 2.9483 - val_loss: 19.1101 - val_mae: 2.9300 - val_mse: 19.1101\n",
      "Epoch 63/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 2.9092 - mae: 1.3241 - mse: 2.9092 - val_loss: 19.3683 - val_mae: 2.9045 - val_mse: 19.3683\n",
      "Epoch 64/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.8186 - mae: 1.3131 - mse: 2.8186 - val_loss: 20.1926 - val_mae: 3.0176 - val_mse: 20.1926\n",
      "Epoch 65/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 2.8271 - mae: 1.3162 - mse: 2.8271 - val_loss: 20.3798 - val_mae: 3.1066 - val_mse: 20.3798\n",
      "Epoch 66/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.7313 - mae: 1.2980 - mse: 2.7313 - val_loss: 20.1227 - val_mae: 3.1068 - val_mse: 20.1227\n",
      "Epoch 67/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.7293 - mae: 1.2870 - mse: 2.7293 - val_loss: 19.5653 - val_mae: 2.9110 - val_mse: 19.5653\n",
      "Epoch 68/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.7033 - mae: 1.2806 - mse: 2.7033 - val_loss: 19.9325 - val_mae: 3.0130 - val_mse: 19.9325\n",
      "Epoch 69/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.5876 - mae: 1.2530 - mse: 2.5876 - val_loss: 20.2419 - val_mae: 3.0183 - val_mse: 20.2419\n",
      "Epoch 70/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.5721 - mae: 1.2580 - mse: 2.5721 - val_loss: 20.1958 - val_mae: 3.0836 - val_mse: 20.1958\n",
      "Epoch 71/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.6206 - mae: 1.2557 - mse: 2.6206 - val_loss: 20.0951 - val_mae: 3.0758 - val_mse: 20.0951\n",
      "Epoch 72/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.5614 - mae: 1.2507 - mse: 2.5614 - val_loss: 20.5831 - val_mae: 3.1400 - val_mse: 20.5831\n",
      "Epoch 73/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.5011 - mae: 1.2445 - mse: 2.5011 - val_loss: 19.6459 - val_mae: 2.9543 - val_mse: 19.6459\n",
      "Epoch 74/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.4268 - mae: 1.2203 - mse: 2.4268 - val_loss: 19.4212 - val_mae: 2.8429 - val_mse: 19.4212\n",
      "Epoch 75/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.4611 - mae: 1.2281 - mse: 2.4611 - val_loss: 20.6284 - val_mae: 3.0771 - val_mse: 20.6284\n",
      "Epoch 76/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 2.4084 - mae: 1.2167 - mse: 2.4084 - val_loss: 19.1700 - val_mae: 2.9381 - val_mse: 19.1700\n",
      "Epoch 77/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.3477 - mae: 1.1919 - mse: 2.3477 - val_loss: 19.4291 - val_mae: 2.9382 - val_mse: 19.4291\n",
      "Epoch 78/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.3555 - mae: 1.1993 - mse: 2.3555 - val_loss: 19.7111 - val_mae: 2.9810 - val_mse: 19.7111\n",
      "Epoch 79/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.3526 - mae: 1.2061 - mse: 2.3526 - val_loss: 19.4157 - val_mae: 2.9244 - val_mse: 19.4157\n",
      "Epoch 80/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.2914 - mae: 1.1846 - mse: 2.2914 - val_loss: 19.4486 - val_mae: 2.8949 - val_mse: 19.4486\n",
      "Epoch 81/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 2.2916 - mae: 1.1917 - mse: 2.2916 - val_loss: 18.8761 - val_mae: 2.8520 - val_mse: 18.8761\n",
      "Epoch 82/500\n",
      "4374/4374 [==============================] - 0s 59us/sample - loss: 2.2933 - mae: 1.1938 - mse: 2.2933 - val_loss: 19.3663 - val_mae: 2.8809 - val_mse: 19.3663\n",
      "Epoch 83/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 2.2321 - mae: 1.1690 - mse: 2.2321 - val_loss: 19.2449 - val_mae: 2.9144 - val_mse: 19.2449\n",
      "Epoch 84/500\n",
      "4374/4374 [==============================] - 0s 56us/sample - loss: 2.2535 - mae: 1.1664 - mse: 2.2535 - val_loss: 19.6872 - val_mae: 2.9013 - val_mse: 19.6872\n",
      "Epoch 85/500\n",
      "4374/4374 [==============================] - 0s 45us/sample - loss: 2.2083 - mae: 1.1587 - mse: 2.2083 - val_loss: 19.0759 - val_mae: 2.8323 - val_mse: 19.0759\n",
      "Epoch 86/500\n",
      "4374/4374 [==============================] - 0s 57us/sample - loss: 2.1491 - mae: 1.1425 - mse: 2.1491 - val_loss: 19.4872 - val_mae: 3.0235 - val_mse: 19.4872\n",
      "Epoch 87/500\n",
      "4374/4374 [==============================] - 0s 41us/sample - loss: 2.1580 - mae: 1.1517 - mse: 2.1580 - val_loss: 19.6484 - val_mae: 3.0252 - val_mse: 19.6484\n",
      "Epoch 88/500\n",
      "4374/4374 [==============================] - 0s 47us/sample - loss: 2.1044 - mae: 1.1318 - mse: 2.1044 - val_loss: 20.7036 - val_mae: 3.3006 - val_mse: 20.7036\n",
      "Epoch 89/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 2.1053 - mae: 1.1347 - mse: 2.1053 - val_loss: 19.5013 - val_mae: 3.0217 - val_mse: 19.5013\n",
      "Epoch 90/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 2.0725 - mae: 1.1183 - mse: 2.0725 - val_loss: 21.0210 - val_mae: 3.0987 - val_mse: 21.0210\n",
      "Epoch 91/500\n",
      "4374/4374 [==============================] - 0s 41us/sample - loss: 2.1291 - mae: 1.1443 - mse: 2.1291 - val_loss: 18.7928 - val_mae: 2.9418 - val_mse: 18.7928\n",
      "Epoch 92/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 2.0694 - mae: 1.1207 - mse: 2.0694 - val_loss: 18.8138 - val_mae: 2.8158 - val_mse: 18.8138\n",
      "Epoch 93/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 2.1062 - mae: 1.1350 - mse: 2.1062 - val_loss: 19.2320 - val_mae: 3.0338 - val_mse: 19.2321\n",
      "Epoch 94/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 2.0508 - mae: 1.1151 - mse: 2.0508 - val_loss: 18.4106 - val_mae: 2.8124 - val_mse: 18.4106\n",
      "Epoch 95/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.9903 - mae: 1.0989 - mse: 1.9903 - val_loss: 19.5848 - val_mae: 2.8313 - val_mse: 19.5848\n",
      "Epoch 96/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 2.0120 - mae: 1.1093 - mse: 2.0120 - val_loss: 18.9127 - val_mae: 2.8572 - val_mse: 18.9127\n",
      "Epoch 97/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.9397 - mae: 1.0840 - mse: 1.9397 - val_loss: 20.0259 - val_mae: 2.8869 - val_mse: 20.0259\n",
      "Epoch 98/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.9381 - mae: 1.0854 - mse: 1.9381 - val_loss: 18.9417 - val_mae: 2.9066 - val_mse: 18.9417\n",
      "Epoch 99/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.9720 - mae: 1.0862 - mse: 1.9720 - val_loss: 19.5851 - val_mae: 3.1076 - val_mse: 19.5851\n",
      "Epoch 100/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.8958 - mae: 1.0695 - mse: 1.8958 - val_loss: 19.0561 - val_mae: 2.9259 - val_mse: 19.0561\n",
      "Epoch 101/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.9165 - mae: 1.0774 - mse: 1.9165 - val_loss: 18.4315 - val_mae: 2.9284 - val_mse: 18.4315\n",
      "Epoch 102/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.8841 - mae: 1.0674 - mse: 1.8841 - val_loss: 18.9202 - val_mae: 2.8145 - val_mse: 18.9202\n",
      "Epoch 103/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 1.8930 - mae: 1.0746 - mse: 1.8930 - val_loss: 18.9631 - val_mae: 2.8765 - val_mse: 18.9631\n",
      "Epoch 104/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.8395 - mae: 1.0525 - mse: 1.8395 - val_loss: 19.5980 - val_mae: 2.8694 - val_mse: 19.5980\n",
      "Epoch 105/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.8548 - mae: 1.0610 - mse: 1.8548 - val_loss: 19.7689 - val_mae: 2.8774 - val_mse: 19.7689\n",
      "Epoch 106/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.8618 - mae: 1.0645 - mse: 1.8618 - val_loss: 18.4971 - val_mae: 2.8408 - val_mse: 18.4971\n",
      "Epoch 107/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.8305 - mae: 1.0519 - mse: 1.8305 - val_loss: 19.0503 - val_mae: 2.8193 - val_mse: 19.0502\n",
      "Epoch 108/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.8221 - mae: 1.0486 - mse: 1.8221 - val_loss: 18.5188 - val_mae: 2.8480 - val_mse: 18.5188\n",
      "Epoch 109/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 1.8277 - mae: 1.0449 - mse: 1.8277 - val_loss: 19.0399 - val_mae: 2.8353 - val_mse: 19.0399\n",
      "Epoch 110/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.7537 - mae: 1.0351 - mse: 1.7537 - val_loss: 18.7954 - val_mae: 2.9119 - val_mse: 18.7954\n",
      "Epoch 111/500\n",
      "4374/4374 [==============================] - 0s 41us/sample - loss: 1.7984 - mae: 1.0465 - mse: 1.7984 - val_loss: 19.0404 - val_mae: 2.8344 - val_mse: 19.0404\n",
      "Epoch 112/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.7500 - mae: 1.0248 - mse: 1.7500 - val_loss: 18.4982 - val_mae: 2.7962 - val_mse: 18.4982\n",
      "Epoch 113/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 1.8023 - mae: 1.0475 - mse: 1.8023 - val_loss: 18.5884 - val_mae: 2.7822 - val_mse: 18.5884\n",
      "Epoch 114/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.7158 - mae: 1.0158 - mse: 1.7158 - val_loss: 19.8183 - val_mae: 3.0477 - val_mse: 19.8183\n",
      "Epoch 115/500\n",
      "4374/4374 [==============================] - 0s 39us/sample - loss: 1.7676 - mae: 1.0378 - mse: 1.7676 - val_loss: 18.8229 - val_mae: 2.9184 - val_mse: 18.8229\n",
      "Epoch 116/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.6987 - mae: 1.0201 - mse: 1.6987 - val_loss: 19.1559 - val_mae: 2.9279 - val_mse: 19.1559\n",
      "Epoch 117/500\n",
      "4374/4374 [==============================] - 0s 41us/sample - loss: 1.7381 - mae: 1.0252 - mse: 1.7381 - val_loss: 19.2229 - val_mae: 2.8818 - val_mse: 19.2229\n",
      "Epoch 118/500\n",
      "4374/4374 [==============================] - 0s 41us/sample - loss: 1.7122 - mae: 1.0118 - mse: 1.7122 - val_loss: 19.2936 - val_mae: 2.9949 - val_mse: 19.2936\n",
      "Epoch 119/500\n",
      "4374/4374 [==============================] - 0s 41us/sample - loss: 1.7344 - mae: 1.0218 - mse: 1.7344 - val_loss: 18.6921 - val_mae: 2.8114 - val_mse: 18.6921\n",
      "Epoch 120/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.6823 - mae: 1.0048 - mse: 1.6823 - val_loss: 18.7263 - val_mae: 2.8885 - val_mse: 18.7263\n",
      "Epoch 121/500\n",
      "4374/4374 [==============================] - 0s 41us/sample - loss: 1.6765 - mae: 1.0074 - mse: 1.6765 - val_loss: 19.2973 - val_mae: 3.0084 - val_mse: 19.2973\n",
      "Epoch 122/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.6781 - mae: 1.0048 - mse: 1.6781 - val_loss: 19.0466 - val_mae: 2.9628 - val_mse: 19.0466\n",
      "Epoch 123/500\n",
      "4374/4374 [==============================] - 0s 42us/sample - loss: 1.6589 - mae: 0.9986 - mse: 1.6589 - val_loss: 18.7043 - val_mae: 2.7841 - val_mse: 18.7043\n",
      "Epoch 124/500\n",
      "4374/4374 [==============================] - 0s 41us/sample - loss: 1.6867 - mae: 1.0084 - mse: 1.6867 - val_loss: 18.6166 - val_mae: 2.8131 - val_mse: 18.6166\n",
      "Epoch 125/500\n",
      "4374/4374 [==============================] - 0s 59us/sample - loss: 1.6490 - mae: 0.9984 - mse: 1.6490 - val_loss: 18.6886 - val_mae: 2.9008 - val_mse: 18.6886\n",
      "Epoch 126/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.6465 - mae: 0.9923 - mse: 1.6465 - val_loss: 18.8624 - val_mae: 2.8429 - val_mse: 18.8624\n",
      "Epoch 127/500\n",
      "4374/4374 [==============================] - 0s 50us/sample - loss: 1.6472 - mae: 1.0023 - mse: 1.6472 - val_loss: 18.8896 - val_mae: 2.8663 - val_mse: 18.8896\n",
      "Epoch 128/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.6299 - mae: 0.9935 - mse: 1.6299 - val_loss: 18.8903 - val_mae: 2.8597 - val_mse: 18.8903\n",
      "Epoch 129/500\n",
      "4374/4374 [==============================] - 0s 50us/sample - loss: 1.6316 - mae: 0.9883 - mse: 1.6316 - val_loss: 18.8256 - val_mae: 2.8538 - val_mse: 18.8256\n",
      "Epoch 130/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.6246 - mae: 0.9956 - mse: 1.6246 - val_loss: 18.6374 - val_mae: 2.7944 - val_mse: 18.6374\n",
      "Epoch 131/500\n",
      "4374/4374 [==============================] - 0s 51us/sample - loss: 1.6333 - mae: 0.9904 - mse: 1.6333 - val_loss: 19.7705 - val_mae: 2.8996 - val_mse: 19.7705\n",
      "Epoch 132/500\n",
      "4374/4374 [==============================] - 0s 47us/sample - loss: 1.6405 - mae: 1.0019 - mse: 1.6405 - val_loss: 19.2997 - val_mae: 2.8983 - val_mse: 19.2997\n",
      "Epoch 133/500\n",
      "4374/4374 [==============================] - 0s 42us/sample - loss: 1.5796 - mae: 0.9747 - mse: 1.5796 - val_loss: 18.7965 - val_mae: 2.8398 - val_mse: 18.7965\n",
      "Epoch 134/500\n",
      "4374/4374 [==============================] - 0s 52us/sample - loss: 1.6310 - mae: 0.9927 - mse: 1.6310 - val_loss: 18.8913 - val_mae: 2.8919 - val_mse: 18.8913\n",
      "Epoch 135/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.6214 - mae: 0.9871 - mse: 1.6214 - val_loss: 19.2684 - val_mae: 2.8808 - val_mse: 19.2684\n",
      "Epoch 136/500\n",
      "4374/4374 [==============================] - 0s 50us/sample - loss: 1.5734 - mae: 0.9746 - mse: 1.5734 - val_loss: 18.7401 - val_mae: 2.8445 - val_mse: 18.7401\n",
      "Epoch 137/500\n",
      "4374/4374 [==============================] - 0s 41us/sample - loss: 1.5814 - mae: 0.9793 - mse: 1.5814 - val_loss: 18.7684 - val_mae: 2.8732 - val_mse: 18.7684\n",
      "Epoch 138/500\n",
      "4374/4374 [==============================] - 0s 45us/sample - loss: 1.5841 - mae: 0.9822 - mse: 1.5841 - val_loss: 19.3469 - val_mae: 2.8761 - val_mse: 19.3469\n",
      "Epoch 139/500\n",
      "4374/4374 [==============================] - 0s 44us/sample - loss: 1.5773 - mae: 0.9730 - mse: 1.5773 - val_loss: 19.0648 - val_mae: 2.8876 - val_mse: 19.0647\n",
      "Epoch 140/500\n",
      "4374/4374 [==============================] - 0s 45us/sample - loss: 1.5311 - mae: 0.9610 - mse: 1.5311 - val_loss: 19.3235 - val_mae: 2.8206 - val_mse: 19.3235\n",
      "Epoch 141/500\n",
      "4374/4374 [==============================] - 0s 46us/sample - loss: 1.5389 - mae: 0.9609 - mse: 1.5389 - val_loss: 19.5346 - val_mae: 2.8246 - val_mse: 19.5346\n",
      "Epoch 142/500\n",
      "4374/4374 [==============================] - 0s 41us/sample - loss: 1.5235 - mae: 0.9613 - mse: 1.5235 - val_loss: 19.4691 - val_mae: 3.0309 - val_mse: 19.4691\n",
      "Epoch 143/500\n",
      "4374/4374 [==============================] - 0s 50us/sample - loss: 1.5403 - mae: 0.9675 - mse: 1.5403 - val_loss: 19.2052 - val_mae: 2.8498 - val_mse: 19.2052\n",
      "Epoch 144/500\n",
      "4374/4374 [==============================] - 0s 40us/sample - loss: 1.5147 - mae: 0.9551 - mse: 1.5147 - val_loss: 19.3127 - val_mae: 2.7795 - val_mse: 19.3127\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5833 samples, validate on 1944 samples\n",
      "Epoch 1/500\n",
      "5833/5833 [==============================] - 1s 129us/sample - loss: 574.4660 - mae: 12.1857 - mse: 574.4663 - val_loss: 151.8208 - val_mae: 8.4384 - val_mse: 151.8208\n",
      "Epoch 2/500\n",
      "5833/5833 [==============================] - 0s 46us/sample - loss: 31.7377 - mae: 3.9289 - mse: 31.7377 - val_loss: 82.8047 - val_mae: 5.9954 - val_mse: 82.8047\n",
      "Epoch 3/500\n",
      "5833/5833 [==============================] - 0s 46us/sample - loss: 18.6441 - mae: 3.1931 - mse: 18.6441 - val_loss: 74.8282 - val_mae: 6.2908 - val_mse: 74.8282\n",
      "Epoch 4/500\n",
      "5833/5833 [==============================] - 0s 47us/sample - loss: 14.6271 - mae: 2.9108 - mse: 14.6271 - val_loss: 50.4921 - val_mae: 4.8400 - val_mse: 50.4921\n",
      "Epoch 5/500\n",
      "5833/5833 [==============================] - 0s 45us/sample - loss: 12.3438 - mae: 2.6549 - mse: 12.3438 - val_loss: 61.1280 - val_mae: 5.8695 - val_mse: 61.1280\n",
      "Epoch 6/500\n",
      "5833/5833 [==============================] - 0s 43us/sample - loss: 11.4456 - mae: 2.5847 - mse: 11.4456 - val_loss: 39.9545 - val_mae: 4.3013 - val_mse: 39.9545\n",
      "Epoch 7/500\n",
      "5833/5833 [==============================] - 0s 50us/sample - loss: 10.7188 - mae: 2.5304 - mse: 10.7188 - val_loss: 37.8042 - val_mae: 4.6307 - val_mse: 37.8042\n",
      "Epoch 8/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 9.9888 - mae: 2.4317 - mse: 9.9888 - val_loss: 44.3751 - val_mae: 4.9475 - val_mse: 44.3751\n",
      "Epoch 9/500\n",
      "5833/5833 [==============================] - 0s 53us/sample - loss: 9.5432 - mae: 2.3890 - mse: 9.5432 - val_loss: 37.4717 - val_mae: 4.4454 - val_mse: 37.4717\n",
      "Epoch 10/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5833/5833 [==============================] - 0s 44us/sample - loss: 9.1777 - mae: 2.3634 - mse: 9.1777 - val_loss: 38.2066 - val_mae: 4.6306 - val_mse: 38.2066\n",
      "Epoch 11/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 8.6412 - mae: 2.2994 - mse: 8.6412 - val_loss: 46.5371 - val_mae: 5.3930 - val_mse: 46.5371\n",
      "Epoch 12/500\n",
      "5833/5833 [==============================] - 0s 43us/sample - loss: 8.2077 - mae: 2.2415 - mse: 8.2077 - val_loss: 36.8161 - val_mae: 4.6571 - val_mse: 36.8161\n",
      "Epoch 13/500\n",
      "5833/5833 [==============================] - 0s 43us/sample - loss: 8.0525 - mae: 2.2514 - mse: 8.0525 - val_loss: 25.2958 - val_mae: 3.6113 - val_mse: 25.2958\n",
      "Epoch 14/500\n",
      "5833/5833 [==============================] - 0s 42us/sample - loss: 7.6602 - mae: 2.1735 - mse: 7.6602 - val_loss: 26.9951 - val_mae: 3.8403 - val_mse: 26.9951\n",
      "Epoch 15/500\n",
      "5833/5833 [==============================] - 0s 42us/sample - loss: 7.3407 - mae: 2.1067 - mse: 7.3407 - val_loss: 23.1335 - val_mae: 3.3692 - val_mse: 23.1335\n",
      "Epoch 16/500\n",
      "5833/5833 [==============================] - 0s 43us/sample - loss: 7.2056 - mae: 2.1037 - mse: 7.2056 - val_loss: 25.8096 - val_mae: 3.5255 - val_mse: 25.8096\n",
      "Epoch 17/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 6.9762 - mae: 2.1023 - mse: 6.9762 - val_loss: 29.3010 - val_mae: 4.1810 - val_mse: 29.3010\n",
      "Epoch 18/500\n",
      "5833/5833 [==============================] - 0s 43us/sample - loss: 6.8369 - mae: 2.0610 - mse: 6.8369 - val_loss: 21.9207 - val_mae: 3.3200 - val_mse: 21.9207\n",
      "Epoch 19/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 6.5362 - mae: 2.0334 - mse: 6.5362 - val_loss: 25.4979 - val_mae: 3.8788 - val_mse: 25.4979\n",
      "Epoch 20/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 6.3780 - mae: 1.9901 - mse: 6.3780 - val_loss: 30.2285 - val_mae: 4.2900 - val_mse: 30.2285\n",
      "Epoch 21/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 6.2827 - mae: 2.0042 - mse: 6.2827 - val_loss: 21.7203 - val_mae: 3.3102 - val_mse: 21.7203\n",
      "Epoch 22/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 6.0860 - mae: 1.9475 - mse: 6.0860 - val_loss: 30.2553 - val_mae: 4.1839 - val_mse: 30.2553\n",
      "Epoch 23/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 6.0123 - mae: 1.9620 - mse: 6.0123 - val_loss: 19.5905 - val_mae: 2.9310 - val_mse: 19.5905\n",
      "Epoch 24/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 5.6736 - mae: 1.8884 - mse: 5.6736 - val_loss: 19.3988 - val_mae: 2.9423 - val_mse: 19.3988\n",
      "Epoch 25/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 5.6495 - mae: 1.8912 - mse: 5.6495 - val_loss: 21.4950 - val_mae: 3.2450 - val_mse: 21.4950\n",
      "Epoch 26/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 5.4868 - mae: 1.8520 - mse: 5.4868 - val_loss: 21.2624 - val_mae: 3.3184 - val_mse: 21.2624\n",
      "Epoch 27/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 5.5386 - mae: 1.8727 - mse: 5.5386 - val_loss: 20.7354 - val_mae: 3.1971 - val_mse: 20.7354\n",
      "Epoch 28/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 5.2970 - mae: 1.8145 - mse: 5.2970 - val_loss: 19.4573 - val_mae: 3.1849 - val_mse: 19.4573\n",
      "Epoch 29/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 5.1318 - mae: 1.7989 - mse: 5.1318 - val_loss: 20.1888 - val_mae: 3.2391 - val_mse: 20.1888\n",
      "Epoch 30/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 5.1980 - mae: 1.7904 - mse: 5.1980 - val_loss: 20.2379 - val_mae: 3.1394 - val_mse: 20.2379\n",
      "Epoch 31/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 4.8140 - mae: 1.7136 - mse: 4.8140 - val_loss: 24.5534 - val_mae: 3.8218 - val_mse: 24.5534\n",
      "Epoch 32/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 4.8446 - mae: 1.7286 - mse: 4.8446 - val_loss: 19.6413 - val_mae: 3.1278 - val_mse: 19.6413\n",
      "Epoch 33/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 4.8969 - mae: 1.7621 - mse: 4.8969 - val_loss: 28.4112 - val_mae: 4.3193 - val_mse: 28.4112\n",
      "Epoch 34/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 4.6926 - mae: 1.7038 - mse: 4.6926 - val_loss: 21.7743 - val_mae: 3.5177 - val_mse: 21.7743\n",
      "Epoch 35/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 4.5977 - mae: 1.6938 - mse: 4.5977 - val_loss: 17.6939 - val_mae: 2.7856 - val_mse: 17.6939\n",
      "Epoch 36/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 4.5747 - mae: 1.6808 - mse: 4.5747 - val_loss: 17.4891 - val_mae: 2.9645 - val_mse: 17.4891\n",
      "Epoch 37/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 4.4766 - mae: 1.6618 - mse: 4.4766 - val_loss: 19.0333 - val_mae: 3.0111 - val_mse: 19.0333\n",
      "Epoch 38/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 4.3637 - mae: 1.6431 - mse: 4.3637 - val_loss: 20.8034 - val_mae: 3.4053 - val_mse: 20.8033\n",
      "Epoch 39/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 4.2955 - mae: 1.6383 - mse: 4.2955 - val_loss: 20.3881 - val_mae: 3.4062 - val_mse: 20.3881\n",
      "Epoch 40/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 4.2100 - mae: 1.6197 - mse: 4.2100 - val_loss: 22.0259 - val_mae: 3.6149 - val_mse: 22.0259\n",
      "Epoch 41/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 4.1824 - mae: 1.6100 - mse: 4.1824 - val_loss: 19.6768 - val_mae: 3.2951 - val_mse: 19.6768\n",
      "Epoch 42/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 4.2232 - mae: 1.6174 - mse: 4.2232 - val_loss: 17.7276 - val_mae: 2.8414 - val_mse: 17.7276\n",
      "Epoch 43/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 3.9997 - mae: 1.5616 - mse: 3.9997 - val_loss: 16.7485 - val_mae: 2.7666 - val_mse: 16.7485\n",
      "Epoch 44/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 3.9844 - mae: 1.5579 - mse: 3.9844 - val_loss: 16.6608 - val_mae: 2.8386 - val_mse: 16.6608\n",
      "Epoch 45/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 3.9067 - mae: 1.5632 - mse: 3.9067 - val_loss: 24.1671 - val_mae: 3.9406 - val_mse: 24.1671\n",
      "Epoch 46/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 3.9123 - mae: 1.5670 - mse: 3.9123 - val_loss: 15.9612 - val_mae: 2.6697 - val_mse: 15.9612\n",
      "Epoch 47/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 3.7850 - mae: 1.5355 - mse: 3.7850 - val_loss: 18.1945 - val_mae: 3.2310 - val_mse: 18.1945\n",
      "Epoch 48/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 3.7668 - mae: 1.5305 - mse: 3.7668 - val_loss: 17.6395 - val_mae: 2.9718 - val_mse: 17.6395\n",
      "Epoch 49/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 3.7558 - mae: 1.5322 - mse: 3.7558 - val_loss: 17.1829 - val_mae: 2.9867 - val_mse: 17.1829\n",
      "Epoch 50/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 3.6007 - mae: 1.4877 - mse: 3.6007 - val_loss: 17.7071 - val_mae: 3.0092 - val_mse: 17.7071\n",
      "Epoch 51/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 3.5801 - mae: 1.4978 - mse: 3.5801 - val_loss: 18.1875 - val_mae: 3.1435 - val_mse: 18.1875\n",
      "Epoch 52/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 3.5515 - mae: 1.4721 - mse: 3.5515 - val_loss: 16.8812 - val_mae: 2.9758 - val_mse: 16.8812\n",
      "Epoch 53/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 3.5407 - mae: 1.4849 - mse: 3.5407 - val_loss: 21.2278 - val_mae: 3.4428 - val_mse: 21.2278\n",
      "Epoch 54/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 3.3439 - mae: 1.4353 - mse: 3.3439 - val_loss: 18.7983 - val_mae: 3.0946 - val_mse: 18.7983\n",
      "Epoch 55/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 3.4164 - mae: 1.4521 - mse: 3.4164 - val_loss: 15.8589 - val_mae: 2.8333 - val_mse: 15.8589\n",
      "Epoch 56/500\n",
      "5833/5833 [==============================] - 0s 43us/sample - loss: 3.4315 - mae: 1.4623 - mse: 3.4315 - val_loss: 15.0713 - val_mae: 2.5771 - val_mse: 15.0713\n",
      "Epoch 57/500\n",
      "5833/5833 [==============================] - 0s 42us/sample - loss: 3.3242 - mae: 1.4468 - mse: 3.3242 - val_loss: 15.9277 - val_mae: 2.7314 - val_mse: 15.9277\n",
      "Epoch 58/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 3.2912 - mae: 1.4296 - mse: 3.2912 - val_loss: 15.3210 - val_mae: 2.7396 - val_mse: 15.3210\n",
      "Epoch 59/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 3.2139 - mae: 1.4150 - mse: 3.2139 - val_loss: 15.2991 - val_mae: 2.7051 - val_mse: 15.2991\n",
      "Epoch 60/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 3.1182 - mae: 1.3840 - mse: 3.1182 - val_loss: 15.9384 - val_mae: 2.6861 - val_mse: 15.9384\n",
      "Epoch 61/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 3.1369 - mae: 1.3949 - mse: 3.1369 - val_loss: 15.2626 - val_mae: 2.6994 - val_mse: 15.2626\n",
      "Epoch 62/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 3.0163 - mae: 1.3583 - mse: 3.0163 - val_loss: 19.3855 - val_mae: 3.3749 - val_mse: 19.3856\n",
      "Epoch 63/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 3.0796 - mae: 1.3757 - mse: 3.0796 - val_loss: 15.2826 - val_mae: 2.6633 - val_mse: 15.2826\n",
      "Epoch 64/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.9699 - mae: 1.3531 - mse: 2.9699 - val_loss: 15.7413 - val_mae: 2.9251 - val_mse: 15.7413\n",
      "Epoch 65/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.9922 - mae: 1.3690 - mse: 2.9922 - val_loss: 14.8568 - val_mae: 2.6440 - val_mse: 14.8568\n",
      "Epoch 66/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.9286 - mae: 1.3393 - mse: 2.9286 - val_loss: 16.7211 - val_mae: 2.8736 - val_mse: 16.7211\n",
      "Epoch 67/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.8642 - mae: 1.3196 - mse: 2.8642 - val_loss: 16.6108 - val_mae: 2.8140 - val_mse: 16.6108\n",
      "Epoch 68/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 2.8454 - mae: 1.3375 - mse: 2.8454 - val_loss: 15.7768 - val_mae: 2.7683 - val_mse: 15.7768\n",
      "Epoch 69/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.7301 - mae: 1.2866 - mse: 2.7301 - val_loss: 14.4907 - val_mae: 2.6891 - val_mse: 14.4907\n",
      "Epoch 70/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.7523 - mae: 1.2988 - mse: 2.7523 - val_loss: 16.3143 - val_mae: 2.7751 - val_mse: 16.3143\n",
      "Epoch 71/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.6739 - mae: 1.2814 - mse: 2.6739 - val_loss: 16.4722 - val_mae: 3.0075 - val_mse: 16.4722\n",
      "Epoch 72/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.6949 - mae: 1.2867 - mse: 2.6949 - val_loss: 14.3417 - val_mae: 2.6344 - val_mse: 14.3417\n",
      "Epoch 73/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.6313 - mae: 1.2785 - mse: 2.6313 - val_loss: 15.1504 - val_mae: 2.8052 - val_mse: 15.1504\n",
      "Epoch 74/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.5600 - mae: 1.2573 - mse: 2.5600 - val_loss: 15.6253 - val_mae: 2.8754 - val_mse: 15.6253\n",
      "Epoch 75/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.6338 - mae: 1.2742 - mse: 2.6338 - val_loss: 14.3599 - val_mae: 2.6156 - val_mse: 14.3599\n",
      "Epoch 76/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.5948 - mae: 1.2686 - mse: 2.5948 - val_loss: 14.5987 - val_mae: 2.7483 - val_mse: 14.5987\n",
      "Epoch 77/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.5328 - mae: 1.2565 - mse: 2.5328 - val_loss: 13.6494 - val_mae: 2.6185 - val_mse: 13.6494\n",
      "Epoch 78/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.4871 - mae: 1.2385 - mse: 2.4871 - val_loss: 14.8276 - val_mae: 2.7813 - val_mse: 14.8276\n",
      "Epoch 79/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.5013 - mae: 1.2433 - mse: 2.5013 - val_loss: 13.1751 - val_mae: 2.4913 - val_mse: 13.1751\n",
      "Epoch 80/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.4331 - mae: 1.2252 - mse: 2.4331 - val_loss: 13.5371 - val_mae: 2.5836 - val_mse: 13.5371\n",
      "Epoch 81/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.3753 - mae: 1.2096 - mse: 2.3753 - val_loss: 16.5464 - val_mae: 3.0941 - val_mse: 16.5464\n",
      "Epoch 82/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.3703 - mae: 1.2115 - mse: 2.3703 - val_loss: 13.1990 - val_mae: 2.6177 - val_mse: 13.1990\n",
      "Epoch 83/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.2963 - mae: 1.1892 - mse: 2.2963 - val_loss: 14.7187 - val_mae: 2.7468 - val_mse: 14.7187\n",
      "Epoch 84/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.2409 - mae: 1.1671 - mse: 2.2409 - val_loss: 14.7305 - val_mae: 2.7175 - val_mse: 14.7305\n",
      "Epoch 85/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.2716 - mae: 1.1849 - mse: 2.2716 - val_loss: 12.8354 - val_mae: 2.6005 - val_mse: 12.8354\n",
      "Epoch 86/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.2453 - mae: 1.1749 - mse: 2.2453 - val_loss: 12.3956 - val_mae: 2.4666 - val_mse: 12.3956\n",
      "Epoch 87/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.1536 - mae: 1.1446 - mse: 2.1536 - val_loss: 13.8204 - val_mae: 2.6966 - val_mse: 13.8204\n",
      "Epoch 88/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.1747 - mae: 1.1549 - mse: 2.1747 - val_loss: 14.9814 - val_mae: 2.8099 - val_mse: 14.9814\n",
      "Epoch 89/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.1583 - mae: 1.1565 - mse: 2.1583 - val_loss: 12.5863 - val_mae: 2.5129 - val_mse: 12.5863\n",
      "Epoch 90/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 2.1709 - mae: 1.1621 - mse: 2.1709 - val_loss: 13.6918 - val_mae: 2.6754 - val_mse: 13.6918\n",
      "Epoch 91/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.1104 - mae: 1.1444 - mse: 2.1103 - val_loss: 12.6697 - val_mae: 2.5039 - val_mse: 12.6697\n",
      "Epoch 92/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.0744 - mae: 1.1358 - mse: 2.0744 - val_loss: 12.5432 - val_mae: 2.4819 - val_mse: 12.5432\n",
      "Epoch 93/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.0993 - mae: 1.1447 - mse: 2.0993 - val_loss: 11.9574 - val_mae: 2.3882 - val_mse: 11.9574\n",
      "Epoch 94/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.0815 - mae: 1.1323 - mse: 2.0815 - val_loss: 12.4222 - val_mae: 2.4016 - val_mse: 12.4222\n",
      "Epoch 95/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.0494 - mae: 1.1217 - mse: 2.0494 - val_loss: 12.7775 - val_mae: 2.4885 - val_mse: 12.7775\n",
      "Epoch 96/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.0447 - mae: 1.1271 - mse: 2.0447 - val_loss: 11.9157 - val_mae: 2.5129 - val_mse: 11.9157\n",
      "Epoch 97/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 2.0177 - mae: 1.1144 - mse: 2.0177 - val_loss: 13.4617 - val_mae: 2.6551 - val_mse: 13.4617\n",
      "Epoch 98/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.9630 - mae: 1.1003 - mse: 1.9630 - val_loss: 14.1534 - val_mae: 2.8109 - val_mse: 14.1534\n",
      "Epoch 99/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.9579 - mae: 1.0983 - mse: 1.9579 - val_loss: 11.9665 - val_mae: 2.4300 - val_mse: 11.9665\n",
      "Epoch 100/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.9448 - mae: 1.0938 - mse: 1.9448 - val_loss: 13.7742 - val_mae: 2.7066 - val_mse: 13.7742\n",
      "Epoch 101/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.9312 - mae: 1.0921 - mse: 1.9312 - val_loss: 11.8783 - val_mae: 2.3545 - val_mse: 11.8783\n",
      "Epoch 102/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.8774 - mae: 1.0753 - mse: 1.8774 - val_loss: 12.0570 - val_mae: 2.3584 - val_mse: 12.0570\n",
      "Epoch 103/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.8844 - mae: 1.0790 - mse: 1.8844 - val_loss: 11.8537 - val_mae: 2.4506 - val_mse: 11.8537\n",
      "Epoch 104/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.8788 - mae: 1.0785 - mse: 1.8788 - val_loss: 11.9693 - val_mae: 2.3960 - val_mse: 11.9693\n",
      "Epoch 105/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.8602 - mae: 1.0703 - mse: 1.8602 - val_loss: 14.9024 - val_mae: 2.8536 - val_mse: 14.9024\n",
      "Epoch 106/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.8006 - mae: 1.0581 - mse: 1.8006 - val_loss: 13.3902 - val_mae: 2.5394 - val_mse: 13.3902\n",
      "Epoch 107/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.8133 - mae: 1.0565 - mse: 1.8133 - val_loss: 11.7862 - val_mae: 2.4691 - val_mse: 11.7862\n",
      "Epoch 108/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.7696 - mae: 1.0395 - mse: 1.7696 - val_loss: 14.4159 - val_mae: 2.6838 - val_mse: 14.4159\n",
      "Epoch 109/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.7781 - mae: 1.0432 - mse: 1.7781 - val_loss: 11.6242 - val_mae: 2.3133 - val_mse: 11.6242\n",
      "Epoch 110/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.7705 - mae: 1.0464 - mse: 1.7705 - val_loss: 13.1836 - val_mae: 2.6322 - val_mse: 13.1836\n",
      "Epoch 111/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.7314 - mae: 1.0274 - mse: 1.7314 - val_loss: 12.2791 - val_mae: 2.3818 - val_mse: 12.2791\n",
      "Epoch 112/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.7069 - mae: 1.0231 - mse: 1.7069 - val_loss: 12.2264 - val_mae: 2.4324 - val_mse: 12.2264\n",
      "Epoch 113/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.7026 - mae: 1.0255 - mse: 1.7026 - val_loss: 11.7814 - val_mae: 2.3594 - val_mse: 11.7814\n",
      "Epoch 114/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 1.6855 - mae: 1.0174 - mse: 1.6855 - val_loss: 12.2189 - val_mae: 2.3896 - val_mse: 12.2189\n",
      "Epoch 115/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.6674 - mae: 1.0073 - mse: 1.6674 - val_loss: 13.5151 - val_mae: 2.5817 - val_mse: 13.5151\n",
      "Epoch 116/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.6503 - mae: 1.0092 - mse: 1.6503 - val_loss: 12.7928 - val_mae: 2.6172 - val_mse: 12.7928\n",
      "Epoch 117/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.6689 - mae: 1.0074 - mse: 1.6689 - val_loss: 11.9260 - val_mae: 2.3751 - val_mse: 11.9260\n",
      "Epoch 118/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.6368 - mae: 1.0041 - mse: 1.6368 - val_loss: 15.1130 - val_mae: 2.8470 - val_mse: 15.1130\n",
      "Epoch 119/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.6582 - mae: 1.0037 - mse: 1.6582 - val_loss: 11.7006 - val_mae: 2.3182 - val_mse: 11.7006\n",
      "Epoch 120/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.6316 - mae: 1.0006 - mse: 1.6316 - val_loss: 11.7916 - val_mae: 2.3736 - val_mse: 11.7916\n",
      "Epoch 121/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.5884 - mae: 0.9836 - mse: 1.5884 - val_loss: 13.9353 - val_mae: 2.6477 - val_mse: 13.9353\n",
      "Epoch 122/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.6138 - mae: 0.9952 - mse: 1.6138 - val_loss: 12.4580 - val_mae: 2.4452 - val_mse: 12.4580\n",
      "Epoch 123/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.5941 - mae: 0.9886 - mse: 1.5941 - val_loss: 13.6086 - val_mae: 2.6057 - val_mse: 13.6086\n",
      "Epoch 124/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.5819 - mae: 0.9820 - mse: 1.5819 - val_loss: 11.5491 - val_mae: 2.2899 - val_mse: 11.5491\n",
      "Epoch 125/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.5796 - mae: 0.9799 - mse: 1.5796 - val_loss: 14.8469 - val_mae: 2.7920 - val_mse: 14.8469\n",
      "Epoch 126/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.5750 - mae: 0.9842 - mse: 1.5750 - val_loss: 12.3526 - val_mae: 2.4101 - val_mse: 12.3526\n",
      "Epoch 127/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.5326 - mae: 0.9655 - mse: 1.5326 - val_loss: 12.2279 - val_mae: 2.3981 - val_mse: 12.2279\n",
      "Epoch 128/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.5247 - mae: 0.9683 - mse: 1.5247 - val_loss: 12.3808 - val_mae: 2.5556 - val_mse: 12.3808\n",
      "Epoch 129/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.5145 - mae: 0.9640 - mse: 1.5145 - val_loss: 12.2830 - val_mae: 2.5738 - val_mse: 12.2830\n",
      "Epoch 130/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.5232 - mae: 0.9664 - mse: 1.5232 - val_loss: 13.9176 - val_mae: 2.6131 - val_mse: 13.9176\n",
      "Epoch 131/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.4852 - mae: 0.9541 - mse: 1.4852 - val_loss: 12.8581 - val_mae: 2.5141 - val_mse: 12.8581\n",
      "Epoch 132/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.4959 - mae: 0.9555 - mse: 1.4959 - val_loss: 11.9488 - val_mae: 2.4394 - val_mse: 11.9488\n",
      "Epoch 133/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.4950 - mae: 0.9552 - mse: 1.4950 - val_loss: 12.1805 - val_mae: 2.4321 - val_mse: 12.1805\n",
      "Epoch 134/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.4694 - mae: 0.9490 - mse: 1.4694 - val_loss: 12.1719 - val_mae: 2.4244 - val_mse: 12.1719\n",
      "Epoch 135/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.4748 - mae: 0.9468 - mse: 1.4748 - val_loss: 15.1562 - val_mae: 2.7877 - val_mse: 15.1562\n",
      "Epoch 136/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.4569 - mae: 0.9431 - mse: 1.4569 - val_loss: 12.7970 - val_mae: 2.4833 - val_mse: 12.7970\n",
      "Epoch 137/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.4163 - mae: 0.9260 - mse: 1.4163 - val_loss: 11.3322 - val_mae: 2.3026 - val_mse: 11.3322\n",
      "Epoch 138/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.4143 - mae: 0.9269 - mse: 1.4143 - val_loss: 13.5698 - val_mae: 2.5545 - val_mse: 13.5698\n",
      "Epoch 139/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.4231 - mae: 0.9268 - mse: 1.4231 - val_loss: 12.0033 - val_mae: 2.3397 - val_mse: 12.0033\n",
      "Epoch 140/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.4037 - mae: 0.9197 - mse: 1.4037 - val_loss: 11.7263 - val_mae: 2.3317 - val_mse: 11.7263\n",
      "Epoch 141/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.3962 - mae: 0.9217 - mse: 1.3962 - val_loss: 11.7983 - val_mae: 2.4565 - val_mse: 11.7983\n",
      "Epoch 142/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.4037 - mae: 0.9195 - mse: 1.4037 - val_loss: 11.8699 - val_mae: 2.3903 - val_mse: 11.8699\n",
      "Epoch 143/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.4064 - mae: 0.9224 - mse: 1.4064 - val_loss: 11.8883 - val_mae: 2.3371 - val_mse: 11.8883\n",
      "Epoch 144/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.3822 - mae: 0.9134 - mse: 1.3822 - val_loss: 13.0559 - val_mae: 2.5708 - val_mse: 13.0559\n",
      "Epoch 145/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.3863 - mae: 0.9138 - mse: 1.3863 - val_loss: 15.4079 - val_mae: 2.8801 - val_mse: 15.4079\n",
      "Epoch 146/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.3385 - mae: 0.8982 - mse: 1.3385 - val_loss: 11.9000 - val_mae: 2.4677 - val_mse: 11.9000\n",
      "Epoch 147/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.3376 - mae: 0.8990 - mse: 1.3376 - val_loss: 12.4378 - val_mae: 2.4121 - val_mse: 12.4378\n",
      "Epoch 148/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.3312 - mae: 0.8961 - mse: 1.3312 - val_loss: 11.4626 - val_mae: 2.3902 - val_mse: 11.4626\n",
      "Epoch 149/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.3467 - mae: 0.9031 - mse: 1.3467 - val_loss: 10.9341 - val_mae: 2.2989 - val_mse: 10.9341\n",
      "Epoch 150/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.3330 - mae: 0.8975 - mse: 1.3330 - val_loss: 13.3179 - val_mae: 2.5666 - val_mse: 13.3179\n",
      "Epoch 151/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.3278 - mae: 0.8932 - mse: 1.3278 - val_loss: 12.4701 - val_mae: 2.5378 - val_mse: 12.4701\n",
      "Epoch 152/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.3142 - mae: 0.8897 - mse: 1.3142 - val_loss: 11.2468 - val_mae: 2.3155 - val_mse: 11.2468\n",
      "Epoch 153/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.3018 - mae: 0.8872 - mse: 1.3018 - val_loss: 13.9348 - val_mae: 2.6806 - val_mse: 13.9348\n",
      "Epoch 154/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.2988 - mae: 0.8819 - mse: 1.2988 - val_loss: 12.7906 - val_mae: 2.4795 - val_mse: 12.7906\n",
      "Epoch 155/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.2903 - mae: 0.8808 - mse: 1.2903 - val_loss: 12.5566 - val_mae: 2.4560 - val_mse: 12.5566\n",
      "Epoch 156/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.2757 - mae: 0.8756 - mse: 1.2757 - val_loss: 11.6994 - val_mae: 2.3174 - val_mse: 11.6994\n",
      "Epoch 157/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.2743 - mae: 0.8789 - mse: 1.2743 - val_loss: 11.5935 - val_mae: 2.3941 - val_mse: 11.5935\n",
      "Epoch 158/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.2736 - mae: 0.8706 - mse: 1.2736 - val_loss: 11.9675 - val_mae: 2.3711 - val_mse: 11.9675\n",
      "Epoch 159/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.2736 - mae: 0.8703 - mse: 1.2736 - val_loss: 11.7162 - val_mae: 2.3502 - val_mse: 11.7162\n",
      "Epoch 160/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.2518 - mae: 0.8625 - mse: 1.2518 - val_loss: 12.9150 - val_mae: 2.4968 - val_mse: 12.9150\n",
      "Epoch 161/500\n",
      "5833/5833 [==============================] - 0s 40us/sample - loss: 1.2619 - mae: 0.8688 - mse: 1.2619 - val_loss: 11.0737 - val_mae: 2.2939 - val_mse: 11.0737\n",
      "Epoch 162/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.2423 - mae: 0.8617 - mse: 1.2423 - val_loss: 11.3006 - val_mae: 2.3898 - val_mse: 11.3006\n",
      "Epoch 163/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.2365 - mae: 0.8562 - mse: 1.2365 - val_loss: 12.9979 - val_mae: 2.4939 - val_mse: 12.9979\n",
      "Epoch 164/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.2531 - mae: 0.8662 - mse: 1.2531 - val_loss: 12.0231 - val_mae: 2.4656 - val_mse: 12.0231\n",
      "Epoch 165/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.2206 - mae: 0.8526 - mse: 1.2206 - val_loss: 11.9123 - val_mae: 2.3448 - val_mse: 11.9123\n",
      "Epoch 166/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.2066 - mae: 0.8547 - mse: 1.2066 - val_loss: 11.5921 - val_mae: 2.4237 - val_mse: 11.5921\n",
      "Epoch 167/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.2067 - mae: 0.8514 - mse: 1.2067 - val_loss: 11.7497 - val_mae: 2.3263 - val_mse: 11.7497\n",
      "Epoch 168/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 1.2018 - mae: 0.8459 - mse: 1.2018 - val_loss: 12.0515 - val_mae: 2.4183 - val_mse: 12.0515\n",
      "Epoch 169/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.2019 - mae: 0.8461 - mse: 1.2019 - val_loss: 12.5365 - val_mae: 2.4528 - val_mse: 12.5365\n",
      "Epoch 170/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1878 - mae: 0.8390 - mse: 1.1878 - val_loss: 13.0165 - val_mae: 2.4592 - val_mse: 13.0165\n",
      "Epoch 171/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 1.1891 - mae: 0.8433 - mse: 1.1891 - val_loss: 11.6648 - val_mae: 2.4017 - val_mse: 11.6648\n",
      "Epoch 172/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1968 - mae: 0.8465 - mse: 1.1968 - val_loss: 13.2275 - val_mae: 2.5725 - val_mse: 13.2275\n",
      "Epoch 173/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.2000 - mae: 0.8479 - mse: 1.2000 - val_loss: 11.3179 - val_mae: 2.2490 - val_mse: 11.3179\n",
      "Epoch 174/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1808 - mae: 0.8399 - mse: 1.1808 - val_loss: 11.3125 - val_mae: 2.2831 - val_mse: 11.3125\n",
      "Epoch 175/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1788 - mae: 0.8396 - mse: 1.1788 - val_loss: 12.4731 - val_mae: 2.3900 - val_mse: 12.4731\n",
      "Epoch 176/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1859 - mae: 0.8378 - mse: 1.1859 - val_loss: 12.0363 - val_mae: 2.3359 - val_mse: 12.0363\n",
      "Epoch 177/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1764 - mae: 0.8405 - mse: 1.1764 - val_loss: 13.3062 - val_mae: 2.5730 - val_mse: 13.3062\n",
      "Epoch 178/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1720 - mae: 0.8399 - mse: 1.1720 - val_loss: 11.9847 - val_mae: 2.3279 - val_mse: 11.9847\n",
      "Epoch 179/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1664 - mae: 0.8350 - mse: 1.1664 - val_loss: 12.3772 - val_mae: 2.4217 - val_mse: 12.3772\n",
      "Epoch 180/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1685 - mae: 0.8322 - mse: 1.1685 - val_loss: 12.6939 - val_mae: 2.4123 - val_mse: 12.6939\n",
      "Epoch 181/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.1451 - mae: 0.8286 - mse: 1.1451 - val_loss: 15.3830 - val_mae: 2.7726 - val_mse: 15.3830\n",
      "Epoch 182/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1501 - mae: 0.8236 - mse: 1.1501 - val_loss: 12.6967 - val_mae: 2.4753 - val_mse: 12.6967\n",
      "Epoch 183/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1514 - mae: 0.8281 - mse: 1.1514 - val_loss: 11.9728 - val_mae: 2.3096 - val_mse: 11.9728\n",
      "Epoch 184/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1576 - mae: 0.8270 - mse: 1.1576 - val_loss: 11.7698 - val_mae: 2.4169 - val_mse: 11.7698\n",
      "Epoch 185/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1504 - mae: 0.8268 - mse: 1.1504 - val_loss: 12.4972 - val_mae: 2.3710 - val_mse: 12.4972\n",
      "Epoch 186/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1477 - mae: 0.8271 - mse: 1.1477 - val_loss: 12.7837 - val_mae: 2.4561 - val_mse: 12.7837\n",
      "Epoch 187/500\n",
      "5833/5833 [==============================] - 0s 41us/sample - loss: 1.1505 - mae: 0.8325 - mse: 1.1505 - val_loss: 11.8371 - val_mae: 2.3089 - val_mse: 11.8371\n",
      "Epoch 188/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1271 - mae: 0.8197 - mse: 1.1271 - val_loss: 12.0067 - val_mae: 2.4305 - val_mse: 12.0067\n",
      "Epoch 189/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1330 - mae: 0.8230 - mse: 1.1330 - val_loss: 11.7522 - val_mae: 2.3420 - val_mse: 11.7522\n",
      "Epoch 190/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1144 - mae: 0.8226 - mse: 1.1144 - val_loss: 13.0459 - val_mae: 2.4893 - val_mse: 13.0459\n",
      "Epoch 191/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1131 - mae: 0.8164 - mse: 1.1131 - val_loss: 12.2131 - val_mae: 2.4826 - val_mse: 12.2131\n",
      "Epoch 192/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1090 - mae: 0.8122 - mse: 1.1090 - val_loss: 13.8523 - val_mae: 2.5425 - val_mse: 13.8523\n",
      "Epoch 193/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1013 - mae: 0.8083 - mse: 1.1013 - val_loss: 11.5044 - val_mae: 2.2676 - val_mse: 11.5044\n",
      "Epoch 194/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1212 - mae: 0.8174 - mse: 1.1212 - val_loss: 13.6933 - val_mae: 2.5219 - val_mse: 13.6933\n",
      "Epoch 195/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1356 - mae: 0.8198 - mse: 1.1356 - val_loss: 12.4043 - val_mae: 2.3256 - val_mse: 12.4043\n",
      "Epoch 196/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.0779 - mae: 0.7997 - mse: 1.0779 - val_loss: 11.5812 - val_mae: 2.3145 - val_mse: 11.5812\n",
      "Epoch 197/500\n",
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.1123 - mae: 0.8150 - mse: 1.1123 - val_loss: 12.7022 - val_mae: 2.4173 - val_mse: 12.7022\n",
      "Epoch 198/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5833/5833 [==============================] - 0s 39us/sample - loss: 1.0982 - mae: 0.8082 - mse: 1.0982 - val_loss: 13.2861 - val_mae: 2.6376 - val_mse: 13.2861\n",
      "Epoch 199/500\n",
      "5833/5833 [==============================] - 0s 38us/sample - loss: 1.1140 - mae: 0.8129 - mse: 1.1140 - val_loss: 12.0606 - val_mae: 2.2991 - val_mse: 12.0606\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7291 samples, validate on 2430 samples\n",
      "Epoch 1/500\n",
      "7291/7291 [==============================] - 1s 86us/sample - loss: 135.4260 - mae: 6.2527 - mse: 135.4261 - val_loss: 55.4817 - val_mae: 5.1916 - val_mse: 55.4817\n",
      "Epoch 2/500\n",
      "7291/7291 [==============================] - 0s 37us/sample - loss: 19.1014 - mae: 3.1257 - mse: 19.1014 - val_loss: 30.5610 - val_mae: 3.7569 - val_mse: 30.5610\n",
      "Epoch 3/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 12.5807 - mae: 2.5904 - mse: 12.5807 - val_loss: 25.8343 - val_mae: 3.4002 - val_mse: 25.8343\n",
      "Epoch 4/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 10.0192 - mae: 2.3714 - mse: 10.0192 - val_loss: 22.6688 - val_mae: 3.1944 - val_mse: 22.6688\n",
      "Epoch 5/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 8.7369 - mae: 2.2210 - mse: 8.7369 - val_loss: 20.0469 - val_mae: 2.8581 - val_mse: 20.0469\n",
      "Epoch 6/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 8.0520 - mae: 2.1763 - mse: 8.0520 - val_loss: 22.9465 - val_mae: 3.3695 - val_mse: 22.9465\n",
      "Epoch 7/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 7.3940 - mae: 2.0932 - mse: 7.3940 - val_loss: 22.7361 - val_mae: 3.4189 - val_mse: 22.7361\n",
      "Epoch 8/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 7.1262 - mae: 2.0608 - mse: 7.1262 - val_loss: 21.4171 - val_mae: 3.2374 - val_mse: 21.4171\n",
      "Epoch 9/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 6.7091 - mae: 2.0252 - mse: 6.7091 - val_loss: 21.5967 - val_mae: 3.1952 - val_mse: 21.5967\n",
      "Epoch 10/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 6.3337 - mae: 1.9491 - mse: 6.3337 - val_loss: 17.1364 - val_mae: 2.5264 - val_mse: 17.1364\n",
      "Epoch 11/500\n",
      "7291/7291 [==============================] - 0s 52us/sample - loss: 6.1364 - mae: 1.9111 - mse: 6.1364 - val_loss: 20.7337 - val_mae: 3.1194 - val_mse: 20.7337\n",
      "Epoch 12/500\n",
      "7291/7291 [==============================] - 0s 43us/sample - loss: 6.0055 - mae: 1.8927 - mse: 6.0055 - val_loss: 25.9390 - val_mae: 3.8526 - val_mse: 25.9390\n",
      "Epoch 13/500\n",
      "7291/7291 [==============================] - 0s 43us/sample - loss: 5.9464 - mae: 1.9135 - mse: 5.9464 - val_loss: 18.7541 - val_mae: 3.0770 - val_mse: 18.7541\n",
      "Epoch 14/500\n",
      "7291/7291 [==============================] - 0s 56us/sample - loss: 5.6294 - mae: 1.8740 - mse: 5.6294 - val_loss: 17.9261 - val_mae: 2.7945 - val_mse: 17.9261\n",
      "Epoch 15/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 5.4938 - mae: 1.8157 - mse: 5.4938 - val_loss: 22.6786 - val_mae: 3.5685 - val_mse: 22.6786\n",
      "Epoch 16/500\n",
      "7291/7291 [==============================] - 0s 50us/sample - loss: 5.2740 - mae: 1.7751 - mse: 5.2740 - val_loss: 18.4127 - val_mae: 2.9868 - val_mse: 18.4127\n",
      "Epoch 17/500\n",
      "7291/7291 [==============================] - 0s 41us/sample - loss: 5.1563 - mae: 1.8047 - mse: 5.1563 - val_loss: 23.8559 - val_mae: 3.6241 - val_mse: 23.8559\n",
      "Epoch 18/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 5.0262 - mae: 1.7443 - mse: 5.0262 - val_loss: 17.7280 - val_mae: 2.8797 - val_mse: 17.7280\n",
      "Epoch 19/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 4.9612 - mae: 1.7660 - mse: 4.9612 - val_loss: 18.2061 - val_mae: 2.8224 - val_mse: 18.2061\n",
      "Epoch 20/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 4.7454 - mae: 1.7236 - mse: 4.7454 - val_loss: 18.0400 - val_mae: 2.6579 - val_mse: 18.0400\n",
      "Epoch 21/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 4.5309 - mae: 1.6750 - mse: 4.5309 - val_loss: 17.7691 - val_mae: 2.7578 - val_mse: 17.7691\n",
      "Epoch 22/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 4.4226 - mae: 1.6473 - mse: 4.4226 - val_loss: 17.3374 - val_mae: 2.6769 - val_mse: 17.3374\n",
      "Epoch 23/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 4.3622 - mae: 1.6414 - mse: 4.3622 - val_loss: 24.0549 - val_mae: 3.6268 - val_mse: 24.0549\n",
      "Epoch 24/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 4.2330 - mae: 1.6200 - mse: 4.2330 - val_loss: 17.1196 - val_mae: 2.6282 - val_mse: 17.1196\n",
      "Epoch 25/500\n",
      "7291/7291 [==============================] - 0s 52us/sample - loss: 4.1727 - mae: 1.6182 - mse: 4.1727 - val_loss: 20.0223 - val_mae: 3.0658 - val_mse: 20.0223\n",
      "Epoch 26/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 4.0576 - mae: 1.5965 - mse: 4.0576 - val_loss: 16.0237 - val_mae: 2.4215 - val_mse: 16.0237\n",
      "Epoch 27/500\n",
      "7291/7291 [==============================] - 0s 53us/sample - loss: 3.9386 - mae: 1.5508 - mse: 3.9386 - val_loss: 16.1690 - val_mae: 2.3126 - val_mse: 16.1690\n",
      "Epoch 28/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 3.8464 - mae: 1.5402 - mse: 3.8464 - val_loss: 17.7776 - val_mae: 2.7994 - val_mse: 17.7776\n",
      "Epoch 29/500\n",
      "7291/7291 [==============================] - 0s 42us/sample - loss: 3.8403 - mae: 1.5449 - mse: 3.8403 - val_loss: 17.0082 - val_mae: 2.6189 - val_mse: 17.0082\n",
      "Epoch 30/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 3.7003 - mae: 1.4983 - mse: 3.7003 - val_loss: 16.6701 - val_mae: 2.4882 - val_mse: 16.6701\n",
      "Epoch 31/500\n",
      "7291/7291 [==============================] - 0s 41us/sample - loss: 3.6890 - mae: 1.5121 - mse: 3.6890 - val_loss: 17.7791 - val_mae: 2.6712 - val_mse: 17.7791\n",
      "Epoch 32/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 3.6468 - mae: 1.5016 - mse: 3.6468 - val_loss: 17.6285 - val_mae: 2.6555 - val_mse: 17.6285\n",
      "Epoch 33/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 3.5032 - mae: 1.4750 - mse: 3.5032 - val_loss: 16.4214 - val_mae: 2.4543 - val_mse: 16.4214\n",
      "Epoch 34/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 3.4594 - mae: 1.4695 - mse: 3.4594 - val_loss: 16.5256 - val_mae: 2.4826 - val_mse: 16.5256\n",
      "Epoch 35/500\n",
      "7291/7291 [==============================] - 0s 52us/sample - loss: 3.4490 - mae: 1.4752 - mse: 3.4490 - val_loss: 15.9564 - val_mae: 2.3383 - val_mse: 15.9564\n",
      "Epoch 36/500\n",
      "7291/7291 [==============================] - 0s 48us/sample - loss: 3.3284 - mae: 1.4437 - mse: 3.3284 - val_loss: 18.0796 - val_mae: 2.8882 - val_mse: 18.0796\n",
      "Epoch 37/500\n",
      "7291/7291 [==============================] - 0s 44us/sample - loss: 3.2867 - mae: 1.4290 - mse: 3.2867 - val_loss: 16.4406 - val_mae: 2.3909 - val_mse: 16.4406\n",
      "Epoch 38/500\n",
      "7291/7291 [==============================] - 0s 51us/sample - loss: 3.2621 - mae: 1.4257 - mse: 3.2621 - val_loss: 16.5631 - val_mae: 2.4939 - val_mse: 16.5631\n",
      "Epoch 39/500\n",
      "7291/7291 [==============================] - 0s 41us/sample - loss: 3.1949 - mae: 1.4158 - mse: 3.1949 - val_loss: 18.9093 - val_mae: 2.8871 - val_mse: 18.9093\n",
      "Epoch 40/500\n",
      "7291/7291 [==============================] - 0s 53us/sample - loss: 3.0973 - mae: 1.3819 - mse: 3.0973 - val_loss: 16.6928 - val_mae: 2.6668 - val_mse: 16.6928\n",
      "Epoch 41/500\n",
      "7291/7291 [==============================] - 0s 41us/sample - loss: 3.0394 - mae: 1.3687 - mse: 3.0394 - val_loss: 16.3226 - val_mae: 2.4303 - val_mse: 16.3226\n",
      "Epoch 42/500\n",
      "7291/7291 [==============================] - 0s 54us/sample - loss: 3.0478 - mae: 1.3874 - mse: 3.0478 - val_loss: 16.5545 - val_mae: 2.4958 - val_mse: 16.5545\n",
      "Epoch 43/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 3.0029 - mae: 1.3722 - mse: 3.0029 - val_loss: 19.6016 - val_mae: 3.0458 - val_mse: 19.6016\n",
      "Epoch 44/500\n",
      "7291/7291 [==============================] - 0s 41us/sample - loss: 2.9241 - mae: 1.3414 - mse: 2.9241 - val_loss: 16.2641 - val_mae: 2.4855 - val_mse: 16.2641\n",
      "Epoch 45/500\n",
      "7291/7291 [==============================] - 0s 43us/sample - loss: 2.8634 - mae: 1.3311 - mse: 2.8634 - val_loss: 15.0932 - val_mae: 2.3395 - val_mse: 15.0932\n",
      "Epoch 46/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 2.7599 - mae: 1.2953 - mse: 2.7599 - val_loss: 15.4461 - val_mae: 2.3666 - val_mse: 15.4461\n",
      "Epoch 47/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 2.7701 - mae: 1.3081 - mse: 2.7701 - val_loss: 17.5705 - val_mae: 2.7904 - val_mse: 17.5705\n",
      "Epoch 48/500\n",
      "7291/7291 [==============================] - 0s 45us/sample - loss: 2.7389 - mae: 1.2874 - mse: 2.7389 - val_loss: 15.3456 - val_mae: 2.4493 - val_mse: 15.3456\n",
      "Epoch 49/500\n",
      "7291/7291 [==============================] - 0s 41us/sample - loss: 2.6733 - mae: 1.2915 - mse: 2.6733 - val_loss: 15.3615 - val_mae: 2.2919 - val_mse: 15.3614\n",
      "Epoch 50/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 2.5902 - mae: 1.2648 - mse: 2.5902 - val_loss: 15.6722 - val_mae: 2.4198 - val_mse: 15.6722\n",
      "Epoch 51/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 2.6479 - mae: 1.2801 - mse: 2.6479 - val_loss: 14.7893 - val_mae: 2.1644 - val_mse: 14.7893\n",
      "Epoch 52/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 2.5670 - mae: 1.2638 - mse: 2.5670 - val_loss: 17.0120 - val_mae: 2.6610 - val_mse: 17.0120\n",
      "Epoch 53/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 2.5652 - mae: 1.2679 - mse: 2.5652 - val_loss: 16.1362 - val_mae: 2.4318 - val_mse: 16.1362\n",
      "Epoch 54/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 2.4767 - mae: 1.2469 - mse: 2.4767 - val_loss: 15.1028 - val_mae: 2.2022 - val_mse: 15.1028\n",
      "Epoch 55/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 2.4746 - mae: 1.2395 - mse: 2.4746 - val_loss: 15.1827 - val_mae: 2.2205 - val_mse: 15.1827\n",
      "Epoch 56/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 2.3890 - mae: 1.2249 - mse: 2.3890 - val_loss: 15.6520 - val_mae: 2.4711 - val_mse: 15.6520\n",
      "Epoch 57/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 2.4027 - mae: 1.2244 - mse: 2.4027 - val_loss: 16.4751 - val_mae: 2.5534 - val_mse: 16.4751\n",
      "Epoch 58/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 2.3696 - mae: 1.2125 - mse: 2.3696 - val_loss: 15.3318 - val_mae: 2.3006 - val_mse: 15.3318\n",
      "Epoch 59/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 2.3446 - mae: 1.2046 - mse: 2.3446 - val_loss: 17.9533 - val_mae: 2.6883 - val_mse: 17.9533\n",
      "Epoch 60/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 2.3030 - mae: 1.2002 - mse: 2.3030 - val_loss: 16.3062 - val_mae: 2.5819 - val_mse: 16.3062\n",
      "Epoch 61/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 2.2582 - mae: 1.1873 - mse: 2.2582 - val_loss: 15.6910 - val_mae: 2.3894 - val_mse: 15.6910\n",
      "Epoch 62/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 2.2367 - mae: 1.1752 - mse: 2.2367 - val_loss: 14.3513 - val_mae: 2.1493 - val_mse: 14.3513\n",
      "Epoch 63/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 2.2460 - mae: 1.1870 - mse: 2.2460 - val_loss: 14.7541 - val_mae: 2.1942 - val_mse: 14.7541\n",
      "Epoch 64/500\n",
      "7291/7291 [==============================] - 0s 41us/sample - loss: 2.1592 - mae: 1.1523 - mse: 2.1592 - val_loss: 15.3636 - val_mae: 2.3071 - val_mse: 15.3635\n",
      "Epoch 65/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 2.1811 - mae: 1.1649 - mse: 2.1811 - val_loss: 14.7079 - val_mae: 2.1744 - val_mse: 14.7079\n",
      "Epoch 66/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 2.1339 - mae: 1.1504 - mse: 2.1339 - val_loss: 15.2029 - val_mae: 2.4348 - val_mse: 15.2029\n",
      "Epoch 67/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 2.1560 - mae: 1.1686 - mse: 2.1560 - val_loss: 14.2212 - val_mae: 2.1740 - val_mse: 14.2212\n",
      "Epoch 68/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 2.0983 - mae: 1.1333 - mse: 2.0983 - val_loss: 14.5299 - val_mae: 2.1543 - val_mse: 14.5299\n",
      "Epoch 69/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 2.0817 - mae: 1.1372 - mse: 2.0817 - val_loss: 14.2368 - val_mae: 2.1398 - val_mse: 14.2368\n",
      "Epoch 70/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 2.0804 - mae: 1.1389 - mse: 2.0804 - val_loss: 16.3818 - val_mae: 2.5759 - val_mse: 16.3818\n",
      "Epoch 71/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 2.0139 - mae: 1.1159 - mse: 2.0139 - val_loss: 14.4339 - val_mae: 2.2069 - val_mse: 14.4339\n",
      "Epoch 72/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 2.0023 - mae: 1.1148 - mse: 2.0023 - val_loss: 14.9465 - val_mae: 2.2742 - val_mse: 14.9465\n",
      "Epoch 73/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.9618 - mae: 1.0940 - mse: 1.9618 - val_loss: 14.1205 - val_mae: 2.1467 - val_mse: 14.1205\n",
      "Epoch 74/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 2.0153 - mae: 1.1215 - mse: 2.0153 - val_loss: 14.5355 - val_mae: 2.2449 - val_mse: 14.5355\n",
      "Epoch 75/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 1.9470 - mae: 1.0998 - mse: 1.9470 - val_loss: 15.0196 - val_mae: 2.3979 - val_mse: 15.0196\n",
      "Epoch 76/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 1.9649 - mae: 1.1031 - mse: 1.9649 - val_loss: 14.1575 - val_mae: 2.1162 - val_mse: 14.1575\n",
      "Epoch 77/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 1.8803 - mae: 1.0773 - mse: 1.8803 - val_loss: 14.2333 - val_mae: 2.2159 - val_mse: 14.2333\n",
      "Epoch 78/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.9143 - mae: 1.0844 - mse: 1.9143 - val_loss: 14.0006 - val_mae: 2.1233 - val_mse: 14.0006\n",
      "Epoch 79/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 1.8355 - mae: 1.0600 - mse: 1.8355 - val_loss: 14.2409 - val_mae: 2.2399 - val_mse: 14.2409\n",
      "Epoch 80/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.8648 - mae: 1.0744 - mse: 1.8648 - val_loss: 16.7916 - val_mae: 2.6626 - val_mse: 16.7916\n",
      "Epoch 81/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.8234 - mae: 1.0576 - mse: 1.8234 - val_loss: 14.3777 - val_mae: 2.3490 - val_mse: 14.3777\n",
      "Epoch 82/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.8238 - mae: 1.0548 - mse: 1.8238 - val_loss: 14.7156 - val_mae: 2.3062 - val_mse: 14.7156\n",
      "Epoch 83/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 1.7692 - mae: 1.0475 - mse: 1.7692 - val_loss: 14.0204 - val_mae: 2.1782 - val_mse: 14.0204\n",
      "Epoch 84/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.7832 - mae: 1.0458 - mse: 1.7832 - val_loss: 13.4607 - val_mae: 2.1239 - val_mse: 13.4607\n",
      "Epoch 85/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 1.7630 - mae: 1.0377 - mse: 1.7630 - val_loss: 14.1049 - val_mae: 2.2193 - val_mse: 14.1049\n",
      "Epoch 86/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.7449 - mae: 1.0347 - mse: 1.7449 - val_loss: 13.1324 - val_mae: 2.0522 - val_mse: 13.1324\n",
      "Epoch 87/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 1.7192 - mae: 1.0266 - mse: 1.7192 - val_loss: 13.8163 - val_mae: 2.1884 - val_mse: 13.8163\n",
      "Epoch 88/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.7339 - mae: 1.0310 - mse: 1.7339 - val_loss: 13.2821 - val_mae: 2.0993 - val_mse: 13.2821\n",
      "Epoch 89/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.6944 - mae: 1.0230 - mse: 1.6944 - val_loss: 14.6903 - val_mae: 2.3161 - val_mse: 14.6903\n",
      "Epoch 90/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.6687 - mae: 1.0104 - mse: 1.6687 - val_loss: 13.1336 - val_mae: 2.1894 - val_mse: 13.1336\n",
      "Epoch 91/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.6725 - mae: 1.0110 - mse: 1.6725 - val_loss: 12.8254 - val_mae: 2.0921 - val_mse: 12.8254\n",
      "Epoch 92/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.6572 - mae: 1.0080 - mse: 1.6572 - val_loss: 12.8380 - val_mae: 2.1396 - val_mse: 12.8380\n",
      "Epoch 93/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.6523 - mae: 1.0070 - mse: 1.6523 - val_loss: 13.2480 - val_mae: 2.3253 - val_mse: 13.2480\n",
      "Epoch 94/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.5956 - mae: 0.9781 - mse: 1.5956 - val_loss: 13.4033 - val_mae: 2.1680 - val_mse: 13.4033\n",
      "Epoch 95/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.5948 - mae: 0.9871 - mse: 1.5948 - val_loss: 14.2165 - val_mae: 2.2673 - val_mse: 14.2165\n",
      "Epoch 96/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.5929 - mae: 0.9763 - mse: 1.5929 - val_loss: 12.7487 - val_mae: 2.0707 - val_mse: 12.7487\n",
      "Epoch 97/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.5645 - mae: 0.9769 - mse: 1.5645 - val_loss: 13.1324 - val_mae: 2.1183 - val_mse: 13.1324\n",
      "Epoch 98/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.5719 - mae: 0.9757 - mse: 1.5719 - val_loss: 12.6864 - val_mae: 2.0712 - val_mse: 12.6864\n",
      "Epoch 99/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.5221 - mae: 0.9674 - mse: 1.5221 - val_loss: 12.0867 - val_mae: 1.9817 - val_mse: 12.0867\n",
      "Epoch 100/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.5190 - mae: 0.9621 - mse: 1.5190 - val_loss: 12.7089 - val_mae: 2.1156 - val_mse: 12.7089\n",
      "Epoch 101/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.5258 - mae: 0.9622 - mse: 1.5258 - val_loss: 12.8722 - val_mae: 2.0501 - val_mse: 12.8722\n",
      "Epoch 102/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.5223 - mae: 0.9606 - mse: 1.5223 - val_loss: 12.0792 - val_mae: 2.0723 - val_mse: 12.0792\n",
      "Epoch 103/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.5074 - mae: 0.9569 - mse: 1.5074 - val_loss: 13.1620 - val_mae: 2.1956 - val_mse: 13.1620\n",
      "Epoch 104/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.4922 - mae: 0.9513 - mse: 1.4922 - val_loss: 12.1930 - val_mae: 2.1765 - val_mse: 12.1930\n",
      "Epoch 105/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.4661 - mae: 0.9476 - mse: 1.4661 - val_loss: 12.1698 - val_mae: 2.1126 - val_mse: 12.1698\n",
      "Epoch 106/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.4824 - mae: 0.9475 - mse: 1.4824 - val_loss: 11.7876 - val_mae: 1.9914 - val_mse: 11.7876\n",
      "Epoch 107/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.4373 - mae: 0.9355 - mse: 1.4373 - val_loss: 13.6271 - val_mae: 2.3540 - val_mse: 13.6271\n",
      "Epoch 108/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.4423 - mae: 0.9355 - mse: 1.4423 - val_loss: 11.4943 - val_mae: 1.9633 - val_mse: 11.4943\n",
      "Epoch 109/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.4551 - mae: 0.9399 - mse: 1.4551 - val_loss: 12.7101 - val_mae: 2.1101 - val_mse: 12.7101\n",
      "Epoch 110/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.4244 - mae: 0.9287 - mse: 1.4244 - val_loss: 11.8633 - val_mae: 2.0583 - val_mse: 11.8633\n",
      "Epoch 111/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.4353 - mae: 0.9289 - mse: 1.4353 - val_loss: 11.5188 - val_mae: 2.0305 - val_mse: 11.5188\n",
      "Epoch 112/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.4072 - mae: 0.9247 - mse: 1.4072 - val_loss: 12.0709 - val_mae: 2.0401 - val_mse: 12.0709\n",
      "Epoch 113/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.4153 - mae: 0.9261 - mse: 1.4153 - val_loss: 11.6368 - val_mae: 1.9791 - val_mse: 11.6368\n",
      "Epoch 114/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.3793 - mae: 0.9159 - mse: 1.3793 - val_loss: 11.3341 - val_mae: 1.9417 - val_mse: 11.3341\n",
      "Epoch 115/500\n",
      "7291/7291 [==============================] - 0s 37us/sample - loss: 1.3956 - mae: 0.9164 - mse: 1.3956 - val_loss: 12.1248 - val_mae: 2.1297 - val_mse: 12.1248\n",
      "Epoch 116/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.3841 - mae: 0.9148 - mse: 1.3841 - val_loss: 11.3041 - val_mae: 1.9518 - val_mse: 11.3041\n",
      "Epoch 117/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.3823 - mae: 0.9149 - mse: 1.3823 - val_loss: 12.8992 - val_mae: 2.1630 - val_mse: 12.8992\n",
      "Epoch 118/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.3650 - mae: 0.9090 - mse: 1.3650 - val_loss: 12.0738 - val_mae: 2.0352 - val_mse: 12.0738\n",
      "Epoch 119/500\n",
      "7291/7291 [==============================] - 0s 37us/sample - loss: 1.3504 - mae: 0.9036 - mse: 1.3504 - val_loss: 11.6772 - val_mae: 2.0462 - val_mse: 11.6772\n",
      "Epoch 120/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.3486 - mae: 0.8989 - mse: 1.3486 - val_loss: 12.1985 - val_mae: 2.0791 - val_mse: 12.1985\n",
      "Epoch 121/500\n",
      "7291/7291 [==============================] - 0s 37us/sample - loss: 1.3208 - mae: 0.8924 - mse: 1.3208 - val_loss: 12.0799 - val_mae: 2.0509 - val_mse: 12.0799\n",
      "Epoch 122/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.3014 - mae: 0.8902 - mse: 1.3014 - val_loss: 11.4158 - val_mae: 1.9680 - val_mse: 11.4158\n",
      "Epoch 123/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.2917 - mae: 0.8828 - mse: 1.2917 - val_loss: 12.1887 - val_mae: 2.1432 - val_mse: 12.1887\n",
      "Epoch 124/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.3011 - mae: 0.8875 - mse: 1.3011 - val_loss: 11.4813 - val_mae: 1.9661 - val_mse: 11.4813\n",
      "Epoch 125/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 1.3015 - mae: 0.8830 - mse: 1.3015 - val_loss: 11.8289 - val_mae: 1.9962 - val_mse: 11.8289\n",
      "Epoch 126/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.2739 - mae: 0.8766 - mse: 1.2739 - val_loss: 12.5410 - val_mae: 2.1847 - val_mse: 12.5410\n",
      "Epoch 127/500\n",
      "7291/7291 [==============================] - 0s 40us/sample - loss: 1.2756 - mae: 0.8781 - mse: 1.2756 - val_loss: 12.3485 - val_mae: 2.0480 - val_mse: 12.3485\n",
      "Epoch 128/500\n",
      "7291/7291 [==============================] - 1s 69us/sample - loss: 1.2671 - mae: 0.8732 - mse: 1.2671 - val_loss: 11.7779 - val_mae: 1.9781 - val_mse: 11.7779\n",
      "Epoch 129/500\n",
      "7291/7291 [==============================] - 0s 52us/sample - loss: 1.2393 - mae: 0.8646 - mse: 1.2393 - val_loss: 11.8238 - val_mae: 1.9819 - val_mse: 11.8238\n",
      "Epoch 130/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.2440 - mae: 0.8667 - mse: 1.2440 - val_loss: 11.9272 - val_mae: 2.1019 - val_mse: 11.9272\n",
      "Epoch 131/500\n",
      "7291/7291 [==============================] - 0s 47us/sample - loss: 1.2236 - mae: 0.8591 - mse: 1.2236 - val_loss: 12.3273 - val_mae: 2.0000 - val_mse: 12.3273\n",
      "Epoch 132/500\n",
      "7291/7291 [==============================] - 0s 43us/sample - loss: 1.2415 - mae: 0.8641 - mse: 1.2415 - val_loss: 12.3677 - val_mae: 2.0904 - val_mse: 12.3677\n",
      "Epoch 133/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.2402 - mae: 0.8675 - mse: 1.2402 - val_loss: 11.5192 - val_mae: 1.9684 - val_mse: 11.5192\n",
      "Epoch 134/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.2302 - mae: 0.8631 - mse: 1.2302 - val_loss: 12.0268 - val_mae: 1.9709 - val_mse: 12.0268\n",
      "Epoch 135/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.2062 - mae: 0.8526 - mse: 1.2062 - val_loss: 12.7733 - val_mae: 2.1645 - val_mse: 12.7733\n",
      "Epoch 136/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.2015 - mae: 0.8517 - mse: 1.2015 - val_loss: 12.9820 - val_mae: 2.2080 - val_mse: 12.9820\n",
      "Epoch 137/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.1860 - mae: 0.8418 - mse: 1.1860 - val_loss: 11.6193 - val_mae: 1.9891 - val_mse: 11.6193\n",
      "Epoch 138/500\n",
      "7291/7291 [==============================] - 0s 39us/sample - loss: 1.1953 - mae: 0.8449 - mse: 1.1953 - val_loss: 12.3734 - val_mae: 2.0527 - val_mse: 12.3734\n",
      "Epoch 139/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1921 - mae: 0.8452 - mse: 1.1921 - val_loss: 12.1286 - val_mae: 2.0713 - val_mse: 12.1286\n",
      "Epoch 140/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1869 - mae: 0.8448 - mse: 1.1869 - val_loss: 11.7775 - val_mae: 2.0331 - val_mse: 11.7775\n",
      "Epoch 141/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1834 - mae: 0.8498 - mse: 1.1834 - val_loss: 12.7262 - val_mae: 2.1106 - val_mse: 12.7262\n",
      "Epoch 142/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1634 - mae: 0.8343 - mse: 1.1634 - val_loss: 12.4353 - val_mae: 2.1573 - val_mse: 12.4353\n",
      "Epoch 143/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1719 - mae: 0.8350 - mse: 1.1719 - val_loss: 11.9615 - val_mae: 2.0451 - val_mse: 11.9615\n",
      "Epoch 144/500\n",
      "7291/7291 [==============================] - 0s 37us/sample - loss: 1.1568 - mae: 0.8300 - mse: 1.1568 - val_loss: 11.8591 - val_mae: 1.9763 - val_mse: 11.8591\n",
      "Epoch 145/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1606 - mae: 0.8313 - mse: 1.1606 - val_loss: 12.9147 - val_mae: 2.1557 - val_mse: 12.9147\n",
      "Epoch 146/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1630 - mae: 0.8374 - mse: 1.1630 - val_loss: 12.7825 - val_mae: 2.1442 - val_mse: 12.7825\n",
      "Epoch 147/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1593 - mae: 0.8353 - mse: 1.1593 - val_loss: 12.7045 - val_mae: 2.0425 - val_mse: 12.7045\n",
      "Epoch 148/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1623 - mae: 0.8363 - mse: 1.1623 - val_loss: 11.8278 - val_mae: 1.9580 - val_mse: 11.8278\n",
      "Epoch 149/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1241 - mae: 0.8240 - mse: 1.1241 - val_loss: 13.9949 - val_mae: 2.3294 - val_mse: 13.9949\n",
      "Epoch 150/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1225 - mae: 0.8256 - mse: 1.1225 - val_loss: 12.7450 - val_mae: 2.1898 - val_mse: 12.7450\n",
      "Epoch 151/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1385 - mae: 0.8297 - mse: 1.1385 - val_loss: 12.4411 - val_mae: 2.0165 - val_mse: 12.4411\n",
      "Epoch 152/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1162 - mae: 0.8192 - mse: 1.1162 - val_loss: 13.7999 - val_mae: 2.2942 - val_mse: 13.7999\n",
      "Epoch 153/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1067 - mae: 0.8135 - mse: 1.1067 - val_loss: 12.6348 - val_mae: 2.0607 - val_mse: 12.6348\n",
      "Epoch 154/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1081 - mae: 0.8195 - mse: 1.1081 - val_loss: 12.6177 - val_mae: 2.1229 - val_mse: 12.6177\n",
      "Epoch 155/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1190 - mae: 0.8234 - mse: 1.1190 - val_loss: 12.5497 - val_mae: 2.0378 - val_mse: 12.5497\n",
      "Epoch 156/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1076 - mae: 0.8177 - mse: 1.1076 - val_loss: 12.2509 - val_mae: 2.0149 - val_mse: 12.2509\n",
      "Epoch 157/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1013 - mae: 0.8154 - mse: 1.1013 - val_loss: 12.0599 - val_mae: 2.0014 - val_mse: 12.0599\n",
      "Epoch 158/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.0923 - mae: 0.8104 - mse: 1.0923 - val_loss: 12.4657 - val_mae: 1.9997 - val_mse: 12.4657\n",
      "Epoch 159/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.1107 - mae: 0.8205 - mse: 1.1107 - val_loss: 12.3863 - val_mae: 2.0664 - val_mse: 12.3863\n",
      "Epoch 160/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.0888 - mae: 0.8108 - mse: 1.0888 - val_loss: 12.4756 - val_mae: 1.9937 - val_mse: 12.4756\n",
      "Epoch 161/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.0856 - mae: 0.8104 - mse: 1.0856 - val_loss: 12.2345 - val_mae: 2.0555 - val_mse: 12.2345\n",
      "Epoch 162/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.0962 - mae: 0.8152 - mse: 1.0962 - val_loss: 11.9942 - val_mae: 1.9938 - val_mse: 11.9942\n",
      "Epoch 163/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.0745 - mae: 0.8032 - mse: 1.0745 - val_loss: 12.4449 - val_mae: 1.9932 - val_mse: 12.4449\n",
      "Epoch 164/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.0837 - mae: 0.8106 - mse: 1.0837 - val_loss: 13.3120 - val_mae: 2.1745 - val_mse: 13.3120\n",
      "Epoch 165/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.0667 - mae: 0.7997 - mse: 1.0667 - val_loss: 12.5633 - val_mae: 2.0041 - val_mse: 12.5633\n",
      "Epoch 166/500\n",
      "7291/7291 [==============================] - 0s 38us/sample - loss: 1.0630 - mae: 0.7977 - mse: 1.0630 - val_loss: 12.5156 - val_mae: 2.1452 - val_mse: 12.5156\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8749 samples, validate on 2916 samples\n",
      "Epoch 1/500\n",
      "8749/8749 [==============================] - 1s 78us/sample - loss: 46.5180 - mae: 4.2775 - mse: 46.5180 - val_loss: 54.3069 - val_mae: 4.3992 - val_mse: 54.3069\n",
      "Epoch 2/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 14.0291 - mae: 2.6494 - mse: 14.0291 - val_loss: 33.9782 - val_mae: 3.6616 - val_mse: 33.9782\n",
      "Epoch 3/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 8.9986 - mae: 2.1953 - mse: 8.9986 - val_loss: 25.6934 - val_mae: 2.9526 - val_mse: 25.6934\n",
      "Epoch 4/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 6.8243 - mae: 1.9417 - mse: 6.8243 - val_loss: 23.8654 - val_mae: 2.9374 - val_mse: 23.8654\n",
      "Epoch 5/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 5.5672 - mae: 1.7651 - mse: 5.5672 - val_loss: 22.5088 - val_mae: 2.8887 - val_mse: 22.5088\n",
      "Epoch 6/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 4.7281 - mae: 1.6267 - mse: 4.7281 - val_loss: 19.4598 - val_mae: 2.4344 - val_mse: 19.4598\n",
      "Epoch 7/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 4.1971 - mae: 1.5485 - mse: 4.1971 - val_loss: 22.3836 - val_mae: 3.1558 - val_mse: 22.3836\n",
      "Epoch 8/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 3.8837 - mae: 1.4968 - mse: 3.8837 - val_loss: 18.3615 - val_mae: 2.4208 - val_mse: 18.3615\n",
      "Epoch 9/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 3.5227 - mae: 1.4305 - mse: 3.5227 - val_loss: 19.1371 - val_mae: 2.5270 - val_mse: 19.1371\n",
      "Epoch 10/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 3.3539 - mae: 1.4057 - mse: 3.3539 - val_loss: 17.7872 - val_mae: 2.6577 - val_mse: 17.7872\n",
      "Epoch 11/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 3.1295 - mae: 1.3592 - mse: 3.1295 - val_loss: 17.1272 - val_mae: 2.2962 - val_mse: 17.1272\n",
      "Epoch 12/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 2.9932 - mae: 1.3285 - mse: 2.9932 - val_loss: 16.0852 - val_mae: 2.1854 - val_mse: 16.0852\n",
      "Epoch 13/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8749/8749 [==============================] - 0s 38us/sample - loss: 2.8553 - mae: 1.3006 - mse: 2.8553 - val_loss: 16.3424 - val_mae: 2.2743 - val_mse: 16.3424\n",
      "Epoch 14/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 2.7332 - mae: 1.2658 - mse: 2.7332 - val_loss: 16.4454 - val_mae: 2.4560 - val_mse: 16.4454\n",
      "Epoch 15/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 2.6882 - mae: 1.2603 - mse: 2.6882 - val_loss: 15.9068 - val_mae: 2.2825 - val_mse: 15.9068\n",
      "Epoch 16/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 2.5855 - mae: 1.2349 - mse: 2.5855 - val_loss: 18.0038 - val_mae: 2.5847 - val_mse: 18.0038\n",
      "Epoch 17/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 2.4725 - mae: 1.2120 - mse: 2.4725 - val_loss: 17.3455 - val_mae: 2.7247 - val_mse: 17.3455\n",
      "Epoch 18/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 2.4645 - mae: 1.2105 - mse: 2.4645 - val_loss: 15.0879 - val_mae: 2.2168 - val_mse: 15.0879\n",
      "Epoch 19/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 2.3617 - mae: 1.1820 - mse: 2.3617 - val_loss: 15.5530 - val_mae: 2.2299 - val_mse: 15.5530\n",
      "Epoch 20/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 2.3233 - mae: 1.1744 - mse: 2.3233 - val_loss: 14.9319 - val_mae: 2.1610 - val_mse: 14.9319\n",
      "Epoch 21/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 2.2541 - mae: 1.1601 - mse: 2.2541 - val_loss: 14.8845 - val_mae: 2.2112 - val_mse: 14.8845\n",
      "Epoch 22/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 2.2405 - mae: 1.1552 - mse: 2.2405 - val_loss: 16.3795 - val_mae: 2.3691 - val_mse: 16.3795\n",
      "Epoch 23/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 2.1563 - mae: 1.1300 - mse: 2.1563 - val_loss: 14.7183 - val_mae: 2.3115 - val_mse: 14.7183\n",
      "Epoch 24/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 2.1197 - mae: 1.1175 - mse: 2.1197 - val_loss: 16.2634 - val_mae: 2.4430 - val_mse: 16.2634\n",
      "Epoch 25/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 2.0951 - mae: 1.1141 - mse: 2.0951 - val_loss: 17.0574 - val_mae: 2.6022 - val_mse: 17.0574\n",
      "Epoch 26/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 2.0791 - mae: 1.1013 - mse: 2.0791 - val_loss: 14.2368 - val_mae: 2.0860 - val_mse: 14.2368\n",
      "Epoch 27/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 2.0274 - mae: 1.0948 - mse: 2.0274 - val_loss: 13.9900 - val_mae: 2.1297 - val_mse: 13.9900\n",
      "Epoch 28/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 1.9593 - mae: 1.0747 - mse: 1.9593 - val_loss: 14.1734 - val_mae: 2.2588 - val_mse: 14.1734\n",
      "Epoch 29/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.9245 - mae: 1.0659 - mse: 1.9245 - val_loss: 15.9704 - val_mae: 2.3149 - val_mse: 15.9704\n",
      "Epoch 30/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.8802 - mae: 1.0524 - mse: 1.8802 - val_loss: 14.4437 - val_mae: 2.1526 - val_mse: 14.4437\n",
      "Epoch 31/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.8413 - mae: 1.0404 - mse: 1.8413 - val_loss: 14.1852 - val_mae: 2.1816 - val_mse: 14.1852\n",
      "Epoch 32/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.8327 - mae: 1.0386 - mse: 1.8327 - val_loss: 14.9197 - val_mae: 2.1810 - val_mse: 14.9197\n",
      "Epoch 33/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 1.8113 - mae: 1.0368 - mse: 1.8113 - val_loss: 15.4974 - val_mae: 2.3112 - val_mse: 15.4974\n",
      "Epoch 34/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 1.7736 - mae: 1.0169 - mse: 1.7736 - val_loss: 13.7892 - val_mae: 2.1202 - val_mse: 13.7892\n",
      "Epoch 35/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.7433 - mae: 1.0123 - mse: 1.7433 - val_loss: 13.4445 - val_mae: 2.0131 - val_mse: 13.4445\n",
      "Epoch 36/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.7098 - mae: 0.9992 - mse: 1.7098 - val_loss: 14.5517 - val_mae: 2.2108 - val_mse: 14.5517\n",
      "Epoch 37/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.6701 - mae: 0.9887 - mse: 1.6701 - val_loss: 14.5459 - val_mae: 2.1685 - val_mse: 14.5459\n",
      "Epoch 38/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.6676 - mae: 0.9871 - mse: 1.6676 - val_loss: 15.2397 - val_mae: 2.2702 - val_mse: 15.2397\n",
      "Epoch 39/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.6403 - mae: 0.9787 - mse: 1.6403 - val_loss: 14.7679 - val_mae: 2.1617 - val_mse: 14.7679\n",
      "Epoch 40/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.6301 - mae: 0.9766 - mse: 1.6301 - val_loss: 13.8739 - val_mae: 2.0837 - val_mse: 13.8739\n",
      "Epoch 41/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 1.5985 - mae: 0.9657 - mse: 1.5985 - val_loss: 13.7942 - val_mae: 2.0506 - val_mse: 13.7942\n",
      "Epoch 42/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.5898 - mae: 0.9670 - mse: 1.5898 - val_loss: 14.3104 - val_mae: 2.2263 - val_mse: 14.3104\n",
      "Epoch 43/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.5570 - mae: 0.9562 - mse: 1.5570 - val_loss: 15.5511 - val_mae: 2.3555 - val_mse: 15.5511\n",
      "Epoch 44/500\n",
      "8749/8749 [==============================] - 1s 63us/sample - loss: 1.5469 - mae: 0.9475 - mse: 1.5469 - val_loss: 16.1334 - val_mae: 2.4893 - val_mse: 16.1333\n",
      "Epoch 45/500\n",
      "8749/8749 [==============================] - 0s 44us/sample - loss: 1.5513 - mae: 0.9574 - mse: 1.5513 - val_loss: 13.7043 - val_mae: 2.0576 - val_mse: 13.7043\n",
      "Epoch 46/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.5245 - mae: 0.9383 - mse: 1.5245 - val_loss: 14.7539 - val_mae: 2.1926 - val_mse: 14.7539\n",
      "Epoch 47/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 1.5117 - mae: 0.9405 - mse: 1.5117 - val_loss: 12.9886 - val_mae: 1.9870 - val_mse: 12.9886\n",
      "Epoch 48/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.4859 - mae: 0.9329 - mse: 1.4859 - val_loss: 14.2801 - val_mae: 2.1858 - val_mse: 14.2801\n",
      "Epoch 49/500\n",
      "8749/8749 [==============================] - 0s 55us/sample - loss: 1.4746 - mae: 0.9297 - mse: 1.4746 - val_loss: 13.5022 - val_mae: 2.0550 - val_mse: 13.5022\n",
      "Epoch 50/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.4781 - mae: 0.9292 - mse: 1.4781 - val_loss: 13.6914 - val_mae: 2.1901 - val_mse: 13.6914\n",
      "Epoch 51/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.4703 - mae: 0.9313 - mse: 1.4703 - val_loss: 12.6946 - val_mae: 1.9531 - val_mse: 12.6946\n",
      "Epoch 52/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 1.4387 - mae: 0.9161 - mse: 1.4387 - val_loss: 12.5348 - val_mae: 1.9258 - val_mse: 12.5348\n",
      "Epoch 53/500\n",
      "8749/8749 [==============================] - 0s 49us/sample - loss: 1.4415 - mae: 0.9161 - mse: 1.4415 - val_loss: 12.3351 - val_mae: 1.9463 - val_mse: 12.3351\n",
      "Epoch 54/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.4134 - mae: 0.9054 - mse: 1.4134 - val_loss: 12.4889 - val_mae: 2.0624 - val_mse: 12.4889\n",
      "Epoch 55/500\n",
      "8749/8749 [==============================] - 0s 45us/sample - loss: 1.3996 - mae: 0.9031 - mse: 1.3996 - val_loss: 12.8820 - val_mae: 1.9754 - val_mse: 12.8820\n",
      "Epoch 56/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.4006 - mae: 0.9015 - mse: 1.4006 - val_loss: 12.3140 - val_mae: 2.0397 - val_mse: 12.3140\n",
      "Epoch 57/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 1.3804 - mae: 0.8960 - mse: 1.3804 - val_loss: 13.2383 - val_mae: 2.0265 - val_mse: 13.2383\n",
      "Epoch 58/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.3680 - mae: 0.8937 - mse: 1.3680 - val_loss: 12.8041 - val_mae: 1.9609 - val_mse: 12.8041\n",
      "Epoch 59/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 1.3596 - mae: 0.8912 - mse: 1.3596 - val_loss: 12.6538 - val_mae: 2.0107 - val_mse: 12.6538\n",
      "Epoch 60/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.3509 - mae: 0.8859 - mse: 1.3509 - val_loss: 14.6981 - val_mae: 2.3215 - val_mse: 14.6981\n",
      "Epoch 61/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.3441 - mae: 0.8884 - mse: 1.3441 - val_loss: 13.8817 - val_mae: 2.1636 - val_mse: 13.8817\n",
      "Epoch 62/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.3226 - mae: 0.8795 - mse: 1.3226 - val_loss: 12.8141 - val_mae: 2.0073 - val_mse: 12.8141\n",
      "Epoch 63/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.3288 - mae: 0.8768 - mse: 1.3288 - val_loss: 11.7908 - val_mae: 1.9405 - val_mse: 11.7908\n",
      "Epoch 64/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.3029 - mae: 0.8726 - mse: 1.3029 - val_loss: 12.7425 - val_mae: 1.9392 - val_mse: 12.7425\n",
      "Epoch 65/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.3111 - mae: 0.8754 - mse: 1.3111 - val_loss: 13.3094 - val_mae: 2.1178 - val_mse: 13.3094\n",
      "Epoch 66/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 1.2651 - mae: 0.8558 - mse: 1.2651 - val_loss: 12.4634 - val_mae: 2.0714 - val_mse: 12.4634\n",
      "Epoch 67/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.2614 - mae: 0.8548 - mse: 1.2614 - val_loss: 11.8953 - val_mae: 1.8856 - val_mse: 11.8953\n",
      "Epoch 68/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.2374 - mae: 0.8462 - mse: 1.2374 - val_loss: 12.6037 - val_mae: 1.9492 - val_mse: 12.6037\n",
      "Epoch 69/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.2421 - mae: 0.8497 - mse: 1.2421 - val_loss: 12.9458 - val_mae: 2.0396 - val_mse: 12.9458\n",
      "Epoch 70/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.2242 - mae: 0.8413 - mse: 1.2242 - val_loss: 11.4763 - val_mae: 1.8738 - val_mse: 11.4763\n",
      "Epoch 71/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.2190 - mae: 0.8409 - mse: 1.2190 - val_loss: 11.4870 - val_mae: 1.8458 - val_mse: 11.4870\n",
      "Epoch 72/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.2046 - mae: 0.8349 - mse: 1.2046 - val_loss: 12.3881 - val_mae: 1.9585 - val_mse: 12.3881\n",
      "Epoch 73/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.2171 - mae: 0.8374 - mse: 1.2171 - val_loss: 12.2965 - val_mae: 2.0025 - val_mse: 12.2965\n",
      "Epoch 74/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.1983 - mae: 0.8327 - mse: 1.1983 - val_loss: 12.2553 - val_mae: 1.9576 - val_mse: 12.2553\n",
      "Epoch 75/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.1843 - mae: 0.8267 - mse: 1.1843 - val_loss: 11.1611 - val_mae: 1.9214 - val_mse: 11.1611\n",
      "Epoch 76/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 1.1997 - mae: 0.8333 - mse: 1.1997 - val_loss: 11.9545 - val_mae: 1.8817 - val_mse: 11.9545\n",
      "Epoch 77/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.1641 - mae: 0.8218 - mse: 1.1641 - val_loss: 10.9800 - val_mae: 1.9143 - val_mse: 10.9800\n",
      "Epoch 78/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 1.1577 - mae: 0.8214 - mse: 1.1577 - val_loss: 13.3072 - val_mae: 2.1643 - val_mse: 13.3073\n",
      "Epoch 79/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 1.1583 - mae: 0.8196 - mse: 1.1583 - val_loss: 11.9121 - val_mae: 1.9068 - val_mse: 11.9121\n",
      "Epoch 80/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 1.1555 - mae: 0.8154 - mse: 1.1555 - val_loss: 11.4943 - val_mae: 1.9731 - val_mse: 11.4943\n",
      "Epoch 81/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.1512 - mae: 0.8147 - mse: 1.1512 - val_loss: 11.2533 - val_mae: 1.8400 - val_mse: 11.2533\n",
      "Epoch 82/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 1.1517 - mae: 0.8174 - mse: 1.1517 - val_loss: 11.5637 - val_mae: 1.8638 - val_mse: 11.5637\n",
      "Epoch 83/500\n",
      "8749/8749 [==============================] - 0s 43us/sample - loss: 1.1308 - mae: 0.8094 - mse: 1.1308 - val_loss: 11.2991 - val_mae: 1.8713 - val_mse: 11.2991\n",
      "Epoch 84/500\n",
      "8749/8749 [==============================] - 0s 53us/sample - loss: 1.1378 - mae: 0.8112 - mse: 1.1378 - val_loss: 11.4687 - val_mae: 1.8691 - val_mse: 11.4687\n",
      "Epoch 85/500\n",
      "8749/8749 [==============================] - 0s 53us/sample - loss: 1.1262 - mae: 0.8056 - mse: 1.1262 - val_loss: 10.8380 - val_mae: 1.8565 - val_mse: 10.8380\n",
      "Epoch 86/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 1.1172 - mae: 0.8031 - mse: 1.1172 - val_loss: 11.9025 - val_mae: 2.0186 - val_mse: 11.9025\n",
      "Epoch 87/500\n",
      "8749/8749 [==============================] - 0s 42us/sample - loss: 1.1079 - mae: 0.8029 - mse: 1.1079 - val_loss: 10.2145 - val_mae: 1.7712 - val_mse: 10.2145\n",
      "Epoch 88/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 1.1096 - mae: 0.7992 - mse: 1.1096 - val_loss: 10.7966 - val_mae: 1.8279 - val_mse: 10.7966\n",
      "Epoch 89/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 1.0960 - mae: 0.7956 - mse: 1.0960 - val_loss: 11.4266 - val_mae: 1.8666 - val_mse: 11.4266\n",
      "Epoch 90/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 1.0875 - mae: 0.7938 - mse: 1.0875 - val_loss: 11.7747 - val_mae: 2.1169 - val_mse: 11.7747\n",
      "Epoch 91/500\n",
      "8749/8749 [==============================] - 0s 41us/sample - loss: 1.0905 - mae: 0.7971 - mse: 1.0905 - val_loss: 10.4389 - val_mae: 1.7637 - val_mse: 10.4389\n",
      "Epoch 92/500\n",
      "8749/8749 [==============================] - 0s 41us/sample - loss: 1.0751 - mae: 0.7871 - mse: 1.0751 - val_loss: 10.7439 - val_mae: 1.8877 - val_mse: 10.7439\n",
      "Epoch 93/500\n",
      "8749/8749 [==============================] - 0s 52us/sample - loss: 1.0800 - mae: 0.7927 - mse: 1.0800 - val_loss: 10.9749 - val_mae: 1.8034 - val_mse: 10.9749\n",
      "Epoch 94/500\n",
      "8749/8749 [==============================] - 0s 42us/sample - loss: 1.0766 - mae: 0.7867 - mse: 1.0766 - val_loss: 11.1520 - val_mae: 1.8293 - val_mse: 11.1520\n",
      "Epoch 95/500\n",
      "8749/8749 [==============================] - 0s 43us/sample - loss: 1.0636 - mae: 0.7836 - mse: 1.0636 - val_loss: 11.0289 - val_mae: 2.0260 - val_mse: 11.0289\n",
      "Epoch 96/500\n",
      "8749/8749 [==============================] - 0s 48us/sample - loss: 1.0686 - mae: 0.7860 - mse: 1.0686 - val_loss: 10.3275 - val_mae: 1.8005 - val_mse: 10.3275\n",
      "Epoch 97/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 1.0532 - mae: 0.7812 - mse: 1.0532 - val_loss: 10.6261 - val_mae: 1.8080 - val_mse: 10.6261\n",
      "Epoch 98/500\n",
      "8749/8749 [==============================] - 0s 48us/sample - loss: 1.0470 - mae: 0.7781 - mse: 1.0470 - val_loss: 11.6696 - val_mae: 1.9893 - val_mse: 11.6696\n",
      "Epoch 99/500\n",
      "8749/8749 [==============================] - 0s 41us/sample - loss: 1.0489 - mae: 0.7795 - mse: 1.0489 - val_loss: 10.3455 - val_mae: 1.9166 - val_mse: 10.3455\n",
      "Epoch 100/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 1.0311 - mae: 0.7704 - mse: 1.0311 - val_loss: 10.5170 - val_mae: 1.9250 - val_mse: 10.5170\n",
      "Epoch 101/500\n",
      "8749/8749 [==============================] - 0s 56us/sample - loss: 1.0377 - mae: 0.7704 - mse: 1.0377 - val_loss: 10.1339 - val_mae: 1.7087 - val_mse: 10.1339\n",
      "Epoch 102/500\n",
      "8749/8749 [==============================] - 0s 45us/sample - loss: 1.0234 - mae: 0.7681 - mse: 1.0234 - val_loss: 10.6979 - val_mae: 1.9472 - val_mse: 10.6979\n",
      "Epoch 103/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 1.0186 - mae: 0.7669 - mse: 1.0186 - val_loss: 9.9084 - val_mae: 1.7512 - val_mse: 9.9084\n",
      "Epoch 104/500\n",
      "8749/8749 [==============================] - 0s 50us/sample - loss: 1.0237 - mae: 0.7689 - mse: 1.0237 - val_loss: 10.1599 - val_mae: 1.7377 - val_mse: 10.1599\n",
      "Epoch 105/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 1.0248 - mae: 0.7674 - mse: 1.0248 - val_loss: 10.3404 - val_mae: 1.8577 - val_mse: 10.3404\n",
      "Epoch 106/500\n",
      "8749/8749 [==============================] - 0s 49us/sample - loss: 1.0374 - mae: 0.7748 - mse: 1.0374 - val_loss: 10.4453 - val_mae: 1.8880 - val_mse: 10.4453\n",
      "Epoch 107/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8749/8749 [==============================] - 0s 47us/sample - loss: 1.0126 - mae: 0.7635 - mse: 1.0126 - val_loss: 9.7815 - val_mae: 1.6985 - val_mse: 9.7815\n",
      "Epoch 108/500\n",
      "8749/8749 [==============================] - 0s 53us/sample - loss: 0.9960 - mae: 0.7582 - mse: 0.9960 - val_loss: 9.6051 - val_mae: 1.7099 - val_mse: 9.6051\n",
      "Epoch 109/500\n",
      "8749/8749 [==============================] - 0s 47us/sample - loss: 1.0127 - mae: 0.7657 - mse: 1.0127 - val_loss: 9.4124 - val_mae: 1.6960 - val_mse: 9.4124\n",
      "Epoch 110/500\n",
      "8749/8749 [==============================] - 0s 48us/sample - loss: 1.0191 - mae: 0.7683 - mse: 1.0191 - val_loss: 9.5425 - val_mae: 1.7152 - val_mse: 9.5425\n",
      "Epoch 111/500\n",
      "8749/8749 [==============================] - 0s 43us/sample - loss: 0.9917 - mae: 0.7539 - mse: 0.9917 - val_loss: 9.3358 - val_mae: 1.7252 - val_mse: 9.3358\n",
      "Epoch 112/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 1.0092 - mae: 0.7641 - mse: 1.0092 - val_loss: 9.3319 - val_mae: 1.7024 - val_mse: 9.3319\n",
      "Epoch 113/500\n",
      "8749/8749 [==============================] - 0s 44us/sample - loss: 0.9854 - mae: 0.7554 - mse: 0.9854 - val_loss: 9.9724 - val_mae: 1.7518 - val_mse: 9.9724\n",
      "Epoch 114/500\n",
      "8749/8749 [==============================] - 0s 41us/sample - loss: 0.9745 - mae: 0.7520 - mse: 0.9745 - val_loss: 9.5980 - val_mae: 1.8286 - val_mse: 9.5980\n",
      "Epoch 115/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.9836 - mae: 0.7534 - mse: 0.9836 - val_loss: 9.1432 - val_mae: 1.6921 - val_mse: 9.1432\n",
      "Epoch 116/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9649 - mae: 0.7466 - mse: 0.9649 - val_loss: 9.3625 - val_mae: 1.6280 - val_mse: 9.3625\n",
      "Epoch 117/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9753 - mae: 0.7497 - mse: 0.9753 - val_loss: 9.2632 - val_mae: 1.6442 - val_mse: 9.2632\n",
      "Epoch 118/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9684 - mae: 0.7450 - mse: 0.9684 - val_loss: 10.3534 - val_mae: 1.8962 - val_mse: 10.3534\n",
      "Epoch 119/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9720 - mae: 0.7508 - mse: 0.9720 - val_loss: 8.9731 - val_mae: 1.6119 - val_mse: 8.9731\n",
      "Epoch 120/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.9605 - mae: 0.7439 - mse: 0.9605 - val_loss: 9.2357 - val_mae: 1.6614 - val_mse: 9.2357\n",
      "Epoch 121/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.9619 - mae: 0.7467 - mse: 0.9619 - val_loss: 10.2017 - val_mae: 1.9076 - val_mse: 10.2017\n",
      "Epoch 122/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.9491 - mae: 0.7383 - mse: 0.9491 - val_loss: 9.6233 - val_mae: 1.7080 - val_mse: 9.6233\n",
      "Epoch 123/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9614 - mae: 0.7408 - mse: 0.9614 - val_loss: 9.6229 - val_mae: 1.7232 - val_mse: 9.6229\n",
      "Epoch 124/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9459 - mae: 0.7372 - mse: 0.9459 - val_loss: 9.0316 - val_mae: 1.6214 - val_mse: 9.0316\n",
      "Epoch 125/500\n",
      "8749/8749 [==============================] - 0s 41us/sample - loss: 0.9438 - mae: 0.7387 - mse: 0.9438 - val_loss: 10.4366 - val_mae: 1.9280 - val_mse: 10.4366\n",
      "Epoch 126/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9363 - mae: 0.7355 - mse: 0.9363 - val_loss: 10.0230 - val_mae: 1.8579 - val_mse: 10.0230\n",
      "Epoch 127/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9489 - mae: 0.7383 - mse: 0.9489 - val_loss: 9.0585 - val_mae: 1.6464 - val_mse: 9.0585\n",
      "Epoch 128/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9339 - mae: 0.7347 - mse: 0.9339 - val_loss: 8.9747 - val_mae: 1.6161 - val_mse: 8.9747\n",
      "Epoch 129/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.9411 - mae: 0.7347 - mse: 0.9411 - val_loss: 8.9865 - val_mae: 1.6116 - val_mse: 8.9865\n",
      "Epoch 130/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9376 - mae: 0.7376 - mse: 0.9376 - val_loss: 8.6323 - val_mae: 1.6757 - val_mse: 8.6322\n",
      "Epoch 131/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9230 - mae: 0.7288 - mse: 0.9230 - val_loss: 9.1044 - val_mae: 1.6478 - val_mse: 9.1044\n",
      "Epoch 132/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9322 - mae: 0.7294 - mse: 0.9322 - val_loss: 9.2941 - val_mae: 1.7398 - val_mse: 9.2941\n",
      "Epoch 133/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.9295 - mae: 0.7288 - mse: 0.9295 - val_loss: 8.4794 - val_mae: 1.6234 - val_mse: 8.4794\n",
      "Epoch 134/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.9333 - mae: 0.7319 - mse: 0.9333 - val_loss: 9.0549 - val_mae: 1.6490 - val_mse: 9.0549\n",
      "Epoch 135/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9117 - mae: 0.7232 - mse: 0.9118 - val_loss: 9.1848 - val_mae: 1.7275 - val_mse: 9.1848\n",
      "Epoch 136/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9398 - mae: 0.7382 - mse: 0.9398 - val_loss: 9.2007 - val_mae: 1.7461 - val_mse: 9.2007\n",
      "Epoch 137/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.9224 - mae: 0.7288 - mse: 0.9224 - val_loss: 9.0525 - val_mae: 1.6184 - val_mse: 9.0525\n",
      "Epoch 138/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9210 - mae: 0.7291 - mse: 0.9210 - val_loss: 9.1972 - val_mae: 1.6439 - val_mse: 9.1972\n",
      "Epoch 139/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9234 - mae: 0.7286 - mse: 0.9234 - val_loss: 9.4827 - val_mae: 1.7693 - val_mse: 9.4827\n",
      "Epoch 140/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9127 - mae: 0.7265 - mse: 0.9127 - val_loss: 8.8456 - val_mae: 1.6396 - val_mse: 8.8456\n",
      "Epoch 141/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.9134 - mae: 0.7236 - mse: 0.9134 - val_loss: 8.9689 - val_mae: 1.7144 - val_mse: 8.9689\n",
      "Epoch 142/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9051 - mae: 0.7236 - mse: 0.9051 - val_loss: 8.9468 - val_mae: 1.7180 - val_mse: 8.9468\n",
      "Epoch 143/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9120 - mae: 0.7239 - mse: 0.9120 - val_loss: 8.7058 - val_mae: 1.6409 - val_mse: 8.7058\n",
      "Epoch 144/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9052 - mae: 0.7207 - mse: 0.9052 - val_loss: 8.6776 - val_mae: 1.6305 - val_mse: 8.6776\n",
      "Epoch 145/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9001 - mae: 0.7219 - mse: 0.9001 - val_loss: 10.0923 - val_mae: 1.9068 - val_mse: 10.0923\n",
      "Epoch 146/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9217 - mae: 0.7301 - mse: 0.9217 - val_loss: 9.0779 - val_mae: 1.7140 - val_mse: 9.0779\n",
      "Epoch 147/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.8986 - mae: 0.7209 - mse: 0.8986 - val_loss: 8.7270 - val_mae: 1.6419 - val_mse: 8.7270\n",
      "Epoch 148/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.9008 - mae: 0.7210 - mse: 0.9008 - val_loss: 8.8332 - val_mae: 1.6742 - val_mse: 8.8332\n",
      "Epoch 149/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.8841 - mae: 0.7143 - mse: 0.8841 - val_loss: 8.9495 - val_mae: 1.7423 - val_mse: 8.9495\n",
      "Epoch 150/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.8921 - mae: 0.7196 - mse: 0.8921 - val_loss: 9.4419 - val_mae: 1.8549 - val_mse: 9.4419\n",
      "Epoch 151/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.8865 - mae: 0.7126 - mse: 0.8865 - val_loss: 8.7274 - val_mae: 1.6677 - val_mse: 8.7274\n",
      "Epoch 152/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.8819 - mae: 0.7144 - mse: 0.8819 - val_loss: 10.4169 - val_mae: 1.9730 - val_mse: 10.4169\n",
      "Epoch 153/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.8940 - mae: 0.7201 - mse: 0.8940 - val_loss: 8.8080 - val_mae: 1.7055 - val_mse: 8.8080\n",
      "Epoch 154/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.8816 - mae: 0.7153 - mse: 0.8816 - val_loss: 9.2400 - val_mae: 1.9359 - val_mse: 9.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8898 - mae: 0.7183 - mse: 0.8898 - val_loss: 8.2793 - val_mae: 1.5877 - val_mse: 8.2793\n",
      "Epoch 156/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8772 - mae: 0.7137 - mse: 0.8772 - val_loss: 8.5158 - val_mae: 1.6008 - val_mse: 8.5158\n",
      "Epoch 157/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8759 - mae: 0.7089 - mse: 0.8759 - val_loss: 8.8006 - val_mae: 1.7204 - val_mse: 8.8006\n",
      "Epoch 158/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8831 - mae: 0.7138 - mse: 0.8831 - val_loss: 8.7564 - val_mae: 1.5914 - val_mse: 8.7564\n",
      "Epoch 159/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8793 - mae: 0.7111 - mse: 0.8793 - val_loss: 8.6957 - val_mae: 1.7116 - val_mse: 8.6957\n",
      "Epoch 160/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8698 - mae: 0.7054 - mse: 0.8698 - val_loss: 8.8567 - val_mae: 1.7514 - val_mse: 8.8567\n",
      "Epoch 161/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8733 - mae: 0.7098 - mse: 0.8733 - val_loss: 8.2583 - val_mae: 1.5982 - val_mse: 8.2583\n",
      "Epoch 162/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8739 - mae: 0.7105 - mse: 0.8739 - val_loss: 9.0593 - val_mae: 1.7861 - val_mse: 9.0593\n",
      "Epoch 163/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.8714 - mae: 0.7095 - mse: 0.8714 - val_loss: 8.6065 - val_mae: 1.7202 - val_mse: 8.6065\n",
      "Epoch 164/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8740 - mae: 0.7130 - mse: 0.8740 - val_loss: 8.6314 - val_mae: 1.6984 - val_mse: 8.6314\n",
      "Epoch 165/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8621 - mae: 0.7061 - mse: 0.8621 - val_loss: 8.4466 - val_mae: 1.5768 - val_mse: 8.4466\n",
      "Epoch 166/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8716 - mae: 0.7089 - mse: 0.8716 - val_loss: 9.1871 - val_mae: 1.8150 - val_mse: 9.1871\n",
      "Epoch 167/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8617 - mae: 0.7079 - mse: 0.8617 - val_loss: 8.9550 - val_mae: 1.7275 - val_mse: 8.9550\n",
      "Epoch 168/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8492 - mae: 0.6997 - mse: 0.8492 - val_loss: 8.5014 - val_mae: 1.6635 - val_mse: 8.5014\n",
      "Epoch 169/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8626 - mae: 0.7080 - mse: 0.8626 - val_loss: 8.1352 - val_mae: 1.5405 - val_mse: 8.1352\n",
      "Epoch 170/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8525 - mae: 0.7001 - mse: 0.8525 - val_loss: 8.2180 - val_mae: 1.5948 - val_mse: 8.2180\n",
      "Epoch 171/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8597 - mae: 0.7060 - mse: 0.8597 - val_loss: 8.7953 - val_mae: 1.7272 - val_mse: 8.7953\n",
      "Epoch 172/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8668 - mae: 0.7076 - mse: 0.8668 - val_loss: 8.4098 - val_mae: 1.6145 - val_mse: 8.4098\n",
      "Epoch 173/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8568 - mae: 0.7056 - mse: 0.8568 - val_loss: 8.5321 - val_mae: 1.7007 - val_mse: 8.5321\n",
      "Epoch 174/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8420 - mae: 0.6966 - mse: 0.8420 - val_loss: 8.3443 - val_mae: 1.6149 - val_mse: 8.3443\n",
      "Epoch 175/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8430 - mae: 0.6971 - mse: 0.8430 - val_loss: 8.4545 - val_mae: 1.6692 - val_mse: 8.4545\n",
      "Epoch 176/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8478 - mae: 0.7022 - mse: 0.8478 - val_loss: 8.5944 - val_mae: 1.7133 - val_mse: 8.5944\n",
      "Epoch 177/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8488 - mae: 0.6982 - mse: 0.8488 - val_loss: 9.4140 - val_mae: 1.8740 - val_mse: 9.4140\n",
      "Epoch 178/500\n",
      "8749/8749 [==============================] - 0s 53us/sample - loss: 0.8455 - mae: 0.6954 - mse: 0.8455 - val_loss: 8.6502 - val_mae: 1.6680 - val_mse: 8.6502\n",
      "Epoch 179/500\n",
      "8749/8749 [==============================] - 0s 53us/sample - loss: 0.8423 - mae: 0.6968 - mse: 0.8423 - val_loss: 8.8333 - val_mae: 1.6917 - val_mse: 8.8333\n",
      "Epoch 180/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8473 - mae: 0.7000 - mse: 0.8473 - val_loss: 8.5816 - val_mae: 1.6816 - val_mse: 8.5816\n",
      "Epoch 181/500\n",
      "8749/8749 [==============================] - 0s 44us/sample - loss: 0.8481 - mae: 0.6975 - mse: 0.8481 - val_loss: 8.3860 - val_mae: 1.6177 - val_mse: 8.3860\n",
      "Epoch 182/500\n",
      "8749/8749 [==============================] - 0s 56us/sample - loss: 0.8500 - mae: 0.7023 - mse: 0.8500 - val_loss: 8.0213 - val_mae: 1.5366 - val_mse: 8.0213\n",
      "Epoch 183/500\n",
      "8749/8749 [==============================] - 0s 46us/sample - loss: 0.8493 - mae: 0.6994 - mse: 0.8493 - val_loss: 8.1062 - val_mae: 1.5962 - val_mse: 8.1062\n",
      "Epoch 184/500\n",
      "8749/8749 [==============================] - 0s 45us/sample - loss: 0.8372 - mae: 0.6963 - mse: 0.8372 - val_loss: 8.5011 - val_mae: 1.6848 - val_mse: 8.5011\n",
      "Epoch 185/500\n",
      "8749/8749 [==============================] - 0s 44us/sample - loss: 0.8337 - mae: 0.6935 - mse: 0.8337 - val_loss: 8.4676 - val_mae: 1.6523 - val_mse: 8.4676\n",
      "Epoch 186/500\n",
      "8749/8749 [==============================] - 0s 42us/sample - loss: 0.8442 - mae: 0.6974 - mse: 0.8442 - val_loss: 8.6036 - val_mae: 1.7681 - val_mse: 8.6036\n",
      "Epoch 187/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.8280 - mae: 0.6896 - mse: 0.8280 - val_loss: 8.1361 - val_mae: 1.5970 - val_mse: 8.1361\n",
      "Epoch 188/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.8452 - mae: 0.6938 - mse: 0.8452 - val_loss: 8.8937 - val_mae: 1.7495 - val_mse: 8.8937\n",
      "Epoch 189/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.8177 - mae: 0.6849 - mse: 0.8177 - val_loss: 8.7245 - val_mae: 1.7464 - val_mse: 8.7245\n",
      "Epoch 190/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.8357 - mae: 0.6937 - mse: 0.8357 - val_loss: 9.1006 - val_mae: 1.8972 - val_mse: 9.1006\n",
      "Epoch 191/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.8247 - mae: 0.6917 - mse: 0.8247 - val_loss: 8.7340 - val_mae: 1.7349 - val_mse: 8.7340\n",
      "Epoch 192/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.8267 - mae: 0.6884 - mse: 0.8267 - val_loss: 8.4133 - val_mae: 1.6675 - val_mse: 8.4133\n",
      "Epoch 193/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.8166 - mae: 0.6852 - mse: 0.8166 - val_loss: 8.1355 - val_mae: 1.5848 - val_mse: 8.1355\n",
      "Epoch 194/500\n",
      "8749/8749 [==============================] - 0s 41us/sample - loss: 0.8274 - mae: 0.6912 - mse: 0.8274 - val_loss: 8.2240 - val_mae: 1.5852 - val_mse: 8.2240\n",
      "Epoch 195/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.8209 - mae: 0.6871 - mse: 0.8209 - val_loss: 8.2571 - val_mae: 1.6050 - val_mse: 8.2571\n",
      "Epoch 196/500\n",
      "8749/8749 [==============================] - 0s 41us/sample - loss: 0.8194 - mae: 0.6883 - mse: 0.8194 - val_loss: 8.6071 - val_mae: 1.7838 - val_mse: 8.6071\n",
      "Epoch 197/500\n",
      "8749/8749 [==============================] - 0s 49us/sample - loss: 0.8206 - mae: 0.6892 - mse: 0.8206 - val_loss: 9.2793 - val_mae: 1.8455 - val_mse: 9.2793\n",
      "Epoch 198/500\n",
      "8749/8749 [==============================] - 0s 56us/sample - loss: 0.8197 - mae: 0.6827 - mse: 0.8197 - val_loss: 8.7836 - val_mae: 1.7923 - val_mse: 8.7836\n",
      "Epoch 199/500\n",
      "8749/8749 [==============================] - 0s 42us/sample - loss: 0.8258 - mae: 0.6895 - mse: 0.8258 - val_loss: 8.8751 - val_mae: 1.8063 - val_mse: 8.8751\n",
      "Epoch 200/500\n",
      "8749/8749 [==============================] - 0s 50us/sample - loss: 0.8172 - mae: 0.6866 - mse: 0.8172 - val_loss: 7.9371 - val_mae: 1.5703 - val_mse: 7.9371\n",
      "Epoch 201/500\n",
      "8749/8749 [==============================] - 0s 47us/sample - loss: 0.8243 - mae: 0.6888 - mse: 0.8243 - val_loss: 8.1281 - val_mae: 1.5388 - val_mse: 8.1281\n",
      "Epoch 202/500\n",
      "8749/8749 [==============================] - 0s 54us/sample - loss: 0.8076 - mae: 0.6784 - mse: 0.8076 - val_loss: 8.1145 - val_mae: 1.5822 - val_mse: 8.1145\n",
      "Epoch 203/500\n",
      "8749/8749 [==============================] - 0s 46us/sample - loss: 0.8095 - mae: 0.6814 - mse: 0.8095 - val_loss: 7.8434 - val_mae: 1.5405 - val_mse: 7.8434\n",
      "Epoch 204/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8126 - mae: 0.6844 - mse: 0.8126 - val_loss: 8.0096 - val_mae: 1.5367 - val_mse: 8.0096\n",
      "Epoch 205/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.8157 - mae: 0.6881 - mse: 0.8157 - val_loss: 7.9627 - val_mae: 1.5548 - val_mse: 7.9627\n",
      "Epoch 206/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8088 - mae: 0.6850 - mse: 0.8088 - val_loss: 7.9493 - val_mae: 1.5676 - val_mse: 7.9493\n",
      "Epoch 207/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.8245 - mae: 0.6906 - mse: 0.8245 - val_loss: 8.1265 - val_mae: 1.6054 - val_mse: 8.1265\n",
      "Epoch 208/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8142 - mae: 0.6825 - mse: 0.8142 - val_loss: 8.6399 - val_mae: 1.7153 - val_mse: 8.6399\n",
      "Epoch 209/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8089 - mae: 0.6830 - mse: 0.8089 - val_loss: 8.5695 - val_mae: 1.7249 - val_mse: 8.5695\n",
      "Epoch 210/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8055 - mae: 0.6814 - mse: 0.8055 - val_loss: 8.6619 - val_mae: 1.7204 - val_mse: 8.6619\n",
      "Epoch 211/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.8134 - mae: 0.6820 - mse: 0.8134 - val_loss: 8.0035 - val_mae: 1.5556 - val_mse: 8.0035\n",
      "Epoch 212/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8144 - mae: 0.6817 - mse: 0.8144 - val_loss: 8.3583 - val_mae: 1.6388 - val_mse: 8.3583\n",
      "Epoch 213/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8073 - mae: 0.6806 - mse: 0.8073 - val_loss: 8.3212 - val_mae: 1.6426 - val_mse: 8.3212\n",
      "Epoch 214/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8118 - mae: 0.6830 - mse: 0.8118 - val_loss: 8.6535 - val_mae: 1.7579 - val_mse: 8.6535\n",
      "Epoch 215/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.8047 - mae: 0.6781 - mse: 0.8047 - val_loss: 8.4745 - val_mae: 1.7387 - val_mse: 8.4745\n",
      "Epoch 216/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8029 - mae: 0.6792 - mse: 0.8029 - val_loss: 8.9315 - val_mae: 1.7364 - val_mse: 8.9315\n",
      "Epoch 217/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7945 - mae: 0.6759 - mse: 0.7945 - val_loss: 8.2736 - val_mae: 1.5615 - val_mse: 8.2736\n",
      "Epoch 218/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.8019 - mae: 0.6786 - mse: 0.8019 - val_loss: 8.1916 - val_mae: 1.6268 - val_mse: 8.1916\n",
      "Epoch 219/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.8044 - mae: 0.6810 - mse: 0.8044 - val_loss: 8.2551 - val_mae: 1.5944 - val_mse: 8.2551\n",
      "Epoch 220/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.7912 - mae: 0.6737 - mse: 0.7912 - val_loss: 8.1292 - val_mae: 1.5427 - val_mse: 8.1292\n",
      "Epoch 221/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.8043 - mae: 0.6778 - mse: 0.8043 - val_loss: 8.0279 - val_mae: 1.5790 - val_mse: 8.0279\n",
      "Epoch 222/500\n",
      "8749/8749 [==============================] - 0s 56us/sample - loss: 0.8012 - mae: 0.6778 - mse: 0.8012 - val_loss: 7.9967 - val_mae: 1.6198 - val_mse: 7.9967\n",
      "Epoch 223/500\n",
      "8749/8749 [==============================] - 0s 55us/sample - loss: 0.8035 - mae: 0.6827 - mse: 0.8035 - val_loss: 7.9203 - val_mae: 1.5087 - val_mse: 7.9203\n",
      "Epoch 224/500\n",
      "8749/8749 [==============================] - 0s 42us/sample - loss: 0.7898 - mae: 0.6746 - mse: 0.7898 - val_loss: 8.0362 - val_mae: 1.5758 - val_mse: 8.0362\n",
      "Epoch 225/500\n",
      "8749/8749 [==============================] - 0s 41us/sample - loss: 0.7957 - mae: 0.6775 - mse: 0.7957 - val_loss: 8.1991 - val_mae: 1.6332 - val_mse: 8.1991\n",
      "Epoch 226/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.7953 - mae: 0.6788 - mse: 0.7953 - val_loss: 8.2594 - val_mae: 1.6367 - val_mse: 8.2594\n",
      "Epoch 227/500\n",
      "8749/8749 [==============================] - 0s 40us/sample - loss: 0.7981 - mae: 0.6775 - mse: 0.7981 - val_loss: 7.9007 - val_mae: 1.6012 - val_mse: 7.9007\n",
      "Epoch 228/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7870 - mae: 0.6729 - mse: 0.7870 - val_loss: 8.3292 - val_mae: 1.6444 - val_mse: 8.3292\n",
      "Epoch 229/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7989 - mae: 0.6780 - mse: 0.7989 - val_loss: 8.1834 - val_mae: 1.6578 - val_mse: 8.1834\n",
      "Epoch 230/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7803 - mae: 0.6687 - mse: 0.7803 - val_loss: 7.5906 - val_mae: 1.5025 - val_mse: 7.5906\n",
      "Epoch 231/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.7923 - mae: 0.6736 - mse: 0.7923 - val_loss: 8.1349 - val_mae: 1.6089 - val_mse: 8.1349\n",
      "Epoch 232/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.7910 - mae: 0.6756 - mse: 0.7910 - val_loss: 8.0697 - val_mae: 1.5874 - val_mse: 8.0697\n",
      "Epoch 233/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7881 - mae: 0.6717 - mse: 0.7881 - val_loss: 8.3123 - val_mae: 1.5691 - val_mse: 8.3123\n",
      "Epoch 234/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7869 - mae: 0.6761 - mse: 0.7869 - val_loss: 8.0882 - val_mae: 1.6036 - val_mse: 8.0882\n",
      "Epoch 235/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7760 - mae: 0.6663 - mse: 0.7760 - val_loss: 8.1511 - val_mae: 1.5841 - val_mse: 8.1511\n",
      "Epoch 236/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7925 - mae: 0.6754 - mse: 0.7925 - val_loss: 7.9061 - val_mae: 1.5584 - val_mse: 7.9061\n",
      "Epoch 237/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7847 - mae: 0.6733 - mse: 0.7847 - val_loss: 8.0511 - val_mae: 1.5990 - val_mse: 8.0511\n",
      "Epoch 238/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7797 - mae: 0.6689 - mse: 0.7797 - val_loss: 8.8327 - val_mae: 1.7849 - val_mse: 8.8327\n",
      "Epoch 239/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7964 - mae: 0.6752 - mse: 0.7964 - val_loss: 7.8591 - val_mae: 1.5471 - val_mse: 7.8591\n",
      "Epoch 240/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7799 - mae: 0.6682 - mse: 0.7799 - val_loss: 8.5409 - val_mae: 1.7020 - val_mse: 8.5409\n",
      "Epoch 241/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7849 - mae: 0.6703 - mse: 0.7849 - val_loss: 7.9802 - val_mae: 1.5873 - val_mse: 7.9802\n",
      "Epoch 242/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7874 - mae: 0.6738 - mse: 0.7874 - val_loss: 8.1605 - val_mae: 1.6256 - val_mse: 8.1605\n",
      "Epoch 243/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7791 - mae: 0.6678 - mse: 0.7791 - val_loss: 7.9937 - val_mae: 1.5939 - val_mse: 7.9937\n",
      "Epoch 244/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7900 - mae: 0.6721 - mse: 0.7900 - val_loss: 7.8172 - val_mae: 1.5020 - val_mse: 7.8172\n",
      "Epoch 245/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7876 - mae: 0.6694 - mse: 0.7876 - val_loss: 8.2080 - val_mae: 1.6074 - val_mse: 8.2080\n",
      "Epoch 246/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7732 - mae: 0.6645 - mse: 0.7732 - val_loss: 8.2640 - val_mae: 1.6121 - val_mse: 8.2640\n",
      "Epoch 247/500\n",
      "8749/8749 [==============================] - 0s 39us/sample - loss: 0.7812 - mae: 0.6692 - mse: 0.7812 - val_loss: 8.5044 - val_mae: 1.5883 - val_mse: 8.5044\n",
      "Epoch 248/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7642 - mae: 0.6623 - mse: 0.7642 - val_loss: 8.6296 - val_mae: 1.6962 - val_mse: 8.6296\n",
      "Epoch 249/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7727 - mae: 0.6637 - mse: 0.7727 - val_loss: 8.7613 - val_mae: 1.7239 - val_mse: 8.7613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.7711 - mae: 0.6659 - mse: 0.7711 - val_loss: 8.8010 - val_mae: 1.7783 - val_mse: 8.8010\n",
      "Epoch 251/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.7705 - mae: 0.6634 - mse: 0.7705 - val_loss: 7.9429 - val_mae: 1.5452 - val_mse: 7.9429\n",
      "Epoch 252/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7580 - mae: 0.6578 - mse: 0.7580 - val_loss: 7.9906 - val_mae: 1.5473 - val_mse: 7.9906\n",
      "Epoch 253/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.7627 - mae: 0.6606 - mse: 0.7627 - val_loss: 8.1422 - val_mae: 1.6215 - val_mse: 8.1422\n",
      "Epoch 254/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7630 - mae: 0.6590 - mse: 0.7630 - val_loss: 8.4241 - val_mae: 1.6679 - val_mse: 8.4241\n",
      "Epoch 255/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7724 - mae: 0.6669 - mse: 0.7724 - val_loss: 7.8139 - val_mae: 1.5073 - val_mse: 7.8139\n",
      "Epoch 256/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.7580 - mae: 0.6589 - mse: 0.7580 - val_loss: 8.6642 - val_mae: 1.7062 - val_mse: 8.6642\n",
      "Epoch 257/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7544 - mae: 0.6571 - mse: 0.7544 - val_loss: 8.2050 - val_mae: 1.6468 - val_mse: 8.2050\n",
      "Epoch 258/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7623 - mae: 0.6589 - mse: 0.7623 - val_loss: 8.2839 - val_mae: 1.5986 - val_mse: 8.2839\n",
      "Epoch 259/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7626 - mae: 0.6606 - mse: 0.7626 - val_loss: 8.0021 - val_mae: 1.5210 - val_mse: 8.0021\n",
      "Epoch 260/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7557 - mae: 0.6578 - mse: 0.7557 - val_loss: 8.0797 - val_mae: 1.6231 - val_mse: 8.0797\n",
      "Epoch 261/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7621 - mae: 0.6630 - mse: 0.7621 - val_loss: 8.0240 - val_mae: 1.5569 - val_mse: 8.0240\n",
      "Epoch 262/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7487 - mae: 0.6567 - mse: 0.7487 - val_loss: 7.9996 - val_mae: 1.5618 - val_mse: 7.9996\n",
      "Epoch 263/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7628 - mae: 0.6628 - mse: 0.7628 - val_loss: 8.1989 - val_mae: 1.5993 - val_mse: 8.1989\n",
      "Epoch 264/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7478 - mae: 0.6531 - mse: 0.7478 - val_loss: 8.4666 - val_mae: 1.6622 - val_mse: 8.4666\n",
      "Epoch 265/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7578 - mae: 0.6584 - mse: 0.7578 - val_loss: 8.2353 - val_mae: 1.6066 - val_mse: 8.2353\n",
      "Epoch 266/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7560 - mae: 0.6589 - mse: 0.7560 - val_loss: 8.4285 - val_mae: 1.6825 - val_mse: 8.4285\n",
      "Epoch 267/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7654 - mae: 0.6615 - mse: 0.7654 - val_loss: 7.6822 - val_mae: 1.5003 - val_mse: 7.6822\n",
      "Epoch 268/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7533 - mae: 0.6575 - mse: 0.7533 - val_loss: 8.7033 - val_mae: 1.8786 - val_mse: 8.7033\n",
      "Epoch 269/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.7538 - mae: 0.6577 - mse: 0.7538 - val_loss: 8.0798 - val_mae: 1.5580 - val_mse: 8.0798\n",
      "Epoch 270/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.7538 - mae: 0.6582 - mse: 0.7538 - val_loss: 8.0624 - val_mae: 1.5827 - val_mse: 8.0624\n",
      "Epoch 271/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7467 - mae: 0.6532 - mse: 0.7467 - val_loss: 7.8464 - val_mae: 1.5175 - val_mse: 7.8464\n",
      "Epoch 272/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7435 - mae: 0.6522 - mse: 0.7435 - val_loss: 7.9973 - val_mae: 1.5482 - val_mse: 7.9973\n",
      "Epoch 273/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.7523 - mae: 0.6573 - mse: 0.7523 - val_loss: 7.6928 - val_mae: 1.5037 - val_mse: 7.6928\n",
      "Epoch 274/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.7451 - mae: 0.6540 - mse: 0.7451 - val_loss: 8.0964 - val_mae: 1.6080 - val_mse: 8.0964\n",
      "Epoch 275/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7397 - mae: 0.6516 - mse: 0.7397 - val_loss: 8.2111 - val_mae: 1.6081 - val_mse: 8.2111\n",
      "Epoch 276/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.7409 - mae: 0.6524 - mse: 0.7409 - val_loss: 7.8913 - val_mae: 1.5238 - val_mse: 7.8913\n",
      "Epoch 277/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7390 - mae: 0.6499 - mse: 0.7390 - val_loss: 8.1864 - val_mae: 1.6354 - val_mse: 8.1864\n",
      "Epoch 278/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7540 - mae: 0.6563 - mse: 0.7540 - val_loss: 8.0740 - val_mae: 1.5933 - val_mse: 8.0740\n",
      "Epoch 279/500\n",
      "8749/8749 [==============================] - 0s 38us/sample - loss: 0.7476 - mae: 0.6527 - mse: 0.7476 - val_loss: 7.7459 - val_mae: 1.5197 - val_mse: 7.7459\n",
      "Epoch 280/500\n",
      "8749/8749 [==============================] - 0s 37us/sample - loss: 0.7396 - mae: 0.6517 - mse: 0.7396 - val_loss: 8.4565 - val_mae: 1.8185 - val_mse: 8.4565\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10207 samples, validate on 3403 samples\n",
      "Epoch 1/500\n",
      "10207/10207 [==============================] - 1s 79us/sample - loss: 360.1077 - mae: 8.3663 - mse: 360.1077 - val_loss: 64.2072 - val_mae: 4.7321 - val_mse: 64.2072\n",
      "Epoch 2/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 18.7039 - mae: 3.1515 - mse: 18.7039 - val_loss: 47.8958 - val_mae: 4.5443 - val_mse: 47.8958\n",
      "Epoch 3/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 14.1742 - mae: 2.8840 - mse: 14.1742 - val_loss: 33.5842 - val_mae: 3.5230 - val_mse: 33.5843\n",
      "Epoch 4/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 11.7611 - mae: 2.6531 - mse: 11.7611 - val_loss: 30.9902 - val_mae: 3.6940 - val_mse: 30.9902\n",
      "Epoch 5/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 10.5417 - mae: 2.5216 - mse: 10.5417 - val_loss: 23.7528 - val_mae: 2.8760 - val_mse: 23.7528\n",
      "Epoch 6/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 9.3383 - mae: 2.4021 - mse: 9.3383 - val_loss: 27.8144 - val_mae: 3.7540 - val_mse: 27.8144\n",
      "Epoch 7/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 8.6194 - mae: 2.3130 - mse: 8.6194 - val_loss: 20.6875 - val_mae: 2.9178 - val_mse: 20.6875\n",
      "Epoch 8/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 8.1415 - mae: 2.2551 - mse: 8.1415 - val_loss: 20.8852 - val_mae: 3.0818 - val_mse: 20.8852\n",
      "Epoch 9/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 7.7966 - mae: 2.2099 - mse: 7.7966 - val_loss: 18.1530 - val_mae: 2.5793 - val_mse: 18.1530\n",
      "Epoch 10/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 7.5755 - mae: 2.1782 - mse: 7.5755 - val_loss: 17.5775 - val_mae: 2.4469 - val_mse: 17.5775\n",
      "Epoch 11/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 7.3630 - mae: 2.1592 - mse: 7.3630 - val_loss: 18.4214 - val_mae: 2.6212 - val_mse: 18.4214\n",
      "Epoch 12/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 7.1344 - mae: 2.1189 - mse: 7.1344 - val_loss: 19.9075 - val_mae: 2.9156 - val_mse: 19.9075\n",
      "Epoch 13/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 6.9984 - mae: 2.1068 - mse: 6.9984 - val_loss: 17.4342 - val_mae: 2.3918 - val_mse: 17.4342\n",
      "Epoch 14/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 6.7794 - mae: 2.0600 - mse: 6.7794 - val_loss: 19.2284 - val_mae: 3.0227 - val_mse: 19.2284\n",
      "Epoch 15/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 6.6716 - mae: 2.0842 - mse: 6.6716 - val_loss: 20.4761 - val_mae: 3.3874 - val_mse: 20.4761\n",
      "Epoch 16/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 6.5329 - mae: 2.0394 - mse: 6.5329 - val_loss: 17.5385 - val_mae: 2.7095 - val_mse: 17.5385\n",
      "Epoch 17/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 6.3764 - mae: 2.0250 - mse: 6.3764 - val_loss: 17.5020 - val_mae: 2.7200 - val_mse: 17.5020\n",
      "Epoch 18/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 6.3068 - mae: 1.9973 - mse: 6.3068 - val_loss: 15.9300 - val_mae: 2.3385 - val_mse: 15.9300\n",
      "Epoch 19/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 6.2062 - mae: 1.9977 - mse: 6.2062 - val_loss: 19.0544 - val_mae: 3.0401 - val_mse: 19.0544\n",
      "Epoch 20/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 6.0349 - mae: 1.9599 - mse: 6.0349 - val_loss: 19.7934 - val_mae: 3.1236 - val_mse: 19.7934\n",
      "Epoch 21/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 5.9315 - mae: 1.9556 - mse: 5.9315 - val_loss: 16.0669 - val_mae: 2.5899 - val_mse: 16.0669\n",
      "Epoch 22/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 5.9270 - mae: 1.9590 - mse: 5.9270 - val_loss: 17.3143 - val_mae: 2.6026 - val_mse: 17.3143\n",
      "Epoch 23/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 5.8280 - mae: 1.9285 - mse: 5.8280 - val_loss: 16.8543 - val_mae: 2.5350 - val_mse: 16.8543\n",
      "Epoch 24/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 5.7192 - mae: 1.9259 - mse: 5.7192 - val_loss: 28.1543 - val_mae: 3.8417 - val_mse: 28.1543\n",
      "Epoch 25/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 5.5992 - mae: 1.8763 - mse: 5.5992 - val_loss: 17.3946 - val_mae: 2.8485 - val_mse: 17.3946\n",
      "Epoch 26/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 5.5023 - mae: 1.8979 - mse: 5.5023 - val_loss: 19.9211 - val_mae: 2.9925 - val_mse: 19.9211\n",
      "Epoch 27/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 5.4373 - mae: 1.8639 - mse: 5.4373 - val_loss: 14.9433 - val_mae: 2.4842 - val_mse: 14.9433\n",
      "Epoch 28/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 5.3053 - mae: 1.8345 - mse: 5.3053 - val_loss: 15.5328 - val_mae: 2.6516 - val_mse: 15.5328\n",
      "Epoch 29/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 5.2386 - mae: 1.8473 - mse: 5.2386 - val_loss: 13.2969 - val_mae: 2.1802 - val_mse: 13.2969\n",
      "Epoch 30/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 5.1719 - mae: 1.8338 - mse: 5.1719 - val_loss: 14.1816 - val_mae: 2.3478 - val_mse: 14.1816\n",
      "Epoch 31/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 5.1057 - mae: 1.7963 - mse: 5.1057 - val_loss: 14.8418 - val_mae: 2.4606 - val_mse: 14.8418\n",
      "Epoch 32/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 4.8976 - mae: 1.7639 - mse: 4.8976 - val_loss: 12.5874 - val_mae: 1.9863 - val_mse: 12.5874\n",
      "Epoch 33/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 4.8866 - mae: 1.7480 - mse: 4.8866 - val_loss: 14.0888 - val_mae: 2.4198 - val_mse: 14.0888\n",
      "Epoch 34/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 4.8790 - mae: 1.7745 - mse: 4.8790 - val_loss: 14.3811 - val_mae: 2.3445 - val_mse: 14.3811\n",
      "Epoch 35/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 4.7486 - mae: 1.7460 - mse: 4.7486 - val_loss: 18.8367 - val_mae: 3.0214 - val_mse: 18.8367\n",
      "Epoch 36/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 4.6792 - mae: 1.7401 - mse: 4.6792 - val_loss: 14.0757 - val_mae: 2.3577 - val_mse: 14.0757\n",
      "Epoch 37/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 4.5386 - mae: 1.7154 - mse: 4.5387 - val_loss: 17.9773 - val_mae: 2.9368 - val_mse: 17.9773\n",
      "Epoch 38/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 4.5370 - mae: 1.7098 - mse: 4.5370 - val_loss: 12.7102 - val_mae: 2.1529 - val_mse: 12.7102\n",
      "Epoch 39/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 4.3537 - mae: 1.6686 - mse: 4.3537 - val_loss: 14.4308 - val_mae: 2.6899 - val_mse: 14.4308\n",
      "Epoch 40/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 4.3102 - mae: 1.6469 - mse: 4.3102 - val_loss: 11.2954 - val_mae: 1.8891 - val_mse: 11.2954\n",
      "Epoch 41/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 4.2737 - mae: 1.6549 - mse: 4.2737 - val_loss: 13.7798 - val_mae: 2.4041 - val_mse: 13.7798\n",
      "Epoch 42/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 4.1939 - mae: 1.6420 - mse: 4.1940 - val_loss: 12.1954 - val_mae: 2.2363 - val_mse: 12.1954\n",
      "Epoch 43/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 4.1014 - mae: 1.6158 - mse: 4.1014 - val_loss: 13.7872 - val_mae: 2.5171 - val_mse: 13.7872\n",
      "Epoch 44/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 4.0399 - mae: 1.6045 - mse: 4.0399 - val_loss: 12.4623 - val_mae: 2.0569 - val_mse: 12.4623\n",
      "Epoch 45/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.9660 - mae: 1.5935 - mse: 3.9660 - val_loss: 12.0969 - val_mae: 2.1545 - val_mse: 12.0969\n",
      "Epoch 46/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.9003 - mae: 1.5699 - mse: 3.9002 - val_loss: 15.5594 - val_mae: 2.6669 - val_mse: 15.5594\n",
      "Epoch 47/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.8811 - mae: 1.5818 - mse: 3.8811 - val_loss: 11.8278 - val_mae: 2.1608 - val_mse: 11.8278\n",
      "Epoch 48/500\n",
      "10207/10207 [==============================] - 0s 39us/sample - loss: 3.8465 - mae: 1.5663 - mse: 3.8465 - val_loss: 12.5641 - val_mae: 2.1930 - val_mse: 12.5641\n",
      "Epoch 49/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.7745 - mae: 1.5527 - mse: 3.7745 - val_loss: 14.1573 - val_mae: 2.4476 - val_mse: 14.1573\n",
      "Epoch 50/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.6901 - mae: 1.5291 - mse: 3.6901 - val_loss: 12.0064 - val_mae: 2.0505 - val_mse: 12.0064\n",
      "Epoch 51/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.6556 - mae: 1.5291 - mse: 3.6556 - val_loss: 14.0983 - val_mae: 2.5161 - val_mse: 14.0983\n",
      "Epoch 52/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.5993 - mae: 1.5246 - mse: 3.5993 - val_loss: 11.2500 - val_mae: 2.0783 - val_mse: 11.2500\n",
      "Epoch 53/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.5346 - mae: 1.4923 - mse: 3.5346 - val_loss: 13.2177 - val_mae: 2.2669 - val_mse: 13.2177\n",
      "Epoch 54/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.4747 - mae: 1.4809 - mse: 3.4747 - val_loss: 12.2365 - val_mae: 2.1563 - val_mse: 12.2365\n",
      "Epoch 55/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.3859 - mae: 1.4696 - mse: 3.3859 - val_loss: 12.0433 - val_mae: 2.1500 - val_mse: 12.0433\n",
      "Epoch 56/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.3440 - mae: 1.4512 - mse: 3.3440 - val_loss: 10.9043 - val_mae: 1.9155 - val_mse: 10.9043\n",
      "Epoch 57/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.3052 - mae: 1.4460 - mse: 3.3052 - val_loss: 13.9670 - val_mae: 2.6185 - val_mse: 13.9670\n",
      "Epoch 58/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.2185 - mae: 1.4261 - mse: 3.2185 - val_loss: 11.2845 - val_mae: 2.0181 - val_mse: 11.2845\n",
      "Epoch 59/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.2138 - mae: 1.4278 - mse: 3.2138 - val_loss: 10.2556 - val_mae: 1.7967 - val_mse: 10.2556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.1048 - mae: 1.3981 - mse: 3.1048 - val_loss: 10.2109 - val_mae: 1.8265 - val_mse: 10.2109\n",
      "Epoch 61/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.1170 - mae: 1.3931 - mse: 3.1170 - val_loss: 11.0283 - val_mae: 1.9941 - val_mse: 11.0283\n",
      "Epoch 62/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.9987 - mae: 1.3843 - mse: 2.9987 - val_loss: 9.8985 - val_mae: 1.8324 - val_mse: 9.8985\n",
      "Epoch 63/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 3.0064 - mae: 1.3706 - mse: 3.0064 - val_loss: 12.5578 - val_mae: 2.3553 - val_mse: 12.5578\n",
      "Epoch 64/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 2.9342 - mae: 1.3564 - mse: 2.9342 - val_loss: 11.1871 - val_mae: 2.1919 - val_mse: 11.1871\n",
      "Epoch 65/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.8680 - mae: 1.3453 - mse: 2.8680 - val_loss: 10.3809 - val_mae: 2.0972 - val_mse: 10.3809\n",
      "Epoch 66/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 2.8324 - mae: 1.3411 - mse: 2.8324 - val_loss: 9.1666 - val_mae: 1.8785 - val_mse: 9.1666\n",
      "Epoch 67/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 2.8036 - mae: 1.3245 - mse: 2.8036 - val_loss: 9.1159 - val_mae: 1.7190 - val_mse: 9.1159\n",
      "Epoch 68/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.7629 - mae: 1.3061 - mse: 2.7629 - val_loss: 11.5036 - val_mae: 2.4894 - val_mse: 11.5036\n",
      "Epoch 69/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 2.7437 - mae: 1.3085 - mse: 2.7437 - val_loss: 9.6416 - val_mae: 1.9378 - val_mse: 9.6416\n",
      "Epoch 70/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.6743 - mae: 1.2964 - mse: 2.6743 - val_loss: 9.0256 - val_mae: 1.7925 - val_mse: 9.0256\n",
      "Epoch 71/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.6096 - mae: 1.2804 - mse: 2.6096 - val_loss: 8.4950 - val_mae: 1.7067 - val_mse: 8.4950\n",
      "Epoch 72/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.5964 - mae: 1.2807 - mse: 2.5964 - val_loss: 9.2654 - val_mae: 1.8807 - val_mse: 9.2654\n",
      "Epoch 73/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 2.5642 - mae: 1.2671 - mse: 2.5642 - val_loss: 9.3838 - val_mae: 1.9674 - val_mse: 9.3838\n",
      "Epoch 74/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.5442 - mae: 1.2657 - mse: 2.5442 - val_loss: 9.7169 - val_mae: 1.9772 - val_mse: 9.7169\n",
      "Epoch 75/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.4794 - mae: 1.2464 - mse: 2.4794 - val_loss: 9.2249 - val_mae: 1.9138 - val_mse: 9.2249\n",
      "Epoch 76/500\n",
      "10207/10207 [==============================] - 0s 39us/sample - loss: 2.4661 - mae: 1.2368 - mse: 2.4661 - val_loss: 9.7834 - val_mae: 2.1024 - val_mse: 9.7834\n",
      "Epoch 77/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.4570 - mae: 1.2426 - mse: 2.4570 - val_loss: 8.3581 - val_mae: 1.6619 - val_mse: 8.3581\n",
      "Epoch 78/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.4010 - mae: 1.2266 - mse: 2.4010 - val_loss: 8.6981 - val_mae: 1.7864 - val_mse: 8.6981\n",
      "Epoch 79/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.3345 - mae: 1.2045 - mse: 2.3345 - val_loss: 8.2176 - val_mae: 1.6636 - val_mse: 8.2176\n",
      "Epoch 80/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 2.3222 - mae: 1.2057 - mse: 2.3222 - val_loss: 11.1539 - val_mae: 2.2990 - val_mse: 11.1539\n",
      "Epoch 81/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.3521 - mae: 1.2152 - mse: 2.3521 - val_loss: 7.9760 - val_mae: 1.7132 - val_mse: 7.9760\n",
      "Epoch 82/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.2660 - mae: 1.1812 - mse: 2.2660 - val_loss: 8.5726 - val_mae: 1.8194 - val_mse: 8.5726\n",
      "Epoch 83/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.2350 - mae: 1.1818 - mse: 2.2350 - val_loss: 10.7070 - val_mae: 2.3450 - val_mse: 10.7070\n",
      "Epoch 84/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.2260 - mae: 1.1792 - mse: 2.2260 - val_loss: 8.5830 - val_mae: 1.7874 - val_mse: 8.5830\n",
      "Epoch 85/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.1798 - mae: 1.1645 - mse: 2.1798 - val_loss: 8.3529 - val_mae: 1.6963 - val_mse: 8.3529\n",
      "Epoch 86/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.1635 - mae: 1.1555 - mse: 2.1635 - val_loss: 8.2438 - val_mae: 1.7447 - val_mse: 8.2438\n",
      "Epoch 87/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.1245 - mae: 1.1519 - mse: 2.1245 - val_loss: 10.0667 - val_mae: 2.1756 - val_mse: 10.0667\n",
      "Epoch 88/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.1157 - mae: 1.1477 - mse: 2.1157 - val_loss: 9.2335 - val_mae: 1.9277 - val_mse: 9.2335\n",
      "Epoch 89/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.0977 - mae: 1.1370 - mse: 2.0977 - val_loss: 8.4390 - val_mae: 1.7556 - val_mse: 8.4390\n",
      "Epoch 90/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.0447 - mae: 1.1257 - mse: 2.0447 - val_loss: 8.6961 - val_mae: 1.8096 - val_mse: 8.6961\n",
      "Epoch 91/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.0418 - mae: 1.1206 - mse: 2.0418 - val_loss: 9.2363 - val_mae: 1.9501 - val_mse: 9.2363\n",
      "Epoch 92/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 2.0147 - mae: 1.1169 - mse: 2.0147 - val_loss: 8.5515 - val_mae: 1.7443 - val_mse: 8.5515\n",
      "Epoch 93/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.9781 - mae: 1.1114 - mse: 1.9781 - val_loss: 7.8875 - val_mae: 1.6024 - val_mse: 7.8875\n",
      "Epoch 94/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.9612 - mae: 1.1008 - mse: 1.9612 - val_loss: 7.6525 - val_mae: 1.6054 - val_mse: 7.6525\n",
      "Epoch 95/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.9295 - mae: 1.0937 - mse: 1.9295 - val_loss: 7.8212 - val_mae: 1.6077 - val_mse: 7.8212\n",
      "Epoch 96/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.8961 - mae: 1.0803 - mse: 1.8961 - val_loss: 7.8420 - val_mae: 1.6982 - val_mse: 7.8420\n",
      "Epoch 97/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.8823 - mae: 1.0756 - mse: 1.8823 - val_loss: 7.6919 - val_mae: 1.5727 - val_mse: 7.6919\n",
      "Epoch 98/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.8477 - mae: 1.0654 - mse: 1.8477 - val_loss: 8.8920 - val_mae: 1.8911 - val_mse: 8.8920\n",
      "Epoch 99/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.8262 - mae: 1.0570 - mse: 1.8262 - val_loss: 8.0855 - val_mae: 1.6194 - val_mse: 8.0855\n",
      "Epoch 100/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.7674 - mae: 1.0378 - mse: 1.7675 - val_loss: 8.4920 - val_mae: 1.7180 - val_mse: 8.4920\n",
      "Epoch 101/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.7506 - mae: 1.0342 - mse: 1.7506 - val_loss: 7.8140 - val_mae: 1.6293 - val_mse: 7.8140\n",
      "Epoch 102/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.7343 - mae: 1.0299 - mse: 1.7343 - val_loss: 7.4420 - val_mae: 1.5394 - val_mse: 7.4420\n",
      "Epoch 103/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.7159 - mae: 1.0233 - mse: 1.7159 - val_loss: 8.0957 - val_mae: 1.7149 - val_mse: 8.0957\n",
      "Epoch 104/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 1.7054 - mae: 1.0214 - mse: 1.7054 - val_loss: 8.1210 - val_mae: 1.6056 - val_mse: 8.1210\n",
      "Epoch 105/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.6756 - mae: 1.0145 - mse: 1.6756 - val_loss: 9.0713 - val_mae: 1.8309 - val_mse: 9.0713\n",
      "Epoch 106/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.6449 - mae: 1.0005 - mse: 1.6449 - val_loss: 8.7691 - val_mae: 1.8151 - val_mse: 8.7691\n",
      "Epoch 107/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.6229 - mae: 0.9973 - mse: 1.6229 - val_loss: 8.3276 - val_mae: 1.6994 - val_mse: 8.3276\n",
      "Epoch 108/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.6173 - mae: 0.9930 - mse: 1.6173 - val_loss: 7.9515 - val_mae: 1.5905 - val_mse: 7.9515\n",
      "Epoch 109/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.5891 - mae: 0.9837 - mse: 1.5891 - val_loss: 8.0344 - val_mae: 1.6197 - val_mse: 8.0344\n",
      "Epoch 110/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.5753 - mae: 0.9791 - mse: 1.5753 - val_loss: 7.8161 - val_mae: 1.6689 - val_mse: 7.8161\n",
      "Epoch 111/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.5669 - mae: 0.9809 - mse: 1.5669 - val_loss: 8.2838 - val_mae: 1.6482 - val_mse: 8.2838\n",
      "Epoch 112/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.5492 - mae: 0.9707 - mse: 1.5492 - val_loss: 8.0350 - val_mae: 1.6635 - val_mse: 8.0350\n",
      "Epoch 113/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.5115 - mae: 0.9596 - mse: 1.5115 - val_loss: 8.4591 - val_mae: 1.6667 - val_mse: 8.4591\n",
      "Epoch 114/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.5245 - mae: 0.9603 - mse: 1.5245 - val_loss: 8.0630 - val_mae: 1.6477 - val_mse: 8.0630\n",
      "Epoch 115/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.5014 - mae: 0.9517 - mse: 1.5014 - val_loss: 8.2213 - val_mae: 1.6903 - val_mse: 8.2213\n",
      "Epoch 116/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.4873 - mae: 0.9501 - mse: 1.4873 - val_loss: 8.1381 - val_mae: 1.6708 - val_mse: 8.1381\n",
      "Epoch 117/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.4729 - mae: 0.9433 - mse: 1.4729 - val_loss: 9.1109 - val_mae: 1.7863 - val_mse: 9.1109\n",
      "Epoch 118/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.4706 - mae: 0.9399 - mse: 1.4706 - val_loss: 8.3635 - val_mae: 1.6610 - val_mse: 8.3635\n",
      "Epoch 119/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.4464 - mae: 0.9342 - mse: 1.4464 - val_loss: 7.8664 - val_mae: 1.6250 - val_mse: 7.8664\n",
      "Epoch 120/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.4377 - mae: 0.9324 - mse: 1.4377 - val_loss: 8.7137 - val_mae: 1.7505 - val_mse: 8.7137\n",
      "Epoch 121/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.4285 - mae: 0.9249 - mse: 1.4285 - val_loss: 8.3756 - val_mae: 1.6858 - val_mse: 8.3756\n",
      "Epoch 122/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.3987 - mae: 0.9183 - mse: 1.3987 - val_loss: 8.9664 - val_mae: 1.8510 - val_mse: 8.9664\n",
      "Epoch 123/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.4089 - mae: 0.9195 - mse: 1.4089 - val_loss: 8.5067 - val_mae: 1.6624 - val_mse: 8.5067\n",
      "Epoch 124/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.3945 - mae: 0.9139 - mse: 1.3945 - val_loss: 7.8800 - val_mae: 1.5897 - val_mse: 7.8800\n",
      "Epoch 125/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.3680 - mae: 0.9083 - mse: 1.3680 - val_loss: 9.8640 - val_mae: 2.0007 - val_mse: 9.8640\n",
      "Epoch 126/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.3604 - mae: 0.9033 - mse: 1.3604 - val_loss: 8.8896 - val_mae: 1.7707 - val_mse: 8.8896\n",
      "Epoch 127/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.3652 - mae: 0.9039 - mse: 1.3652 - val_loss: 9.0542 - val_mae: 1.8187 - val_mse: 9.0542\n",
      "Epoch 128/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.3483 - mae: 0.9016 - mse: 1.3483 - val_loss: 7.8548 - val_mae: 1.5727 - val_mse: 7.8548\n",
      "Epoch 129/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.3412 - mae: 0.8992 - mse: 1.3412 - val_loss: 8.3666 - val_mae: 1.6964 - val_mse: 8.3666\n",
      "Epoch 130/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.3279 - mae: 0.8930 - mse: 1.3279 - val_loss: 8.5876 - val_mae: 1.8202 - val_mse: 8.5876\n",
      "Epoch 131/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.3371 - mae: 0.8952 - mse: 1.3371 - val_loss: 7.6700 - val_mae: 1.5691 - val_mse: 7.6700\n",
      "Epoch 132/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.3095 - mae: 0.8876 - mse: 1.3095 - val_loss: 7.9958 - val_mae: 1.5867 - val_mse: 7.9958\n",
      "Epoch 133/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.3262 - mae: 0.8906 - mse: 1.3262 - val_loss: 8.5025 - val_mae: 1.6994 - val_mse: 8.5025\n",
      "Epoch 134/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.3034 - mae: 0.8831 - mse: 1.3034 - val_loss: 8.6170 - val_mae: 1.7080 - val_mse: 8.6170\n",
      "Epoch 135/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.2943 - mae: 0.8784 - mse: 1.2943 - val_loss: 8.1232 - val_mae: 1.6639 - val_mse: 8.1232\n",
      "Epoch 136/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.2862 - mae: 0.8789 - mse: 1.2862 - val_loss: 7.9517 - val_mae: 1.6969 - val_mse: 7.9517\n",
      "Epoch 137/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.2803 - mae: 0.8775 - mse: 1.2803 - val_loss: 8.5712 - val_mae: 1.6749 - val_mse: 8.5712\n",
      "Epoch 138/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.2937 - mae: 0.8794 - mse: 1.2937 - val_loss: 8.0547 - val_mae: 1.6364 - val_mse: 8.0547\n",
      "Epoch 139/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.2517 - mae: 0.8659 - mse: 1.2517 - val_loss: 8.0812 - val_mae: 1.6718 - val_mse: 8.0812\n",
      "Epoch 140/500\n",
      "10207/10207 [==============================] - 0s 37us/sample - loss: 1.2486 - mae: 0.8656 - mse: 1.2486 - val_loss: 7.9848 - val_mae: 1.5552 - val_mse: 7.9848\n",
      "Epoch 141/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.2414 - mae: 0.8606 - mse: 1.2414 - val_loss: 8.2958 - val_mae: 1.5869 - val_mse: 8.2958\n",
      "Epoch 142/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.2279 - mae: 0.8554 - mse: 1.2279 - val_loss: 7.9341 - val_mae: 1.5544 - val_mse: 7.9341\n",
      "Epoch 143/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.2285 - mae: 0.8548 - mse: 1.2285 - val_loss: 8.0565 - val_mae: 1.6950 - val_mse: 8.0565\n",
      "Epoch 144/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.2247 - mae: 0.8549 - mse: 1.2247 - val_loss: 8.1076 - val_mae: 1.5856 - val_mse: 8.1076\n",
      "Epoch 145/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.2376 - mae: 0.8578 - mse: 1.2376 - val_loss: 8.0063 - val_mae: 1.5737 - val_mse: 8.0063\n",
      "Epoch 146/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.2192 - mae: 0.8502 - mse: 1.2192 - val_loss: 8.0574 - val_mae: 1.5660 - val_mse: 8.0574\n",
      "Epoch 147/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.2193 - mae: 0.8530 - mse: 1.2193 - val_loss: 8.6051 - val_mae: 1.6502 - val_mse: 8.6051\n",
      "Epoch 148/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.2029 - mae: 0.8451 - mse: 1.2029 - val_loss: 9.1668 - val_mae: 1.8514 - val_mse: 9.1668\n",
      "Epoch 149/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.2185 - mae: 0.8521 - mse: 1.2185 - val_loss: 8.8883 - val_mae: 1.7955 - val_mse: 8.8883\n",
      "Epoch 150/500\n",
      "10207/10207 [==============================] - 0s 39us/sample - loss: 1.1937 - mae: 0.8436 - mse: 1.1937 - val_loss: 8.3695 - val_mae: 1.6960 - val_mse: 8.3695\n",
      "Epoch 151/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.1975 - mae: 0.8431 - mse: 1.1975 - val_loss: 9.4860 - val_mae: 1.8961 - val_mse: 9.4860\n",
      "Epoch 152/500\n",
      "10207/10207 [==============================] - 0s 38us/sample - loss: 1.1864 - mae: 0.8401 - mse: 1.1864 - val_loss: 8.3429 - val_mae: 1.7692 - val_mse: 8.3429\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11665 samples, validate on 3889 samples\n",
      "Epoch 1/500\n",
      "11665/11665 [==============================] - 1s 67us/sample - loss: 114.1302 - mae: 5.5060 - mse: 114.1301 - val_loss: 49.5310 - val_mae: 4.0590 - val_mse: 49.5310\n",
      "Epoch 2/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 14.8212 - mae: 2.7361 - mse: 14.8212 - val_loss: 32.6444 - val_mae: 3.3087 - val_mse: 32.6444\n",
      "Epoch 3/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 10.5650 - mae: 2.4301 - mse: 10.5650 - val_loss: 33.1212 - val_mae: 4.1549 - val_mse: 33.1212\n",
      "Epoch 4/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 8.6410 - mae: 2.2360 - mse: 8.6410 - val_loss: 24.4629 - val_mae: 3.4055 - val_mse: 24.4629\n",
      "Epoch 5/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 7.7613 - mae: 2.1488 - mse: 7.7613 - val_loss: 18.3848 - val_mae: 2.5432 - val_mse: 18.3848\n",
      "Epoch 6/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 7.0587 - mae: 2.0576 - mse: 7.0587 - val_loss: 14.9925 - val_mae: 2.1920 - val_mse: 14.9925\n",
      "Epoch 7/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 6.5337 - mae: 1.9946 - mse: 6.5337 - val_loss: 15.3367 - val_mae: 2.4441 - val_mse: 15.3367\n",
      "Epoch 8/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 6.0755 - mae: 1.9341 - mse: 6.0755 - val_loss: 13.4820 - val_mae: 2.2362 - val_mse: 13.4820\n",
      "Epoch 9/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 5.7731 - mae: 1.9007 - mse: 5.7731 - val_loss: 13.1998 - val_mae: 2.2865 - val_mse: 13.1998\n",
      "Epoch 10/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 5.3935 - mae: 1.8389 - mse: 5.3935 - val_loss: 11.3445 - val_mae: 1.9853 - val_mse: 11.3445\n",
      "Epoch 11/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 5.2026 - mae: 1.8065 - mse: 5.2026 - val_loss: 11.2378 - val_mae: 2.1633 - val_mse: 11.2378\n",
      "Epoch 12/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 4.8789 - mae: 1.7609 - mse: 4.8789 - val_loss: 15.7029 - val_mae: 2.9771 - val_mse: 15.7029\n",
      "Epoch 13/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 4.7343 - mae: 1.7389 - mse: 4.7343 - val_loss: 10.8242 - val_mae: 2.1422 - val_mse: 10.8242\n",
      "Epoch 14/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 4.5578 - mae: 1.7013 - mse: 4.5578 - val_loss: 10.5612 - val_mae: 2.1238 - val_mse: 10.5612\n",
      "Epoch 15/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 4.4464 - mae: 1.6837 - mse: 4.4464 - val_loss: 9.7724 - val_mae: 1.9785 - val_mse: 9.7724\n",
      "Epoch 16/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 4.2313 - mae: 1.6417 - mse: 4.2313 - val_loss: 9.8213 - val_mae: 2.0142 - val_mse: 9.8213\n",
      "Epoch 17/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 4.0892 - mae: 1.6190 - mse: 4.0892 - val_loss: 11.4994 - val_mae: 2.3524 - val_mse: 11.4994\n",
      "Epoch 18/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 4.0245 - mae: 1.6004 - mse: 4.0245 - val_loss: 13.4274 - val_mae: 2.8461 - val_mse: 13.4274\n",
      "Epoch 19/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 3.9385 - mae: 1.5877 - mse: 3.9385 - val_loss: 9.8315 - val_mae: 2.1164 - val_mse: 9.8315\n",
      "Epoch 20/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 3.8550 - mae: 1.5756 - mse: 3.8550 - val_loss: 8.4344 - val_mae: 1.8667 - val_mse: 8.4344\n",
      "Epoch 21/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 3.7697 - mae: 1.5534 - mse: 3.7697 - val_loss: 9.0303 - val_mae: 1.9946 - val_mse: 9.0303\n",
      "Epoch 22/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 3.6275 - mae: 1.5205 - mse: 3.6275 - val_loss: 8.3988 - val_mae: 1.8612 - val_mse: 8.3988\n",
      "Epoch 23/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 3.5929 - mae: 1.5166 - mse: 3.5929 - val_loss: 9.9110 - val_mae: 2.1968 - val_mse: 9.9110\n",
      "Epoch 24/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 3.4734 - mae: 1.4894 - mse: 3.4734 - val_loss: 9.4539 - val_mae: 2.0781 - val_mse: 9.4539\n",
      "Epoch 25/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 3.4031 - mae: 1.4802 - mse: 3.4031 - val_loss: 9.1624 - val_mae: 2.1076 - val_mse: 9.1624\n",
      "Epoch 26/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 3.3214 - mae: 1.4472 - mse: 3.3214 - val_loss: 10.3632 - val_mae: 2.3065 - val_mse: 10.3632\n",
      "Epoch 27/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 3.2817 - mae: 1.4584 - mse: 3.2817 - val_loss: 8.5882 - val_mae: 1.9700 - val_mse: 8.5882\n",
      "Epoch 28/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 3.2120 - mae: 1.4330 - mse: 3.2120 - val_loss: 11.6685 - val_mae: 2.5895 - val_mse: 11.6685\n",
      "Epoch 29/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 3.1431 - mae: 1.4200 - mse: 3.1431 - val_loss: 8.2288 - val_mae: 1.8992 - val_mse: 8.2288\n",
      "Epoch 30/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 3.0940 - mae: 1.4039 - mse: 3.0940 - val_loss: 7.4837 - val_mae: 1.6818 - val_mse: 7.4837\n",
      "Epoch 31/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 3.0155 - mae: 1.3895 - mse: 3.0155 - val_loss: 7.9681 - val_mae: 1.8443 - val_mse: 7.9681\n",
      "Epoch 32/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 2.9555 - mae: 1.3683 - mse: 2.9555 - val_loss: 9.1564 - val_mae: 2.0829 - val_mse: 9.1564\n",
      "Epoch 33/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 2.9337 - mae: 1.3613 - mse: 2.9337 - val_loss: 9.2224 - val_mae: 2.1185 - val_mse: 9.2224\n",
      "Epoch 34/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 2.8673 - mae: 1.3526 - mse: 2.8672 - val_loss: 8.9693 - val_mae: 2.0769 - val_mse: 8.9693\n",
      "Epoch 35/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 2.8633 - mae: 1.3525 - mse: 2.8633 - val_loss: 8.2379 - val_mae: 1.9313 - val_mse: 8.2379\n",
      "Epoch 36/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 2.7324 - mae: 1.3208 - mse: 2.7324 - val_loss: 8.6640 - val_mae: 2.0919 - val_mse: 8.6640\n",
      "Epoch 37/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 2.7131 - mae: 1.3128 - mse: 2.7131 - val_loss: 7.0311 - val_mae: 1.6409 - val_mse: 7.0311\n",
      "Epoch 38/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 2.6584 - mae: 1.2987 - mse: 2.6584 - val_loss: 7.0118 - val_mae: 1.6810 - val_mse: 7.0118\n",
      "Epoch 39/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 2.5679 - mae: 1.2729 - mse: 2.5679 - val_loss: 9.5378 - val_mae: 2.2172 - val_mse: 9.5378\n",
      "Epoch 40/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 2.5525 - mae: 1.2706 - mse: 2.5525 - val_loss: 7.9488 - val_mae: 1.9311 - val_mse: 7.9488\n",
      "Epoch 41/500\n",
      "11665/11665 [==============================] - 0s 43us/sample - loss: 2.4948 - mae: 1.2566 - mse: 2.4948 - val_loss: 7.9552 - val_mae: 1.8534 - val_mse: 7.9552\n",
      "Epoch 42/500\n",
      "11665/11665 [==============================] - 1s 53us/sample - loss: 2.4696 - mae: 1.2457 - mse: 2.4696 - val_loss: 6.8131 - val_mae: 1.5938 - val_mse: 6.8131\n",
      "Epoch 43/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 2.4195 - mae: 1.2340 - mse: 2.4195 - val_loss: 7.2490 - val_mae: 1.8074 - val_mse: 7.2490\n",
      "Epoch 44/500\n",
      "11665/11665 [==============================] - 1s 51us/sample - loss: 2.3832 - mae: 1.2306 - mse: 2.3832 - val_loss: 8.5295 - val_mae: 2.0271 - val_mse: 8.5295\n",
      "Epoch 45/500\n",
      "11665/11665 [==============================] - 1s 48us/sample - loss: 2.3531 - mae: 1.2204 - mse: 2.3531 - val_loss: 7.4552 - val_mae: 1.8004 - val_mse: 7.4552\n",
      "Epoch 46/500\n",
      "11665/11665 [==============================] - 1s 44us/sample - loss: 2.3143 - mae: 1.2015 - mse: 2.3143 - val_loss: 8.3847 - val_mae: 1.9834 - val_mse: 8.3847\n",
      "Epoch 47/500\n",
      "11665/11665 [==============================] - 1s 47us/sample - loss: 2.2875 - mae: 1.2011 - mse: 2.2875 - val_loss: 6.8280 - val_mae: 1.6934 - val_mse: 6.8280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/500\n",
      "11665/11665 [==============================] - 1s 51us/sample - loss: 2.2248 - mae: 1.1856 - mse: 2.2248 - val_loss: 10.0122 - val_mae: 2.3201 - val_mse: 10.0122\n",
      "Epoch 49/500\n",
      "11665/11665 [==============================] - 0s 42us/sample - loss: 2.1684 - mae: 1.1666 - mse: 2.1684 - val_loss: 7.3137 - val_mae: 1.8225 - val_mse: 7.3137\n",
      "Epoch 50/500\n",
      "11665/11665 [==============================] - 1s 46us/sample - loss: 2.1294 - mae: 1.1570 - mse: 2.1294 - val_loss: 6.8453 - val_mae: 1.6167 - val_mse: 6.8453\n",
      "Epoch 51/500\n",
      "11665/11665 [==============================] - 1s 52us/sample - loss: 2.1434 - mae: 1.1646 - mse: 2.1434 - val_loss: 6.5843 - val_mae: 1.5823 - val_mse: 6.5843\n",
      "Epoch 52/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 2.0551 - mae: 1.1378 - mse: 2.0551 - val_loss: 7.8551 - val_mae: 1.9499 - val_mse: 7.8551\n",
      "Epoch 53/500\n",
      "11665/11665 [==============================] - 1s 43us/sample - loss: 2.0422 - mae: 1.1294 - mse: 2.0422 - val_loss: 7.4435 - val_mae: 1.7494 - val_mse: 7.4435\n",
      "Epoch 54/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 2.0299 - mae: 1.1306 - mse: 2.0299 - val_loss: 7.8113 - val_mae: 1.8656 - val_mse: 7.8113\n",
      "Epoch 55/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 2.0044 - mae: 1.1207 - mse: 2.0044 - val_loss: 7.1761 - val_mae: 1.6760 - val_mse: 7.1761\n",
      "Epoch 56/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 1.9441 - mae: 1.0997 - mse: 1.9441 - val_loss: 6.8090 - val_mae: 1.6744 - val_mse: 6.8090\n",
      "Epoch 57/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 1.9444 - mae: 1.1027 - mse: 1.9444 - val_loss: 7.4963 - val_mae: 1.7604 - val_mse: 7.4963\n",
      "Epoch 58/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 1.8678 - mae: 1.0818 - mse: 1.8678 - val_loss: 8.3183 - val_mae: 1.9197 - val_mse: 8.3183\n",
      "Epoch 59/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 1.8533 - mae: 1.0719 - mse: 1.8533 - val_loss: 8.4211 - val_mae: 1.9466 - val_mse: 8.4211\n",
      "Epoch 60/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 1.7805 - mae: 1.0550 - mse: 1.7805 - val_loss: 7.5282 - val_mae: 1.7703 - val_mse: 7.5282\n",
      "Epoch 61/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 1.7700 - mae: 1.0450 - mse: 1.7700 - val_loss: 6.7426 - val_mae: 1.6002 - val_mse: 6.7426\n",
      "Epoch 62/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 1.7471 - mae: 1.0414 - mse: 1.7471 - val_loss: 7.8920 - val_mae: 1.8942 - val_mse: 7.8920\n",
      "Epoch 63/500\n",
      "11665/11665 [==============================] - 0s 42us/sample - loss: 1.7083 - mae: 1.0237 - mse: 1.7083 - val_loss: 8.2626 - val_mae: 1.9257 - val_mse: 8.2626\n",
      "Epoch 64/500\n",
      "11665/11665 [==============================] - 0s 41us/sample - loss: 1.6785 - mae: 1.0181 - mse: 1.6785 - val_loss: 7.6970 - val_mae: 1.7898 - val_mse: 7.6970\n",
      "Epoch 65/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 1.6446 - mae: 1.0107 - mse: 1.6446 - val_loss: 7.7617 - val_mae: 1.7903 - val_mse: 7.7617\n",
      "Epoch 66/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 1.6115 - mae: 0.9969 - mse: 1.6115 - val_loss: 8.0399 - val_mae: 1.8518 - val_mse: 8.0399\n",
      "Epoch 67/500\n",
      "11665/11665 [==============================] - 1s 49us/sample - loss: 1.5834 - mae: 0.9888 - mse: 1.5834 - val_loss: 7.5483 - val_mae: 1.7713 - val_mse: 7.5483\n",
      "Epoch 68/500\n",
      "11665/11665 [==============================] - 1s 43us/sample - loss: 1.5804 - mae: 0.9846 - mse: 1.5804 - val_loss: 7.4574 - val_mae: 1.6868 - val_mse: 7.4574\n",
      "Epoch 69/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 1.5555 - mae: 0.9743 - mse: 1.5555 - val_loss: 6.9445 - val_mae: 1.6524 - val_mse: 6.9445\n",
      "Epoch 70/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 1.5348 - mae: 0.9676 - mse: 1.5348 - val_loss: 6.8288 - val_mae: 1.6706 - val_mse: 6.8288\n",
      "Epoch 71/500\n",
      "11665/11665 [==============================] - 0s 37us/sample - loss: 1.4932 - mae: 0.9545 - mse: 1.4932 - val_loss: 7.0000 - val_mae: 1.6214 - val_mse: 7.0000\n",
      "Epoch 72/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 1.4847 - mae: 0.9508 - mse: 1.4847 - val_loss: 6.5535 - val_mae: 1.5598 - val_mse: 6.5535\n",
      "Epoch 73/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 1.4406 - mae: 0.9378 - mse: 1.4406 - val_loss: 7.2051 - val_mae: 1.6333 - val_mse: 7.2051\n",
      "Epoch 74/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 1.4346 - mae: 0.9410 - mse: 1.4346 - val_loss: 7.6425 - val_mae: 1.9029 - val_mse: 7.6425\n",
      "Epoch 75/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 1.3967 - mae: 0.9233 - mse: 1.3967 - val_loss: 8.6892 - val_mae: 1.9236 - val_mse: 8.6892\n",
      "Epoch 76/500\n",
      "11665/11665 [==============================] - 1s 52us/sample - loss: 1.3672 - mae: 0.9132 - mse: 1.3672 - val_loss: 6.7415 - val_mae: 1.6459 - val_mse: 6.7415\n",
      "Epoch 77/500\n",
      "11665/11665 [==============================] - 1s 64us/sample - loss: 1.3724 - mae: 0.9106 - mse: 1.3724 - val_loss: 7.5528 - val_mae: 1.7453 - val_mse: 7.5528\n",
      "Epoch 78/500\n",
      "11665/11665 [==============================] - 1s 55us/sample - loss: 1.3466 - mae: 0.9057 - mse: 1.3466 - val_loss: 7.7834 - val_mae: 1.7840 - val_mse: 7.7834\n",
      "Epoch 79/500\n",
      "11665/11665 [==============================] - 1s 52us/sample - loss: 1.3291 - mae: 0.9009 - mse: 1.3291 - val_loss: 7.0222 - val_mae: 1.6378 - val_mse: 7.0222\n",
      "Epoch 80/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 1.3047 - mae: 0.8941 - mse: 1.3047 - val_loss: 7.6866 - val_mae: 1.7583 - val_mse: 7.6866\n",
      "Epoch 81/500\n",
      "11665/11665 [==============================] - 0s 40us/sample - loss: 1.3064 - mae: 0.8875 - mse: 1.3064 - val_loss: 7.8458 - val_mae: 1.7912 - val_mse: 7.8458\n",
      "Epoch 82/500\n",
      "11665/11665 [==============================] - 1s 47us/sample - loss: 1.2700 - mae: 0.8772 - mse: 1.2700 - val_loss: 6.8067 - val_mae: 1.5839 - val_mse: 6.8067\n",
      "Epoch 83/500\n",
      "11665/11665 [==============================] - 1s 46us/sample - loss: 1.2654 - mae: 0.8780 - mse: 1.2654 - val_loss: 7.7324 - val_mae: 1.7826 - val_mse: 7.7324\n",
      "Epoch 84/500\n",
      "11665/11665 [==============================] - 1s 45us/sample - loss: 1.2438 - mae: 0.8656 - mse: 1.2438 - val_loss: 7.7472 - val_mae: 1.7525 - val_mse: 7.7472\n",
      "Epoch 85/500\n",
      "11665/11665 [==============================] - 1s 44us/sample - loss: 1.2244 - mae: 0.8586 - mse: 1.2244 - val_loss: 6.8533 - val_mae: 1.6164 - val_mse: 6.8533\n",
      "Epoch 86/500\n",
      "11665/11665 [==============================] - 0s 40us/sample - loss: 1.2010 - mae: 0.8517 - mse: 1.2010 - val_loss: 7.2779 - val_mae: 1.6964 - val_mse: 7.2779\n",
      "Epoch 87/500\n",
      "11665/11665 [==============================] - 0s 43us/sample - loss: 1.1990 - mae: 0.8475 - mse: 1.1990 - val_loss: 7.3642 - val_mae: 1.6697 - val_mse: 7.3642\n",
      "Epoch 88/500\n",
      "11665/11665 [==============================] - 1s 51us/sample - loss: 1.1818 - mae: 0.8417 - mse: 1.1818 - val_loss: 7.7699 - val_mae: 1.8596 - val_mse: 7.7699\n",
      "Epoch 89/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 1.1828 - mae: 0.8451 - mse: 1.1828 - val_loss: 7.1806 - val_mae: 1.7153 - val_mse: 7.1806\n",
      "Epoch 90/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 1.1794 - mae: 0.8460 - mse: 1.1794 - val_loss: 7.2918 - val_mae: 1.6987 - val_mse: 7.2918\n",
      "Epoch 91/500\n",
      "11665/11665 [==============================] - 0s 41us/sample - loss: 1.1534 - mae: 0.8327 - mse: 1.1534 - val_loss: 7.7801 - val_mae: 1.7088 - val_mse: 7.7801\n",
      "Epoch 92/500\n",
      "11665/11665 [==============================] - 1s 43us/sample - loss: 1.1595 - mae: 0.8340 - mse: 1.1595 - val_loss: 8.0606 - val_mae: 1.8360 - val_mse: 8.0606\n",
      "Epoch 93/500\n",
      "11665/11665 [==============================] - 1s 53us/sample - loss: 1.1489 - mae: 0.8295 - mse: 1.1489 - val_loss: 7.5983 - val_mae: 1.6951 - val_mse: 7.5983\n",
      "Epoch 94/500\n",
      "11665/11665 [==============================] - 0s 42us/sample - loss: 1.1336 - mae: 0.8223 - mse: 1.1336 - val_loss: 7.9643 - val_mae: 1.7335 - val_mse: 7.9643\n",
      "Epoch 95/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 1.1352 - mae: 0.8246 - mse: 1.1352 - val_loss: 7.6485 - val_mae: 1.6933 - val_mse: 7.6485\n",
      "Epoch 96/500\n",
      "11665/11665 [==============================] - 1s 43us/sample - loss: 1.1114 - mae: 0.8162 - mse: 1.1114 - val_loss: 7.0287 - val_mae: 1.6300 - val_mse: 7.0287\n",
      "Epoch 97/500\n",
      "11665/11665 [==============================] - 0s 42us/sample - loss: 1.1016 - mae: 0.8138 - mse: 1.1016 - val_loss: 7.0643 - val_mae: 1.6299 - val_mse: 7.0643\n",
      "Epoch 98/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 1.0915 - mae: 0.8084 - mse: 1.0915 - val_loss: 7.1101 - val_mae: 1.5873 - val_mse: 7.1101\n",
      "Epoch 99/500\n",
      "11665/11665 [==============================] - 0s 38us/sample - loss: 1.0888 - mae: 0.8067 - mse: 1.0888 - val_loss: 7.7450 - val_mae: 1.7094 - val_mse: 7.7450\n",
      "Epoch 100/500\n",
      "11665/11665 [==============================] - 1s 43us/sample - loss: 1.0817 - mae: 0.8044 - mse: 1.0817 - val_loss: 7.2397 - val_mae: 1.6038 - val_mse: 7.2397\n",
      "Epoch 101/500\n",
      "11665/11665 [==============================] - 1s 47us/sample - loss: 1.0744 - mae: 0.7996 - mse: 1.0744 - val_loss: 7.2048 - val_mae: 1.6120 - val_mse: 7.2048\n",
      "Epoch 102/500\n",
      "11665/11665 [==============================] - 1s 47us/sample - loss: 1.0848 - mae: 0.8037 - mse: 1.0848 - val_loss: 7.4810 - val_mae: 1.6219 - val_mse: 7.4810\n",
      "Epoch 103/500\n",
      "11665/11665 [==============================] - 0s 42us/sample - loss: 1.0550 - mae: 0.7934 - mse: 1.0550 - val_loss: 7.1796 - val_mae: 1.5817 - val_mse: 7.1796\n",
      "Epoch 104/500\n",
      "11665/11665 [==============================] - 1s 56us/sample - loss: 1.0589 - mae: 0.7972 - mse: 1.0589 - val_loss: 7.2648 - val_mae: 1.6180 - val_mse: 7.2648\n",
      "Epoch 105/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 1.0550 - mae: 0.7931 - mse: 1.0550 - val_loss: 7.7565 - val_mae: 1.6238 - val_mse: 7.7565\n",
      "Epoch 106/500\n",
      "11665/11665 [==============================] - 1s 50us/sample - loss: 1.0397 - mae: 0.7861 - mse: 1.0397 - val_loss: 7.0126 - val_mae: 1.6013 - val_mse: 7.0126\n",
      "Epoch 107/500\n",
      "11665/11665 [==============================] - 1s 46us/sample - loss: 1.0352 - mae: 0.7851 - mse: 1.0352 - val_loss: 7.8958 - val_mae: 1.6959 - val_mse: 7.8958\n",
      "Epoch 108/500\n",
      "11665/11665 [==============================] - 1s 44us/sample - loss: 1.0256 - mae: 0.7836 - mse: 1.0256 - val_loss: 7.5965 - val_mae: 1.6609 - val_mse: 7.5965\n",
      "Epoch 109/500\n",
      "11665/11665 [==============================] - 0s 41us/sample - loss: 1.0132 - mae: 0.7768 - mse: 1.0132 - val_loss: 7.2799 - val_mae: 1.6049 - val_mse: 7.2799\n",
      "Epoch 110/500\n",
      "11665/11665 [==============================] - 0s 41us/sample - loss: 1.0037 - mae: 0.7756 - mse: 1.0037 - val_loss: 7.5008 - val_mae: 1.7521 - val_mse: 7.5008\n",
      "Epoch 111/500\n",
      "11665/11665 [==============================] - 0s 40us/sample - loss: 1.0010 - mae: 0.7710 - mse: 1.0010 - val_loss: 7.6410 - val_mae: 1.6648 - val_mse: 7.6410\n",
      "Epoch 112/500\n",
      "11665/11665 [==============================] - 0s 40us/sample - loss: 1.0040 - mae: 0.7710 - mse: 1.0040 - val_loss: 7.3480 - val_mae: 1.6237 - val_mse: 7.3480\n",
      "Epoch 113/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 0.9798 - mae: 0.7641 - mse: 0.9798 - val_loss: 8.5378 - val_mae: 1.7611 - val_mse: 8.5378\n",
      "Epoch 114/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 0.9792 - mae: 0.7631 - mse: 0.9792 - val_loss: 7.8017 - val_mae: 1.6691 - val_mse: 7.8017\n",
      "Epoch 115/500\n",
      "11665/11665 [==============================] - 0s 40us/sample - loss: 0.9671 - mae: 0.7589 - mse: 0.9671 - val_loss: 7.3542 - val_mae: 1.6466 - val_mse: 7.3542\n",
      "Epoch 116/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 0.9699 - mae: 0.7583 - mse: 0.9699 - val_loss: 7.2815 - val_mae: 1.6436 - val_mse: 7.2815\n",
      "Epoch 117/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 0.9567 - mae: 0.7518 - mse: 0.9567 - val_loss: 7.7438 - val_mae: 1.6302 - val_mse: 7.7438\n",
      "Epoch 118/500\n",
      "11665/11665 [==============================] - 0s 40us/sample - loss: 0.9593 - mae: 0.7532 - mse: 0.9593 - val_loss: 7.6536 - val_mae: 1.6684 - val_mse: 7.6536\n",
      "Epoch 119/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 0.9529 - mae: 0.7518 - mse: 0.9529 - val_loss: 7.8048 - val_mae: 1.7391 - val_mse: 7.8048\n",
      "Epoch 120/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 0.9454 - mae: 0.7474 - mse: 0.9454 - val_loss: 7.9280 - val_mae: 1.6685 - val_mse: 7.9280\n",
      "Epoch 121/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 0.9473 - mae: 0.7495 - mse: 0.9473 - val_loss: 8.3130 - val_mae: 1.7452 - val_mse: 8.3130\n",
      "Epoch 122/500\n",
      "11665/11665 [==============================] - 0s 39us/sample - loss: 0.9375 - mae: 0.7464 - mse: 0.9375 - val_loss: 7.9361 - val_mae: 1.6552 - val_mse: 7.9361\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 13124 samples, validate on 4375 samples\n",
      "Epoch 1/500\n",
      "13124/13124 [==============================] - 1s 72us/sample - loss: 45.8306 - mae: 4.1739 - mse: 45.8306 - val_loss: 31.2700 - val_mae: 3.8037 - val_mse: 31.2700\n",
      "Epoch 2/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 11.4928 - mae: 2.5510 - mse: 11.4928 - val_loss: 19.3424 - val_mae: 2.8008 - val_mse: 19.3424\n",
      "Epoch 3/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 8.3853 - mae: 2.2306 - mse: 8.3853 - val_loss: 15.7966 - val_mae: 2.3808 - val_mse: 15.7966\n",
      "Epoch 4/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 7.1826 - mae: 2.0784 - mse: 7.1826 - val_loss: 16.3210 - val_mae: 2.4794 - val_mse: 16.3210\n",
      "Epoch 5/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 6.4374 - mae: 1.9688 - mse: 6.4374 - val_loss: 18.2758 - val_mae: 2.8365 - val_mse: 18.2758\n",
      "Epoch 6/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 5.9806 - mae: 1.9051 - mse: 5.9806 - val_loss: 17.2274 - val_mae: 2.6469 - val_mse: 17.2274\n",
      "Epoch 7/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 5.5883 - mae: 1.8347 - mse: 5.5882 - val_loss: 26.1046 - val_mae: 4.1861 - val_mse: 26.1046\n",
      "Epoch 8/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 5.3110 - mae: 1.7987 - mse: 5.3110 - val_loss: 17.2724 - val_mae: 2.8475 - val_mse: 17.2724\n",
      "Epoch 9/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 5.0541 - mae: 1.7554 - mse: 5.0541 - val_loss: 13.4166 - val_mae: 2.1827 - val_mse: 13.4166\n",
      "Epoch 10/500\n",
      "13124/13124 [==============================] - 1s 40us/sample - loss: 4.7380 - mae: 1.6971 - mse: 4.7380 - val_loss: 15.4790 - val_mae: 2.6159 - val_mse: 15.4790\n",
      "Epoch 11/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 4.5217 - mae: 1.6625 - mse: 4.5217 - val_loss: 12.1744 - val_mae: 2.0134 - val_mse: 12.1744\n",
      "Epoch 12/500\n",
      "13124/13124 [==============================] - 1s 40us/sample - loss: 4.2474 - mae: 1.6093 - mse: 4.2474 - val_loss: 18.9052 - val_mae: 3.3301 - val_mse: 18.9052\n",
      "Epoch 13/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 4.1347 - mae: 1.5836 - mse: 4.1347 - val_loss: 15.0731 - val_mae: 2.6788 - val_mse: 15.0731\n",
      "Epoch 14/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 3.9611 - mae: 1.5620 - mse: 3.9611 - val_loss: 11.8411 - val_mae: 2.0758 - val_mse: 11.8411\n",
      "Epoch 15/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 3.7832 - mae: 1.5226 - mse: 3.7832 - val_loss: 14.7446 - val_mae: 2.6875 - val_mse: 14.7446\n",
      "Epoch 16/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13124/13124 [==============================] - 1s 38us/sample - loss: 3.6714 - mae: 1.5020 - mse: 3.6714 - val_loss: 12.1475 - val_mae: 2.2539 - val_mse: 12.1475\n",
      "Epoch 17/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 3.5164 - mae: 1.4715 - mse: 3.5164 - val_loss: 13.8657 - val_mae: 2.5791 - val_mse: 13.8657\n",
      "Epoch 18/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 3.4145 - mae: 1.4501 - mse: 3.4145 - val_loss: 9.7168 - val_mae: 1.8015 - val_mse: 9.7168\n",
      "Epoch 19/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 3.3143 - mae: 1.4286 - mse: 3.3143 - val_loss: 15.3365 - val_mae: 2.9090 - val_mse: 15.3365\n",
      "Epoch 20/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 3.2252 - mae: 1.4072 - mse: 3.2252 - val_loss: 10.1740 - val_mae: 2.0225 - val_mse: 10.1740\n",
      "Epoch 21/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 3.1217 - mae: 1.3953 - mse: 3.1217 - val_loss: 10.7181 - val_mae: 2.2319 - val_mse: 10.7181\n",
      "Epoch 22/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 3.0328 - mae: 1.3691 - mse: 3.0328 - val_loss: 9.8905 - val_mae: 2.0032 - val_mse: 9.8905\n",
      "Epoch 23/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 2.9707 - mae: 1.3531 - mse: 2.9707 - val_loss: 9.7788 - val_mae: 1.9039 - val_mse: 9.7788\n",
      "Epoch 24/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 2.8600 - mae: 1.3298 - mse: 2.8600 - val_loss: 9.6529 - val_mae: 1.8227 - val_mse: 9.6529\n",
      "Epoch 25/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 2.8013 - mae: 1.3116 - mse: 2.8013 - val_loss: 10.6857 - val_mae: 2.0943 - val_mse: 10.6857\n",
      "Epoch 26/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 2.7308 - mae: 1.2965 - mse: 2.7308 - val_loss: 11.3332 - val_mae: 2.1682 - val_mse: 11.3332\n",
      "Epoch 27/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 2.6882 - mae: 1.2911 - mse: 2.6882 - val_loss: 11.2884 - val_mae: 2.2171 - val_mse: 11.2884\n",
      "Epoch 28/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 2.5763 - mae: 1.2575 - mse: 2.5763 - val_loss: 12.6096 - val_mae: 2.6199 - val_mse: 12.6096\n",
      "Epoch 29/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 2.5186 - mae: 1.2489 - mse: 2.5186 - val_loss: 9.8850 - val_mae: 1.8996 - val_mse: 9.8850\n",
      "Epoch 30/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 2.4535 - mae: 1.2277 - mse: 2.4535 - val_loss: 10.5569 - val_mae: 2.0653 - val_mse: 10.5569\n",
      "Epoch 31/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 2.3643 - mae: 1.2005 - mse: 2.3643 - val_loss: 10.1888 - val_mae: 2.0217 - val_mse: 10.1888\n",
      "Epoch 32/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 2.2884 - mae: 1.1895 - mse: 2.2884 - val_loss: 14.4678 - val_mae: 2.7612 - val_mse: 14.4678\n",
      "Epoch 33/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 2.2410 - mae: 1.1743 - mse: 2.2410 - val_loss: 9.8037 - val_mae: 1.7940 - val_mse: 9.8037\n",
      "Epoch 34/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 2.1813 - mae: 1.1558 - mse: 2.1813 - val_loss: 10.5318 - val_mae: 2.1847 - val_mse: 10.5318\n",
      "Epoch 35/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 2.1355 - mae: 1.1423 - mse: 2.1355 - val_loss: 11.0815 - val_mae: 2.2664 - val_mse: 11.0815\n",
      "Epoch 36/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 2.0928 - mae: 1.1263 - mse: 2.0928 - val_loss: 10.7654 - val_mae: 2.0544 - val_mse: 10.7654\n",
      "Epoch 37/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 2.0741 - mae: 1.1275 - mse: 2.0741 - val_loss: 11.3948 - val_mae: 2.2273 - val_mse: 11.3948\n",
      "Epoch 38/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 2.0256 - mae: 1.1105 - mse: 2.0256 - val_loss: 10.1708 - val_mae: 1.8506 - val_mse: 10.1708\n",
      "Epoch 39/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 2.0070 - mae: 1.1048 - mse: 2.0070 - val_loss: 9.4691 - val_mae: 1.8580 - val_mse: 9.4691\n",
      "Epoch 40/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 1.9617 - mae: 1.0924 - mse: 1.9617 - val_loss: 10.6823 - val_mae: 2.0372 - val_mse: 10.6823\n",
      "Epoch 41/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 1.9305 - mae: 1.0866 - mse: 1.9305 - val_loss: 11.6114 - val_mae: 2.1087 - val_mse: 11.6114\n",
      "Epoch 42/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 1.9223 - mae: 1.0816 - mse: 1.9223 - val_loss: 10.3259 - val_mae: 2.0493 - val_mse: 10.3259\n",
      "Epoch 43/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 1.8754 - mae: 1.0648 - mse: 1.8754 - val_loss: 11.4267 - val_mae: 2.2697 - val_mse: 11.4267\n",
      "Epoch 44/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 1.8651 - mae: 1.0614 - mse: 1.8651 - val_loss: 9.8375 - val_mae: 1.7942 - val_mse: 9.8375\n",
      "Epoch 45/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 1.8198 - mae: 1.0494 - mse: 1.8198 - val_loss: 10.7103 - val_mae: 2.1413 - val_mse: 10.7103\n",
      "Epoch 46/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 1.7952 - mae: 1.0422 - mse: 1.7952 - val_loss: 10.8384 - val_mae: 2.2786 - val_mse: 10.8384\n",
      "Epoch 47/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 1.7683 - mae: 1.0313 - mse: 1.7683 - val_loss: 9.8535 - val_mae: 1.7867 - val_mse: 9.8535\n",
      "Epoch 48/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 1.7821 - mae: 1.0374 - mse: 1.7821 - val_loss: 10.2843 - val_mae: 1.7473 - val_mse: 10.2843\n",
      "Epoch 49/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 1.7384 - mae: 1.0238 - mse: 1.7384 - val_loss: 9.8163 - val_mae: 1.8478 - val_mse: 9.8163\n",
      "Epoch 50/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 1.6966 - mae: 1.0134 - mse: 1.6966 - val_loss: 11.1663 - val_mae: 2.0152 - val_mse: 11.1663\n",
      "Epoch 51/500\n",
      "13124/13124 [==============================] - 1s 40us/sample - loss: 1.7078 - mae: 1.0126 - mse: 1.7078 - val_loss: 8.8740 - val_mae: 1.7103 - val_mse: 8.8740\n",
      "Epoch 52/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 1.6619 - mae: 0.9976 - mse: 1.6619 - val_loss: 10.8142 - val_mae: 2.1554 - val_mse: 10.8142\n",
      "Epoch 53/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 1.6477 - mae: 0.9965 - mse: 1.6477 - val_loss: 9.0571 - val_mae: 1.8492 - val_mse: 9.0571\n",
      "Epoch 54/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 1.6302 - mae: 0.9930 - mse: 1.6302 - val_loss: 9.6255 - val_mae: 1.8757 - val_mse: 9.6255\n",
      "Epoch 55/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 1.6111 - mae: 0.9865 - mse: 1.6111 - val_loss: 9.8181 - val_mae: 1.8614 - val_mse: 9.8181\n",
      "Epoch 56/500\n",
      "13124/13124 [==============================] - 1s 41us/sample - loss: 1.5867 - mae: 0.9784 - mse: 1.5867 - val_loss: 9.3463 - val_mae: 1.8156 - val_mse: 9.3463\n",
      "Epoch 57/500\n",
      "13124/13124 [==============================] - 1s 54us/sample - loss: 1.5638 - mae: 0.9709 - mse: 1.5638 - val_loss: 10.9538 - val_mae: 2.2714 - val_mse: 10.9538\n",
      "Epoch 58/500\n",
      "13124/13124 [==============================] - 1s 47us/sample - loss: 1.5579 - mae: 0.9662 - mse: 1.5579 - val_loss: 8.5303 - val_mae: 1.7314 - val_mse: 8.5303\n",
      "Epoch 59/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 1.5166 - mae: 0.9505 - mse: 1.5166 - val_loss: 9.7158 - val_mae: 2.1222 - val_mse: 9.7158\n",
      "Epoch 60/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 1.5145 - mae: 0.9527 - mse: 1.5145 - val_loss: 9.4490 - val_mae: 1.9309 - val_mse: 9.4490\n",
      "Epoch 61/500\n",
      "13124/13124 [==============================] - 1s 46us/sample - loss: 1.5016 - mae: 0.9491 - mse: 1.5016 - val_loss: 8.2540 - val_mae: 1.5800 - val_mse: 8.2540\n",
      "Epoch 62/500\n",
      "13124/13124 [==============================] - 1s 48us/sample - loss: 1.4642 - mae: 0.9349 - mse: 1.4642 - val_loss: 11.1547 - val_mae: 2.0282 - val_mse: 11.1547\n",
      "Epoch 63/500\n",
      "13124/13124 [==============================] - 1s 40us/sample - loss: 1.4462 - mae: 0.9309 - mse: 1.4462 - val_loss: 8.8141 - val_mae: 1.8714 - val_mse: 8.8141\n",
      "Epoch 64/500\n",
      "13124/13124 [==============================] - 1s 42us/sample - loss: 1.4321 - mae: 0.9238 - mse: 1.4321 - val_loss: 10.1373 - val_mae: 2.0026 - val_mse: 10.1373\n",
      "Epoch 65/500\n",
      "13124/13124 [==============================] - 1s 53us/sample - loss: 1.4150 - mae: 0.9149 - mse: 1.4150 - val_loss: 10.2986 - val_mae: 2.1432 - val_mse: 10.2986\n",
      "Epoch 66/500\n",
      "13124/13124 [==============================] - 1s 46us/sample - loss: 1.3996 - mae: 0.9140 - mse: 1.3996 - val_loss: 8.5805 - val_mae: 1.7290 - val_mse: 8.5805\n",
      "Epoch 67/500\n",
      "13124/13124 [==============================] - 1s 44us/sample - loss: 1.3888 - mae: 0.9096 - mse: 1.3888 - val_loss: 9.4582 - val_mae: 1.9043 - val_mse: 9.4582\n",
      "Epoch 68/500\n",
      "13124/13124 [==============================] - 1s 54us/sample - loss: 1.3648 - mae: 0.9018 - mse: 1.3648 - val_loss: 10.1095 - val_mae: 2.0800 - val_mse: 10.1095\n",
      "Epoch 69/500\n",
      "13124/13124 [==============================] - 1s 40us/sample - loss: 1.3805 - mae: 0.9050 - mse: 1.3805 - val_loss: 10.2534 - val_mae: 2.0729 - val_mse: 10.2534\n",
      "Epoch 70/500\n",
      "13124/13124 [==============================] - 1s 41us/sample - loss: 1.3666 - mae: 0.9003 - mse: 1.3666 - val_loss: 9.2577 - val_mae: 1.7387 - val_mse: 9.2577\n",
      "Epoch 71/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.3457 - mae: 0.8948 - mse: 1.3457 - val_loss: 8.9705 - val_mae: 1.7395 - val_mse: 8.9705\n",
      "Epoch 72/500\n",
      "13124/13124 [==============================] - 1s 38us/sample - loss: 1.3397 - mae: 0.8928 - mse: 1.3397 - val_loss: 9.2126 - val_mae: 1.7699 - val_mse: 9.2126\n",
      "Epoch 73/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.3168 - mae: 0.8860 - mse: 1.3168 - val_loss: 9.8654 - val_mae: 1.9129 - val_mse: 9.8654\n",
      "Epoch 74/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.3050 - mae: 0.8779 - mse: 1.3050 - val_loss: 10.4934 - val_mae: 2.0016 - val_mse: 10.4934\n",
      "Epoch 75/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.3100 - mae: 0.8796 - mse: 1.3100 - val_loss: 8.8081 - val_mae: 1.7676 - val_mse: 8.8081\n",
      "Epoch 76/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.2936 - mae: 0.8758 - mse: 1.2936 - val_loss: 8.6150 - val_mae: 1.6758 - val_mse: 8.6150\n",
      "Epoch 77/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.2825 - mae: 0.8720 - mse: 1.2825 - val_loss: 9.6457 - val_mae: 1.8867 - val_mse: 9.6457\n",
      "Epoch 78/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.2752 - mae: 0.8696 - mse: 1.2752 - val_loss: 9.0848 - val_mae: 1.6971 - val_mse: 9.0847\n",
      "Epoch 79/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.2598 - mae: 0.8608 - mse: 1.2598 - val_loss: 8.4777 - val_mae: 1.6142 - val_mse: 8.4777\n",
      "Epoch 80/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.2534 - mae: 0.8623 - mse: 1.2534 - val_loss: 9.2919 - val_mae: 1.8516 - val_mse: 9.2919\n",
      "Epoch 81/500\n",
      "13124/13124 [==============================] - 1s 38us/sample - loss: 1.2370 - mae: 0.8536 - mse: 1.2370 - val_loss: 8.3796 - val_mae: 1.6210 - val_mse: 8.3796\n",
      "Epoch 82/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.2252 - mae: 0.8490 - mse: 1.2252 - val_loss: 10.0080 - val_mae: 1.9000 - val_mse: 10.0080\n",
      "Epoch 83/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.2282 - mae: 0.8526 - mse: 1.2282 - val_loss: 8.9388 - val_mae: 1.8740 - val_mse: 8.9388\n",
      "Epoch 84/500\n",
      "13124/13124 [==============================] - 1s 38us/sample - loss: 1.2054 - mae: 0.8419 - mse: 1.2054 - val_loss: 9.8941 - val_mae: 2.1384 - val_mse: 9.8941\n",
      "Epoch 85/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1947 - mae: 0.8383 - mse: 1.1947 - val_loss: 9.2233 - val_mae: 1.8097 - val_mse: 9.2233\n",
      "Epoch 86/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1898 - mae: 0.8389 - mse: 1.1898 - val_loss: 8.0619 - val_mae: 1.5710 - val_mse: 8.0619\n",
      "Epoch 87/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1841 - mae: 0.8380 - mse: 1.1841 - val_loss: 8.8067 - val_mae: 1.7743 - val_mse: 8.8067\n",
      "Epoch 88/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1722 - mae: 0.8352 - mse: 1.1722 - val_loss: 8.0037 - val_mae: 1.5490 - val_mse: 8.0037\n",
      "Epoch 89/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1746 - mae: 0.8317 - mse: 1.1746 - val_loss: 8.8445 - val_mae: 1.7545 - val_mse: 8.8445\n",
      "Epoch 90/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1634 - mae: 0.8269 - mse: 1.1634 - val_loss: 9.0376 - val_mae: 1.7211 - val_mse: 9.0376\n",
      "Epoch 91/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1532 - mae: 0.8225 - mse: 1.1532 - val_loss: 8.7138 - val_mae: 1.7696 - val_mse: 8.7138\n",
      "Epoch 92/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1635 - mae: 0.8273 - mse: 1.1635 - val_loss: 7.8508 - val_mae: 1.5398 - val_mse: 7.8508\n",
      "Epoch 93/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1359 - mae: 0.8201 - mse: 1.1359 - val_loss: 8.7997 - val_mae: 1.7137 - val_mse: 8.7997\n",
      "Epoch 94/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1340 - mae: 0.8174 - mse: 1.1340 - val_loss: 8.0712 - val_mae: 1.7142 - val_mse: 8.0712\n",
      "Epoch 95/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1279 - mae: 0.8142 - mse: 1.1279 - val_loss: 8.2879 - val_mae: 1.6823 - val_mse: 8.2879\n",
      "Epoch 96/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1221 - mae: 0.8131 - mse: 1.1221 - val_loss: 8.7508 - val_mae: 1.7758 - val_mse: 8.7508\n",
      "Epoch 97/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1183 - mae: 0.8122 - mse: 1.1183 - val_loss: 8.0615 - val_mae: 1.7414 - val_mse: 8.0615\n",
      "Epoch 98/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1153 - mae: 0.8071 - mse: 1.1153 - val_loss: 8.3045 - val_mae: 1.6242 - val_mse: 8.3045\n",
      "Epoch 99/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.1104 - mae: 0.8107 - mse: 1.1104 - val_loss: 9.0883 - val_mae: 1.7274 - val_mse: 9.0883\n",
      "Epoch 100/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.0845 - mae: 0.7977 - mse: 1.0845 - val_loss: 8.2632 - val_mae: 1.5922 - val_mse: 8.2632\n",
      "Epoch 101/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.0866 - mae: 0.8026 - mse: 1.0866 - val_loss: 8.0817 - val_mae: 1.6431 - val_mse: 8.0817\n",
      "Epoch 102/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.0882 - mae: 0.8006 - mse: 1.0882 - val_loss: 8.7731 - val_mae: 1.9099 - val_mse: 8.7731\n",
      "Epoch 103/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.0889 - mae: 0.7988 - mse: 1.0889 - val_loss: 8.4296 - val_mae: 1.6673 - val_mse: 8.4296\n",
      "Epoch 104/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.0643 - mae: 0.7908 - mse: 1.0643 - val_loss: 8.7408 - val_mae: 1.6696 - val_mse: 8.7408\n",
      "Epoch 105/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.0781 - mae: 0.7971 - mse: 1.0781 - val_loss: 8.0398 - val_mae: 1.5459 - val_mse: 8.0398\n",
      "Epoch 106/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.0600 - mae: 0.7884 - mse: 1.0600 - val_loss: 8.5684 - val_mae: 1.6552 - val_mse: 8.5684\n",
      "Epoch 107/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.0541 - mae: 0.7864 - mse: 1.0541 - val_loss: 7.8567 - val_mae: 1.6405 - val_mse: 7.8567\n",
      "Epoch 108/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.0454 - mae: 0.7829 - mse: 1.0454 - val_loss: 8.3792 - val_mae: 1.6858 - val_mse: 8.3792\n",
      "Epoch 109/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 1.0472 - mae: 0.7867 - mse: 1.0472 - val_loss: 9.1809 - val_mae: 1.7524 - val_mse: 9.1809\n",
      "Epoch 110/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13124/13124 [==============================] - 0s 38us/sample - loss: 1.0435 - mae: 0.7859 - mse: 1.0435 - val_loss: 8.8609 - val_mae: 1.7526 - val_mse: 8.8609\n",
      "Epoch 111/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 1.0352 - mae: 0.7847 - mse: 1.0352 - val_loss: 8.1023 - val_mae: 1.8199 - val_mse: 8.1023\n",
      "Epoch 112/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 1.0231 - mae: 0.7777 - mse: 1.0231 - val_loss: 8.1397 - val_mae: 1.8424 - val_mse: 8.1397\n",
      "Epoch 113/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 1.0141 - mae: 0.7716 - mse: 1.0141 - val_loss: 7.3635 - val_mae: 1.7151 - val_mse: 7.3635\n",
      "Epoch 114/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 1.0316 - mae: 0.7776 - mse: 1.0316 - val_loss: 8.4918 - val_mae: 1.7546 - val_mse: 8.4918\n",
      "Epoch 115/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 1.0120 - mae: 0.7697 - mse: 1.0120 - val_loss: 7.5927 - val_mae: 1.5611 - val_mse: 7.5927\n",
      "Epoch 116/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.9933 - mae: 0.7645 - mse: 0.9933 - val_loss: 9.3517 - val_mae: 1.9423 - val_mse: 9.3517\n",
      "Epoch 117/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 1.0087 - mae: 0.7690 - mse: 1.0087 - val_loss: 7.7388 - val_mae: 1.6990 - val_mse: 7.7388\n",
      "Epoch 118/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 0.9816 - mae: 0.7590 - mse: 0.9816 - val_loss: 8.1805 - val_mae: 1.6777 - val_mse: 8.1805\n",
      "Epoch 119/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.9774 - mae: 0.7564 - mse: 0.9774 - val_loss: 8.3991 - val_mae: 1.6562 - val_mse: 8.3991\n",
      "Epoch 120/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.9842 - mae: 0.7601 - mse: 0.9842 - val_loss: 7.8555 - val_mae: 1.5576 - val_mse: 7.8555\n",
      "Epoch 121/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 0.9764 - mae: 0.7562 - mse: 0.9764 - val_loss: 8.0723 - val_mae: 1.7053 - val_mse: 8.0723\n",
      "Epoch 122/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 0.9543 - mae: 0.7468 - mse: 0.9543 - val_loss: 7.9904 - val_mae: 1.5938 - val_mse: 7.9904\n",
      "Epoch 123/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.9624 - mae: 0.7494 - mse: 0.9624 - val_loss: 7.4841 - val_mae: 1.6485 - val_mse: 7.4841\n",
      "Epoch 124/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.9570 - mae: 0.7485 - mse: 0.9570 - val_loss: 7.6624 - val_mae: 1.5429 - val_mse: 7.6624\n",
      "Epoch 125/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 0.9447 - mae: 0.7407 - mse: 0.9447 - val_loss: 8.6813 - val_mae: 1.7658 - val_mse: 8.6813\n",
      "Epoch 126/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 0.9535 - mae: 0.7457 - mse: 0.9535 - val_loss: 8.1296 - val_mae: 1.6282 - val_mse: 8.1296\n",
      "Epoch 127/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 0.9503 - mae: 0.7453 - mse: 0.9503 - val_loss: 9.4490 - val_mae: 1.8331 - val_mse: 9.4490\n",
      "Epoch 128/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.9405 - mae: 0.7424 - mse: 0.9405 - val_loss: 8.4889 - val_mae: 1.6388 - val_mse: 8.4889\n",
      "Epoch 129/500\n",
      "13124/13124 [==============================] - 1s 41us/sample - loss: 0.9402 - mae: 0.7413 - mse: 0.9402 - val_loss: 8.9672 - val_mae: 1.8146 - val_mse: 8.9672\n",
      "Epoch 130/500\n",
      "13124/13124 [==============================] - 1s 44us/sample - loss: 0.9494 - mae: 0.7451 - mse: 0.9494 - val_loss: 8.3234 - val_mae: 1.6829 - val_mse: 8.3234\n",
      "Epoch 131/500\n",
      "13124/13124 [==============================] - 1s 47us/sample - loss: 0.9405 - mae: 0.7420 - mse: 0.9405 - val_loss: 7.8538 - val_mae: 1.5662 - val_mse: 7.8538\n",
      "Epoch 132/500\n",
      "13124/13124 [==============================] - 1s 47us/sample - loss: 0.9245 - mae: 0.7358 - mse: 0.9245 - val_loss: 10.2845 - val_mae: 1.9992 - val_mse: 10.2845\n",
      "Epoch 133/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 0.9374 - mae: 0.7416 - mse: 0.9374 - val_loss: 7.6537 - val_mae: 1.6048 - val_mse: 7.6537\n",
      "Epoch 134/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 0.9328 - mae: 0.7379 - mse: 0.9328 - val_loss: 8.7112 - val_mae: 1.7126 - val_mse: 8.7112\n",
      "Epoch 135/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.9258 - mae: 0.7347 - mse: 0.9258 - val_loss: 8.3192 - val_mae: 1.7140 - val_mse: 8.3192\n",
      "Epoch 136/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 0.9197 - mae: 0.7298 - mse: 0.9197 - val_loss: 9.8487 - val_mae: 2.0274 - val_mse: 9.8487\n",
      "Epoch 137/500\n",
      "13124/13124 [==============================] - 1s 38us/sample - loss: 0.9168 - mae: 0.7304 - mse: 0.9168 - val_loss: 7.9942 - val_mae: 1.5739 - val_mse: 7.9942\n",
      "Epoch 138/500\n",
      "13124/13124 [==============================] - 1s 39us/sample - loss: 0.9155 - mae: 0.7324 - mse: 0.9155 - val_loss: 8.7117 - val_mae: 1.9565 - val_mse: 8.7117\n",
      "Epoch 139/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.9199 - mae: 0.7345 - mse: 0.9199 - val_loss: 8.7923 - val_mae: 1.6776 - val_mse: 8.7923\n",
      "Epoch 140/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.9093 - mae: 0.7311 - mse: 0.9093 - val_loss: 7.9151 - val_mae: 1.5793 - val_mse: 7.9151\n",
      "Epoch 141/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.9034 - mae: 0.7265 - mse: 0.9034 - val_loss: 8.1064 - val_mae: 1.7034 - val_mse: 8.1064\n",
      "Epoch 142/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.9102 - mae: 0.7293 - mse: 0.9102 - val_loss: 9.4638 - val_mae: 1.9460 - val_mse: 9.4638\n",
      "Epoch 143/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.9070 - mae: 0.7271 - mse: 0.9070 - val_loss: 8.3446 - val_mae: 1.5685 - val_mse: 8.3446\n",
      "Epoch 144/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.9076 - mae: 0.7306 - mse: 0.9076 - val_loss: 8.1449 - val_mae: 1.6323 - val_mse: 8.1449\n",
      "Epoch 145/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 0.8975 - mae: 0.7240 - mse: 0.8975 - val_loss: 7.9210 - val_mae: 1.5773 - val_mse: 7.9210\n",
      "Epoch 146/500\n",
      "13124/13124 [==============================] - 1s 45us/sample - loss: 0.9027 - mae: 0.7274 - mse: 0.9027 - val_loss: 7.9965 - val_mae: 1.5504 - val_mse: 7.9965\n",
      "Epoch 147/500\n",
      "13124/13124 [==============================] - 1s 44us/sample - loss: 0.8910 - mae: 0.7216 - mse: 0.8910 - val_loss: 9.1421 - val_mae: 1.6974 - val_mse: 9.1421\n",
      "Epoch 148/500\n",
      "13124/13124 [==============================] - 1s 47us/sample - loss: 0.9023 - mae: 0.7266 - mse: 0.9023 - val_loss: 8.1979 - val_mae: 1.5557 - val_mse: 8.1979\n",
      "Epoch 149/500\n",
      "13124/13124 [==============================] - 1s 48us/sample - loss: 0.8840 - mae: 0.7190 - mse: 0.8840 - val_loss: 8.1407 - val_mae: 1.6528 - val_mse: 8.1407\n",
      "Epoch 150/500\n",
      "13124/13124 [==============================] - 1s 42us/sample - loss: 0.8906 - mae: 0.7211 - mse: 0.8906 - val_loss: 9.1099 - val_mae: 1.6798 - val_mse: 9.1099\n",
      "Epoch 151/500\n",
      "13124/13124 [==============================] - 1s 48us/sample - loss: 0.8743 - mae: 0.7152 - mse: 0.8743 - val_loss: 8.4573 - val_mae: 1.8008 - val_mse: 8.4573\n",
      "Epoch 152/500\n",
      "13124/13124 [==============================] - 1s 47us/sample - loss: 0.8830 - mae: 0.7180 - mse: 0.8830 - val_loss: 7.4720 - val_mae: 1.4847 - val_mse: 7.4720\n",
      "Epoch 153/500\n",
      "13124/13124 [==============================] - 0s 38us/sample - loss: 0.8743 - mae: 0.7151 - mse: 0.8743 - val_loss: 8.6413 - val_mae: 1.7170 - val_mse: 8.6413\n",
      "Epoch 154/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.8697 - mae: 0.7139 - mse: 0.8697 - val_loss: 8.0484 - val_mae: 1.6298 - val_mse: 8.0484\n",
      "Epoch 155/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.8586 - mae: 0.7093 - mse: 0.8586 - val_loss: 8.8172 - val_mae: 1.7256 - val_mse: 8.8172\n",
      "Epoch 156/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.8674 - mae: 0.7103 - mse: 0.8674 - val_loss: 9.2357 - val_mae: 1.8064 - val_mse: 9.2357\n",
      "Epoch 157/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.8700 - mae: 0.7124 - mse: 0.8700 - val_loss: 8.5983 - val_mae: 1.6234 - val_mse: 8.5983\n",
      "Epoch 158/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.8597 - mae: 0.7106 - mse: 0.8597 - val_loss: 8.4294 - val_mae: 1.6547 - val_mse: 8.4294\n",
      "Epoch 159/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.8558 - mae: 0.7096 - mse: 0.8558 - val_loss: 8.4064 - val_mae: 1.8238 - val_mse: 8.4064\n",
      "Epoch 160/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.8630 - mae: 0.7114 - mse: 0.8630 - val_loss: 8.4232 - val_mae: 1.5923 - val_mse: 8.4232\n",
      "Epoch 161/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.8564 - mae: 0.7068 - mse: 0.8564 - val_loss: 8.8594 - val_mae: 1.7259 - val_mse: 8.8594\n",
      "Epoch 162/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.8568 - mae: 0.7058 - mse: 0.8568 - val_loss: 7.8620 - val_mae: 1.5420 - val_mse: 7.8620\n",
      "Epoch 163/500\n",
      "13124/13124 [==============================] - 0s 37us/sample - loss: 0.8518 - mae: 0.7045 - mse: 0.8518 - val_loss: 8.1969 - val_mae: 1.5809 - val_mse: 8.1969\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 14582 samples, validate on 4861 samples\n",
      "Epoch 1/500\n",
      "14582/14582 [==============================] - 1s 60us/sample - loss: 49.8153 - mae: 4.2690 - mse: 49.8153 - val_loss: 39.4609 - val_mae: 3.6564 - val_mse: 39.4610\n",
      "Epoch 2/500\n",
      "14582/14582 [==============================] - 1s 45us/sample - loss: 14.5523 - mae: 2.8129 - mse: 14.5523 - val_loss: 25.6305 - val_mae: 2.9396 - val_mse: 25.6305\n",
      "Epoch 3/500\n",
      "14582/14582 [==============================] - 1s 48us/sample - loss: 10.2570 - mae: 2.4482 - mse: 10.2570 - val_loss: 19.9106 - val_mae: 2.6361 - val_mse: 19.9106\n",
      "Epoch 4/500\n",
      "14582/14582 [==============================] - 1s 50us/sample - loss: 8.5060 - mae: 2.2560 - mse: 8.5060 - val_loss: 25.2863 - val_mae: 3.7651 - val_mse: 25.2863\n",
      "Epoch 5/500\n",
      "14582/14582 [==============================] - 1s 40us/sample - loss: 7.6778 - mae: 2.1585 - mse: 7.6778 - val_loss: 18.8584 - val_mae: 3.0573 - val_mse: 18.8585\n",
      "Epoch 6/500\n",
      "14582/14582 [==============================] - 1s 50us/sample - loss: 6.9099 - mae: 2.0767 - mse: 6.9099 - val_loss: 12.9777 - val_mae: 2.3639 - val_mse: 12.9777\n",
      "Epoch 7/500\n",
      "14582/14582 [==============================] - 1s 44us/sample - loss: 6.4891 - mae: 2.0297 - mse: 6.4891 - val_loss: 11.3230 - val_mae: 2.2105 - val_mse: 11.3230\n",
      "Epoch 8/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 6.0318 - mae: 1.9548 - mse: 6.0318 - val_loss: 19.0954 - val_mae: 3.6277 - val_mse: 19.0954\n",
      "Epoch 9/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 5.7145 - mae: 1.9084 - mse: 5.7145 - val_loss: 12.2311 - val_mae: 2.5563 - val_mse: 12.2311\n",
      "Epoch 10/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 5.4477 - mae: 1.8722 - mse: 5.4477 - val_loss: 11.9505 - val_mae: 2.5193 - val_mse: 11.9505\n",
      "Epoch 11/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 5.1581 - mae: 1.8040 - mse: 5.1581 - val_loss: 9.6319 - val_mae: 2.1164 - val_mse: 9.6319\n",
      "Epoch 12/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 4.9046 - mae: 1.7660 - mse: 4.9046 - val_loss: 7.5403 - val_mae: 1.6733 - val_mse: 7.5403\n",
      "Epoch 13/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 4.7112 - mae: 1.7446 - mse: 4.7112 - val_loss: 8.0003 - val_mae: 1.8135 - val_mse: 8.0003\n",
      "Epoch 14/500\n",
      "14582/14582 [==============================] - 1s 44us/sample - loss: 4.5233 - mae: 1.6991 - mse: 4.5233 - val_loss: 8.2210 - val_mae: 1.9679 - val_mse: 8.2210\n",
      "Epoch 15/500\n",
      "14582/14582 [==============================] - 1s 46us/sample - loss: 4.3982 - mae: 1.6829 - mse: 4.3981 - val_loss: 7.5012 - val_mae: 1.8850 - val_mse: 7.5012\n",
      "Epoch 16/500\n",
      "14582/14582 [==============================] - 1s 46us/sample - loss: 4.2316 - mae: 1.6620 - mse: 4.2316 - val_loss: 7.4608 - val_mae: 1.8727 - val_mse: 7.4608\n",
      "Epoch 17/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 4.0723 - mae: 1.6118 - mse: 4.0723 - val_loss: 7.5164 - val_mae: 1.9021 - val_mse: 7.5164\n",
      "Epoch 18/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 3.8894 - mae: 1.5753 - mse: 3.8894 - val_loss: 7.8916 - val_mae: 2.0197 - val_mse: 7.8916\n",
      "Epoch 19/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 3.7221 - mae: 1.5457 - mse: 3.7221 - val_loss: 8.6178 - val_mae: 2.1917 - val_mse: 8.6178\n",
      "Epoch 20/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 3.6054 - mae: 1.5087 - mse: 3.6054 - val_loss: 5.7654 - val_mae: 1.5383 - val_mse: 5.7654\n",
      "Epoch 21/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 3.4542 - mae: 1.4829 - mse: 3.4542 - val_loss: 6.1866 - val_mae: 1.6647 - val_mse: 6.1866\n",
      "Epoch 22/500\n",
      "14582/14582 [==============================] - 1s 47us/sample - loss: 3.3826 - mae: 1.4613 - mse: 3.3826 - val_loss: 5.4707 - val_mae: 1.5318 - val_mse: 5.4707\n",
      "Epoch 23/500\n",
      "14582/14582 [==============================] - 1s 53us/sample - loss: 3.2482 - mae: 1.4241 - mse: 3.2482 - val_loss: 6.5986 - val_mae: 1.8215 - val_mse: 6.5986\n",
      "Epoch 24/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 3.1610 - mae: 1.4119 - mse: 3.1610 - val_loss: 8.6271 - val_mae: 2.3286 - val_mse: 8.6271\n",
      "Epoch 25/500\n",
      "14582/14582 [==============================] - 1s 41us/sample - loss: 3.0409 - mae: 1.3864 - mse: 3.0409 - val_loss: 6.9738 - val_mae: 1.9167 - val_mse: 6.9738\n",
      "Epoch 26/500\n",
      "14582/14582 [==============================] - 1s 44us/sample - loss: 2.9987 - mae: 1.3771 - mse: 2.9987 - val_loss: 6.0967 - val_mae: 1.7414 - val_mse: 6.0967\n",
      "Epoch 27/500\n",
      "14582/14582 [==============================] - 1s 42us/sample - loss: 2.8625 - mae: 1.3396 - mse: 2.8625 - val_loss: 5.9565 - val_mae: 1.7197 - val_mse: 5.9565\n",
      "Epoch 28/500\n",
      "14582/14582 [==============================] - 1s 48us/sample - loss: 2.7845 - mae: 1.3213 - mse: 2.7845 - val_loss: 6.6716 - val_mae: 1.9049 - val_mse: 6.6716\n",
      "Epoch 29/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 2.7522 - mae: 1.3109 - mse: 2.7522 - val_loss: 5.1549 - val_mae: 1.5130 - val_mse: 5.1549\n",
      "Epoch 30/500\n",
      "14582/14582 [==============================] - 1s 47us/sample - loss: 2.6285 - mae: 1.2820 - mse: 2.6285 - val_loss: 6.6166 - val_mae: 1.9151 - val_mse: 6.6166\n",
      "Epoch 31/500\n",
      "14582/14582 [==============================] - 1s 46us/sample - loss: 2.5655 - mae: 1.2588 - mse: 2.5655 - val_loss: 5.0454 - val_mae: 1.4900 - val_mse: 5.0454\n",
      "Epoch 32/500\n",
      "14582/14582 [==============================] - 1s 47us/sample - loss: 2.5113 - mae: 1.2488 - mse: 2.5113 - val_loss: 4.7177 - val_mae: 1.3820 - val_mse: 4.7177\n",
      "Epoch 33/500\n",
      "14582/14582 [==============================] - 1s 41us/sample - loss: 2.4427 - mae: 1.2332 - mse: 2.4427 - val_loss: 5.0269 - val_mae: 1.4734 - val_mse: 5.0269\n",
      "Epoch 34/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 2.3740 - mae: 1.2137 - mse: 2.3740 - val_loss: 5.0881 - val_mae: 1.5247 - val_mse: 5.0881\n",
      "Epoch 35/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 2.3297 - mae: 1.1980 - mse: 2.3297 - val_loss: 5.2420 - val_mae: 1.5529 - val_mse: 5.2419\n",
      "Epoch 36/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 2.2847 - mae: 1.1886 - mse: 2.2847 - val_loss: 4.8890 - val_mae: 1.4139 - val_mse: 4.8890\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14582/14582 [==============================] - 1s 42us/sample - loss: 2.2119 - mae: 1.1658 - mse: 2.2119 - val_loss: 5.8860 - val_mae: 1.7091 - val_mse: 5.8860\n",
      "Epoch 38/500\n",
      "14582/14582 [==============================] - 1s 42us/sample - loss: 2.1790 - mae: 1.1553 - mse: 2.1790 - val_loss: 5.7984 - val_mae: 1.6997 - val_mse: 5.7984\n",
      "Epoch 39/500\n",
      "14582/14582 [==============================] - 1s 41us/sample - loss: 2.1290 - mae: 1.1442 - mse: 2.1290 - val_loss: 4.8719 - val_mae: 1.3873 - val_mse: 4.8719\n",
      "Epoch 40/500\n",
      "14582/14582 [==============================] - 1s 42us/sample - loss: 2.0885 - mae: 1.1285 - mse: 2.0885 - val_loss: 6.0123 - val_mae: 1.6943 - val_mse: 6.0123\n",
      "Epoch 41/500\n",
      "14582/14582 [==============================] - 1s 44us/sample - loss: 2.0300 - mae: 1.1110 - mse: 2.0300 - val_loss: 6.5197 - val_mae: 1.8818 - val_mse: 6.5197\n",
      "Epoch 42/500\n",
      "14582/14582 [==============================] - 1s 46us/sample - loss: 1.9911 - mae: 1.1000 - mse: 1.9911 - val_loss: 7.4112 - val_mae: 2.0024 - val_mse: 7.4112\n",
      "Epoch 43/500\n",
      "14582/14582 [==============================] - 1s 41us/sample - loss: 1.9347 - mae: 1.0833 - mse: 1.9347 - val_loss: 5.3382 - val_mae: 1.4890 - val_mse: 5.3382\n",
      "Epoch 44/500\n",
      "14582/14582 [==============================] - 1s 48us/sample - loss: 1.9192 - mae: 1.0806 - mse: 1.9192 - val_loss: 5.3444 - val_mae: 1.4907 - val_mse: 5.3444\n",
      "Epoch 45/500\n",
      "14582/14582 [==============================] - 1s 46us/sample - loss: 1.8910 - mae: 1.0711 - mse: 1.8910 - val_loss: 5.0551 - val_mae: 1.3467 - val_mse: 5.0551\n",
      "Epoch 46/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.8570 - mae: 1.0594 - mse: 1.8570 - val_loss: 5.1814 - val_mae: 1.3980 - val_mse: 5.1814\n",
      "Epoch 47/500\n",
      "14582/14582 [==============================] - 1s 52us/sample - loss: 1.8226 - mae: 1.0493 - mse: 1.8226 - val_loss: 5.3684 - val_mae: 1.4857 - val_mse: 5.3684\n",
      "Epoch 48/500\n",
      "14582/14582 [==============================] - 1s 46us/sample - loss: 1.8141 - mae: 1.0500 - mse: 1.8141 - val_loss: 5.4531 - val_mae: 1.4696 - val_mse: 5.4531\n",
      "Epoch 49/500\n",
      "14582/14582 [==============================] - 1s 50us/sample - loss: 1.7948 - mae: 1.0392 - mse: 1.7948 - val_loss: 5.0493 - val_mae: 1.3527 - val_mse: 5.0493\n",
      "Epoch 50/500\n",
      "14582/14582 [==============================] - 1s 47us/sample - loss: 1.7468 - mae: 1.0279 - mse: 1.7468 - val_loss: 5.4460 - val_mae: 1.5222 - val_mse: 5.4460\n",
      "Epoch 51/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 1.7385 - mae: 1.0208 - mse: 1.7385 - val_loss: 5.4280 - val_mae: 1.4708 - val_mse: 5.4280\n",
      "Epoch 52/500\n",
      "14582/14582 [==============================] - 1s 38us/sample - loss: 1.7273 - mae: 1.0174 - mse: 1.7273 - val_loss: 5.8373 - val_mae: 1.5785 - val_mse: 5.8373\n",
      "Epoch 53/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 1.6996 - mae: 1.0123 - mse: 1.6996 - val_loss: 6.0967 - val_mae: 1.6520 - val_mse: 6.0967\n",
      "Epoch 54/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 1.6891 - mae: 1.0071 - mse: 1.6891 - val_loss: 6.2810 - val_mae: 1.7210 - val_mse: 6.2810\n",
      "Epoch 55/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 1.6648 - mae: 0.9993 - mse: 1.6648 - val_loss: 6.5159 - val_mae: 1.8136 - val_mse: 6.5159\n",
      "Epoch 56/500\n",
      "14582/14582 [==============================] - 1s 37us/sample - loss: 1.6562 - mae: 0.9958 - mse: 1.6562 - val_loss: 5.4178 - val_mae: 1.4558 - val_mse: 5.4178\n",
      "Epoch 57/500\n",
      "14582/14582 [==============================] - 1s 40us/sample - loss: 1.6417 - mae: 0.9896 - mse: 1.6417 - val_loss: 5.3734 - val_mae: 1.4561 - val_mse: 5.3734\n",
      "Epoch 58/500\n",
      "14582/14582 [==============================] - 1s 42us/sample - loss: 1.6201 - mae: 0.9848 - mse: 1.6201 - val_loss: 5.2062 - val_mae: 1.3623 - val_mse: 5.2062\n",
      "Epoch 59/500\n",
      "14582/14582 [==============================] - 1s 40us/sample - loss: 1.6147 - mae: 0.9814 - mse: 1.6147 - val_loss: 6.1708 - val_mae: 1.6584 - val_mse: 6.1708\n",
      "Epoch 60/500\n",
      "14582/14582 [==============================] - 1s 43us/sample - loss: 1.5933 - mae: 0.9761 - mse: 1.5933 - val_loss: 5.2349 - val_mae: 1.3927 - val_mse: 5.2349\n",
      "Epoch 61/500\n",
      "14582/14582 [==============================] - 1s 44us/sample - loss: 1.6007 - mae: 0.9806 - mse: 1.6007 - val_loss: 5.6681 - val_mae: 1.5005 - val_mse: 5.6681\n",
      "Epoch 62/500\n",
      "14582/14582 [==============================] - 1s 43us/sample - loss: 1.5741 - mae: 0.9711 - mse: 1.5741 - val_loss: 6.3460 - val_mae: 1.7002 - val_mse: 6.3460\n",
      "Epoch 63/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.5617 - mae: 0.9630 - mse: 1.5617 - val_loss: 5.2061 - val_mae: 1.3959 - val_mse: 5.2061\n",
      "Epoch 64/500\n",
      "14582/14582 [==============================] - 1s 41us/sample - loss: 1.5562 - mae: 0.9648 - mse: 1.5562 - val_loss: 5.4100 - val_mae: 1.4658 - val_mse: 5.4100\n",
      "Epoch 65/500\n",
      "14582/14582 [==============================] - 1s 41us/sample - loss: 1.5544 - mae: 0.9620 - mse: 1.5544 - val_loss: 5.0253 - val_mae: 1.3348 - val_mse: 5.0253\n",
      "Epoch 66/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.5307 - mae: 0.9562 - mse: 1.5307 - val_loss: 5.4443 - val_mae: 1.4490 - val_mse: 5.4443\n",
      "Epoch 67/500\n",
      "14582/14582 [==============================] - 1s 41us/sample - loss: 1.5044 - mae: 0.9508 - mse: 1.5044 - val_loss: 6.1821 - val_mae: 1.6817 - val_mse: 6.1821\n",
      "Epoch 68/500\n",
      "14582/14582 [==============================] - 1s 44us/sample - loss: 1.4963 - mae: 0.9489 - mse: 1.4963 - val_loss: 6.1609 - val_mae: 1.6153 - val_mse: 6.1609\n",
      "Epoch 69/500\n",
      "14582/14582 [==============================] - 1s 40us/sample - loss: 1.4907 - mae: 0.9439 - mse: 1.4907 - val_loss: 5.1439 - val_mae: 1.3335 - val_mse: 5.1439\n",
      "Epoch 70/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.4839 - mae: 0.9389 - mse: 1.4839 - val_loss: 5.4949 - val_mae: 1.4785 - val_mse: 5.4949\n",
      "Epoch 71/500\n",
      "14582/14582 [==============================] - 1s 41us/sample - loss: 1.4748 - mae: 0.9350 - mse: 1.4748 - val_loss: 5.9513 - val_mae: 1.5048 - val_mse: 5.9513\n",
      "Epoch 72/500\n",
      "14582/14582 [==============================] - 1s 44us/sample - loss: 1.4592 - mae: 0.9310 - mse: 1.4592 - val_loss: 5.4354 - val_mae: 1.3714 - val_mse: 5.4354\n",
      "Epoch 73/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.4535 - mae: 0.9305 - mse: 1.4535 - val_loss: 5.5365 - val_mae: 1.3857 - val_mse: 5.5365\n",
      "Epoch 74/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.4477 - mae: 0.9285 - mse: 1.4477 - val_loss: 5.5262 - val_mae: 1.4142 - val_mse: 5.5262\n",
      "Epoch 75/500\n",
      "14582/14582 [==============================] - 1s 40us/sample - loss: 1.4260 - mae: 0.9229 - mse: 1.4260 - val_loss: 5.6615 - val_mae: 1.5215 - val_mse: 5.6615\n",
      "Epoch 76/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.4196 - mae: 0.9195 - mse: 1.4196 - val_loss: 5.2252 - val_mae: 1.3574 - val_mse: 5.2252\n",
      "Epoch 77/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.4173 - mae: 0.9160 - mse: 1.4173 - val_loss: 5.4130 - val_mae: 1.4050 - val_mse: 5.4130\n",
      "Epoch 78/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.3980 - mae: 0.9122 - mse: 1.3980 - val_loss: 6.1442 - val_mae: 1.6121 - val_mse: 6.1442\n",
      "Epoch 79/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.4037 - mae: 0.9143 - mse: 1.4037 - val_loss: 5.4994 - val_mae: 1.4721 - val_mse: 5.4994\n",
      "Epoch 80/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.3982 - mae: 0.9133 - mse: 1.3982 - val_loss: 5.9666 - val_mae: 1.5928 - val_mse: 5.9666\n",
      "Epoch 81/500\n",
      "14582/14582 [==============================] - 1s 40us/sample - loss: 1.3750 - mae: 0.9014 - mse: 1.3750 - val_loss: 5.5521 - val_mae: 1.4329 - val_mse: 5.5521\n",
      "Epoch 82/500\n",
      "14582/14582 [==============================] - 1s 39us/sample - loss: 1.3823 - mae: 0.9040 - mse: 1.3823 - val_loss: 5.3916 - val_mae: 1.4028 - val_mse: 5.3916\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for f in range(1, 11, 1):\n",
    "    frac = f / 10.0\n",
    "    sample = data.sample(frac=frac, random_state=12345)\n",
    "    train, validation, test = train_validation_test_split(sample)\n",
    "\n",
    "    train.sort_values(\"time\", inplace=True)\n",
    "    validation.sort_values(\"time\", inplace=True)\n",
    "    test.sort_values(\"time\", inplace=True)\n",
    "\n",
    "    train_rolled = train.groupby(\"location\").rolling(15, min_periods=1).mean().reset_index()\n",
    "    validation_rolled = validation.groupby(\"location\").rolling(15, min_periods=1).mean().reset_index()\n",
    "    test_rolled = test.groupby(\"location\").rolling(15, min_periods=1).mean().reset_index()\n",
    "\n",
    "    train_imputed = train_rolled.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    train_imputed.fillna(0, inplace=True)\n",
    "    train_imputed.reset_index(inplace=True)\n",
    "\n",
    "    validation_imputed = validation_rolled.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    validation_imputed.fillna(0, inplace=True)\n",
    "    validation_imputed.reset_index(inplace=True)\n",
    "\n",
    "    test_imputed = test_rolled.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    test_imputed.fillna(0, inplace=True)\n",
    "    test_imputed.reset_index(inplace=True)\n",
    "\n",
    "    train_imputed[\"X\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "    train_imputed[\"Y\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])\n",
    "\n",
    "    validation_imputed[\"X\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "    validation_imputed[\"Y\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])\n",
    "\n",
    "    test_imputed[\"X\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "    test_imputed[\"Y\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])\n",
    "\n",
    "    X_train, y_train = train_imputed[scanners].values, train_imputed[[\"X\", \"Y\"]].values\n",
    "    X_validation, y_validation = validation_imputed[scanners].values, validation_imputed[[\"X\", \"Y\"]].values\n",
    "    X_test, y_test = test_imputed[scanners].values, test_imputed[[\"X\", \"Y\"]].values\n",
    "\n",
    "    model = MLP()\n",
    "\n",
    "    history = model.fit(X_train, y_train, X_validation, y_validation)\n",
    "    train_loss.append(history.history['loss'][-1])\n",
    "    val_loss.append(history.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "plt.plot(x, train_loss, label='Training loss')\n",
    "plt.plot(x, val_loss, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Dataset size\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
