{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width: 98% !important }<style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 98% !important }<style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_file = \"../Data/pin.csv\"\n",
    "\n",
    "pin = read_pin(pin_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All beacons: ['0117C55D14E4']\n",
      "Selecting 0117C55D14E4\n"
     ]
    }
   ],
   "source": [
    "filename = \"../Data/rssi3.csv\"\n",
    "B1 = \"0117C55D14E4\"\n",
    "\n",
    "data = read_data(filename, B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped = data.groupby([\"location\", pd.Grouper(key=\"time\", freq=\"1s\")]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Validation Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = train_validation_test_split(data_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(\"time\", inplace=True)\n",
    "validation.sort_values(\"time\", inplace=True)\n",
    "test.sort_values(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "1. Forward fill\n",
    "2. Fill NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imputed = train.set_index(\"location\").groupby(\"location\").ffill()\n",
    "train_imputed.fillna(0, inplace=True)\n",
    "train_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_imputed = validation.set_index(\"location\").groupby(\"location\").ffill()\n",
    "validation_imputed.fillna(0, inplace=True)\n",
    "validation_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imputed = test.set_index(\"location\").groupby(\"location\").ffill()\n",
    "test_imputed.fillna(0, inplace=True)\n",
    "test_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Location to Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imputed[\"X\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "train_imputed[\"Y\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_imputed[\"X\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "validation_imputed[\"Y\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imputed[\"X\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "test_imputed[\"Y\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_imputed[scanners].values, train_imputed[[\"X\", \"Y\"]].values\n",
    "X_validation, y_validation = validation_imputed[scanners].values, validation_imputed[[\"X\", \"Y\"]].values\n",
    "X_test, y_test = test_imputed[scanners].values, test_imputed[[\"X\", \"Y\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 812 samples, validate on 271 samples\n",
      "Epoch 1/500\n",
      "812/812 [==============================] - 1s 889us/sample - loss: 1940.9084 - mae: 32.5372 - mse: 1940.9081 - val_loss: 182.0354 - val_mae: 7.5188 - val_mse: 182.0354\n",
      "Epoch 2/500\n",
      "812/812 [==============================] - 0s 56us/sample - loss: 71.9951 - mae: 5.5105 - mse: 71.9951 - val_loss: 173.4168 - val_mae: 7.3661 - val_mse: 173.4168\n",
      "Epoch 3/500\n",
      "812/812 [==============================] - 0s 59us/sample - loss: 61.6930 - mae: 5.2147 - mse: 61.6930 - val_loss: 139.5799 - val_mae: 6.2698 - val_mse: 139.5798\n",
      "Epoch 4/500\n",
      "812/812 [==============================] - 0s 57us/sample - loss: 51.7166 - mae: 4.9055 - mse: 51.7166 - val_loss: 124.3459 - val_mae: 6.2886 - val_mse: 124.3459\n",
      "Epoch 5/500\n",
      "812/812 [==============================] - 0s 58us/sample - loss: 43.8450 - mae: 4.5425 - mse: 43.8450 - val_loss: 102.7772 - val_mae: 5.4927 - val_mse: 102.7772\n",
      "Epoch 6/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 38.2636 - mae: 4.2229 - mse: 38.2636 - val_loss: 103.2149 - val_mae: 6.2963 - val_mse: 103.2149\n",
      "Epoch 7/500\n",
      "812/812 [==============================] - 0s 57us/sample - loss: 34.9320 - mae: 4.1621 - mse: 34.9320 - val_loss: 96.9137 - val_mae: 6.1847 - val_mse: 96.9137\n",
      "Epoch 8/500\n",
      "812/812 [==============================] - 0s 58us/sample - loss: 31.3309 - mae: 3.8928 - mse: 31.3309 - val_loss: 85.2813 - val_mae: 6.0180 - val_mse: 85.2813\n",
      "Epoch 9/500\n",
      "812/812 [==============================] - 0s 58us/sample - loss: 29.2725 - mae: 3.8588 - mse: 29.2725 - val_loss: 66.6881 - val_mae: 4.5347 - val_mse: 66.6881\n",
      "Epoch 10/500\n",
      "812/812 [==============================] - 0s 56us/sample - loss: 26.3316 - mae: 3.7066 - mse: 26.3316 - val_loss: 75.1142 - val_mae: 5.7783 - val_mse: 75.1142\n",
      "Epoch 11/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 23.8324 - mae: 3.5293 - mse: 23.8324 - val_loss: 72.7006 - val_mae: 5.9435 - val_mse: 72.7006\n",
      "Epoch 12/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 21.6285 - mae: 3.4654 - mse: 21.6285 - val_loss: 52.3246 - val_mae: 4.1160 - val_mse: 52.3246\n",
      "Epoch 13/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 21.7836 - mae: 3.4583 - mse: 21.7836 - val_loss: 54.4158 - val_mae: 4.5736 - val_mse: 54.4158\n",
      "Epoch 14/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 18.5962 - mae: 3.1740 - mse: 18.5962 - val_loss: 50.4297 - val_mae: 4.5230 - val_mse: 50.4297\n",
      "Epoch 15/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 17.7361 - mae: 3.1837 - mse: 17.7361 - val_loss: 42.3003 - val_mae: 3.7067 - val_mse: 42.3003\n",
      "Epoch 16/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 18.7477 - mae: 3.2863 - mse: 18.7477 - val_loss: 47.0120 - val_mae: 4.5065 - val_mse: 47.0120\n",
      "Epoch 17/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 15.3025 - mae: 2.9638 - mse: 15.3025 - val_loss: 41.0536 - val_mae: 3.9537 - val_mse: 41.0536\n",
      "Epoch 18/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 14.4460 - mae: 2.8510 - mse: 14.4460 - val_loss: 58.3599 - val_mae: 5.9721 - val_mse: 58.3599\n",
      "Epoch 19/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 14.6622 - mae: 2.9621 - mse: 14.6622 - val_loss: 34.4880 - val_mae: 3.3374 - val_mse: 34.4880\n",
      "Epoch 20/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 14.2383 - mae: 2.9889 - mse: 14.2383 - val_loss: 44.5493 - val_mae: 4.5941 - val_mse: 44.5493\n",
      "Epoch 21/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 13.3212 - mae: 2.7700 - mse: 13.3212 - val_loss: 33.2813 - val_mae: 3.4787 - val_mse: 33.2813\n",
      "Epoch 22/500\n",
      "812/812 [==============================] - 0s 67us/sample - loss: 13.5840 - mae: 2.9187 - mse: 13.5840 - val_loss: 31.2190 - val_mae: 3.2816 - val_mse: 31.2190\n",
      "Epoch 23/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 12.5165 - mae: 2.8153 - mse: 12.5165 - val_loss: 34.6267 - val_mae: 3.9581 - val_mse: 34.6267\n",
      "Epoch 24/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 11.7162 - mae: 2.7067 - mse: 11.7162 - val_loss: 28.8888 - val_mae: 3.0671 - val_mse: 28.8888\n",
      "Epoch 25/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 13.4162 - mae: 2.9366 - mse: 13.4162 - val_loss: 29.2917 - val_mae: 3.2319 - val_mse: 29.2917\n",
      "Epoch 26/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 12.3845 - mae: 2.8405 - mse: 12.3845 - val_loss: 30.5021 - val_mae: 3.4386 - val_mse: 30.5021\n",
      "Epoch 27/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 11.0376 - mae: 2.6396 - mse: 11.0376 - val_loss: 31.0354 - val_mae: 3.6505 - val_mse: 31.0354\n",
      "Epoch 28/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 10.9637 - mae: 2.6269 - mse: 10.9637 - val_loss: 36.3992 - val_mae: 4.4166 - val_mse: 36.3992\n",
      "Epoch 29/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 11.7405 - mae: 2.7818 - mse: 11.7405 - val_loss: 28.5956 - val_mae: 3.3986 - val_mse: 28.5956\n",
      "Epoch 30/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 10.4774 - mae: 2.6121 - mse: 10.4774 - val_loss: 34.4630 - val_mae: 4.1947 - val_mse: 34.4630\n",
      "Epoch 31/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 10.6201 - mae: 2.6203 - mse: 10.6201 - val_loss: 24.1506 - val_mae: 2.7791 - val_mse: 24.1506\n",
      "Epoch 32/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 9.6525 - mae: 2.4644 - mse: 9.6525 - val_loss: 27.3562 - val_mae: 3.4423 - val_mse: 27.3562\n",
      "Epoch 33/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 10.1411 - mae: 2.6181 - mse: 10.1411 - val_loss: 26.7739 - val_mae: 3.2752 - val_mse: 26.7739\n",
      "Epoch 34/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 9.3472 - mae: 2.3854 - mse: 9.3472 - val_loss: 29.1248 - val_mae: 3.7006 - val_mse: 29.1248\n",
      "Epoch 35/500\n",
      "812/812 [==============================] - 0s 57us/sample - loss: 10.5268 - mae: 2.6242 - mse: 10.5268 - val_loss: 37.6643 - val_mae: 4.6819 - val_mse: 37.6643\n",
      "Epoch 36/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 8.8404 - mae: 2.4227 - mse: 8.8404 - val_loss: 30.2045 - val_mae: 3.7965 - val_mse: 30.2045\n",
      "Epoch 37/500\n",
      "812/812 [==============================] - 0s 48us/sample - loss: 9.9441 - mae: 2.6094 - mse: 9.9441 - val_loss: 27.2655 - val_mae: 3.5653 - val_mse: 27.2655\n",
      "Epoch 38/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 8.6708 - mae: 2.3450 - mse: 8.6708 - val_loss: 33.2347 - val_mae: 4.0940 - val_mse: 33.2347\n",
      "Epoch 39/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 9.9556 - mae: 2.5949 - mse: 9.9556 - val_loss: 23.2628 - val_mae: 3.0224 - val_mse: 23.2628\n",
      "Epoch 40/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 10.1213 - mae: 2.5906 - mse: 10.1213 - val_loss: 23.9770 - val_mae: 3.1381 - val_mse: 23.9770\n",
      "Epoch 41/500\n",
      "812/812 [==============================] - 0s 55us/sample - loss: 8.5504 - mae: 2.3942 - mse: 8.5504 - val_loss: 30.7992 - val_mae: 3.9616 - val_mse: 30.7992\n",
      "Epoch 42/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 8.5461 - mae: 2.3591 - mse: 8.5461 - val_loss: 28.7750 - val_mae: 3.8273 - val_mse: 28.7750\n",
      "Epoch 43/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 7.8854 - mae: 2.1593 - mse: 7.8854 - val_loss: 21.9580 - val_mae: 2.9420 - val_mse: 21.9580\n",
      "Epoch 44/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 8.9373 - mae: 2.4857 - mse: 8.9373 - val_loss: 26.1780 - val_mae: 3.6490 - val_mse: 26.1780\n",
      "Epoch 45/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 8.9859 - mae: 2.4685 - mse: 8.9859 - val_loss: 19.3021 - val_mae: 2.3657 - val_mse: 19.3021\n",
      "Epoch 46/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 7.1485 - mae: 2.1218 - mse: 7.1485 - val_loss: 25.1235 - val_mae: 3.3839 - val_mse: 25.1235\n",
      "Epoch 47/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 9.9575 - mae: 2.6565 - mse: 9.9575 - val_loss: 27.4496 - val_mae: 3.7756 - val_mse: 27.4496\n",
      "Epoch 48/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 7.9799 - mae: 2.2517 - mse: 7.9799 - val_loss: 23.3209 - val_mae: 3.1521 - val_mse: 23.3209\n",
      "Epoch 49/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 7.8929 - mae: 2.2956 - mse: 7.8929 - val_loss: 21.3534 - val_mae: 2.8794 - val_mse: 21.3534\n",
      "Epoch 50/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 8.8835 - mae: 2.4722 - mse: 8.8835 - val_loss: 26.8096 - val_mae: 3.7119 - val_mse: 26.8096\n",
      "Epoch 51/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 6.5020 - mae: 2.0121 - mse: 6.5020 - val_loss: 27.7632 - val_mae: 3.8666 - val_mse: 27.7632\n",
      "Epoch 52/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 8.4472 - mae: 2.3829 - mse: 8.4472 - val_loss: 32.7812 - val_mae: 4.5597 - val_mse: 32.7812\n",
      "Epoch 53/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 8.0613 - mae: 2.3259 - mse: 8.0613 - val_loss: 21.7196 - val_mae: 2.9744 - val_mse: 21.7196\n",
      "Epoch 54/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 8.0800 - mae: 2.3059 - mse: 8.0800 - val_loss: 18.3951 - val_mae: 2.4018 - val_mse: 18.3951\n",
      "Epoch 55/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 7.8842 - mae: 2.2785 - mse: 7.8842 - val_loss: 26.9204 - val_mae: 3.6524 - val_mse: 26.9204\n",
      "Epoch 56/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 8.7688 - mae: 2.4005 - mse: 8.7688 - val_loss: 21.3957 - val_mae: 2.8066 - val_mse: 21.3957\n",
      "Epoch 57/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 7.4740 - mae: 2.2291 - mse: 7.4740 - val_loss: 19.1379 - val_mae: 2.4515 - val_mse: 19.1379\n",
      "Epoch 58/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 7.4951 - mae: 2.2274 - mse: 7.4951 - val_loss: 25.5274 - val_mae: 3.7127 - val_mse: 25.5274\n",
      "Epoch 59/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 7.2488 - mae: 2.1968 - mse: 7.2488 - val_loss: 23.3136 - val_mae: 3.2825 - val_mse: 23.3136\n",
      "Epoch 60/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 8.6012 - mae: 2.4033 - mse: 8.6012 - val_loss: 28.1730 - val_mae: 4.1121 - val_mse: 28.1730\n",
      "Epoch 61/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 7.0658 - mae: 2.1456 - mse: 7.0658 - val_loss: 24.5597 - val_mae: 3.3580 - val_mse: 24.5597\n",
      "Epoch 62/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 8.1000 - mae: 2.2681 - mse: 8.1000 - val_loss: 22.0649 - val_mae: 3.2275 - val_mse: 22.0649\n",
      "Epoch 63/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 7.6367 - mae: 2.2813 - mse: 7.6367 - val_loss: 19.0107 - val_mae: 2.4678 - val_mse: 19.0107\n",
      "Epoch 64/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 6.9981 - mae: 2.1890 - mse: 6.9981 - val_loss: 23.7010 - val_mae: 3.2404 - val_mse: 23.7010\n",
      "Epoch 65/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 7.5491 - mae: 2.1854 - mse: 7.5491 - val_loss: 22.2178 - val_mae: 3.2071 - val_mse: 22.2178\n",
      "Epoch 66/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 7.4608 - mae: 2.2178 - mse: 7.4608 - val_loss: 17.5607 - val_mae: 2.2690 - val_mse: 17.5607\n",
      "Epoch 67/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 6.8430 - mae: 2.0791 - mse: 6.8430 - val_loss: 20.6957 - val_mae: 2.9805 - val_mse: 20.6957\n",
      "Epoch 68/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 7.8531 - mae: 2.3373 - mse: 7.8531 - val_loss: 17.8004 - val_mae: 2.3160 - val_mse: 17.8004\n",
      "Epoch 69/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 7.9260 - mae: 2.3152 - mse: 7.9260 - val_loss: 23.2653 - val_mae: 3.4278 - val_mse: 23.2653\n",
      "Epoch 70/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 7.1805 - mae: 2.1792 - mse: 7.1805 - val_loss: 20.3317 - val_mae: 2.8465 - val_mse: 20.3317\n",
      "Epoch 71/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 7.1216 - mae: 2.1890 - mse: 7.1216 - val_loss: 21.2124 - val_mae: 2.9312 - val_mse: 21.2124\n",
      "Epoch 72/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 7.3233 - mae: 2.2609 - mse: 7.3233 - val_loss: 25.2834 - val_mae: 3.4804 - val_mse: 25.2834\n",
      "Epoch 73/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 6.8495 - mae: 2.1116 - mse: 6.8495 - val_loss: 23.5081 - val_mae: 3.1652 - val_mse: 23.5081\n",
      "Epoch 74/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 7.7870 - mae: 2.3265 - mse: 7.7870 - val_loss: 19.1514 - val_mae: 2.8600 - val_mse: 19.1514\n",
      "Epoch 75/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 6.9278 - mae: 2.2021 - mse: 6.9278 - val_loss: 24.3741 - val_mae: 3.4333 - val_mse: 24.3741\n",
      "Epoch 76/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 7.1720 - mae: 2.2115 - mse: 7.1720 - val_loss: 21.5809 - val_mae: 3.0163 - val_mse: 21.5809\n",
      "Epoch 77/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 6.8930 - mae: 2.2035 - mse: 6.8930 - val_loss: 25.5336 - val_mae: 3.5498 - val_mse: 25.5336\n",
      "Epoch 78/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 7.3853 - mae: 2.2368 - mse: 7.3853 - val_loss: 20.4243 - val_mae: 2.9221 - val_mse: 20.4243\n",
      "Epoch 79/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 6.9873 - mae: 2.2119 - mse: 6.9873 - val_loss: 18.9825 - val_mae: 2.6906 - val_mse: 18.9825\n",
      "Epoch 80/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 5.7838 - mae: 1.9387 - mse: 5.7838 - val_loss: 29.0870 - val_mae: 3.9309 - val_mse: 29.0870\n",
      "Epoch 81/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 6.9390 - mae: 2.1867 - mse: 6.9390 - val_loss: 20.7411 - val_mae: 2.7790 - val_mse: 20.7411\n",
      "Epoch 82/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 6.8693 - mae: 2.1328 - mse: 6.8693 - val_loss: 24.2243 - val_mae: 3.2534 - val_mse: 24.2243\n",
      "Epoch 83/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 6.5456 - mae: 2.1186 - mse: 6.5456 - val_loss: 19.4878 - val_mae: 2.8037 - val_mse: 19.4878\n",
      "Epoch 84/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 6.3422 - mae: 2.0919 - mse: 6.3422 - val_loss: 22.9622 - val_mae: 3.0348 - val_mse: 22.9622\n",
      "Epoch 85/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 6.6412 - mae: 2.1022 - mse: 6.6412 - val_loss: 21.7683 - val_mae: 2.9934 - val_mse: 21.7683\n",
      "Epoch 86/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 6.4495 - mae: 2.0808 - mse: 6.4495 - val_loss: 19.4089 - val_mae: 2.8118 - val_mse: 19.4089\n",
      "Epoch 87/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 5.7823 - mae: 1.9630 - mse: 5.7823 - val_loss: 18.3820 - val_mae: 2.4220 - val_mse: 18.3820\n",
      "Epoch 88/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 7.3651 - mae: 2.1749 - mse: 7.3651 - val_loss: 22.0732 - val_mae: 2.8877 - val_mse: 22.0732\n",
      "Epoch 89/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 6.0277 - mae: 2.0188 - mse: 6.0277 - val_loss: 22.3384 - val_mae: 3.1124 - val_mse: 22.3384\n",
      "Epoch 90/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 6.2648 - mae: 2.0323 - mse: 6.2648 - val_loss: 27.7285 - val_mae: 3.8276 - val_mse: 27.7285\n",
      "Epoch 91/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 6.7326 - mae: 2.1056 - mse: 6.7326 - val_loss: 23.3815 - val_mae: 3.2801 - val_mse: 23.3815\n",
      "Epoch 92/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 6.9470 - mae: 2.1348 - mse: 6.9470 - val_loss: 20.8158 - val_mae: 3.0504 - val_mse: 20.8158\n",
      "Epoch 93/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 5.9533 - mae: 1.9947 - mse: 5.9533 - val_loss: 21.8992 - val_mae: 3.1818 - val_mse: 21.8992\n",
      "Epoch 94/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 6.3242 - mae: 2.0971 - mse: 6.3242 - val_loss: 24.5431 - val_mae: 3.3798 - val_mse: 24.5432\n",
      "Epoch 95/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 6.4981 - mae: 2.1339 - mse: 6.4981 - val_loss: 20.8463 - val_mae: 2.9310 - val_mse: 20.8463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 6.9062 - mae: 2.1922 - mse: 6.9062 - val_loss: 24.4660 - val_mae: 3.2950 - val_mse: 24.4660\n",
      "Epoch 97/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 6.1634 - mae: 2.0278 - mse: 6.1634 - val_loss: 20.1071 - val_mae: 2.8373 - val_mse: 20.1071\n",
      "Epoch 98/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 6.0271 - mae: 1.9937 - mse: 6.0271 - val_loss: 18.3967 - val_mae: 2.2557 - val_mse: 18.3967\n",
      "Epoch 99/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 6.5675 - mae: 2.0563 - mse: 6.5675 - val_loss: 22.5590 - val_mae: 3.0268 - val_mse: 22.5590\n",
      "Epoch 100/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 6.0347 - mae: 2.0036 - mse: 6.0347 - val_loss: 21.4439 - val_mae: 2.7100 - val_mse: 21.4439\n",
      "Epoch 101/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 5.9847 - mae: 2.0052 - mse: 5.9847 - val_loss: 20.6788 - val_mae: 2.9753 - val_mse: 20.6788\n",
      "Epoch 102/500\n",
      "812/812 [==============================] - 0s 55us/sample - loss: 6.9564 - mae: 2.1589 - mse: 6.9564 - val_loss: 18.6726 - val_mae: 2.4182 - val_mse: 18.6726\n",
      "Epoch 103/500\n",
      "812/812 [==============================] - 0s 48us/sample - loss: 5.4385 - mae: 1.8872 - mse: 5.4385 - val_loss: 23.1849 - val_mae: 3.0898 - val_mse: 23.1849\n",
      "Epoch 104/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 5.8880 - mae: 1.9159 - mse: 5.8880 - val_loss: 22.4872 - val_mae: 2.9200 - val_mse: 22.4872\n",
      "Epoch 105/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 5.9564 - mae: 1.9308 - mse: 5.9564 - val_loss: 22.0170 - val_mae: 2.7469 - val_mse: 22.0170\n",
      "Epoch 106/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 5.7244 - mae: 1.9003 - mse: 5.7244 - val_loss: 18.5557 - val_mae: 2.5562 - val_mse: 18.5557\n",
      "Epoch 107/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 6.1680 - mae: 2.0693 - mse: 6.1680 - val_loss: 19.0654 - val_mae: 2.4342 - val_mse: 19.0654\n",
      "Epoch 108/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 5.8587 - mae: 1.9359 - mse: 5.8587 - val_loss: 17.8063 - val_mae: 2.4082 - val_mse: 17.8063\n",
      "Epoch 109/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 5.7593 - mae: 1.9709 - mse: 5.7593 - val_loss: 18.8463 - val_mae: 2.7238 - val_mse: 18.8463\n",
      "Epoch 110/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 6.0042 - mae: 1.9564 - mse: 6.0042 - val_loss: 23.4109 - val_mae: 3.3801 - val_mse: 23.4109\n",
      "Epoch 111/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 5.9717 - mae: 2.0214 - mse: 5.9717 - val_loss: 22.7491 - val_mae: 3.1862 - val_mse: 22.7491\n",
      "Epoch 112/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 5.5612 - mae: 1.9278 - mse: 5.5612 - val_loss: 24.6420 - val_mae: 3.6861 - val_mse: 24.6420\n",
      "Epoch 113/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 6.0623 - mae: 1.9845 - mse: 6.0623 - val_loss: 19.6431 - val_mae: 2.5249 - val_mse: 19.6431\n",
      "Epoch 114/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 4.8484 - mae: 1.7616 - mse: 4.8484 - val_loss: 19.8093 - val_mae: 2.9235 - val_mse: 19.8093\n",
      "Epoch 115/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 6.4650 - mae: 2.0533 - mse: 6.4650 - val_loss: 18.9961 - val_mae: 2.6692 - val_mse: 18.9961\n",
      "Epoch 116/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 5.9805 - mae: 2.0215 - mse: 5.9805 - val_loss: 19.3558 - val_mae: 2.7769 - val_mse: 19.3558\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model_validation(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271/1 - 0s - loss: 11.1108 - mae: 2.5026 - mse: 18.4992\n",
      "Test loss: 18.499188348376002\n",
      "Mean absolute error: 2.5026097\n",
      "Mean squared error: 18.499187\n"
     ]
    }
   ],
   "source": [
    "model.model_testing(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 81 samples, validate on 27 samples\n",
      "Epoch 1/500\n",
      "81/81 [==============================] - 0s 6ms/sample - loss: 405.7774 - mae: 16.2465 - mse: 405.7774 - val_loss: 256.9937 - val_mae: 12.4967 - val_mse: 256.9937\n",
      "Epoch 2/500\n",
      "81/81 [==============================] - 0s 231us/sample - loss: 210.3819 - mae: 11.4034 - mse: 210.3819 - val_loss: 240.2737 - val_mae: 12.0432 - val_mse: 240.2737\n",
      "Epoch 3/500\n",
      "81/81 [==============================] - 0s 233us/sample - loss: 187.8984 - mae: 10.2757 - mse: 187.8984 - val_loss: 230.4143 - val_mae: 11.7743 - val_mse: 230.4143\n",
      "Epoch 4/500\n",
      "81/81 [==============================] - 0s 268us/sample - loss: 167.0543 - mae: 9.8512 - mse: 167.0543 - val_loss: 219.0183 - val_mae: 11.2129 - val_mse: 219.0183\n",
      "Epoch 5/500\n",
      "81/81 [==============================] - 0s 215us/sample - loss: 147.8620 - mae: 8.9046 - mse: 147.8620 - val_loss: 208.4792 - val_mae: 10.7903 - val_mse: 208.4792\n",
      "Epoch 6/500\n",
      "81/81 [==============================] - 0s 251us/sample - loss: 136.5306 - mae: 8.4422 - mse: 136.5306 - val_loss: 204.0924 - val_mae: 10.7142 - val_mse: 204.0924\n",
      "Epoch 7/500\n",
      "81/81 [==============================] - 0s 266us/sample - loss: 129.2519 - mae: 8.3573 - mse: 129.2519 - val_loss: 194.3173 - val_mae: 10.3351 - val_mse: 194.3173\n",
      "Epoch 8/500\n",
      "81/81 [==============================] - 0s 264us/sample - loss: 118.2905 - mae: 7.8499 - mse: 118.2905 - val_loss: 188.3786 - val_mae: 10.1588 - val_mse: 188.3786\n",
      "Epoch 9/500\n",
      "81/81 [==============================] - 0s 262us/sample - loss: 109.4999 - mae: 7.5434 - mse: 109.4999 - val_loss: 189.9578 - val_mae: 10.0753 - val_mse: 189.9578\n",
      "Epoch 10/500\n",
      "81/81 [==============================] - 0s 307us/sample - loss: 103.2171 - mae: 7.3060 - mse: 103.2171 - val_loss: 181.2280 - val_mae: 9.8465 - val_mse: 181.2280\n",
      "Epoch 11/500\n",
      "81/81 [==============================] - 0s 289us/sample - loss: 94.7515 - mae: 7.0652 - mse: 94.7515 - val_loss: 192.1198 - val_mae: 10.3512 - val_mse: 192.1198\n",
      "Epoch 12/500\n",
      "81/81 [==============================] - 0s 276us/sample - loss: 89.6373 - mae: 6.8169 - mse: 89.6373 - val_loss: 171.6680 - val_mae: 9.7331 - val_mse: 171.6680\n",
      "Epoch 13/500\n",
      "81/81 [==============================] - 0s 257us/sample - loss: 85.5782 - mae: 6.6879 - mse: 85.5782 - val_loss: 170.3624 - val_mae: 9.7030 - val_mse: 170.3624\n",
      "Epoch 14/500\n",
      "81/81 [==============================] - 0s 260us/sample - loss: 80.6643 - mae: 6.4445 - mse: 80.6643 - val_loss: 180.0972 - val_mae: 10.3560 - val_mse: 180.0972\n",
      "Epoch 15/500\n",
      "81/81 [==============================] - 0s 270us/sample - loss: 76.1172 - mae: 6.2282 - mse: 76.1172 - val_loss: 164.9306 - val_mae: 9.8868 - val_mse: 164.9306\n",
      "Epoch 16/500\n",
      "81/81 [==============================] - 0s 256us/sample - loss: 70.3567 - mae: 6.0858 - mse: 70.3567 - val_loss: 150.2538 - val_mae: 9.2110 - val_mse: 150.2538\n",
      "Epoch 17/500\n",
      "81/81 [==============================] - 0s 260us/sample - loss: 66.1408 - mae: 6.0464 - mse: 66.1408 - val_loss: 168.2952 - val_mae: 9.9004 - val_mse: 168.2952\n",
      "Epoch 18/500\n",
      "81/81 [==============================] - 0s 255us/sample - loss: 63.5829 - mae: 5.7694 - mse: 63.5829 - val_loss: 164.1317 - val_mae: 9.9986 - val_mse: 164.1317\n",
      "Epoch 19/500\n",
      "81/81 [==============================] - 0s 261us/sample - loss: 54.4299 - mae: 5.2134 - mse: 54.4299 - val_loss: 151.8137 - val_mae: 8.8201 - val_mse: 151.8137\n",
      "Epoch 20/500\n",
      "81/81 [==============================] - 0s 245us/sample - loss: 57.2832 - mae: 5.7402 - mse: 57.2832 - val_loss: 143.6022 - val_mae: 8.8012 - val_mse: 143.6022\n",
      "Epoch 21/500\n",
      "81/81 [==============================] - 0s 274us/sample - loss: 49.6133 - mae: 5.1851 - mse: 49.6133 - val_loss: 143.3100 - val_mae: 8.7028 - val_mse: 143.3100\n",
      "Epoch 22/500\n",
      "81/81 [==============================] - 0s 203us/sample - loss: 46.9695 - mae: 4.9528 - mse: 46.9695 - val_loss: 141.5768 - val_mae: 8.8988 - val_mse: 141.5768\n",
      "Epoch 23/500\n",
      "81/81 [==============================] - 0s 213us/sample - loss: 48.7640 - mae: 5.0606 - mse: 48.7640 - val_loss: 136.5101 - val_mae: 8.7868 - val_mse: 136.5101\n",
      "Epoch 24/500\n",
      "81/81 [==============================] - 0s 235us/sample - loss: 44.4362 - mae: 4.9198 - mse: 44.4362 - val_loss: 136.0370 - val_mae: 8.6350 - val_mse: 136.0370\n",
      "Epoch 25/500\n",
      "81/81 [==============================] - 0s 237us/sample - loss: 38.2697 - mae: 4.5802 - mse: 38.2697 - val_loss: 148.8999 - val_mae: 9.3988 - val_mse: 148.8999\n",
      "Epoch 26/500\n",
      "81/81 [==============================] - 0s 228us/sample - loss: 44.0149 - mae: 5.0004 - mse: 44.0149 - val_loss: 132.9238 - val_mae: 8.8979 - val_mse: 132.9238\n",
      "Epoch 27/500\n",
      "81/81 [==============================] - 0s 231us/sample - loss: 35.0524 - mae: 4.3236 - mse: 35.0524 - val_loss: 130.0202 - val_mae: 8.5352 - val_mse: 130.0202\n",
      "Epoch 28/500\n",
      "81/81 [==============================] - 0s 248us/sample - loss: 33.1080 - mae: 4.2227 - mse: 33.1080 - val_loss: 134.6161 - val_mae: 8.8838 - val_mse: 134.6161\n",
      "Epoch 29/500\n",
      "81/81 [==============================] - 0s 231us/sample - loss: 31.1726 - mae: 4.1262 - mse: 31.1726 - val_loss: 129.6840 - val_mae: 8.5274 - val_mse: 129.6840\n",
      "Epoch 30/500\n",
      "81/81 [==============================] - 0s 275us/sample - loss: 31.1404 - mae: 4.1814 - mse: 31.1404 - val_loss: 124.3978 - val_mae: 8.2161 - val_mse: 124.3978\n",
      "Epoch 31/500\n",
      "81/81 [==============================] - 0s 229us/sample - loss: 33.5139 - mae: 4.3327 - mse: 33.5139 - val_loss: 132.3060 - val_mae: 8.8847 - val_mse: 132.3060\n",
      "Epoch 32/500\n",
      "81/81 [==============================] - 0s 272us/sample - loss: 30.8407 - mae: 4.0594 - mse: 30.8407 - val_loss: 129.6926 - val_mae: 8.7155 - val_mse: 129.6926\n",
      "Epoch 33/500\n",
      "81/81 [==============================] - 0s 258us/sample - loss: 35.1613 - mae: 4.6090 - mse: 35.1613 - val_loss: 124.4584 - val_mae: 8.4228 - val_mse: 124.4584\n",
      "Epoch 34/500\n",
      "81/81 [==============================] - 0s 233us/sample - loss: 25.6383 - mae: 3.8514 - mse: 25.6383 - val_loss: 120.8360 - val_mae: 8.4097 - val_mse: 120.8360\n",
      "Epoch 35/500\n",
      "81/81 [==============================] - 0s 246us/sample - loss: 24.2644 - mae: 3.7837 - mse: 24.2644 - val_loss: 129.9298 - val_mae: 8.8312 - val_mse: 129.9298\n",
      "Epoch 36/500\n",
      "81/81 [==============================] - 0s 206us/sample - loss: 24.2036 - mae: 3.7452 - mse: 24.2036 - val_loss: 130.6569 - val_mae: 8.6842 - val_mse: 130.6569\n",
      "Epoch 37/500\n",
      "81/81 [==============================] - 0s 202us/sample - loss: 28.5810 - mae: 3.9923 - mse: 28.5810 - val_loss: 118.9485 - val_mae: 8.1319 - val_mse: 118.9485\n",
      "Epoch 38/500\n",
      "81/81 [==============================] - 0s 218us/sample - loss: 27.0763 - mae: 4.0105 - mse: 27.0763 - val_loss: 125.9015 - val_mae: 8.6329 - val_mse: 125.9015\n",
      "Epoch 39/500\n",
      "81/81 [==============================] - 0s 246us/sample - loss: 24.4951 - mae: 3.8444 - mse: 24.4951 - val_loss: 116.8867 - val_mae: 8.1262 - val_mse: 116.8867\n",
      "Epoch 40/500\n",
      "81/81 [==============================] - 0s 240us/sample - loss: 21.8000 - mae: 3.7044 - mse: 21.8000 - val_loss: 114.2636 - val_mae: 8.1018 - val_mse: 114.2636\n",
      "Epoch 41/500\n",
      "81/81 [==============================] - 0s 221us/sample - loss: 24.1583 - mae: 3.7536 - mse: 24.1583 - val_loss: 117.2574 - val_mae: 8.1345 - val_mse: 117.2574\n",
      "Epoch 42/500\n",
      "81/81 [==============================] - 0s 203us/sample - loss: 22.1699 - mae: 3.6546 - mse: 22.1699 - val_loss: 124.1698 - val_mae: 8.5424 - val_mse: 124.1698\n",
      "Epoch 43/500\n",
      "81/81 [==============================] - 0s 267us/sample - loss: 19.0534 - mae: 3.3089 - mse: 19.0534 - val_loss: 125.8934 - val_mae: 8.5683 - val_mse: 125.8934\n",
      "Epoch 44/500\n",
      "81/81 [==============================] - 0s 283us/sample - loss: 24.4421 - mae: 3.8554 - mse: 24.4421 - val_loss: 111.5156 - val_mae: 8.1912 - val_mse: 111.5156\n",
      "Epoch 45/500\n",
      "81/81 [==============================] - 0s 261us/sample - loss: 18.9168 - mae: 3.3785 - mse: 18.9168 - val_loss: 110.9755 - val_mae: 7.9937 - val_mse: 110.9755\n",
      "Epoch 46/500\n",
      "81/81 [==============================] - 0s 262us/sample - loss: 18.3051 - mae: 3.3469 - mse: 18.3051 - val_loss: 110.1606 - val_mae: 7.9618 - val_mse: 110.1606\n",
      "Epoch 47/500\n",
      "81/81 [==============================] - 0s 261us/sample - loss: 20.9489 - mae: 3.6045 - mse: 20.9489 - val_loss: 134.0688 - val_mae: 9.2734 - val_mse: 134.0688\n",
      "Epoch 48/500\n",
      "81/81 [==============================] - 0s 230us/sample - loss: 24.8382 - mae: 3.8619 - mse: 24.8382 - val_loss: 110.7937 - val_mae: 7.9891 - val_mse: 110.7937\n",
      "Epoch 49/500\n",
      "81/81 [==============================] - 0s 205us/sample - loss: 19.7763 - mae: 3.4087 - mse: 19.7763 - val_loss: 114.2831 - val_mae: 8.1554 - val_mse: 114.2831\n",
      "Epoch 50/500\n",
      "81/81 [==============================] - 0s 170us/sample - loss: 15.9258 - mae: 3.0924 - mse: 15.9258 - val_loss: 110.5084 - val_mae: 8.0508 - val_mse: 110.5084\n",
      "Epoch 51/500\n",
      "81/81 [==============================] - 0s 206us/sample - loss: 16.5241 - mae: 3.1073 - mse: 16.5241 - val_loss: 107.6186 - val_mae: 7.9172 - val_mse: 107.6186\n",
      "Epoch 52/500\n",
      "81/81 [==============================] - 0s 234us/sample - loss: 16.9812 - mae: 3.2667 - mse: 16.9812 - val_loss: 123.8364 - val_mae: 8.6605 - val_mse: 123.8364\n",
      "Epoch 53/500\n",
      "81/81 [==============================] - 0s 208us/sample - loss: 17.5297 - mae: 3.3205 - mse: 17.5297 - val_loss: 106.7048 - val_mae: 7.9150 - val_mse: 106.7048\n",
      "Epoch 54/500\n",
      "81/81 [==============================] - 0s 178us/sample - loss: 15.3616 - mae: 3.0811 - mse: 15.3616 - val_loss: 110.5251 - val_mae: 8.0215 - val_mse: 110.5251\n",
      "Epoch 55/500\n",
      "81/81 [==============================] - 0s 221us/sample - loss: 16.1419 - mae: 3.1812 - mse: 16.1419 - val_loss: 111.3061 - val_mae: 7.9783 - val_mse: 111.3061\n",
      "Epoch 56/500\n",
      "81/81 [==============================] - 0s 206us/sample - loss: 15.3199 - mae: 3.0388 - mse: 15.3199 - val_loss: 105.1160 - val_mae: 7.8660 - val_mse: 105.1160\n",
      "Epoch 57/500\n",
      "81/81 [==============================] - 0s 208us/sample - loss: 15.5400 - mae: 3.0983 - mse: 15.5400 - val_loss: 117.2627 - val_mae: 8.4271 - val_mse: 117.2627\n",
      "Epoch 58/500\n",
      "81/81 [==============================] - 0s 213us/sample - loss: 21.3401 - mae: 3.7390 - mse: 21.3401 - val_loss: 111.3235 - val_mae: 7.9736 - val_mse: 111.3235\n",
      "Epoch 59/500\n",
      "81/81 [==============================] - 0s 200us/sample - loss: 14.6247 - mae: 3.0259 - mse: 14.6247 - val_loss: 105.1460 - val_mae: 7.8289 - val_mse: 105.1460\n",
      "Epoch 60/500\n",
      "81/81 [==============================] - 0s 176us/sample - loss: 13.2965 - mae: 2.8364 - mse: 13.2965 - val_loss: 109.6864 - val_mae: 7.9435 - val_mse: 109.6864\n",
      "Epoch 61/500\n",
      "81/81 [==============================] - 0s 208us/sample - loss: 13.0709 - mae: 2.7893 - mse: 13.0709 - val_loss: 102.5784 - val_mae: 7.7840 - val_mse: 102.5784\n",
      "Epoch 62/500\n",
      "81/81 [==============================] - 0s 277us/sample - loss: 21.3382 - mae: 3.5865 - mse: 21.3382 - val_loss: 110.0806 - val_mae: 8.2124 - val_mse: 110.0806\n",
      "Epoch 63/500\n",
      "81/81 [==============================] - 0s 220us/sample - loss: 14.5518 - mae: 2.9954 - mse: 14.5518 - val_loss: 106.5493 - val_mae: 7.8625 - val_mse: 106.5493\n",
      "Epoch 64/500\n",
      "81/81 [==============================] - 0s 199us/sample - loss: 14.2141 - mae: 3.0167 - mse: 14.2141 - val_loss: 108.0217 - val_mae: 7.9955 - val_mse: 108.0217\n",
      "Epoch 65/500\n",
      "81/81 [==============================] - 0s 190us/sample - loss: 15.3841 - mae: 3.0600 - mse: 15.3841 - val_loss: 102.7443 - val_mae: 7.7419 - val_mse: 102.7443\n",
      "Epoch 66/500\n",
      "81/81 [==============================] - 0s 192us/sample - loss: 12.9512 - mae: 2.7921 - mse: 12.9512 - val_loss: 109.3614 - val_mae: 7.9305 - val_mse: 109.3614\n",
      "Epoch 67/500\n",
      "81/81 [==============================] - 0s 193us/sample - loss: 13.1554 - mae: 2.9147 - mse: 13.1554 - val_loss: 102.4510 - val_mae: 7.9341 - val_mse: 102.4510\n",
      "Epoch 68/500\n",
      "81/81 [==============================] - 0s 185us/sample - loss: 12.7758 - mae: 2.8194 - mse: 12.7758 - val_loss: 124.3098 - val_mae: 8.6453 - val_mse: 124.3098\n",
      "Epoch 69/500\n",
      "81/81 [==============================] - 0s 195us/sample - loss: 19.0023 - mae: 3.5378 - mse: 19.0023 - val_loss: 100.7328 - val_mae: 7.6573 - val_mse: 100.7328\n",
      "Epoch 70/500\n",
      "81/81 [==============================] - 0s 211us/sample - loss: 13.5360 - mae: 2.8786 - mse: 13.5360 - val_loss: 103.5891 - val_mae: 7.7591 - val_mse: 103.5891\n",
      "Epoch 71/500\n",
      "81/81 [==============================] - 0s 206us/sample - loss: 12.3425 - mae: 2.7679 - mse: 12.3425 - val_loss: 108.6176 - val_mae: 8.0724 - val_mse: 108.6176\n",
      "Epoch 72/500\n",
      "81/81 [==============================] - 0s 206us/sample - loss: 12.5927 - mae: 2.7565 - mse: 12.5927 - val_loss: 105.2874 - val_mae: 7.7566 - val_mse: 105.2874\n",
      "Epoch 73/500\n",
      "81/81 [==============================] - 0s 218us/sample - loss: 10.8435 - mae: 2.5976 - mse: 10.8435 - val_loss: 109.7292 - val_mae: 7.9899 - val_mse: 109.7292\n",
      "Epoch 74/500\n",
      "81/81 [==============================] - 0s 187us/sample - loss: 13.1989 - mae: 2.7923 - mse: 13.1989 - val_loss: 98.9555 - val_mae: 7.6286 - val_mse: 98.9555\n",
      "Epoch 75/500\n",
      "81/81 [==============================] - 0s 215us/sample - loss: 21.4611 - mae: 3.6749 - mse: 21.4611 - val_loss: 107.7435 - val_mae: 7.8382 - val_mse: 107.7435\n",
      "Epoch 76/500\n",
      "81/81 [==============================] - 0s 230us/sample - loss: 11.1876 - mae: 2.5639 - mse: 11.1876 - val_loss: 100.1038 - val_mae: 7.6216 - val_mse: 100.1038\n",
      "Epoch 77/500\n",
      "81/81 [==============================] - 0s 234us/sample - loss: 11.0928 - mae: 2.5839 - mse: 11.0928 - val_loss: 103.3105 - val_mae: 7.7112 - val_mse: 103.3105\n",
      "Epoch 78/500\n",
      "81/81 [==============================] - 0s 217us/sample - loss: 11.2296 - mae: 2.5945 - mse: 11.2296 - val_loss: 105.2665 - val_mae: 8.1091 - val_mse: 105.2665\n",
      "Epoch 79/500\n",
      "81/81 [==============================] - 0s 254us/sample - loss: 14.3145 - mae: 3.0391 - mse: 14.3145 - val_loss: 104.8910 - val_mae: 7.7312 - val_mse: 104.8910\n",
      "Epoch 80/500\n",
      "81/81 [==============================] - 0s 231us/sample - loss: 11.0603 - mae: 2.6233 - mse: 11.0603 - val_loss: 101.1884 - val_mae: 7.5951 - val_mse: 101.1884\n",
      "Epoch 81/500\n",
      "81/81 [==============================] - 0s 232us/sample - loss: 9.7985 - mae: 2.4723 - mse: 9.7985 - val_loss: 98.3617 - val_mae: 7.5447 - val_mse: 98.3617\n",
      "Epoch 82/500\n",
      "81/81 [==============================] - 0s 217us/sample - loss: 11.1583 - mae: 2.7129 - mse: 11.1583 - val_loss: 120.3016 - val_mae: 8.6378 - val_mse: 120.3016\n",
      "Epoch 83/500\n",
      "81/81 [==============================] - 0s 226us/sample - loss: 16.7773 - mae: 3.3063 - mse: 16.7773 - val_loss: 96.6933 - val_mae: 7.5103 - val_mse: 96.6933\n",
      "Epoch 84/500\n",
      "81/81 [==============================] - 0s 221us/sample - loss: 18.0496 - mae: 3.5191 - mse: 18.0496 - val_loss: 111.8675 - val_mae: 8.2452 - val_mse: 111.8675\n",
      "Epoch 85/500\n",
      "81/81 [==============================] - 0s 235us/sample - loss: 13.0726 - mae: 2.9057 - mse: 13.0726 - val_loss: 107.5814 - val_mae: 7.8349 - val_mse: 107.5814\n",
      "Epoch 86/500\n",
      "81/81 [==============================] - 0s 212us/sample - loss: 12.0796 - mae: 2.7283 - mse: 12.0796 - val_loss: 94.3410 - val_mae: 7.4192 - val_mse: 94.3410\n",
      "Epoch 87/500\n",
      "81/81 [==============================] - 0s 226us/sample - loss: 9.7942 - mae: 2.5497 - mse: 9.7942 - val_loss: 100.3543 - val_mae: 7.8416 - val_mse: 100.3543\n",
      "Epoch 88/500\n",
      "81/81 [==============================] - 0s 206us/sample - loss: 10.0252 - mae: 2.5221 - mse: 10.0252 - val_loss: 100.6186 - val_mae: 7.5832 - val_mse: 100.6186\n",
      "Epoch 89/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 11.3233 - mae: 2.6497 - mse: 11.3233 - val_loss: 94.9952 - val_mae: 7.4395 - val_mse: 94.9952\n",
      "Epoch 90/500\n",
      "81/81 [==============================] - 0s 227us/sample - loss: 11.1019 - mae: 2.6593 - mse: 11.1019 - val_loss: 99.4623 - val_mae: 7.5669 - val_mse: 99.4623\n",
      "Epoch 91/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 206us/sample - loss: 9.4351 - mae: 2.3919 - mse: 9.4351 - val_loss: 103.5757 - val_mae: 7.7864 - val_mse: 103.5757\n",
      "Epoch 92/500\n",
      "81/81 [==============================] - 0s 222us/sample - loss: 13.4064 - mae: 2.9325 - mse: 13.4064 - val_loss: 99.6124 - val_mae: 7.4846 - val_mse: 99.6124\n",
      "Epoch 93/500\n",
      "81/81 [==============================] - 0s 206us/sample - loss: 15.0631 - mae: 3.0899 - mse: 15.0631 - val_loss: 99.6077 - val_mae: 7.5722 - val_mse: 99.6077\n",
      "Epoch 94/500\n",
      "81/81 [==============================] - 0s 177us/sample - loss: 8.4726 - mae: 2.2972 - mse: 8.4726 - val_loss: 96.7580 - val_mae: 7.4149 - val_mse: 96.7580\n",
      "Epoch 95/500\n",
      "81/81 [==============================] - 0s 222us/sample - loss: 9.8252 - mae: 2.4763 - mse: 9.8252 - val_loss: 103.5311 - val_mae: 7.8552 - val_mse: 103.5311\n",
      "Epoch 96/500\n",
      "81/81 [==============================] - 0s 223us/sample - loss: 11.8371 - mae: 2.8232 - mse: 11.8371 - val_loss: 93.3172 - val_mae: 7.3118 - val_mse: 93.3172\n",
      "Epoch 97/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 9.6222 - mae: 2.4568 - mse: 9.6222 - val_loss: 94.2719 - val_mae: 7.4734 - val_mse: 94.2719\n",
      "Epoch 98/500\n",
      "81/81 [==============================] - 0s 202us/sample - loss: 8.4314 - mae: 2.3359 - mse: 8.4314 - val_loss: 96.4379 - val_mae: 7.3194 - val_mse: 96.4379\n",
      "Epoch 99/500\n",
      "81/81 [==============================] - 0s 196us/sample - loss: 10.9039 - mae: 2.6554 - mse: 10.9039 - val_loss: 98.2634 - val_mae: 7.6321 - val_mse: 98.2634\n",
      "Epoch 100/500\n",
      "81/81 [==============================] - 0s 187us/sample - loss: 10.8255 - mae: 2.6088 - mse: 10.8255 - val_loss: 92.0186 - val_mae: 7.2116 - val_mse: 92.0186\n",
      "Epoch 101/500\n",
      "81/81 [==============================] - 0s 197us/sample - loss: 11.7474 - mae: 2.7159 - mse: 11.7474 - val_loss: 98.6478 - val_mae: 7.5783 - val_mse: 98.6478\n",
      "Epoch 102/500\n",
      "81/81 [==============================] - 0s 197us/sample - loss: 11.7322 - mae: 2.7617 - mse: 11.7322 - val_loss: 92.4628 - val_mae: 7.2188 - val_mse: 92.4628\n",
      "Epoch 103/500\n",
      "81/81 [==============================] - 0s 215us/sample - loss: 11.0364 - mae: 2.6132 - mse: 11.0364 - val_loss: 103.2308 - val_mae: 7.6533 - val_mse: 103.2308\n",
      "Epoch 104/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 9.6168 - mae: 2.5019 - mse: 9.6168 - val_loss: 90.2348 - val_mae: 7.1922 - val_mse: 90.2348\n",
      "Epoch 105/500\n",
      "81/81 [==============================] - 0s 193us/sample - loss: 8.0900 - mae: 2.2786 - mse: 8.0900 - val_loss: 93.4177 - val_mae: 7.5048 - val_mse: 93.4177\n",
      "Epoch 106/500\n",
      "81/81 [==============================] - 0s 200us/sample - loss: 8.0022 - mae: 2.2460 - mse: 8.0022 - val_loss: 97.1214 - val_mae: 7.5402 - val_mse: 97.1214\n",
      "Epoch 107/500\n",
      "81/81 [==============================] - 0s 183us/sample - loss: 9.6861 - mae: 2.4881 - mse: 9.6861 - val_loss: 91.4849 - val_mae: 7.2610 - val_mse: 91.4849\n",
      "Epoch 108/500\n",
      "81/81 [==============================] - 0s 182us/sample - loss: 14.3845 - mae: 3.0939 - mse: 14.3845 - val_loss: 108.9478 - val_mae: 8.1703 - val_mse: 108.9478\n",
      "Epoch 109/500\n",
      "81/81 [==============================] - 0s 207us/sample - loss: 12.1457 - mae: 2.7768 - mse: 12.1457 - val_loss: 90.6439 - val_mae: 7.2120 - val_mse: 90.6439\n",
      "Epoch 110/500\n",
      "81/81 [==============================] - 0s 217us/sample - loss: 7.7315 - mae: 2.1558 - mse: 7.7315 - val_loss: 89.0804 - val_mae: 7.1832 - val_mse: 89.0804\n",
      "Epoch 111/500\n",
      "81/81 [==============================] - 0s 197us/sample - loss: 8.8202 - mae: 2.3598 - mse: 8.8202 - val_loss: 90.9798 - val_mae: 7.1973 - val_mse: 90.9798\n",
      "Epoch 112/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 7.6256 - mae: 2.1994 - mse: 7.6256 - val_loss: 104.0064 - val_mae: 7.7910 - val_mse: 104.0064\n",
      "Epoch 113/500\n",
      "81/81 [==============================] - 0s 212us/sample - loss: 14.6520 - mae: 3.0110 - mse: 14.6520 - val_loss: 88.8892 - val_mae: 7.1026 - val_mse: 88.8892\n",
      "Epoch 114/500\n",
      "81/81 [==============================] - 0s 207us/sample - loss: 12.6220 - mae: 2.8811 - mse: 12.6220 - val_loss: 87.8951 - val_mae: 7.2426 - val_mse: 87.8951\n",
      "Epoch 115/500\n",
      "81/81 [==============================] - 0s 192us/sample - loss: 7.7217 - mae: 2.2101 - mse: 7.7217 - val_loss: 88.2349 - val_mae: 7.1490 - val_mse: 88.2349\n",
      "Epoch 116/500\n",
      "81/81 [==============================] - 0s 188us/sample - loss: 7.9900 - mae: 2.2875 - mse: 7.9900 - val_loss: 91.4937 - val_mae: 7.4161 - val_mse: 91.4937\n",
      "Epoch 117/500\n",
      "81/81 [==============================] - 0s 183us/sample - loss: 9.1588 - mae: 2.4177 - mse: 9.1588 - val_loss: 93.0834 - val_mae: 7.1860 - val_mse: 93.0834\n",
      "Epoch 118/500\n",
      "81/81 [==============================] - 0s 204us/sample - loss: 8.0072 - mae: 2.2650 - mse: 8.0072 - val_loss: 96.0174 - val_mae: 7.5125 - val_mse: 96.0174\n",
      "Epoch 119/500\n",
      "81/81 [==============================] - 0s 200us/sample - loss: 9.0293 - mae: 2.4070 - mse: 9.0293 - val_loss: 86.5764 - val_mae: 7.1064 - val_mse: 86.5764\n",
      "Epoch 120/500\n",
      "81/81 [==============================] - 0s 194us/sample - loss: 15.4109 - mae: 3.1723 - mse: 15.4109 - val_loss: 95.1704 - val_mae: 7.3630 - val_mse: 95.1704\n",
      "Epoch 121/500\n",
      "81/81 [==============================] - 0s 205us/sample - loss: 7.4212 - mae: 2.1883 - mse: 7.4212 - val_loss: 98.1016 - val_mae: 7.5180 - val_mse: 98.1016\n",
      "Epoch 122/500\n",
      "81/81 [==============================] - 0s 192us/sample - loss: 12.0847 - mae: 2.7707 - mse: 12.0847 - val_loss: 92.1258 - val_mae: 7.1406 - val_mse: 92.1258\n",
      "Epoch 123/500\n",
      "81/81 [==============================] - 0s 183us/sample - loss: 8.8647 - mae: 2.3156 - mse: 8.8647 - val_loss: 92.7278 - val_mae: 7.4225 - val_mse: 92.7278\n",
      "Epoch 124/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 7.3154 - mae: 2.1598 - mse: 7.3154 - val_loss: 94.8684 - val_mae: 7.2806 - val_mse: 94.8684\n",
      "Epoch 125/500\n",
      "81/81 [==============================] - 0s 197us/sample - loss: 8.4189 - mae: 2.3427 - mse: 8.4189 - val_loss: 85.9566 - val_mae: 7.1304 - val_mse: 85.9566\n",
      "Epoch 126/500\n",
      "81/81 [==============================] - 0s 204us/sample - loss: 7.4601 - mae: 2.1663 - mse: 7.4601 - val_loss: 94.5076 - val_mae: 7.4040 - val_mse: 94.5076\n",
      "Epoch 127/500\n",
      "81/81 [==============================] - 0s 200us/sample - loss: 10.5041 - mae: 2.5848 - mse: 10.5041 - val_loss: 87.3045 - val_mae: 7.0252 - val_mse: 87.3045\n",
      "Epoch 128/500\n",
      "81/81 [==============================] - 0s 203us/sample - loss: 9.6922 - mae: 2.4849 - mse: 9.6922 - val_loss: 90.6711 - val_mae: 7.0907 - val_mse: 90.6711\n",
      "Epoch 129/500\n",
      "81/81 [==============================] - 0s 171us/sample - loss: 6.9910 - mae: 2.1187 - mse: 6.9910 - val_loss: 86.3867 - val_mae: 7.0071 - val_mse: 86.3867\n",
      "Epoch 130/500\n",
      "81/81 [==============================] - 0s 194us/sample - loss: 7.5678 - mae: 2.2029 - mse: 7.5678 - val_loss: 84.7638 - val_mae: 6.8763 - val_mse: 84.7638\n",
      "Epoch 131/500\n",
      "81/81 [==============================] - 0s 200us/sample - loss: 13.7368 - mae: 3.0309 - mse: 13.7368 - val_loss: 101.1733 - val_mae: 7.8214 - val_mse: 101.1733\n",
      "Epoch 132/500\n",
      "81/81 [==============================] - 0s 188us/sample - loss: 9.1606 - mae: 2.4111 - mse: 9.1606 - val_loss: 83.5874 - val_mae: 6.8849 - val_mse: 83.5874\n",
      "Epoch 133/500\n",
      "81/81 [==============================] - 0s 175us/sample - loss: 7.8811 - mae: 2.2958 - mse: 7.8811 - val_loss: 94.6003 - val_mae: 7.3309 - val_mse: 94.6003\n",
      "Epoch 134/500\n",
      "81/81 [==============================] - 0s 191us/sample - loss: 7.5498 - mae: 2.1792 - mse: 7.5498 - val_loss: 84.4736 - val_mae: 7.0531 - val_mse: 84.4736\n",
      "Epoch 135/500\n",
      "81/81 [==============================] - 0s 192us/sample - loss: 6.6625 - mae: 2.0674 - mse: 6.6625 - val_loss: 83.4743 - val_mae: 6.9309 - val_mse: 83.4743\n",
      "Epoch 136/500\n",
      "81/81 [==============================] - 0s 205us/sample - loss: 10.4279 - mae: 2.5939 - mse: 10.4279 - val_loss: 93.3854 - val_mae: 7.4959 - val_mse: 93.3854\n",
      "Epoch 137/500\n",
      "81/81 [==============================] - 0s 188us/sample - loss: 10.1801 - mae: 2.5905 - mse: 10.1801 - val_loss: 86.1346 - val_mae: 6.9481 - val_mse: 86.1346\n",
      "Epoch 138/500\n",
      "81/81 [==============================] - 0s 172us/sample - loss: 6.9490 - mae: 2.1360 - mse: 6.9490 - val_loss: 93.0460 - val_mae: 7.4428 - val_mse: 93.0460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/500\n",
      "81/81 [==============================] - 0s 186us/sample - loss: 8.2902 - mae: 2.2485 - mse: 8.2902 - val_loss: 91.2502 - val_mae: 7.0847 - val_mse: 91.2502\n",
      "Epoch 140/500\n",
      "81/81 [==============================] - 0s 212us/sample - loss: 9.0858 - mae: 2.3789 - mse: 9.0858 - val_loss: 84.8410 - val_mae: 6.9423 - val_mse: 84.8410\n",
      "Epoch 141/500\n",
      "81/81 [==============================] - 0s 193us/sample - loss: 7.7776 - mae: 2.2716 - mse: 7.7776 - val_loss: 97.4074 - val_mae: 7.5963 - val_mse: 97.4074\n",
      "Epoch 142/500\n",
      "81/81 [==============================] - 0s 191us/sample - loss: 10.0905 - mae: 2.5077 - mse: 10.0905 - val_loss: 90.4538 - val_mae: 7.0316 - val_mse: 90.4538\n",
      "Epoch 143/500\n",
      "81/81 [==============================] - 0s 185us/sample - loss: 8.4068 - mae: 2.2963 - mse: 8.4068 - val_loss: 98.4557 - val_mae: 7.6334 - val_mse: 98.4557\n",
      "Epoch 144/500\n",
      "81/81 [==============================] - 0s 179us/sample - loss: 9.6805 - mae: 2.5001 - mse: 9.6805 - val_loss: 82.9365 - val_mae: 6.8802 - val_mse: 82.9365\n",
      "Epoch 145/500\n",
      "81/81 [==============================] - 0s 190us/sample - loss: 6.7808 - mae: 2.0429 - mse: 6.7808 - val_loss: 83.6982 - val_mae: 6.8653 - val_mse: 83.6982\n",
      "Epoch 146/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 7.4388 - mae: 2.1412 - mse: 7.4388 - val_loss: 96.9633 - val_mae: 7.4731 - val_mse: 96.9633\n",
      "Epoch 147/500\n",
      "81/81 [==============================] - 0s 187us/sample - loss: 10.5352 - mae: 2.5809 - mse: 10.5352 - val_loss: 86.0684 - val_mae: 6.9159 - val_mse: 86.0684\n",
      "Epoch 148/500\n",
      "81/81 [==============================] - 0s 196us/sample - loss: 11.8694 - mae: 2.7747 - mse: 11.8694 - val_loss: 93.8415 - val_mae: 7.3351 - val_mse: 93.8415\n",
      "Epoch 149/500\n",
      "81/81 [==============================] - 0s 179us/sample - loss: 8.9452 - mae: 2.3386 - mse: 8.9452 - val_loss: 81.7759 - val_mae: 6.8408 - val_mse: 81.7759\n",
      "Epoch 150/500\n",
      "81/81 [==============================] - 0s 190us/sample - loss: 7.2591 - mae: 2.1519 - mse: 7.2591 - val_loss: 89.7487 - val_mae: 7.2179 - val_mse: 89.7487\n",
      "Epoch 151/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 7.2008 - mae: 2.1812 - mse: 7.2008 - val_loss: 81.2348 - val_mae: 6.8359 - val_mse: 81.2348\n",
      "Epoch 152/500\n",
      "81/81 [==============================] - 0s 197us/sample - loss: 8.9315 - mae: 2.5070 - mse: 8.9315 - val_loss: 82.9546 - val_mae: 6.7102 - val_mse: 82.9546\n",
      "Epoch 153/500\n",
      "81/81 [==============================] - 0s 213us/sample - loss: 8.1952 - mae: 2.2749 - mse: 8.1952 - val_loss: 85.9585 - val_mae: 6.9754 - val_mse: 85.9585\n",
      "Epoch 154/500\n",
      "81/81 [==============================] - 0s 181us/sample - loss: 6.8431 - mae: 2.0943 - mse: 6.8431 - val_loss: 83.6132 - val_mae: 6.7516 - val_mse: 83.6132\n",
      "Epoch 155/500\n",
      "81/81 [==============================] - 0s 184us/sample - loss: 11.9691 - mae: 2.8259 - mse: 11.9691 - val_loss: 92.1711 - val_mae: 7.3309 - val_mse: 92.1711\n",
      "Epoch 156/500\n",
      "81/81 [==============================] - 0s 195us/sample - loss: 9.2748 - mae: 2.4229 - mse: 9.2748 - val_loss: 82.6438 - val_mae: 6.7215 - val_mse: 82.6438\n",
      "Epoch 157/500\n",
      "81/81 [==============================] - 0s 203us/sample - loss: 5.5864 - mae: 1.9042 - mse: 5.5864 - val_loss: 86.6455 - val_mae: 6.9617 - val_mse: 86.6455\n",
      "Epoch 158/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 6.1281 - mae: 1.9869 - mse: 6.1281 - val_loss: 84.6306 - val_mae: 6.8965 - val_mse: 84.6306\n",
      "Epoch 159/500\n",
      "81/81 [==============================] - 0s 206us/sample - loss: 6.5189 - mae: 2.0058 - mse: 6.5189 - val_loss: 82.6287 - val_mae: 6.7091 - val_mse: 82.6287\n",
      "Epoch 160/500\n",
      "81/81 [==============================] - 0s 197us/sample - loss: 8.9190 - mae: 2.3940 - mse: 8.9190 - val_loss: 96.2213 - val_mae: 7.5606 - val_mse: 96.2213\n",
      "Epoch 161/500\n",
      "81/81 [==============================] - 0s 177us/sample - loss: 10.9498 - mae: 2.6765 - mse: 10.9498 - val_loss: 79.1862 - val_mae: 6.6999 - val_mse: 79.1862\n",
      "Epoch 162/500\n",
      "81/81 [==============================] - 0s 196us/sample - loss: 5.8624 - mae: 1.9484 - mse: 5.8624 - val_loss: 82.4241 - val_mae: 6.7101 - val_mse: 82.4241\n",
      "Epoch 163/500\n",
      "81/81 [==============================] - 0s 203us/sample - loss: 5.5218 - mae: 1.8649 - mse: 5.5218 - val_loss: 84.3812 - val_mae: 6.9376 - val_mse: 84.3812\n",
      "Epoch 164/500\n",
      "81/81 [==============================] - 0s 205us/sample - loss: 6.3661 - mae: 2.0469 - mse: 6.3661 - val_loss: 76.7505 - val_mae: 6.6396 - val_mse: 76.7505\n",
      "Epoch 165/500\n",
      "81/81 [==============================] - 0s 205us/sample - loss: 11.0141 - mae: 2.6856 - mse: 11.0141 - val_loss: 81.6329 - val_mae: 6.8178 - val_mse: 81.6329\n",
      "Epoch 166/500\n",
      "81/81 [==============================] - 0s 196us/sample - loss: 6.0677 - mae: 1.9310 - mse: 6.0677 - val_loss: 81.6404 - val_mae: 6.7060 - val_mse: 81.6404\n",
      "Epoch 167/500\n",
      "81/81 [==============================] - 0s 201us/sample - loss: 7.4154 - mae: 2.2227 - mse: 7.4154 - val_loss: 83.4622 - val_mae: 6.8674 - val_mse: 83.4622\n",
      "Epoch 168/500\n",
      "81/81 [==============================] - 0s 170us/sample - loss: 5.4898 - mae: 1.8893 - mse: 5.4898 - val_loss: 78.4247 - val_mae: 6.6964 - val_mse: 78.4247\n",
      "Epoch 169/500\n",
      "81/81 [==============================] - 0s 209us/sample - loss: 5.8342 - mae: 1.9650 - mse: 5.8342 - val_loss: 90.1436 - val_mae: 7.1602 - val_mse: 90.1436\n",
      "Epoch 170/500\n",
      "81/81 [==============================] - 0s 212us/sample - loss: 13.3366 - mae: 2.9004 - mse: 13.3366 - val_loss: 80.0304 - val_mae: 6.6797 - val_mse: 80.0304\n",
      "Epoch 171/500\n",
      "81/81 [==============================] - 0s 205us/sample - loss: 9.7813 - mae: 2.4151 - mse: 9.7813 - val_loss: 84.8792 - val_mae: 6.7525 - val_mse: 84.8792\n",
      "Epoch 172/500\n",
      "81/81 [==============================] - 0s 213us/sample - loss: 5.9844 - mae: 1.9967 - mse: 5.9844 - val_loss: 78.0034 - val_mae: 6.6057 - val_mse: 78.0034\n",
      "Epoch 173/500\n",
      "81/81 [==============================] - 0s 175us/sample - loss: 6.2548 - mae: 2.0648 - mse: 6.2548 - val_loss: 87.2571 - val_mae: 6.7966 - val_mse: 87.2571\n",
      "Epoch 174/500\n",
      "81/81 [==============================] - 0s 178us/sample - loss: 5.5659 - mae: 1.9414 - mse: 5.5659 - val_loss: 87.5285 - val_mae: 6.8643 - val_mse: 87.5285\n",
      "Epoch 175/500\n",
      "81/81 [==============================] - 0s 208us/sample - loss: 7.7285 - mae: 2.2398 - mse: 7.7285 - val_loss: 80.5063 - val_mae: 6.6282 - val_mse: 80.5063\n",
      "Epoch 176/500\n",
      "81/81 [==============================] - 0s 202us/sample - loss: 9.7419 - mae: 2.5869 - mse: 9.7419 - val_loss: 81.0294 - val_mae: 6.5988 - val_mse: 81.0294\n",
      "Epoch 177/500\n",
      "81/81 [==============================] - 0s 204us/sample - loss: 5.5266 - mae: 1.8819 - mse: 5.5266 - val_loss: 76.2181 - val_mae: 6.5092 - val_mse: 76.2181\n",
      "Epoch 178/500\n",
      "81/81 [==============================] - 0s 212us/sample - loss: 6.3504 - mae: 2.0551 - mse: 6.3504 - val_loss: 82.8932 - val_mae: 6.6523 - val_mse: 82.8932\n",
      "Epoch 179/500\n",
      "81/81 [==============================] - 0s 181us/sample - loss: 5.2438 - mae: 1.8188 - mse: 5.2438 - val_loss: 89.8478 - val_mae: 7.1187 - val_mse: 89.8478\n",
      "Epoch 180/500\n",
      "81/81 [==============================] - 0s 191us/sample - loss: 9.7348 - mae: 2.5161 - mse: 9.7348 - val_loss: 75.1008 - val_mae: 6.4832 - val_mse: 75.1008\n",
      "Epoch 181/500\n",
      "81/81 [==============================] - 0s 201us/sample - loss: 8.0436 - mae: 2.2769 - mse: 8.0436 - val_loss: 80.8498 - val_mae: 6.7608 - val_mse: 80.8498\n",
      "Epoch 182/500\n",
      "81/81 [==============================] - 0s 197us/sample - loss: 7.0013 - mae: 2.0017 - mse: 7.0013 - val_loss: 75.7894 - val_mae: 6.5204 - val_mse: 75.7894\n",
      "Epoch 183/500\n",
      "81/81 [==============================] - 0s 208us/sample - loss: 11.2966 - mae: 2.7230 - mse: 11.2966 - val_loss: 85.5012 - val_mae: 6.8463 - val_mse: 85.5012\n",
      "Epoch 184/500\n",
      "81/81 [==============================] - 0s 180us/sample - loss: 6.7181 - mae: 2.1181 - mse: 6.7181 - val_loss: 74.9257 - val_mae: 6.3902 - val_mse: 74.9257\n",
      "Epoch 185/500\n",
      "81/81 [==============================] - 0s 189us/sample - loss: 6.7772 - mae: 2.0940 - mse: 6.7772 - val_loss: 86.8682 - val_mae: 6.8266 - val_mse: 86.8682\n",
      "Epoch 186/500\n",
      "81/81 [==============================] - 0s 206us/sample - loss: 8.1763 - mae: 2.2368 - mse: 8.1763 - val_loss: 76.7605 - val_mae: 6.4255 - val_mse: 76.7605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/500\n",
      "81/81 [==============================] - 0s 197us/sample - loss: 8.0445 - mae: 2.2721 - mse: 8.0445 - val_loss: 85.1038 - val_mae: 6.8678 - val_mse: 85.1038\n",
      "Epoch 188/500\n",
      "81/81 [==============================] - 0s 187us/sample - loss: 6.8315 - mae: 2.0784 - mse: 6.8315 - val_loss: 74.4240 - val_mae: 6.2538 - val_mse: 74.4240\n",
      "Epoch 189/500\n",
      "81/81 [==============================] - 0s 181us/sample - loss: 7.8959 - mae: 2.2929 - mse: 7.8959 - val_loss: 78.9544 - val_mae: 6.5229 - val_mse: 78.9544\n",
      "Epoch 190/500\n",
      "81/81 [==============================] - 0s 172us/sample - loss: 5.4942 - mae: 1.8549 - mse: 5.4942 - val_loss: 73.4364 - val_mae: 6.2674 - val_mse: 73.4364\n",
      "Epoch 191/500\n",
      "81/81 [==============================] - 0s 185us/sample - loss: 5.1185 - mae: 1.8573 - mse: 5.1185 - val_loss: 72.8094 - val_mae: 6.2845 - val_mse: 72.8094\n",
      "Epoch 192/500\n",
      "81/81 [==============================] - 0s 191us/sample - loss: 6.6299 - mae: 2.0522 - mse: 6.6299 - val_loss: 95.3320 - val_mae: 7.4394 - val_mse: 95.3320\n",
      "Epoch 193/500\n",
      "81/81 [==============================] - 0s 184us/sample - loss: 10.0230 - mae: 2.4969 - mse: 10.0230 - val_loss: 72.9779 - val_mae: 6.3704 - val_mse: 72.9779\n",
      "Epoch 194/500\n",
      "81/81 [==============================] - 0s 174us/sample - loss: 6.3641 - mae: 2.0272 - mse: 6.3641 - val_loss: 78.0242 - val_mae: 6.3481 - val_mse: 78.0242\n",
      "Epoch 195/500\n",
      "81/81 [==============================] - 0s 172us/sample - loss: 8.5851 - mae: 2.4179 - mse: 8.5851 - val_loss: 78.1420 - val_mae: 6.4802 - val_mse: 78.1420\n",
      "Epoch 196/500\n",
      "81/81 [==============================] - 0s 204us/sample - loss: 5.0904 - mae: 1.7826 - mse: 5.0904 - val_loss: 75.4370 - val_mae: 6.3163 - val_mse: 75.4370\n",
      "Epoch 197/500\n",
      "81/81 [==============================] - 0s 188us/sample - loss: 5.2499 - mae: 1.8145 - mse: 5.2499 - val_loss: 74.0968 - val_mae: 6.2881 - val_mse: 74.0968\n",
      "Epoch 198/500\n",
      "81/81 [==============================] - 0s 192us/sample - loss: 11.9538 - mae: 2.8500 - mse: 11.9538 - val_loss: 93.2931 - val_mae: 7.3095 - val_mse: 93.2931\n",
      "Epoch 199/500\n",
      "81/81 [==============================] - 0s 199us/sample - loss: 10.1160 - mae: 2.4561 - mse: 10.1160 - val_loss: 74.9657 - val_mae: 6.2535 - val_mse: 74.9657\n",
      "Epoch 200/500\n",
      "81/81 [==============================] - 0s 172us/sample - loss: 4.7482 - mae: 1.7541 - mse: 4.7482 - val_loss: 81.5270 - val_mae: 6.5977 - val_mse: 81.5270\n",
      "Epoch 201/500\n",
      "81/81 [==============================] - 0s 196us/sample - loss: 6.6286 - mae: 2.0133 - mse: 6.6286 - val_loss: 72.1531 - val_mae: 6.2737 - val_mse: 72.1531\n",
      "Epoch 202/500\n",
      "81/81 [==============================] - 0s 189us/sample - loss: 9.2475 - mae: 2.4512 - mse: 9.2475 - val_loss: 81.7625 - val_mae: 6.6861 - val_mse: 81.7625\n",
      "Epoch 203/500\n",
      "81/81 [==============================] - 0s 193us/sample - loss: 5.6207 - mae: 1.8284 - mse: 5.6207 - val_loss: 80.5239 - val_mae: 6.3699 - val_mse: 80.5239\n",
      "Epoch 204/500\n",
      "81/81 [==============================] - 0s 193us/sample - loss: 4.8103 - mae: 1.7195 - mse: 4.8103 - val_loss: 73.9869 - val_mae: 6.2128 - val_mse: 73.9869\n",
      "Epoch 205/500\n",
      "81/81 [==============================] - 0s 185us/sample - loss: 5.2454 - mae: 1.7973 - mse: 5.2454 - val_loss: 80.8216 - val_mae: 6.5765 - val_mse: 80.8216\n",
      "Epoch 206/500\n",
      "81/81 [==============================] - 0s 183us/sample - loss: 5.2497 - mae: 1.7547 - mse: 5.2497 - val_loss: 75.3825 - val_mae: 6.2749 - val_mse: 75.3825\n",
      "Epoch 207/500\n",
      "81/81 [==============================] - 0s 182us/sample - loss: 9.6545 - mae: 2.4086 - mse: 9.6545 - val_loss: 92.9659 - val_mae: 7.1900 - val_mse: 92.9659\n",
      "Epoch 208/500\n",
      "81/81 [==============================] - 0s 200us/sample - loss: 7.6233 - mae: 2.1828 - mse: 7.6233 - val_loss: 77.0254 - val_mae: 6.3061 - val_mse: 77.0254\n",
      "Epoch 209/500\n",
      "81/81 [==============================] - 0s 186us/sample - loss: 8.8825 - mae: 2.3605 - mse: 8.8825 - val_loss: 87.1082 - val_mae: 6.9664 - val_mse: 87.1082\n",
      "Epoch 210/500\n",
      "81/81 [==============================] - 0s 172us/sample - loss: 8.2851 - mae: 2.3351 - mse: 8.2851 - val_loss: 73.1321 - val_mae: 6.2743 - val_mse: 73.1321\n",
      "Epoch 211/500\n",
      "81/81 [==============================] - 0s 182us/sample - loss: 6.7052 - mae: 2.0656 - mse: 6.7052 - val_loss: 74.3209 - val_mae: 6.1893 - val_mse: 74.3209\n",
      "Epoch 212/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 4.3812 - mae: 1.6699 - mse: 4.3812 - val_loss: 78.4635 - val_mae: 6.3112 - val_mse: 78.4635\n",
      "Epoch 213/500\n",
      "81/81 [==============================] - 0s 196us/sample - loss: 5.6007 - mae: 1.8380 - mse: 5.6007 - val_loss: 73.7245 - val_mae: 6.3487 - val_mse: 73.7245\n",
      "Epoch 214/500\n",
      "81/81 [==============================] - 0s 186us/sample - loss: 13.1185 - mae: 2.9956 - mse: 13.1185 - val_loss: 79.9960 - val_mae: 6.5273 - val_mse: 79.9960\n",
      "Epoch 215/500\n",
      "81/81 [==============================] - 0s 196us/sample - loss: 5.2539 - mae: 1.8296 - mse: 5.2539 - val_loss: 72.7525 - val_mae: 6.0208 - val_mse: 72.7525\n",
      "Epoch 216/500\n",
      "81/81 [==============================] - 0s 171us/sample - loss: 4.6327 - mae: 1.7641 - mse: 4.6327 - val_loss: 71.3344 - val_mae: 6.1178 - val_mse: 71.3344\n",
      "Epoch 217/500\n",
      "81/81 [==============================] - 0s 189us/sample - loss: 7.6839 - mae: 2.2149 - mse: 7.6839 - val_loss: 85.8400 - val_mae: 6.8052 - val_mse: 85.8400\n",
      "Epoch 218/500\n",
      "81/81 [==============================] - 0s 191us/sample - loss: 9.4895 - mae: 2.5018 - mse: 9.4895 - val_loss: 70.3037 - val_mae: 6.0244 - val_mse: 70.3037\n",
      "Epoch 219/500\n",
      "81/81 [==============================] - 0s 191us/sample - loss: 6.0452 - mae: 1.9872 - mse: 6.0452 - val_loss: 77.6776 - val_mae: 6.1671 - val_mse: 77.6776\n",
      "Epoch 220/500\n",
      "81/81 [==============================] - 0s 168us/sample - loss: 4.7501 - mae: 1.6876 - mse: 4.7501 - val_loss: 74.9919 - val_mae: 6.1419 - val_mse: 74.9919\n",
      "Epoch 221/500\n",
      "81/81 [==============================] - 0s 179us/sample - loss: 4.6496 - mae: 1.7057 - mse: 4.6496 - val_loss: 70.4458 - val_mae: 6.0905 - val_mse: 70.4458\n",
      "Epoch 222/500\n",
      "81/81 [==============================] - 0s 193us/sample - loss: 5.2007 - mae: 1.8130 - mse: 5.2007 - val_loss: 83.8044 - val_mae: 6.6662 - val_mse: 83.8044\n",
      "Epoch 223/500\n",
      "81/81 [==============================] - 0s 193us/sample - loss: 10.7976 - mae: 2.6410 - mse: 10.7976 - val_loss: 73.2736 - val_mae: 6.1301 - val_mse: 73.2736\n",
      "Epoch 224/500\n",
      "81/81 [==============================] - 0s 197us/sample - loss: 7.1300 - mae: 2.1881 - mse: 7.1300 - val_loss: 81.2030 - val_mae: 6.5512 - val_mse: 81.2030\n",
      "Epoch 225/500\n",
      "81/81 [==============================] - 0s 185us/sample - loss: 6.3202 - mae: 2.0414 - mse: 6.3202 - val_loss: 69.8993 - val_mae: 6.0582 - val_mse: 69.8993\n",
      "Epoch 226/500\n",
      "81/81 [==============================] - 0s 192us/sample - loss: 5.2401 - mae: 1.8420 - mse: 5.2401 - val_loss: 76.3768 - val_mae: 6.1185 - val_mse: 76.3768\n",
      "Epoch 227/500\n",
      "81/81 [==============================] - 0s 196us/sample - loss: 6.3182 - mae: 1.9406 - mse: 6.3182 - val_loss: 75.1334 - val_mae: 6.1990 - val_mse: 75.1334\n",
      "Epoch 228/500\n",
      "81/81 [==============================] - 0s 191us/sample - loss: 4.8245 - mae: 1.7258 - mse: 4.8245 - val_loss: 70.6573 - val_mae: 5.9867 - val_mse: 70.6573\n",
      "Epoch 229/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 6.7487 - mae: 2.1189 - mse: 6.7487 - val_loss: 86.2407 - val_mae: 6.8199 - val_mse: 86.2407\n",
      "Epoch 230/500\n",
      "81/81 [==============================] - 0s 182us/sample - loss: 6.8366 - mae: 2.0848 - mse: 6.8366 - val_loss: 76.7709 - val_mae: 6.1129 - val_mse: 76.7709\n",
      "Epoch 231/500\n",
      "81/81 [==============================] - 0s 195us/sample - loss: 4.8550 - mae: 1.6642 - mse: 4.8550 - val_loss: 69.5695 - val_mae: 5.9200 - val_mse: 69.5695\n",
      "Epoch 232/500\n",
      "81/81 [==============================] - 0s 193us/sample - loss: 7.1653 - mae: 2.1014 - mse: 7.1653 - val_loss: 91.1397 - val_mae: 7.1333 - val_mse: 91.1397\n",
      "Epoch 233/500\n",
      "81/81 [==============================] - 0s 209us/sample - loss: 10.4187 - mae: 2.5595 - mse: 10.4187 - val_loss: 76.4784 - val_mae: 6.1069 - val_mse: 76.4784\n",
      "Epoch 234/500\n",
      "81/81 [==============================] - 0s 186us/sample - loss: 5.4400 - mae: 1.7954 - mse: 5.4400 - val_loss: 73.2976 - val_mae: 6.0399 - val_mse: 73.2976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/500\n",
      "81/81 [==============================] - 0s 170us/sample - loss: 4.2875 - mae: 1.6435 - mse: 4.2875 - val_loss: 74.8424 - val_mae: 6.0397 - val_mse: 74.8424\n",
      "Epoch 236/500\n",
      "81/81 [==============================] - 0s 183us/sample - loss: 6.2275 - mae: 1.9833 - mse: 6.2275 - val_loss: 80.7600 - val_mae: 6.5190 - val_mse: 80.7600\n",
      "Epoch 237/500\n",
      "81/81 [==============================] - 0s 196us/sample - loss: 10.7084 - mae: 2.6420 - mse: 10.7084 - val_loss: 70.7616 - val_mae: 6.0930 - val_mse: 70.7616\n",
      "Epoch 238/500\n",
      "81/81 [==============================] - 0s 202us/sample - loss: 10.5095 - mae: 2.6811 - mse: 10.5095 - val_loss: 75.6203 - val_mae: 6.2127 - val_mse: 75.6203\n",
      "Epoch 239/500\n",
      "81/81 [==============================] - 0s 199us/sample - loss: 4.4720 - mae: 1.6285 - mse: 4.4720 - val_loss: 72.3611 - val_mae: 5.9960 - val_mse: 72.3611\n",
      "Epoch 240/500\n",
      "81/81 [==============================] - 0s 186us/sample - loss: 4.3959 - mae: 1.6422 - mse: 4.3959 - val_loss: 77.4813 - val_mae: 6.3140 - val_mse: 77.4813\n",
      "Epoch 241/500\n",
      "81/81 [==============================] - 0s 174us/sample - loss: 4.9914 - mae: 1.7658 - mse: 4.9914 - val_loss: 71.1326 - val_mae: 5.8868 - val_mse: 71.1326\n",
      "Epoch 242/500\n",
      "81/81 [==============================] - 0s 183us/sample - loss: 4.8418 - mae: 1.7342 - mse: 4.8418 - val_loss: 76.7740 - val_mae: 6.1986 - val_mse: 76.7740\n",
      "Epoch 243/500\n",
      "81/81 [==============================] - 0s 192us/sample - loss: 4.9313 - mae: 1.7296 - mse: 4.9313 - val_loss: 69.6932 - val_mae: 5.9303 - val_mse: 69.6932\n",
      "Epoch 244/500\n",
      "81/81 [==============================] - 0s 188us/sample - loss: 10.0858 - mae: 2.5518 - mse: 10.0858 - val_loss: 96.1612 - val_mae: 7.4543 - val_mse: 96.1612\n",
      "Epoch 245/500\n",
      "81/81 [==============================] - 0s 190us/sample - loss: 10.1213 - mae: 2.5395 - mse: 10.1213 - val_loss: 71.2756 - val_mae: 5.9338 - val_mse: 71.2756\n",
      "Epoch 246/500\n",
      "81/81 [==============================] - 0s 183us/sample - loss: 4.2215 - mae: 1.6089 - mse: 4.2215 - val_loss: 69.8510 - val_mae: 5.9265 - val_mse: 69.8510\n",
      "Epoch 247/500\n",
      "81/81 [==============================] - 0s 172us/sample - loss: 7.2635 - mae: 2.2503 - mse: 7.2635 - val_loss: 74.6603 - val_mae: 6.2633 - val_mse: 74.6603\n",
      "Epoch 248/500\n",
      "81/81 [==============================] - 0s 189us/sample - loss: 4.5122 - mae: 1.6411 - mse: 4.5122 - val_loss: 74.3589 - val_mae: 6.0564 - val_mse: 74.3589\n",
      "Epoch 249/500\n",
      "81/81 [==============================] - 0s 187us/sample - loss: 4.5905 - mae: 1.6732 - mse: 4.5905 - val_loss: 67.9286 - val_mae: 5.9057 - val_mse: 67.9286\n",
      "Epoch 250/500\n",
      "81/81 [==============================] - 0s 185us/sample - loss: 7.7932 - mae: 2.2846 - mse: 7.7932 - val_loss: 89.2388 - val_mae: 7.0404 - val_mse: 89.2388\n",
      "Epoch 251/500\n",
      "81/81 [==============================] - 0s 181us/sample - loss: 9.1270 - mae: 2.4471 - mse: 9.1270 - val_loss: 68.1296 - val_mae: 5.8925 - val_mse: 68.1296\n",
      "Epoch 252/500\n",
      "81/81 [==============================] - 0s 178us/sample - loss: 4.8874 - mae: 1.7890 - mse: 4.8874 - val_loss: 70.0161 - val_mae: 5.8098 - val_mse: 70.0161\n",
      "Epoch 253/500\n",
      "81/81 [==============================] - 0s 185us/sample - loss: 5.6745 - mae: 1.9274 - mse: 5.6745 - val_loss: 78.7981 - val_mae: 6.4057 - val_mse: 78.7981\n",
      "Epoch 254/500\n",
      "81/81 [==============================] - 0s 190us/sample - loss: 6.7119 - mae: 1.9928 - mse: 6.7119 - val_loss: 67.4171 - val_mae: 5.8515 - val_mse: 67.4171\n",
      "Epoch 255/500\n",
      "81/81 [==============================] - 0s 175us/sample - loss: 5.8865 - mae: 1.9830 - mse: 5.8865 - val_loss: 77.3729 - val_mae: 6.2149 - val_mse: 77.3729\n",
      "Epoch 256/500\n",
      "81/81 [==============================] - 0s 251us/sample - loss: 4.8897 - mae: 1.7608 - mse: 4.8897 - val_loss: 74.6154 - val_mae: 5.9996 - val_mse: 74.6154\n",
      "Epoch 257/500\n",
      "81/81 [==============================] - 0s 235us/sample - loss: 3.8793 - mae: 1.5621 - mse: 3.8793 - val_loss: 78.3947 - val_mae: 6.3616 - val_mse: 78.3947\n",
      "Epoch 258/500\n",
      "81/81 [==============================] - 0s 182us/sample - loss: 9.8270 - mae: 2.4464 - mse: 9.8270 - val_loss: 66.7432 - val_mae: 5.8049 - val_mse: 66.7432\n",
      "Epoch 259/500\n",
      "81/81 [==============================] - 0s 184us/sample - loss: 5.9865 - mae: 1.9515 - mse: 5.9865 - val_loss: 79.0777 - val_mae: 6.3058 - val_mse: 79.0777\n",
      "Epoch 260/500\n",
      "81/81 [==============================] - 0s 192us/sample - loss: 4.3053 - mae: 1.6839 - mse: 4.3053 - val_loss: 79.1875 - val_mae: 6.2511 - val_mse: 79.1875\n",
      "Epoch 261/500\n",
      "81/81 [==============================] - 0s 185us/sample - loss: 6.6559 - mae: 2.0108 - mse: 6.6559 - val_loss: 68.6261 - val_mae: 5.7589 - val_mse: 68.6261\n",
      "Epoch 262/500\n",
      "81/81 [==============================] - 0s 185us/sample - loss: 4.4204 - mae: 1.6898 - mse: 4.4204 - val_loss: 72.8663 - val_mae: 5.8818 - val_mse: 72.8663\n",
      "Epoch 263/500\n",
      "81/81 [==============================] - 0s 177us/sample - loss: 6.2208 - mae: 1.9369 - mse: 6.2208 - val_loss: 87.3795 - val_mae: 6.9617 - val_mse: 87.3795\n",
      "Epoch 264/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 9.9067 - mae: 2.5755 - mse: 9.9067 - val_loss: 70.2211 - val_mae: 5.7861 - val_mse: 70.2211\n",
      "Epoch 265/500\n",
      "81/81 [==============================] - 0s 208us/sample - loss: 3.6890 - mae: 1.5431 - mse: 3.6890 - val_loss: 74.5486 - val_mae: 5.9825 - val_mse: 74.5486\n",
      "Epoch 266/500\n",
      "81/81 [==============================] - 0s 204us/sample - loss: 4.7921 - mae: 1.7098 - mse: 4.7921 - val_loss: 65.0069 - val_mae: 5.8104 - val_mse: 65.0069\n",
      "Epoch 267/500\n",
      "81/81 [==============================] - 0s 212us/sample - loss: 8.8029 - mae: 2.3810 - mse: 8.8029 - val_loss: 79.9881 - val_mae: 6.3918 - val_mse: 79.9881\n",
      "Epoch 268/500\n",
      "81/81 [==============================] - 0s 180us/sample - loss: 5.7481 - mae: 1.9597 - mse: 5.7481 - val_loss: 69.1025 - val_mae: 5.7928 - val_mse: 69.1025\n",
      "Epoch 269/500\n",
      "81/81 [==============================] - 0s 184us/sample - loss: 5.7699 - mae: 1.9163 - mse: 5.7699 - val_loss: 76.6335 - val_mae: 6.0654 - val_mse: 76.6335\n",
      "Epoch 270/500\n",
      "81/81 [==============================] - 0s 191us/sample - loss: 4.5335 - mae: 1.6735 - mse: 4.5335 - val_loss: 67.2187 - val_mae: 5.7628 - val_mse: 67.2187\n",
      "Epoch 271/500\n",
      "81/81 [==============================] - 0s 184us/sample - loss: 8.8379 - mae: 2.4158 - mse: 8.8379 - val_loss: 83.1425 - val_mae: 6.6187 - val_mse: 83.1425\n",
      "Epoch 272/500\n",
      "81/81 [==============================] - 0s 180us/sample - loss: 8.5009 - mae: 2.3962 - mse: 8.5009 - val_loss: 68.3018 - val_mae: 5.6760 - val_mse: 68.3018\n",
      "Epoch 273/500\n",
      "81/81 [==============================] - 0s 171us/sample - loss: 4.6431 - mae: 1.7205 - mse: 4.6431 - val_loss: 69.0209 - val_mae: 5.8771 - val_mse: 69.0209\n",
      "Epoch 274/500\n",
      "81/81 [==============================] - 0s 182us/sample - loss: 4.2170 - mae: 1.6349 - mse: 4.2170 - val_loss: 73.8650 - val_mae: 5.8807 - val_mse: 73.8650\n",
      "Epoch 275/500\n",
      "81/81 [==============================] - 0s 207us/sample - loss: 4.0314 - mae: 1.5703 - mse: 4.0314 - val_loss: 68.6531 - val_mae: 5.7900 - val_mse: 68.6531\n",
      "Epoch 276/500\n",
      "81/81 [==============================] - 0s 189us/sample - loss: 5.1005 - mae: 1.8759 - mse: 5.1005 - val_loss: 68.7450 - val_mae: 5.9713 - val_mse: 68.7450\n",
      "Epoch 277/500\n",
      "81/81 [==============================] - 0s 173us/sample - loss: 9.2566 - mae: 2.4737 - mse: 9.2566 - val_loss: 77.7673 - val_mae: 6.3625 - val_mse: 77.7673\n",
      "Epoch 278/500\n",
      "81/81 [==============================] - 0s 187us/sample - loss: 6.1559 - mae: 1.9750 - mse: 6.1559 - val_loss: 66.8968 - val_mae: 5.7722 - val_mse: 66.8968\n",
      "Epoch 279/500\n",
      "81/81 [==============================] - 0s 190us/sample - loss: 6.5620 - mae: 2.0761 - mse: 6.5620 - val_loss: 75.3421 - val_mae: 6.1554 - val_mse: 75.3421\n",
      "Epoch 280/500\n",
      "81/81 [==============================] - 0s 211us/sample - loss: 3.9541 - mae: 1.4807 - mse: 3.9541 - val_loss: 68.2112 - val_mae: 5.7199 - val_mse: 68.2112\n",
      "Epoch 281/500\n",
      "81/81 [==============================] - 0s 191us/sample - loss: 4.4681 - mae: 1.6776 - mse: 4.4681 - val_loss: 71.6813 - val_mae: 5.8460 - val_mse: 71.6813\n",
      "Epoch 282/500\n",
      "81/81 [==============================] - 0s 171us/sample - loss: 3.7517 - mae: 1.5503 - mse: 3.7517 - val_loss: 67.7044 - val_mae: 5.8316 - val_mse: 67.7044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/500\n",
      "81/81 [==============================] - 0s 192us/sample - loss: 7.0252 - mae: 2.1229 - mse: 7.0252 - val_loss: 83.6257 - val_mae: 6.6081 - val_mse: 83.6257\n",
      "Epoch 284/500\n",
      "81/81 [==============================] - 0s 181us/sample - loss: 9.3597 - mae: 2.5566 - mse: 9.3597 - val_loss: 68.8453 - val_mae: 5.7316 - val_mse: 68.8453\n",
      "Epoch 285/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 4.6332 - mae: 1.6777 - mse: 4.6332 - val_loss: 69.3914 - val_mae: 5.7147 - val_mse: 69.3914\n",
      "Epoch 286/500\n",
      "81/81 [==============================] - 0s 194us/sample - loss: 4.8081 - mae: 1.7733 - mse: 4.8081 - val_loss: 75.8326 - val_mae: 6.1704 - val_mse: 75.8326\n",
      "Epoch 287/500\n",
      "81/81 [==============================] - 0s 180us/sample - loss: 4.6637 - mae: 1.6526 - mse: 4.6637 - val_loss: 67.7805 - val_mae: 5.8704 - val_mse: 67.7805\n",
      "Epoch 288/500\n",
      "81/81 [==============================] - 0s 192us/sample - loss: 10.3171 - mae: 2.6961 - mse: 10.3171 - val_loss: 78.3525 - val_mae: 6.1879 - val_mse: 78.3525\n",
      "Epoch 289/500\n",
      "81/81 [==============================] - 0s 195us/sample - loss: 4.3804 - mae: 1.6100 - mse: 4.3804 - val_loss: 67.6935 - val_mae: 5.8493 - val_mse: 67.6935\n",
      "Epoch 290/500\n",
      "81/81 [==============================] - 0s 182us/sample - loss: 9.4869 - mae: 2.5255 - mse: 9.4869 - val_loss: 80.3977 - val_mae: 6.4171 - val_mse: 80.3977\n",
      "Epoch 291/500\n",
      "81/81 [==============================] - 0s 194us/sample - loss: 4.9160 - mae: 1.7450 - mse: 4.9160 - val_loss: 72.4211 - val_mae: 5.7993 - val_mse: 72.4211\n",
      "Epoch 292/500\n",
      "81/81 [==============================] - 0s 186us/sample - loss: 3.9997 - mae: 1.5326 - mse: 3.9997 - val_loss: 73.5464 - val_mae: 6.0500 - val_mse: 73.5464\n",
      "Epoch 293/500\n",
      "81/81 [==============================] - 0s 185us/sample - loss: 3.5009 - mae: 1.4422 - mse: 3.5009 - val_loss: 68.7307 - val_mae: 5.7265 - val_mse: 68.7307\n",
      "Epoch 294/500\n",
      "81/81 [==============================] - 0s 169us/sample - loss: 6.3049 - mae: 2.0003 - mse: 6.3049 - val_loss: 85.7914 - val_mae: 6.7682 - val_mse: 85.7914\n",
      "Epoch 295/500\n",
      "81/81 [==============================] - 0s 172us/sample - loss: 6.4456 - mae: 2.0372 - mse: 6.4456 - val_loss: 65.0527 - val_mae: 5.7341 - val_mse: 65.0527\n",
      "Epoch 296/500\n",
      "81/81 [==============================] - 0s 192us/sample - loss: 9.2060 - mae: 2.5812 - mse: 9.2060 - val_loss: 74.6139 - val_mae: 6.0510 - val_mse: 74.6139\n",
      "Epoch 297/500\n",
      "81/81 [==============================] - 0s 195us/sample - loss: 4.1283 - mae: 1.5921 - mse: 4.1283 - val_loss: 74.0637 - val_mae: 5.8740 - val_mse: 74.0637\n",
      "Epoch 298/500\n",
      "81/81 [==============================] - 0s 183us/sample - loss: 3.4342 - mae: 1.4376 - mse: 3.4342 - val_loss: 76.0998 - val_mae: 6.0730 - val_mse: 76.0998\n",
      "Epoch 299/500\n",
      "81/81 [==============================] - 0s 179us/sample - loss: 4.4881 - mae: 1.6702 - mse: 4.4881 - val_loss: 66.3194 - val_mae: 5.6800 - val_mse: 66.3194\n",
      "Epoch 300/500\n",
      "81/81 [==============================] - 0s 189us/sample - loss: 7.3320 - mae: 2.2072 - mse: 7.3320 - val_loss: 97.0987 - val_mae: 7.3957 - val_mse: 97.0987\n",
      "Epoch 301/500\n",
      "81/81 [==============================] - 0s 194us/sample - loss: 7.1829 - mae: 2.1252 - mse: 7.1829 - val_loss: 74.5751 - val_mae: 6.1381 - val_mse: 74.5751\n",
      "Epoch 302/500\n",
      "81/81 [==============================] - 0s 175us/sample - loss: 6.7196 - mae: 2.0763 - mse: 6.7196 - val_loss: 69.0702 - val_mae: 5.8162 - val_mse: 69.0702\n",
      "Epoch 303/500\n",
      "81/81 [==============================] - 0s 177us/sample - loss: 6.7246 - mae: 2.1638 - mse: 6.7246 - val_loss: 73.7847 - val_mae: 5.9553 - val_mse: 73.7847\n",
      "Epoch 304/500\n",
      "81/81 [==============================] - 0s 179us/sample - loss: 4.6705 - mae: 1.6983 - mse: 4.6705 - val_loss: 68.1286 - val_mae: 5.7437 - val_mse: 68.1286\n",
      "Epoch 305/500\n",
      "81/81 [==============================] - 0s 194us/sample - loss: 6.0619 - mae: 1.9296 - mse: 6.0619 - val_loss: 87.4039 - val_mae: 6.6515 - val_mse: 87.4039\n",
      "Epoch 306/500\n",
      "81/81 [==============================] - 0s 187us/sample - loss: 6.4315 - mae: 2.0121 - mse: 6.4315 - val_loss: 66.4706 - val_mae: 5.8099 - val_mse: 66.4706\n",
      "Epoch 307/500\n",
      "81/81 [==============================] - 0s 172us/sample - loss: 7.8643 - mae: 2.3228 - mse: 7.8643 - val_loss: 75.8247 - val_mae: 6.1219 - val_mse: 75.8247\n",
      "Epoch 308/500\n",
      "81/81 [==============================] - 0s 179us/sample - loss: 4.6316 - mae: 1.6599 - mse: 4.6316 - val_loss: 68.4423 - val_mae: 5.6546 - val_mse: 68.4423\n",
      "Epoch 309/500\n",
      "81/81 [==============================] - 0s 174us/sample - loss: 3.6952 - mae: 1.5002 - mse: 3.6952 - val_loss: 66.6271 - val_mae: 5.6869 - val_mse: 66.6271\n",
      "Epoch 310/500\n",
      "81/81 [==============================] - 0s 188us/sample - loss: 5.8470 - mae: 1.9390 - mse: 5.8470 - val_loss: 78.5654 - val_mae: 6.2834 - val_mse: 78.5654\n",
      "Epoch 311/500\n",
      "81/81 [==============================] - 0s 201us/sample - loss: 5.1199 - mae: 1.7327 - mse: 5.1199 - val_loss: 69.5045 - val_mae: 5.6082 - val_mse: 69.5045\n",
      "Epoch 312/500\n",
      "81/81 [==============================] - 0s 167us/sample - loss: 5.0907 - mae: 1.8316 - mse: 5.0907 - val_loss: 79.1811 - val_mae: 6.2307 - val_mse: 79.1811\n",
      "Epoch 313/500\n",
      "81/81 [==============================] - 0s 188us/sample - loss: 7.4440 - mae: 2.1821 - mse: 7.4440 - val_loss: 63.7764 - val_mae: 5.6040 - val_mse: 63.7764\n",
      "Epoch 314/500\n",
      "81/81 [==============================] - 0s 199us/sample - loss: 4.8102 - mae: 1.7356 - mse: 4.8102 - val_loss: 83.2874 - val_mae: 6.4288 - val_mse: 83.2874\n",
      "Epoch 315/500\n",
      "81/81 [==============================] - 0s 190us/sample - loss: 5.7136 - mae: 1.8767 - mse: 5.7136 - val_loss: 66.0110 - val_mae: 5.5906 - val_mse: 66.0110\n",
      "Epoch 316/500\n",
      "81/81 [==============================] - 0s 201us/sample - loss: 3.8605 - mae: 1.5879 - mse: 3.8605 - val_loss: 80.5020 - val_mae: 6.4396 - val_mse: 80.5020\n",
      "Epoch 317/500\n",
      "81/81 [==============================] - 0s 179us/sample - loss: 8.8800 - mae: 2.4856 - mse: 8.8800 - val_loss: 67.9391 - val_mae: 5.6118 - val_mse: 67.9391\n",
      "Epoch 318/500\n",
      "81/81 [==============================] - 0s 182us/sample - loss: 3.7059 - mae: 1.5517 - mse: 3.7059 - val_loss: 74.2148 - val_mae: 5.8695 - val_mse: 74.2148\n",
      "Epoch 319/500\n",
      "81/81 [==============================] - 0s 195us/sample - loss: 3.6031 - mae: 1.4443 - mse: 3.6031 - val_loss: 68.3413 - val_mae: 5.6156 - val_mse: 68.3413\n",
      "Epoch 320/500\n",
      "81/81 [==============================] - 0s 196us/sample - loss: 6.3824 - mae: 1.9617 - mse: 6.3824 - val_loss: 85.9816 - val_mae: 6.7590 - val_mse: 85.9816\n",
      "Epoch 321/500\n",
      "81/81 [==============================] - 0s 184us/sample - loss: 6.1064 - mae: 2.0134 - mse: 6.1064 - val_loss: 70.6148 - val_mae: 5.6898 - val_mse: 70.6148\n",
      "Epoch 322/500\n",
      "81/81 [==============================] - 0s 170us/sample - loss: 6.3348 - mae: 2.0039 - mse: 6.3348 - val_loss: 82.1593 - val_mae: 6.4948 - val_mse: 82.1593\n",
      "Epoch 323/500\n",
      "81/81 [==============================] - 0s 194us/sample - loss: 5.1079 - mae: 1.8246 - mse: 5.1079 - val_loss: 67.5485 - val_mae: 5.7112 - val_mse: 67.5485\n",
      "Epoch 324/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 4.0451 - mae: 1.6266 - mse: 4.0451 - val_loss: 81.1815 - val_mae: 6.3023 - val_mse: 81.1815\n",
      "Epoch 325/500\n",
      "81/81 [==============================] - 0s 189us/sample - loss: 5.3536 - mae: 1.8172 - mse: 5.3536 - val_loss: 66.8842 - val_mae: 5.6435 - val_mse: 66.8842\n",
      "Epoch 326/500\n",
      "81/81 [==============================] - 0s 185us/sample - loss: 7.0841 - mae: 2.1684 - mse: 7.0841 - val_loss: 84.7671 - val_mae: 6.4980 - val_mse: 84.7671\n",
      "Epoch 327/500\n",
      "81/81 [==============================] - 0s 177us/sample - loss: 9.1584 - mae: 2.3703 - mse: 9.1584 - val_loss: 70.9172 - val_mae: 5.6387 - val_mse: 70.9172\n",
      "Epoch 328/500\n",
      "81/81 [==============================] - 0s 199us/sample - loss: 5.8039 - mae: 1.9634 - mse: 5.8039 - val_loss: 74.5325 - val_mae: 5.9270 - val_mse: 74.5325\n",
      "Epoch 329/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 4.2875 - mae: 1.5951 - mse: 4.2875 - val_loss: 70.1236 - val_mae: 5.6160 - val_mse: 70.1236\n",
      "Epoch 330/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 5.0424 - mae: 1.7803 - mse: 5.0424 - val_loss: 81.5241 - val_mae: 6.4780 - val_mse: 81.5241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/500\n",
      "81/81 [==============================] - 0s 184us/sample - loss: 6.4376 - mae: 2.0595 - mse: 6.4376 - val_loss: 68.4676 - val_mae: 5.5991 - val_mse: 68.4676\n",
      "Epoch 332/500\n",
      "81/81 [==============================] - 0s 179us/sample - loss: 3.5346 - mae: 1.4907 - mse: 3.5346 - val_loss: 81.1876 - val_mae: 6.3402 - val_mse: 81.1876\n",
      "Epoch 333/500\n",
      "81/81 [==============================] - 0s 184us/sample - loss: 6.2562 - mae: 1.9219 - mse: 6.2562 - val_loss: 64.1625 - val_mae: 5.7198 - val_mse: 64.1625\n",
      "Epoch 334/500\n",
      "81/81 [==============================] - 0s 194us/sample - loss: 5.7741 - mae: 1.9347 - mse: 5.7741 - val_loss: 80.7708 - val_mae: 6.2610 - val_mse: 80.7708\n",
      "Epoch 335/500\n",
      "81/81 [==============================] - 0s 189us/sample - loss: 3.9652 - mae: 1.5886 - mse: 3.9652 - val_loss: 76.9441 - val_mae: 5.9921 - val_mse: 76.9441\n",
      "Epoch 336/500\n",
      "81/81 [==============================] - 0s 191us/sample - loss: 4.4131 - mae: 1.6286 - mse: 4.4131 - val_loss: 71.5628 - val_mae: 5.7122 - val_mse: 71.5628\n",
      "Epoch 337/500\n",
      "81/81 [==============================] - 0s 174us/sample - loss: 3.2252 - mae: 1.3895 - mse: 3.2252 - val_loss: 75.6642 - val_mae: 5.9643 - val_mse: 75.6642\n",
      "Epoch 338/500\n",
      "81/81 [==============================] - 0s 179us/sample - loss: 3.7023 - mae: 1.4633 - mse: 3.7023 - val_loss: 66.5911 - val_mae: 5.6929 - val_mse: 66.5911\n",
      "Epoch 339/500\n",
      "81/81 [==============================] - 0s 200us/sample - loss: 11.5416 - mae: 2.9180 - mse: 11.5416 - val_loss: 85.1381 - val_mae: 6.7042 - val_mse: 85.1381\n",
      "Epoch 340/500\n",
      "81/81 [==============================] - 0s 184us/sample - loss: 5.6329 - mae: 1.9379 - mse: 5.6329 - val_loss: 69.1136 - val_mae: 5.6198 - val_mse: 69.1136\n",
      "Epoch 341/500\n",
      "81/81 [==============================] - 0s 195us/sample - loss: 3.0728 - mae: 1.4062 - mse: 3.0728 - val_loss: 74.2884 - val_mae: 5.8062 - val_mse: 74.2884\n",
      "Epoch 342/500\n",
      "81/81 [==============================] - 0s 183us/sample - loss: 3.5987 - mae: 1.4793 - mse: 3.5987 - val_loss: 70.6009 - val_mae: 5.7937 - val_mse: 70.6009\n",
      "Epoch 343/500\n",
      "81/81 [==============================] - 0s 178us/sample - loss: 3.9351 - mae: 1.5549 - mse: 3.9351 - val_loss: 81.6386 - val_mae: 6.5043 - val_mse: 81.6386\n",
      "Epoch 344/500\n",
      "81/81 [==============================] - 0s 185us/sample - loss: 7.9025 - mae: 2.3391 - mse: 7.9025 - val_loss: 65.9669 - val_mae: 5.7444 - val_mse: 65.9669\n",
      "Epoch 345/500\n",
      "81/81 [==============================] - 0s 185us/sample - loss: 5.1007 - mae: 1.7371 - mse: 5.1007 - val_loss: 78.9245 - val_mae: 6.2540 - val_mse: 78.9245\n",
      "Epoch 346/500\n",
      "81/81 [==============================] - 0s 199us/sample - loss: 5.1687 - mae: 1.7591 - mse: 5.1687 - val_loss: 65.8465 - val_mae: 5.7437 - val_mse: 65.8465\n",
      "Epoch 347/500\n",
      "81/81 [==============================] - 0s 175us/sample - loss: 8.0362 - mae: 2.2993 - mse: 8.0362 - val_loss: 80.6032 - val_mae: 6.1292 - val_mse: 80.6032\n",
      "Epoch 348/500\n",
      "81/81 [==============================] - 0s 175us/sample - loss: 4.3983 - mae: 1.6515 - mse: 4.3983 - val_loss: 66.7830 - val_mae: 5.5952 - val_mse: 66.7830\n",
      "Epoch 349/500\n",
      "81/81 [==============================] - 0s 190us/sample - loss: 5.4492 - mae: 1.8869 - mse: 5.4492 - val_loss: 83.9137 - val_mae: 6.5881 - val_mse: 83.9137\n",
      "Epoch 350/500\n",
      "81/81 [==============================] - 0s 189us/sample - loss: 5.9698 - mae: 1.9126 - mse: 5.9697 - val_loss: 70.1698 - val_mae: 5.6158 - val_mse: 70.1698\n",
      "Epoch 351/500\n",
      "81/81 [==============================] - 0s 191us/sample - loss: 2.9453 - mae: 1.3604 - mse: 2.9453 - val_loss: 70.5061 - val_mae: 5.7263 - val_mse: 70.5061\n",
      "Epoch 352/500\n",
      "81/81 [==============================] - 0s 192us/sample - loss: 3.0262 - mae: 1.3302 - mse: 3.0262 - val_loss: 68.5009 - val_mae: 5.6823 - val_mse: 68.5009\n",
      "Epoch 353/500\n",
      "81/81 [==============================] - 0s 174us/sample - loss: 5.3450 - mae: 1.8308 - mse: 5.3450 - val_loss: 89.2235 - val_mae: 6.9223 - val_mse: 89.2235\n",
      "Epoch 354/500\n",
      "81/81 [==============================] - 0s 197us/sample - loss: 11.6320 - mae: 2.9049 - mse: 11.6320 - val_loss: 66.6124 - val_mae: 5.5818 - val_mse: 66.6124\n",
      "Epoch 355/500\n",
      "81/81 [==============================] - 0s 205us/sample - loss: 6.1109 - mae: 2.0113 - mse: 6.1109 - val_loss: 75.0036 - val_mae: 5.9269 - val_mse: 75.0036\n",
      "Epoch 356/500\n",
      "81/81 [==============================] - 0s 200us/sample - loss: 3.4174 - mae: 1.4434 - mse: 3.4174 - val_loss: 68.7624 - val_mae: 5.5622 - val_mse: 68.7624\n",
      "Epoch 357/500\n",
      "81/81 [==============================] - 0s 198us/sample - loss: 3.0316 - mae: 1.3897 - mse: 3.0316 - val_loss: 69.8404 - val_mae: 5.8018 - val_mse: 69.8404\n",
      "Epoch 358/500\n",
      "81/81 [==============================] - 0s 192us/sample - loss: 3.3086 - mae: 1.3912 - mse: 3.3086 - val_loss: 70.4316 - val_mae: 5.7062 - val_mse: 70.4316\n",
      "Epoch 359/500\n",
      "81/81 [==============================] - 0s 181us/sample - loss: 2.9233 - mae: 1.3691 - mse: 2.9233 - val_loss: 74.1313 - val_mae: 5.8973 - val_mse: 74.1313\n",
      "Epoch 360/500\n",
      "81/81 [==============================] - 0s 206us/sample - loss: 4.0045 - mae: 1.5677 - mse: 4.0045 - val_loss: 67.3953 - val_mae: 5.6840 - val_mse: 67.3953\n",
      "Epoch 361/500\n",
      "81/81 [==============================] - 0s 188us/sample - loss: 6.0691 - mae: 1.9256 - mse: 6.0691 - val_loss: 84.1784 - val_mae: 6.6826 - val_mse: 84.1784\n",
      "Epoch 362/500\n",
      "81/81 [==============================] - 0s 201us/sample - loss: 8.5494 - mae: 2.4411 - mse: 8.5494 - val_loss: 66.4691 - val_mae: 5.7346 - val_mse: 66.4691\n",
      "Epoch 363/500\n",
      "81/81 [==============================] - 0s 179us/sample - loss: 5.1980 - mae: 1.8174 - mse: 5.1980 - val_loss: 78.5062 - val_mae: 6.2180 - val_mse: 78.5062\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 162 samples, validate on 54 samples\n",
      "Epoch 1/500\n",
      "162/162 [==============================] - 0s 2ms/sample - loss: 291.4850 - mae: 11.4757 - mse: 291.4850 - val_loss: 600.6878 - val_mae: 18.5915 - val_mse: 600.6878\n",
      "Epoch 2/500\n",
      "162/162 [==============================] - 0s 124us/sample - loss: 207.7498 - mae: 9.8798 - mse: 207.7498 - val_loss: 671.2868 - val_mae: 20.1352 - val_mse: 671.2868\n",
      "Epoch 3/500\n",
      "162/162 [==============================] - 0s 119us/sample - loss: 196.9726 - mae: 9.3037 - mse: 196.9726 - val_loss: 580.4330 - val_mae: 18.1243 - val_mse: 580.4330\n",
      "Epoch 4/500\n",
      "162/162 [==============================] - 0s 120us/sample - loss: 166.5033 - mae: 8.3453 - mse: 166.5033 - val_loss: 551.6692 - val_mae: 17.8210 - val_mse: 551.6692\n",
      "Epoch 5/500\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 149.7569 - mae: 7.7586 - mse: 149.7569 - val_loss: 562.5951 - val_mae: 18.6915 - val_mse: 562.5951\n",
      "Epoch 6/500\n",
      "162/162 [==============================] - 0s 121us/sample - loss: 154.5267 - mae: 8.3224 - mse: 154.5267 - val_loss: 444.9783 - val_mae: 15.7569 - val_mse: 444.9783\n",
      "Epoch 7/500\n",
      "162/162 [==============================] - 0s 123us/sample - loss: 133.3326 - mae: 7.3437 - mse: 133.3326 - val_loss: 428.7070 - val_mae: 15.6495 - val_mse: 428.7070\n",
      "Epoch 8/500\n",
      "162/162 [==============================] - 0s 114us/sample - loss: 121.6988 - mae: 7.2147 - mse: 121.6988 - val_loss: 430.6682 - val_mae: 15.4961 - val_mse: 430.6682\n",
      "Epoch 9/500\n",
      "162/162 [==============================] - 0s 117us/sample - loss: 105.8442 - mae: 6.5041 - mse: 105.8442 - val_loss: 421.6057 - val_mae: 15.6475 - val_mse: 421.6057\n",
      "Epoch 10/500\n",
      "162/162 [==============================] - 0s 114us/sample - loss: 104.5765 - mae: 6.8383 - mse: 104.5765 - val_loss: 528.9908 - val_mae: 18.1676 - val_mse: 528.9908\n",
      "Epoch 11/500\n",
      "162/162 [==============================] - 0s 126us/sample - loss: 113.4965 - mae: 6.9531 - mse: 113.4965 - val_loss: 359.5778 - val_mae: 14.1787 - val_mse: 359.5778\n",
      "Epoch 12/500\n",
      "162/162 [==============================] - 0s 123us/sample - loss: 91.0746 - mae: 6.4067 - mse: 91.0746 - val_loss: 325.9750 - val_mae: 13.3780 - val_mse: 325.9750\n",
      "Epoch 13/500\n",
      "162/162 [==============================] - 0s 117us/sample - loss: 84.0577 - mae: 5.8950 - mse: 84.0577 - val_loss: 321.4021 - val_mae: 13.2851 - val_mse: 321.4021\n",
      "Epoch 14/500\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 78.8051 - mae: 5.8043 - mse: 78.8051 - val_loss: 317.8846 - val_mae: 13.0611 - val_mse: 317.8846\n",
      "Epoch 15/500\n",
      "162/162 [==============================] - 0s 124us/sample - loss: 74.0550 - mae: 5.5292 - mse: 74.0550 - val_loss: 297.4578 - val_mae: 12.6711 - val_mse: 297.4578\n",
      "Epoch 16/500\n",
      "162/162 [==============================] - 0s 125us/sample - loss: 66.7870 - mae: 5.1514 - mse: 66.7870 - val_loss: 344.9653 - val_mae: 14.5995 - val_mse: 344.9654\n",
      "Epoch 17/500\n",
      "162/162 [==============================] - 0s 121us/sample - loss: 82.2744 - mae: 6.4912 - mse: 82.2744 - val_loss: 256.0145 - val_mae: 11.6385 - val_mse: 256.0145\n",
      "Epoch 18/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 61.3147 - mae: 5.1277 - mse: 61.3147 - val_loss: 253.8908 - val_mae: 12.3305 - val_mse: 253.8907\n",
      "Epoch 19/500\n",
      "162/162 [==============================] - 0s 120us/sample - loss: 67.5767 - mae: 5.6328 - mse: 67.5767 - val_loss: 250.6218 - val_mae: 11.7263 - val_mse: 250.6218\n",
      "Epoch 20/500\n",
      "162/162 [==============================] - 0s 117us/sample - loss: 53.9750 - mae: 4.7702 - mse: 53.9750 - val_loss: 225.7916 - val_mae: 11.3347 - val_mse: 225.7916\n",
      "Epoch 21/500\n",
      "162/162 [==============================] - 0s 118us/sample - loss: 58.7100 - mae: 5.2588 - mse: 58.7100 - val_loss: 252.6378 - val_mae: 12.0461 - val_mse: 252.6378\n",
      "Epoch 22/500\n",
      "162/162 [==============================] - 0s 123us/sample - loss: 51.4506 - mae: 4.7820 - mse: 51.4506 - val_loss: 209.3801 - val_mae: 10.7959 - val_mse: 209.3801\n",
      "Epoch 23/500\n",
      "162/162 [==============================] - 0s 120us/sample - loss: 55.0712 - mae: 5.1616 - mse: 55.0712 - val_loss: 219.1720 - val_mae: 11.1008 - val_mse: 219.1720\n",
      "Epoch 24/500\n",
      "162/162 [==============================] - 0s 127us/sample - loss: 46.6337 - mae: 4.5012 - mse: 46.6337 - val_loss: 220.3809 - val_mae: 11.2198 - val_mse: 220.3809\n",
      "Epoch 25/500\n",
      "162/162 [==============================] - 0s 119us/sample - loss: 51.7130 - mae: 5.0291 - mse: 51.7130 - val_loss: 205.5115 - val_mae: 11.2853 - val_mse: 205.5115\n",
      "Epoch 26/500\n",
      "162/162 [==============================] - 0s 117us/sample - loss: 57.5114 - mae: 5.3598 - mse: 57.5114 - val_loss: 180.0227 - val_mae: 9.9302 - val_mse: 180.0227\n",
      "Epoch 27/500\n",
      "162/162 [==============================] - 0s 117us/sample - loss: 44.7056 - mae: 4.6387 - mse: 44.7056 - val_loss: 179.6501 - val_mae: 9.8522 - val_mse: 179.6501\n",
      "Epoch 28/500\n",
      "162/162 [==============================] - 0s 118us/sample - loss: 48.9883 - mae: 5.1502 - mse: 48.9883 - val_loss: 172.9314 - val_mae: 9.6720 - val_mse: 172.9314\n",
      "Epoch 29/500\n",
      "162/162 [==============================] - 0s 119us/sample - loss: 40.8610 - mae: 4.3645 - mse: 40.8610 - val_loss: 161.7541 - val_mae: 9.2899 - val_mse: 161.7540\n",
      "Epoch 30/500\n",
      "162/162 [==============================] - 0s 121us/sample - loss: 40.7982 - mae: 4.4531 - mse: 40.7982 - val_loss: 159.4185 - val_mae: 9.3350 - val_mse: 159.4185\n",
      "Epoch 31/500\n",
      "162/162 [==============================] - 0s 123us/sample - loss: 49.1916 - mae: 5.1970 - mse: 49.1916 - val_loss: 159.6095 - val_mae: 9.3077 - val_mse: 159.6095\n",
      "Epoch 32/500\n",
      "162/162 [==============================] - 0s 125us/sample - loss: 34.6835 - mae: 3.9712 - mse: 34.6835 - val_loss: 158.8836 - val_mae: 9.3320 - val_mse: 158.8836\n",
      "Epoch 33/500\n",
      "162/162 [==============================] - 0s 117us/sample - loss: 39.8303 - mae: 4.6518 - mse: 39.8303 - val_loss: 154.0428 - val_mae: 9.1909 - val_mse: 154.0428\n",
      "Epoch 34/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 33.5222 - mae: 3.9005 - mse: 33.5222 - val_loss: 148.2634 - val_mae: 8.9943 - val_mse: 148.2634\n",
      "Epoch 35/500\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 37.4412 - mae: 4.4011 - mse: 37.4412 - val_loss: 155.5061 - val_mae: 9.3507 - val_mse: 155.5061\n",
      "Epoch 36/500\n",
      "162/162 [==============================] - 0s 121us/sample - loss: 38.0705 - mae: 4.2288 - mse: 38.0705 - val_loss: 151.6671 - val_mae: 9.1528 - val_mse: 151.6671\n",
      "Epoch 37/500\n",
      "162/162 [==============================] - 0s 121us/sample - loss: 40.0702 - mae: 4.8074 - mse: 40.0702 - val_loss: 163.5087 - val_mae: 9.6575 - val_mse: 163.5087\n",
      "Epoch 38/500\n",
      "162/162 [==============================] - 0s 120us/sample - loss: 31.9318 - mae: 3.9976 - mse: 31.9318 - val_loss: 143.3065 - val_mae: 8.8996 - val_mse: 143.3065\n",
      "Epoch 39/500\n",
      "162/162 [==============================] - 0s 129us/sample - loss: 32.8970 - mae: 4.1191 - mse: 32.8970 - val_loss: 144.6048 - val_mae: 9.4507 - val_mse: 144.6048\n",
      "Epoch 40/500\n",
      "162/162 [==============================] - 0s 122us/sample - loss: 35.7722 - mae: 4.3887 - mse: 35.7722 - val_loss: 158.6810 - val_mae: 9.5990 - val_mse: 158.6810\n",
      "Epoch 41/500\n",
      "162/162 [==============================] - 0s 124us/sample - loss: 33.0944 - mae: 4.3669 - mse: 33.0944 - val_loss: 165.6218 - val_mae: 10.0105 - val_mse: 165.6218\n",
      "Epoch 42/500\n",
      "162/162 [==============================] - 0s 118us/sample - loss: 31.2136 - mae: 4.0584 - mse: 31.2136 - val_loss: 125.2643 - val_mae: 8.6254 - val_mse: 125.2643\n",
      "Epoch 43/500\n",
      "162/162 [==============================] - 0s 121us/sample - loss: 31.2433 - mae: 4.1016 - mse: 31.2433 - val_loss: 136.8851 - val_mae: 8.8531 - val_mse: 136.8851\n",
      "Epoch 44/500\n",
      "162/162 [==============================] - 0s 125us/sample - loss: 26.2046 - mae: 3.6440 - mse: 26.2046 - val_loss: 124.6610 - val_mae: 8.2524 - val_mse: 124.6610\n",
      "Epoch 45/500\n",
      "162/162 [==============================] - 0s 120us/sample - loss: 28.2614 - mae: 3.7018 - mse: 28.2614 - val_loss: 151.6293 - val_mae: 9.5324 - val_mse: 151.6293\n",
      "Epoch 46/500\n",
      "162/162 [==============================] - 0s 119us/sample - loss: 34.2368 - mae: 4.3421 - mse: 34.2368 - val_loss: 111.7171 - val_mae: 7.7197 - val_mse: 111.7171\n",
      "Epoch 47/500\n",
      "162/162 [==============================] - 0s 119us/sample - loss: 22.7960 - mae: 3.4307 - mse: 22.7960 - val_loss: 117.7833 - val_mae: 8.4150 - val_mse: 117.7833\n",
      "Epoch 48/500\n",
      "162/162 [==============================] - 0s 131us/sample - loss: 26.2424 - mae: 3.7620 - mse: 26.2424 - val_loss: 126.7637 - val_mae: 8.4458 - val_mse: 126.7637\n",
      "Epoch 49/500\n",
      "162/162 [==============================] - 0s 121us/sample - loss: 27.2067 - mae: 3.8237 - mse: 27.2067 - val_loss: 174.6287 - val_mae: 10.7577 - val_mse: 174.6287\n",
      "Epoch 50/500\n",
      "162/162 [==============================] - 0s 128us/sample - loss: 33.0094 - mae: 4.3754 - mse: 33.0094 - val_loss: 107.9361 - val_mae: 7.8592 - val_mse: 107.9361\n",
      "Epoch 51/500\n",
      "162/162 [==============================] - 0s 122us/sample - loss: 24.7202 - mae: 3.5256 - mse: 24.7202 - val_loss: 120.7584 - val_mae: 8.1457 - val_mse: 120.7584\n",
      "Epoch 52/500\n",
      "162/162 [==============================] - 0s 125us/sample - loss: 24.6192 - mae: 3.6048 - mse: 24.6192 - val_loss: 126.9855 - val_mae: 8.6588 - val_mse: 126.9855\n",
      "Epoch 53/500\n",
      "162/162 [==============================] - 0s 119us/sample - loss: 22.2559 - mae: 3.4162 - mse: 22.2559 - val_loss: 105.2880 - val_mae: 7.8388 - val_mse: 105.2880\n",
      "Epoch 54/500\n",
      "162/162 [==============================] - 0s 117us/sample - loss: 24.4727 - mae: 3.6344 - mse: 24.4727 - val_loss: 103.3669 - val_mae: 7.5242 - val_mse: 103.3669\n",
      "Epoch 55/500\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 31.5258 - mae: 4.4072 - mse: 31.5258 - val_loss: 101.7738 - val_mae: 7.5041 - val_mse: 101.7738\n",
      "Epoch 56/500\n",
      "162/162 [==============================] - 0s 124us/sample - loss: 18.9429 - mae: 3.1253 - mse: 18.9429 - val_loss: 101.2851 - val_mae: 7.3802 - val_mse: 101.2851\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 114us/sample - loss: 29.7832 - mae: 4.2437 - mse: 29.7832 - val_loss: 107.3657 - val_mae: 7.6769 - val_mse: 107.3657\n",
      "Epoch 58/500\n",
      "162/162 [==============================] - 0s 118us/sample - loss: 18.2543 - mae: 2.9544 - mse: 18.2543 - val_loss: 125.6037 - val_mae: 8.6201 - val_mse: 125.6037\n",
      "Epoch 59/500\n",
      "162/162 [==============================] - 0s 118us/sample - loss: 29.5843 - mae: 4.3377 - mse: 29.5843 - val_loss: 109.2591 - val_mae: 7.8437 - val_mse: 109.2591\n",
      "Epoch 60/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 20.5774 - mae: 3.3214 - mse: 20.5774 - val_loss: 97.8253 - val_mae: 7.1500 - val_mse: 97.8253\n",
      "Epoch 61/500\n",
      "162/162 [==============================] - 0s 122us/sample - loss: 17.5138 - mae: 3.0494 - mse: 17.5138 - val_loss: 107.5369 - val_mae: 7.7616 - val_mse: 107.5369\n",
      "Epoch 62/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 31.1632 - mae: 4.5360 - mse: 31.1632 - val_loss: 97.4150 - val_mae: 7.1543 - val_mse: 97.4150\n",
      "Epoch 63/500\n",
      "162/162 [==============================] - 0s 118us/sample - loss: 14.9603 - mae: 2.7016 - mse: 14.9603 - val_loss: 128.3862 - val_mae: 8.9748 - val_mse: 128.3862\n",
      "Epoch 64/500\n",
      "162/162 [==============================] - 0s 113us/sample - loss: 24.0606 - mae: 3.7787 - mse: 24.0606 - val_loss: 88.0723 - val_mae: 6.8141 - val_mse: 88.0723\n",
      "Epoch 65/500\n",
      "162/162 [==============================] - 0s 121us/sample - loss: 14.5632 - mae: 2.7564 - mse: 14.5632 - val_loss: 132.3667 - val_mae: 9.2210 - val_mse: 132.3667\n",
      "Epoch 66/500\n",
      "162/162 [==============================] - 0s 125us/sample - loss: 22.5300 - mae: 3.4104 - mse: 22.5300 - val_loss: 97.6233 - val_mae: 7.8135 - val_mse: 97.6233\n",
      "Epoch 67/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 25.9090 - mae: 4.0803 - mse: 25.9090 - val_loss: 108.4046 - val_mae: 7.9720 - val_mse: 108.4046\n",
      "Epoch 68/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 20.5545 - mae: 3.5273 - mse: 20.5545 - val_loss: 86.7194 - val_mae: 6.7436 - val_mse: 86.7194\n",
      "Epoch 69/500\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 19.1738 - mae: 3.3733 - mse: 19.1738 - val_loss: 117.1587 - val_mae: 8.6307 - val_mse: 117.1587\n",
      "Epoch 70/500\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 17.7815 - mae: 3.2013 - mse: 17.7815 - val_loss: 96.3499 - val_mae: 7.2599 - val_mse: 96.3499\n",
      "Epoch 71/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 24.3345 - mae: 4.0552 - mse: 24.3345 - val_loss: 125.9032 - val_mae: 9.0015 - val_mse: 125.9032\n",
      "Epoch 72/500\n",
      "162/162 [==============================] - 0s 114us/sample - loss: 19.9617 - mae: 3.2399 - mse: 19.9617 - val_loss: 82.4212 - val_mae: 6.4068 - val_mse: 82.4212\n",
      "Epoch 73/500\n",
      "162/162 [==============================] - 0s 118us/sample - loss: 12.7747 - mae: 2.6389 - mse: 12.7747 - val_loss: 92.0927 - val_mae: 7.1217 - val_mse: 92.0928\n",
      "Epoch 74/500\n",
      "162/162 [==============================] - 0s 118us/sample - loss: 16.1652 - mae: 3.0978 - mse: 16.1652 - val_loss: 109.8801 - val_mae: 8.2194 - val_mse: 109.8801\n",
      "Epoch 75/500\n",
      "162/162 [==============================] - 0s 164us/sample - loss: 24.4164 - mae: 3.8463 - mse: 24.4164 - val_loss: 90.0590 - val_mae: 6.9697 - val_mse: 90.0590\n",
      "Epoch 76/500\n",
      "162/162 [==============================] - 0s 189us/sample - loss: 17.0929 - mae: 3.1833 - mse: 17.0929 - val_loss: 84.9309 - val_mae: 6.7415 - val_mse: 84.9309\n",
      "Epoch 77/500\n",
      "162/162 [==============================] - 0s 185us/sample - loss: 13.9530 - mae: 2.8485 - mse: 13.9530 - val_loss: 81.7484 - val_mae: 6.5360 - val_mse: 81.7484\n",
      "Epoch 78/500\n",
      "162/162 [==============================] - 0s 186us/sample - loss: 11.3371 - mae: 2.4756 - mse: 11.3371 - val_loss: 95.7281 - val_mae: 7.4534 - val_mse: 95.7281\n",
      "Epoch 79/500\n",
      "162/162 [==============================] - 0s 180us/sample - loss: 26.4269 - mae: 4.3390 - mse: 26.4269 - val_loss: 78.1248 - val_mae: 6.2579 - val_mse: 78.1248\n",
      "Epoch 80/500\n",
      "162/162 [==============================] - 0s 172us/sample - loss: 11.1635 - mae: 2.4446 - mse: 11.1635 - val_loss: 109.2728 - val_mae: 8.2965 - val_mse: 109.2728\n",
      "Epoch 81/500\n",
      "162/162 [==============================] - 0s 190us/sample - loss: 24.3278 - mae: 4.0238 - mse: 24.3278 - val_loss: 79.1215 - val_mae: 6.4122 - val_mse: 79.1215\n",
      "Epoch 82/500\n",
      "162/162 [==============================] - 0s 182us/sample - loss: 11.0988 - mae: 2.4716 - mse: 11.0988 - val_loss: 90.9271 - val_mae: 7.2561 - val_mse: 90.9271\n",
      "Epoch 83/500\n",
      "162/162 [==============================] - 0s 175us/sample - loss: 21.6280 - mae: 3.8818 - mse: 21.6280 - val_loss: 98.0460 - val_mae: 7.6881 - val_mse: 98.0460\n",
      "Epoch 84/500\n",
      "162/162 [==============================] - 0s 202us/sample - loss: 13.0552 - mae: 2.7944 - mse: 13.0552 - val_loss: 83.4406 - val_mae: 6.8494 - val_mse: 83.4406\n",
      "Epoch 85/500\n",
      "162/162 [==============================] - 0s 145us/sample - loss: 22.8412 - mae: 3.9306 - mse: 22.8412 - val_loss: 73.0055 - val_mae: 6.1016 - val_mse: 73.0055\n",
      "Epoch 86/500\n",
      "162/162 [==============================] - 0s 158us/sample - loss: 11.7166 - mae: 2.6341 - mse: 11.7166 - val_loss: 77.2422 - val_mae: 6.3216 - val_mse: 77.2422\n",
      "Epoch 87/500\n",
      "162/162 [==============================] - 0s 144us/sample - loss: 11.0676 - mae: 2.5061 - mse: 11.0676 - val_loss: 75.1824 - val_mae: 6.3668 - val_mse: 75.1824\n",
      "Epoch 88/500\n",
      "162/162 [==============================] - 0s 167us/sample - loss: 26.2092 - mae: 4.2241 - mse: 26.2092 - val_loss: 73.2361 - val_mae: 6.1403 - val_mse: 73.2361\n",
      "Epoch 89/500\n",
      "162/162 [==============================] - 0s 135us/sample - loss: 14.2367 - mae: 2.9814 - mse: 14.2367 - val_loss: 90.4495 - val_mae: 7.4001 - val_mse: 90.4495\n",
      "Epoch 90/500\n",
      "162/162 [==============================] - 0s 148us/sample - loss: 13.7751 - mae: 2.7417 - mse: 13.7751 - val_loss: 83.0249 - val_mae: 6.8813 - val_mse: 83.0248\n",
      "Epoch 91/500\n",
      "162/162 [==============================] - 0s 145us/sample - loss: 17.1986 - mae: 3.4063 - mse: 17.1986 - val_loss: 68.8147 - val_mae: 5.8683 - val_mse: 68.8147\n",
      "Epoch 92/500\n",
      "162/162 [==============================] - 0s 180us/sample - loss: 10.1204 - mae: 2.3867 - mse: 10.1204 - val_loss: 88.2410 - val_mae: 7.2404 - val_mse: 88.2410\n",
      "Epoch 93/500\n",
      "162/162 [==============================] - 0s 130us/sample - loss: 20.3947 - mae: 3.4816 - mse: 20.3947 - val_loss: 78.5680 - val_mae: 6.7056 - val_mse: 78.5680\n",
      "Epoch 94/500\n",
      "162/162 [==============================] - 0s 106us/sample - loss: 10.1725 - mae: 2.4426 - mse: 10.1725 - val_loss: 67.8614 - val_mae: 5.8601 - val_mse: 67.8614\n",
      "Epoch 95/500\n",
      "162/162 [==============================] - 0s 139us/sample - loss: 9.2543 - mae: 2.2103 - mse: 9.2543 - val_loss: 95.4612 - val_mae: 7.8233 - val_mse: 95.4612\n",
      "Epoch 96/500\n",
      "162/162 [==============================] - 0s 117us/sample - loss: 19.6239 - mae: 3.6813 - mse: 19.6239 - val_loss: 79.0590 - val_mae: 6.7400 - val_mse: 79.0590\n",
      "Epoch 97/500\n",
      "162/162 [==============================] - 0s 120us/sample - loss: 8.8729 - mae: 2.2948 - mse: 8.8729 - val_loss: 71.5900 - val_mae: 6.1560 - val_mse: 71.5900\n",
      "Epoch 98/500\n",
      "162/162 [==============================] - 0s 114us/sample - loss: 18.1757 - mae: 3.5745 - mse: 18.1757 - val_loss: 68.6636 - val_mae: 5.9535 - val_mse: 68.6637\n",
      "Epoch 99/500\n",
      "162/162 [==============================] - 0s 114us/sample - loss: 12.1124 - mae: 2.7816 - mse: 12.1124 - val_loss: 70.0286 - val_mae: 6.1070 - val_mse: 70.0286\n",
      "Epoch 100/500\n",
      "162/162 [==============================] - 0s 120us/sample - loss: 11.9779 - mae: 2.7628 - mse: 11.9779 - val_loss: 67.2570 - val_mae: 5.8652 - val_mse: 67.2570\n",
      "Epoch 101/500\n",
      "162/162 [==============================] - 0s 113us/sample - loss: 13.8794 - mae: 3.0079 - mse: 13.8794 - val_loss: 70.8806 - val_mae: 6.3617 - val_mse: 70.8806\n",
      "Epoch 102/500\n",
      "162/162 [==============================] - 0s 110us/sample - loss: 14.9026 - mae: 2.9947 - mse: 14.9026 - val_loss: 67.6225 - val_mae: 5.9272 - val_mse: 67.6225\n",
      "Epoch 103/500\n",
      "162/162 [==============================] - 0s 117us/sample - loss: 8.3710 - mae: 2.2196 - mse: 8.3710 - val_loss: 83.8020 - val_mae: 6.8045 - val_mse: 83.8020\n",
      "Epoch 104/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 117us/sample - loss: 16.8845 - mae: 3.2009 - mse: 16.8845 - val_loss: 67.4167 - val_mae: 5.9989 - val_mse: 67.4167\n",
      "Epoch 105/500\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 14.0912 - mae: 3.0705 - mse: 14.0912 - val_loss: 60.9388 - val_mae: 5.4329 - val_mse: 60.9388\n",
      "Epoch 106/500\n",
      "162/162 [==============================] - 0s 125us/sample - loss: 7.0252 - mae: 1.9866 - mse: 7.0252 - val_loss: 61.9092 - val_mae: 5.4802 - val_mse: 61.9092\n",
      "Epoch 107/500\n",
      "162/162 [==============================] - 0s 113us/sample - loss: 16.9669 - mae: 3.2557 - mse: 16.9669 - val_loss: 63.3532 - val_mae: 5.6499 - val_mse: 63.3532\n",
      "Epoch 108/500\n",
      "162/162 [==============================] - 0s 113us/sample - loss: 8.7764 - mae: 2.2850 - mse: 8.7764 - val_loss: 67.0027 - val_mae: 6.0771 - val_mse: 67.0027\n",
      "Epoch 109/500\n",
      "162/162 [==============================] - 0s 114us/sample - loss: 10.3836 - mae: 2.5289 - mse: 10.3836 - val_loss: 69.9160 - val_mae: 6.3907 - val_mse: 69.9160\n",
      "Epoch 110/500\n",
      "162/162 [==============================] - 0s 117us/sample - loss: 13.5929 - mae: 3.0022 - mse: 13.5929 - val_loss: 58.9647 - val_mae: 5.2706 - val_mse: 58.9647\n",
      "Epoch 111/500\n",
      "162/162 [==============================] - 0s 114us/sample - loss: 7.6572 - mae: 2.1715 - mse: 7.6572 - val_loss: 59.6448 - val_mae: 5.4184 - val_mse: 59.6448\n",
      "Epoch 112/500\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 11.8675 - mae: 2.7572 - mse: 11.8675 - val_loss: 75.6025 - val_mae: 6.6352 - val_mse: 75.6025\n",
      "Epoch 113/500\n",
      "162/162 [==============================] - 0s 107us/sample - loss: 13.8793 - mae: 2.8892 - mse: 13.8793 - val_loss: 62.6778 - val_mae: 5.7296 - val_mse: 62.6778\n",
      "Epoch 114/500\n",
      "162/162 [==============================] - 0s 109us/sample - loss: 7.0971 - mae: 2.0867 - mse: 7.0971 - val_loss: 68.7501 - val_mae: 6.1848 - val_mse: 68.7501\n",
      "Epoch 115/500\n",
      "162/162 [==============================] - 0s 108us/sample - loss: 12.6437 - mae: 2.9051 - mse: 12.6437 - val_loss: 65.1887 - val_mae: 5.9604 - val_mse: 65.1887\n",
      "Epoch 116/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 13.9232 - mae: 3.1365 - mse: 13.9232 - val_loss: 72.4115 - val_mae: 6.4654 - val_mse: 72.4115\n",
      "Epoch 117/500\n",
      "162/162 [==============================] - 0s 107us/sample - loss: 10.3175 - mae: 2.6363 - mse: 10.3175 - val_loss: 76.4502 - val_mae: 6.6894 - val_mse: 76.4502\n",
      "Epoch 118/500\n",
      "162/162 [==============================] - 0s 112us/sample - loss: 10.5917 - mae: 2.6056 - mse: 10.5917 - val_loss: 70.9869 - val_mae: 6.4033 - val_mse: 70.9869\n",
      "Epoch 119/500\n",
      "162/162 [==============================] - 0s 107us/sample - loss: 11.8082 - mae: 2.8681 - mse: 11.8082 - val_loss: 74.4639 - val_mae: 6.5770 - val_mse: 74.4639\n",
      "Epoch 120/500\n",
      "162/162 [==============================] - 0s 126us/sample - loss: 10.5313 - mae: 2.5709 - mse: 10.5313 - val_loss: 59.5584 - val_mae: 5.3514 - val_mse: 59.5584\n",
      "Epoch 121/500\n",
      "162/162 [==============================] - 0s 103us/sample - loss: 5.9665 - mae: 1.8894 - mse: 5.9665 - val_loss: 73.1331 - val_mae: 6.2818 - val_mse: 73.1331\n",
      "Epoch 122/500\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 17.6677 - mae: 3.5643 - mse: 17.6677 - val_loss: 68.6128 - val_mae: 5.9859 - val_mse: 68.6128\n",
      "Epoch 123/500\n",
      "162/162 [==============================] - 0s 119us/sample - loss: 10.6482 - mae: 2.6833 - mse: 10.6482 - val_loss: 59.6081 - val_mae: 5.4117 - val_mse: 59.6081\n",
      "Epoch 124/500\n",
      "162/162 [==============================] - 0s 126us/sample - loss: 7.3235 - mae: 2.1286 - mse: 7.3235 - val_loss: 60.0505 - val_mae: 5.3482 - val_mse: 60.0505\n",
      "Epoch 125/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 14.4774 - mae: 3.2307 - mse: 14.4774 - val_loss: 64.2036 - val_mae: 5.6776 - val_mse: 64.2036\n",
      "Epoch 126/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 10.8634 - mae: 2.6616 - mse: 10.8634 - val_loss: 60.7020 - val_mae: 5.5753 - val_mse: 60.7020\n",
      "Epoch 127/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 5.7910 - mae: 1.8822 - mse: 5.7910 - val_loss: 77.7287 - val_mae: 6.8652 - val_mse: 77.7287\n",
      "Epoch 128/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 14.0153 - mae: 3.0381 - mse: 14.0153 - val_loss: 60.2301 - val_mae: 5.4499 - val_mse: 60.2301\n",
      "Epoch 129/500\n",
      "162/162 [==============================] - 0s 124us/sample - loss: 12.2259 - mae: 2.9940 - mse: 12.2259 - val_loss: 73.4923 - val_mae: 6.3777 - val_mse: 73.4923\n",
      "Epoch 130/500\n",
      "162/162 [==============================] - 0s 123us/sample - loss: 13.4394 - mae: 2.9478 - mse: 13.4394 - val_loss: 59.3016 - val_mae: 5.3972 - val_mse: 59.3016\n",
      "Epoch 131/500\n",
      "162/162 [==============================] - 0s 118us/sample - loss: 5.6230 - mae: 1.8597 - mse: 5.6230 - val_loss: 60.8472 - val_mae: 5.7453 - val_mse: 60.8472\n",
      "Epoch 132/500\n",
      "162/162 [==============================] - 0s 119us/sample - loss: 12.9532 - mae: 3.0088 - mse: 12.9532 - val_loss: 62.3848 - val_mae: 5.7566 - val_mse: 62.3848\n",
      "Epoch 133/500\n",
      "162/162 [==============================] - 0s 126us/sample - loss: 9.4912 - mae: 2.4930 - mse: 9.4911 - val_loss: 77.4706 - val_mae: 7.1021 - val_mse: 77.4706\n",
      "Epoch 134/500\n",
      "162/162 [==============================] - 0s 120us/sample - loss: 12.0047 - mae: 2.8006 - mse: 12.0047 - val_loss: 71.5258 - val_mae: 6.6079 - val_mse: 71.5258\n",
      "Epoch 135/500\n",
      "162/162 [==============================] - 0s 123us/sample - loss: 12.4019 - mae: 2.9776 - mse: 12.4019 - val_loss: 63.6819 - val_mae: 5.9586 - val_mse: 63.6819\n",
      "Epoch 136/500\n",
      "162/162 [==============================] - 0s 118us/sample - loss: 7.2618 - mae: 2.2069 - mse: 7.2618 - val_loss: 56.0502 - val_mae: 5.1208 - val_mse: 56.0502\n",
      "Epoch 137/500\n",
      "162/162 [==============================] - 0s 112us/sample - loss: 13.2460 - mae: 3.0310 - mse: 13.2460 - val_loss: 64.0890 - val_mae: 5.8295 - val_mse: 64.0890\n",
      "Epoch 138/500\n",
      "162/162 [==============================] - 0s 118us/sample - loss: 5.6728 - mae: 1.8470 - mse: 5.6728 - val_loss: 65.9175 - val_mae: 5.9767 - val_mse: 65.9175\n",
      "Epoch 139/500\n",
      "162/162 [==============================] - 0s 120us/sample - loss: 8.8031 - mae: 2.4156 - mse: 8.8031 - val_loss: 72.9637 - val_mae: 6.4009 - val_mse: 72.9637\n",
      "Epoch 140/500\n",
      "162/162 [==============================] - 0s 124us/sample - loss: 14.9530 - mae: 3.2899 - mse: 14.9530 - val_loss: 56.4104 - val_mae: 5.1753 - val_mse: 56.4104\n",
      "Epoch 141/500\n",
      "162/162 [==============================] - 0s 124us/sample - loss: 4.3075 - mae: 1.5897 - mse: 4.3075 - val_loss: 60.5045 - val_mae: 5.5565 - val_mse: 60.5045\n",
      "Epoch 142/500\n",
      "162/162 [==============================] - 0s 112us/sample - loss: 8.5950 - mae: 2.3729 - mse: 8.5950 - val_loss: 63.8069 - val_mae: 5.9431 - val_mse: 63.8069\n",
      "Epoch 143/500\n",
      "162/162 [==============================] - 0s 120us/sample - loss: 12.8634 - mae: 3.0224 - mse: 12.8634 - val_loss: 64.4139 - val_mae: 5.6764 - val_mse: 64.4139\n",
      "Epoch 144/500\n",
      "162/162 [==============================] - 0s 125us/sample - loss: 11.1389 - mae: 2.7556 - mse: 11.1390 - val_loss: 64.9195 - val_mae: 5.8926 - val_mse: 64.9195\n",
      "Epoch 145/500\n",
      "162/162 [==============================] - 0s 123us/sample - loss: 4.6813 - mae: 1.7190 - mse: 4.6813 - val_loss: 58.3889 - val_mae: 5.3858 - val_mse: 58.3889\n",
      "Epoch 146/500\n",
      "162/162 [==============================] - 0s 128us/sample - loss: 8.8228 - mae: 2.4273 - mse: 8.8228 - val_loss: 85.6724 - val_mae: 7.6481 - val_mse: 85.6724\n",
      "Epoch 147/500\n",
      "162/162 [==============================] - 0s 128us/sample - loss: 11.5805 - mae: 2.5324 - mse: 11.5805 - val_loss: 59.2400 - val_mae: 5.2793 - val_mse: 59.2400\n",
      "Epoch 148/500\n",
      "162/162 [==============================] - 0s 125us/sample - loss: 4.7653 - mae: 1.7043 - mse: 4.7653 - val_loss: 74.0868 - val_mae: 6.2240 - val_mse: 74.0868\n",
      "Epoch 149/500\n",
      "162/162 [==============================] - 0s 162us/sample - loss: 16.3036 - mae: 3.3725 - mse: 16.3036 - val_loss: 59.6660 - val_mae: 5.3145 - val_mse: 59.6660\n",
      "Epoch 150/500\n",
      "162/162 [==============================] - 0s 132us/sample - loss: 3.6814 - mae: 1.5095 - mse: 3.6814 - val_loss: 72.7739 - val_mae: 6.7562 - val_mse: 72.7739\n",
      "Epoch 151/500\n",
      "162/162 [==============================] - 0s 123us/sample - loss: 13.4242 - mae: 3.1929 - mse: 13.4242 - val_loss: 60.8915 - val_mae: 5.6499 - val_mse: 60.8915\n",
      "Epoch 152/500\n",
      "162/162 [==============================] - 0s 122us/sample - loss: 5.5990 - mae: 1.9219 - mse: 5.5990 - val_loss: 59.9627 - val_mae: 5.5667 - val_mse: 59.9627\n",
      "Epoch 153/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 12.4342 - mae: 2.9956 - mse: 12.4342 - val_loss: 62.3118 - val_mae: 5.7818 - val_mse: 62.3118\n",
      "Epoch 154/500\n",
      "162/162 [==============================] - 0s 122us/sample - loss: 6.1005 - mae: 1.9851 - mse: 6.1005 - val_loss: 69.4049 - val_mae: 6.3615 - val_mse: 69.4049\n",
      "Epoch 155/500\n",
      "162/162 [==============================] - 0s 120us/sample - loss: 10.4408 - mae: 2.7468 - mse: 10.4408 - val_loss: 57.7566 - val_mae: 5.3814 - val_mse: 57.7566\n",
      "Epoch 156/500\n",
      "162/162 [==============================] - 0s 118us/sample - loss: 6.3701 - mae: 2.0289 - mse: 6.3701 - val_loss: 71.0208 - val_mae: 6.3284 - val_mse: 71.0208\n",
      "Epoch 157/500\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 8.7338 - mae: 2.4015 - mse: 8.7338 - val_loss: 69.7775 - val_mae: 6.5359 - val_mse: 69.7775\n",
      "Epoch 158/500\n",
      "162/162 [==============================] - 0s 110us/sample - loss: 9.9923 - mae: 2.4453 - mse: 9.9923 - val_loss: 61.5800 - val_mae: 5.6637 - val_mse: 61.5800\n",
      "Epoch 159/500\n",
      "162/162 [==============================] - 0s 119us/sample - loss: 6.8436 - mae: 2.1582 - mse: 6.8436 - val_loss: 65.0790 - val_mae: 6.1945 - val_mse: 65.0790\n",
      "Epoch 160/500\n",
      "162/162 [==============================] - 0s 122us/sample - loss: 13.2355 - mae: 3.0700 - mse: 13.2355 - val_loss: 57.4610 - val_mae: 5.2145 - val_mse: 57.4610\n",
      "Epoch 161/500\n",
      "162/162 [==============================] - 0s 125us/sample - loss: 5.5897 - mae: 1.9228 - mse: 5.5897 - val_loss: 59.9448 - val_mae: 5.3338 - val_mse: 59.9448\n",
      "Epoch 162/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 11.6118 - mae: 2.9283 - mse: 11.6118 - val_loss: 64.5936 - val_mae: 5.6548 - val_mse: 64.5936\n",
      "Epoch 163/500\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 9.6896 - mae: 2.5967 - mse: 9.6896 - val_loss: 63.2518 - val_mae: 5.5054 - val_mse: 63.2518\n",
      "Epoch 164/500\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 7.2679 - mae: 2.1911 - mse: 7.2679 - val_loss: 60.8167 - val_mae: 5.3740 - val_mse: 60.8167\n",
      "Epoch 165/500\n",
      "162/162 [==============================] - 0s 130us/sample - loss: 9.0523 - mae: 2.5507 - mse: 9.0523 - val_loss: 58.2637 - val_mae: 5.2684 - val_mse: 58.2637\n",
      "Epoch 166/500\n",
      "162/162 [==============================] - 0s 113us/sample - loss: 5.2687 - mae: 1.8304 - mse: 5.2687 - val_loss: 61.7986 - val_mae: 5.5028 - val_mse: 61.7986\n",
      "Epoch 167/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 14.2964 - mae: 3.2816 - mse: 14.2964 - val_loss: 60.1709 - val_mae: 5.2840 - val_mse: 60.1709\n",
      "Epoch 168/500\n",
      "162/162 [==============================] - 0s 110us/sample - loss: 5.8241 - mae: 1.9338 - mse: 5.8241 - val_loss: 61.6463 - val_mae: 5.5481 - val_mse: 61.6463\n",
      "Epoch 169/500\n",
      "162/162 [==============================] - 0s 122us/sample - loss: 7.1021 - mae: 2.1225 - mse: 7.1021 - val_loss: 72.3246 - val_mae: 6.6996 - val_mse: 72.3246\n",
      "Epoch 170/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 10.5247 - mae: 2.6970 - mse: 10.5247 - val_loss: 60.8518 - val_mae: 5.7587 - val_mse: 60.8518\n",
      "Epoch 171/500\n",
      "162/162 [==============================] - 0s 120us/sample - loss: 5.5134 - mae: 1.8515 - mse: 5.5134 - val_loss: 65.9472 - val_mae: 6.1405 - val_mse: 65.9472\n",
      "Epoch 172/500\n",
      "162/162 [==============================] - 0s 114us/sample - loss: 11.9468 - mae: 3.0416 - mse: 11.9468 - val_loss: 57.4424 - val_mae: 5.1855 - val_mse: 57.4424\n",
      "Epoch 173/500\n",
      "162/162 [==============================] - 0s 111us/sample - loss: 4.0538 - mae: 1.5959 - mse: 4.0538 - val_loss: 58.4468 - val_mae: 5.4704 - val_mse: 58.4468\n",
      "Epoch 174/500\n",
      "162/162 [==============================] - 0s 123us/sample - loss: 14.3899 - mae: 3.3715 - mse: 14.3899 - val_loss: 73.0954 - val_mae: 6.8043 - val_mse: 73.0954\n",
      "Epoch 175/500\n",
      "162/162 [==============================] - 0s 112us/sample - loss: 10.5354 - mae: 2.7280 - mse: 10.5354 - val_loss: 56.6730 - val_mae: 5.2684 - val_mse: 56.6730\n",
      "Epoch 176/500\n",
      "162/162 [==============================] - 0s 115us/sample - loss: 3.7068 - mae: 1.4954 - mse: 3.7068 - val_loss: 59.7958 - val_mae: 5.4778 - val_mse: 59.7958\n",
      "Epoch 177/500\n",
      "162/162 [==============================] - 0s 113us/sample - loss: 10.5812 - mae: 2.7098 - mse: 10.5812 - val_loss: 62.7602 - val_mae: 6.0314 - val_mse: 62.7602\n",
      "Epoch 178/500\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 7.1841 - mae: 2.1427 - mse: 7.1841 - val_loss: 60.4738 - val_mae: 5.6742 - val_mse: 60.4738\n",
      "Epoch 179/500\n",
      "162/162 [==============================] - 0s 121us/sample - loss: 7.9332 - mae: 2.3656 - mse: 7.9332 - val_loss: 62.0135 - val_mae: 5.7650 - val_mse: 62.0135\n",
      "Epoch 180/500\n",
      "162/162 [==============================] - 0s 114us/sample - loss: 6.8945 - mae: 2.1146 - mse: 6.8945 - val_loss: 66.8984 - val_mae: 6.0589 - val_mse: 66.8984\n",
      "Epoch 181/500\n",
      "162/162 [==============================] - 0s 111us/sample - loss: 9.3618 - mae: 2.5206 - mse: 9.3618 - val_loss: 65.8517 - val_mae: 6.2272 - val_mse: 65.8517\n",
      "Epoch 182/500\n",
      "162/162 [==============================] - 0s 123us/sample - loss: 9.1239 - mae: 2.4733 - mse: 9.1239 - val_loss: 58.0145 - val_mae: 5.2088 - val_mse: 58.0145\n",
      "Epoch 183/500\n",
      "162/162 [==============================] - 0s 105us/sample - loss: 6.2737 - mae: 1.9849 - mse: 6.2737 - val_loss: 82.0239 - val_mae: 6.7539 - val_mse: 82.0239\n",
      "Epoch 184/500\n",
      "162/162 [==============================] - 0s 113us/sample - loss: 12.2198 - mae: 2.6392 - mse: 12.2198 - val_loss: 57.0584 - val_mae: 5.0914 - val_mse: 57.0584\n",
      "Epoch 185/500\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 3.0417 - mae: 1.3728 - mse: 3.0417 - val_loss: 62.2955 - val_mae: 5.8370 - val_mse: 62.2955\n",
      "Epoch 186/500\n",
      "162/162 [==============================] - 0s 124us/sample - loss: 15.0825 - mae: 3.4445 - mse: 15.0826 - val_loss: 57.8812 - val_mae: 5.2825 - val_mse: 57.8812\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 243 samples, validate on 81 samples\n",
      "Epoch 1/500\n",
      "243/243 [==============================] - 0s 2ms/sample - loss: 142.6436 - mae: 8.8687 - mse: 142.6436 - val_loss: 205.2060 - val_mae: 10.6690 - val_mse: 205.2060\n",
      "Epoch 2/500\n",
      "243/243 [==============================] - 0s 91us/sample - loss: 81.1007 - mae: 5.8858 - mse: 81.1006 - val_loss: 205.6845 - val_mae: 10.0977 - val_mse: 205.6845\n",
      "Epoch 3/500\n",
      "243/243 [==============================] - 0s 95us/sample - loss: 65.3203 - mae: 5.2507 - mse: 65.3203 - val_loss: 205.5521 - val_mae: 10.2093 - val_mse: 205.5521\n",
      "Epoch 4/500\n",
      "243/243 [==============================] - 0s 87us/sample - loss: 56.7963 - mae: 4.8983 - mse: 56.7963 - val_loss: 178.1421 - val_mae: 9.3335 - val_mse: 178.1421\n",
      "Epoch 5/500\n",
      "243/243 [==============================] - 0s 90us/sample - loss: 50.9255 - mae: 4.6083 - mse: 50.9255 - val_loss: 146.9184 - val_mae: 8.5333 - val_mse: 146.9184\n",
      "Epoch 6/500\n",
      "243/243 [==============================] - 0s 97us/sample - loss: 47.1200 - mae: 4.4226 - mse: 47.1200 - val_loss: 138.9147 - val_mae: 8.1279 - val_mse: 138.9147\n",
      "Epoch 7/500\n",
      "243/243 [==============================] - 0s 104us/sample - loss: 43.3048 - mae: 4.2106 - mse: 43.3048 - val_loss: 103.4535 - val_mae: 7.0464 - val_mse: 103.4535\n",
      "Epoch 8/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 90us/sample - loss: 37.4656 - mae: 3.9192 - mse: 37.4656 - val_loss: 115.7346 - val_mae: 7.3673 - val_mse: 115.7346\n",
      "Epoch 9/500\n",
      "243/243 [==============================] - 0s 97us/sample - loss: 34.6786 - mae: 3.8873 - mse: 34.6786 - val_loss: 93.1471 - val_mae: 6.6416 - val_mse: 93.1471\n",
      "Epoch 10/500\n",
      "243/243 [==============================] - 0s 97us/sample - loss: 31.4150 - mae: 3.6827 - mse: 31.4150 - val_loss: 80.8492 - val_mae: 6.1916 - val_mse: 80.8492\n",
      "Epoch 11/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 29.0701 - mae: 3.6948 - mse: 29.0701 - val_loss: 107.1250 - val_mae: 7.3860 - val_mse: 107.1250\n",
      "Epoch 12/500\n",
      "243/243 [==============================] - 0s 97us/sample - loss: 25.4407 - mae: 3.3976 - mse: 25.4407 - val_loss: 86.2072 - val_mae: 6.4090 - val_mse: 86.2072\n",
      "Epoch 13/500\n",
      "243/243 [==============================] - 0s 86us/sample - loss: 23.2778 - mae: 3.2401 - mse: 23.2778 - val_loss: 65.6837 - val_mae: 5.6095 - val_mse: 65.6837\n",
      "Epoch 14/500\n",
      "243/243 [==============================] - 0s 95us/sample - loss: 22.2104 - mae: 3.2889 - mse: 22.2104 - val_loss: 66.4989 - val_mae: 5.5735 - val_mse: 66.4989\n",
      "Epoch 15/500\n",
      "243/243 [==============================] - 0s 94us/sample - loss: 20.7099 - mae: 3.0990 - mse: 20.7099 - val_loss: 69.0513 - val_mae: 5.8228 - val_mse: 69.0513\n",
      "Epoch 16/500\n",
      "243/243 [==============================] - 0s 87us/sample - loss: 19.7815 - mae: 3.0191 - mse: 19.7815 - val_loss: 63.0405 - val_mae: 5.4396 - val_mse: 63.0405\n",
      "Epoch 17/500\n",
      "243/243 [==============================] - 0s 90us/sample - loss: 17.6501 - mae: 2.8912 - mse: 17.6501 - val_loss: 67.4473 - val_mae: 5.8573 - val_mse: 67.4473\n",
      "Epoch 18/500\n",
      "243/243 [==============================] - 0s 85us/sample - loss: 18.4651 - mae: 3.0838 - mse: 18.4651 - val_loss: 56.3917 - val_mae: 5.2374 - val_mse: 56.3917\n",
      "Epoch 19/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 15.8941 - mae: 2.7447 - mse: 15.8941 - val_loss: 55.6372 - val_mae: 5.1944 - val_mse: 55.6372\n",
      "Epoch 20/500\n",
      "243/243 [==============================] - 0s 83us/sample - loss: 16.5389 - mae: 2.7973 - mse: 16.5389 - val_loss: 71.5378 - val_mae: 6.1986 - val_mse: 71.5378\n",
      "Epoch 21/500\n",
      "243/243 [==============================] - 0s 88us/sample - loss: 16.8096 - mae: 2.8920 - mse: 16.8096 - val_loss: 48.0754 - val_mae: 4.8308 - val_mse: 48.0754\n",
      "Epoch 22/500\n",
      "243/243 [==============================] - 0s 84us/sample - loss: 15.0293 - mae: 2.6983 - mse: 15.0293 - val_loss: 55.4276 - val_mae: 5.2079 - val_mse: 55.4276\n",
      "Epoch 23/500\n",
      "243/243 [==============================] - 0s 91us/sample - loss: 14.6369 - mae: 2.7016 - mse: 14.6369 - val_loss: 49.2054 - val_mae: 4.9028 - val_mse: 49.2054\n",
      "Epoch 24/500\n",
      "243/243 [==============================] - 0s 93us/sample - loss: 14.0511 - mae: 2.6413 - mse: 14.0511 - val_loss: 45.5485 - val_mae: 4.6957 - val_mse: 45.5485\n",
      "Epoch 25/500\n",
      "243/243 [==============================] - 0s 91us/sample - loss: 12.8732 - mae: 2.5357 - mse: 12.8732 - val_loss: 45.1059 - val_mae: 4.7207 - val_mse: 45.1059\n",
      "Epoch 26/500\n",
      "243/243 [==============================] - 0s 88us/sample - loss: 13.1484 - mae: 2.5808 - mse: 13.1484 - val_loss: 58.4719 - val_mae: 5.5851 - val_mse: 58.4719\n",
      "Epoch 27/500\n",
      "243/243 [==============================] - 0s 84us/sample - loss: 13.8444 - mae: 2.6860 - mse: 13.8444 - val_loss: 40.1407 - val_mae: 4.4430 - val_mse: 40.1407\n",
      "Epoch 28/500\n",
      "243/243 [==============================] - 0s 86us/sample - loss: 12.5991 - mae: 2.5817 - mse: 12.5991 - val_loss: 43.6809 - val_mae: 4.7887 - val_mse: 43.6809\n",
      "Epoch 29/500\n",
      "243/243 [==============================] - 0s 88us/sample - loss: 12.1740 - mae: 2.5597 - mse: 12.1740 - val_loss: 51.9640 - val_mae: 5.2997 - val_mse: 51.9640\n",
      "Epoch 30/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 13.1080 - mae: 2.6672 - mse: 13.1080 - val_loss: 44.9778 - val_mae: 4.7760 - val_mse: 44.9778\n",
      "Epoch 31/500\n",
      "243/243 [==============================] - 0s 91us/sample - loss: 11.5649 - mae: 2.4815 - mse: 11.5649 - val_loss: 45.5728 - val_mae: 4.8944 - val_mse: 45.5728\n",
      "Epoch 32/500\n",
      "243/243 [==============================] - 0s 88us/sample - loss: 11.3636 - mae: 2.4332 - mse: 11.3636 - val_loss: 40.9902 - val_mae: 4.5643 - val_mse: 40.9902\n",
      "Epoch 33/500\n",
      "243/243 [==============================] - 0s 88us/sample - loss: 10.9825 - mae: 2.4313 - mse: 10.9825 - val_loss: 35.9522 - val_mae: 4.2186 - val_mse: 35.9522\n",
      "Epoch 34/500\n",
      "243/243 [==============================] - 0s 91us/sample - loss: 12.1580 - mae: 2.5818 - mse: 12.1580 - val_loss: 40.5149 - val_mae: 4.5839 - val_mse: 40.5149\n",
      "Epoch 35/500\n",
      "243/243 [==============================] - 0s 79us/sample - loss: 10.9675 - mae: 2.4479 - mse: 10.9675 - val_loss: 40.5143 - val_mae: 4.5760 - val_mse: 40.5143\n",
      "Epoch 36/500\n",
      "243/243 [==============================] - 0s 98us/sample - loss: 9.9314 - mae: 2.3314 - mse: 9.9314 - val_loss: 41.3061 - val_mae: 4.7173 - val_mse: 41.3061\n",
      "Epoch 37/500\n",
      "243/243 [==============================] - 0s 91us/sample - loss: 10.7654 - mae: 2.3834 - mse: 10.7654 - val_loss: 47.5022 - val_mae: 5.1573 - val_mse: 47.5022\n",
      "Epoch 38/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 9.5409 - mae: 2.2543 - mse: 9.5409 - val_loss: 34.9523 - val_mae: 4.1778 - val_mse: 34.9523\n",
      "Epoch 39/500\n",
      "243/243 [==============================] - 0s 101us/sample - loss: 9.4390 - mae: 2.2433 - mse: 9.4390 - val_loss: 42.8719 - val_mae: 4.8206 - val_mse: 42.8719\n",
      "Epoch 40/500\n",
      "243/243 [==============================] - 0s 85us/sample - loss: 9.9100 - mae: 2.3080 - mse: 9.9100 - val_loss: 43.9028 - val_mae: 4.9794 - val_mse: 43.9028\n",
      "Epoch 41/500\n",
      "243/243 [==============================] - 0s 95us/sample - loss: 9.3580 - mae: 2.2481 - mse: 9.3580 - val_loss: 34.5350 - val_mae: 4.3003 - val_mse: 34.5350\n",
      "Epoch 42/500\n",
      "243/243 [==============================] - 0s 88us/sample - loss: 10.6778 - mae: 2.4106 - mse: 10.6778 - val_loss: 34.9624 - val_mae: 4.1880 - val_mse: 34.9624\n",
      "Epoch 43/500\n",
      "243/243 [==============================] - 0s 92us/sample - loss: 8.5639 - mae: 2.1766 - mse: 8.5639 - val_loss: 31.7393 - val_mae: 4.0035 - val_mse: 31.7393\n",
      "Epoch 44/500\n",
      "243/243 [==============================] - 0s 83us/sample - loss: 9.7824 - mae: 2.3792 - mse: 9.7824 - val_loss: 34.4023 - val_mae: 4.2094 - val_mse: 34.4023\n",
      "Epoch 45/500\n",
      "243/243 [==============================] - 0s 87us/sample - loss: 8.6966 - mae: 2.1411 - mse: 8.6966 - val_loss: 41.0289 - val_mae: 4.7275 - val_mse: 41.0289\n",
      "Epoch 46/500\n",
      "243/243 [==============================] - 0s 94us/sample - loss: 8.5174 - mae: 2.1585 - mse: 8.5174 - val_loss: 43.0725 - val_mae: 4.8926 - val_mse: 43.0725\n",
      "Epoch 47/500\n",
      "243/243 [==============================] - 0s 94us/sample - loss: 9.6372 - mae: 2.3326 - mse: 9.6372 - val_loss: 33.7160 - val_mae: 4.1752 - val_mse: 33.7160\n",
      "Epoch 48/500\n",
      "243/243 [==============================] - 0s 85us/sample - loss: 9.3061 - mae: 2.2867 - mse: 9.3061 - val_loss: 37.5141 - val_mae: 4.4571 - val_mse: 37.5141\n",
      "Epoch 49/500\n",
      "243/243 [==============================] - 0s 94us/sample - loss: 7.6125 - mae: 2.0788 - mse: 7.6125 - val_loss: 32.4582 - val_mae: 4.0174 - val_mse: 32.4582\n",
      "Epoch 50/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 8.8471 - mae: 2.2125 - mse: 8.8471 - val_loss: 31.4372 - val_mae: 3.9657 - val_mse: 31.4372\n",
      "Epoch 51/500\n",
      "243/243 [==============================] - 0s 96us/sample - loss: 7.5263 - mae: 2.0060 - mse: 7.5263 - val_loss: 30.6959 - val_mae: 3.9664 - val_mse: 30.6959\n",
      "Epoch 52/500\n",
      "243/243 [==============================] - 0s 82us/sample - loss: 9.5160 - mae: 2.3452 - mse: 9.5160 - val_loss: 30.1305 - val_mae: 3.8987 - val_mse: 30.1305\n",
      "Epoch 53/500\n",
      "243/243 [==============================] - 0s 94us/sample - loss: 8.0921 - mae: 2.1100 - mse: 8.0921 - val_loss: 33.8050 - val_mae: 4.2402 - val_mse: 33.8050\n",
      "Epoch 54/500\n",
      "243/243 [==============================] - 0s 91us/sample - loss: 7.6912 - mae: 2.0554 - mse: 7.6912 - val_loss: 32.0882 - val_mae: 4.0847 - val_mse: 32.0882\n",
      "Epoch 55/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 7.8907 - mae: 2.1438 - mse: 7.8907 - val_loss: 26.8096 - val_mae: 3.6257 - val_mse: 26.8096\n",
      "Epoch 56/500\n",
      "243/243 [==============================] - 0s 92us/sample - loss: 7.9228 - mae: 2.1327 - mse: 7.9228 - val_loss: 32.1740 - val_mae: 4.0788 - val_mse: 32.1740\n",
      "Epoch 57/500\n",
      "243/243 [==============================] - 0s 92us/sample - loss: 8.2661 - mae: 2.1671 - mse: 8.2661 - val_loss: 27.1099 - val_mae: 3.6337 - val_mse: 27.1099\n",
      "Epoch 58/500\n",
      "243/243 [==============================] - 0s 86us/sample - loss: 7.9595 - mae: 2.1156 - mse: 7.9595 - val_loss: 31.8881 - val_mae: 4.0643 - val_mse: 31.8881\n",
      "Epoch 59/500\n",
      "243/243 [==============================] - 0s 98us/sample - loss: 7.2179 - mae: 2.0447 - mse: 7.2179 - val_loss: 30.5610 - val_mae: 3.9915 - val_mse: 30.5610\n",
      "Epoch 60/500\n",
      "243/243 [==============================] - 0s 94us/sample - loss: 7.3800 - mae: 2.0811 - mse: 7.3800 - val_loss: 40.4824 - val_mae: 4.7903 - val_mse: 40.4824\n",
      "Epoch 61/500\n",
      "243/243 [==============================] - 0s 92us/sample - loss: 7.7624 - mae: 2.0762 - mse: 7.7624 - val_loss: 30.5053 - val_mae: 3.9606 - val_mse: 30.5053\n",
      "Epoch 62/500\n",
      "243/243 [==============================] - 0s 110us/sample - loss: 8.0314 - mae: 2.1329 - mse: 8.0314 - val_loss: 24.6878 - val_mae: 3.5480 - val_mse: 24.6878\n",
      "Epoch 63/500\n",
      "243/243 [==============================] - 0s 107us/sample - loss: 6.7101 - mae: 1.9312 - mse: 6.7101 - val_loss: 29.5408 - val_mae: 3.8603 - val_mse: 29.5408\n",
      "Epoch 64/500\n",
      "243/243 [==============================] - 0s 117us/sample - loss: 7.0025 - mae: 1.9917 - mse: 7.0025 - val_loss: 29.6010 - val_mae: 4.0374 - val_mse: 29.6010\n",
      "Epoch 65/500\n",
      "243/243 [==============================] - 0s 107us/sample - loss: 8.0065 - mae: 2.1437 - mse: 8.0065 - val_loss: 26.2644 - val_mae: 3.5562 - val_mse: 26.2644\n",
      "Epoch 66/500\n",
      "243/243 [==============================] - 0s 110us/sample - loss: 6.2169 - mae: 1.8698 - mse: 6.2169 - val_loss: 28.9257 - val_mae: 3.8829 - val_mse: 28.9257\n",
      "Epoch 67/500\n",
      "243/243 [==============================] - 0s 96us/sample - loss: 7.4385 - mae: 2.0919 - mse: 7.4385 - val_loss: 24.7720 - val_mae: 3.4160 - val_mse: 24.7720\n",
      "Epoch 68/500\n",
      "243/243 [==============================] - 0s 109us/sample - loss: 6.4608 - mae: 1.9255 - mse: 6.4608 - val_loss: 40.5815 - val_mae: 4.7430 - val_mse: 40.5815\n",
      "Epoch 69/500\n",
      "243/243 [==============================] - 0s 113us/sample - loss: 7.0795 - mae: 2.0403 - mse: 7.0795 - val_loss: 25.3663 - val_mae: 3.4881 - val_mse: 25.3663\n",
      "Epoch 70/500\n",
      "243/243 [==============================] - 0s 109us/sample - loss: 6.4592 - mae: 1.8946 - mse: 6.4592 - val_loss: 28.7704 - val_mae: 3.8106 - val_mse: 28.7704\n",
      "Epoch 71/500\n",
      "243/243 [==============================] - 0s 101us/sample - loss: 7.6975 - mae: 2.1339 - mse: 7.6975 - val_loss: 26.9872 - val_mae: 3.6873 - val_mse: 26.9872\n",
      "Epoch 72/500\n",
      "243/243 [==============================] - 0s 110us/sample - loss: 5.6137 - mae: 1.7802 - mse: 5.6137 - val_loss: 32.8541 - val_mae: 4.1932 - val_mse: 32.8541\n",
      "Epoch 73/500\n",
      "243/243 [==============================] - 0s 96us/sample - loss: 7.4307 - mae: 2.0853 - mse: 7.4307 - val_loss: 30.5598 - val_mae: 3.9562 - val_mse: 30.5598\n",
      "Epoch 74/500\n",
      "243/243 [==============================] - 0s 110us/sample - loss: 5.6090 - mae: 1.7876 - mse: 5.6090 - val_loss: 29.2066 - val_mae: 3.8594 - val_mse: 29.2066\n",
      "Epoch 75/500\n",
      "243/243 [==============================] - 0s 118us/sample - loss: 7.0325 - mae: 2.0452 - mse: 7.0325 - val_loss: 30.6757 - val_mae: 4.0531 - val_mse: 30.6757\n",
      "Epoch 76/500\n",
      "243/243 [==============================] - 0s 84us/sample - loss: 5.9776 - mae: 1.8700 - mse: 5.9776 - val_loss: 24.7151 - val_mae: 3.4707 - val_mse: 24.7151\n",
      "Epoch 77/500\n",
      "243/243 [==============================] - 0s 99us/sample - loss: 5.6703 - mae: 1.8163 - mse: 5.6703 - val_loss: 26.3347 - val_mae: 3.5956 - val_mse: 26.3347\n",
      "Epoch 78/500\n",
      "243/243 [==============================] - 0s 101us/sample - loss: 6.2216 - mae: 1.9217 - mse: 6.2216 - val_loss: 26.5847 - val_mae: 3.6975 - val_mse: 26.5847\n",
      "Epoch 79/500\n",
      "243/243 [==============================] - 0s 87us/sample - loss: 6.9633 - mae: 2.0613 - mse: 6.9633 - val_loss: 30.8083 - val_mae: 4.1052 - val_mse: 30.8083\n",
      "Epoch 80/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 5.3942 - mae: 1.7701 - mse: 5.3942 - val_loss: 25.5674 - val_mae: 3.5465 - val_mse: 25.5674\n",
      "Epoch 81/500\n",
      "243/243 [==============================] - 0s 85us/sample - loss: 6.5752 - mae: 1.9645 - mse: 6.5752 - val_loss: 25.1885 - val_mae: 3.5167 - val_mse: 25.1885\n",
      "Epoch 82/500\n",
      "243/243 [==============================] - 0s 93us/sample - loss: 5.4178 - mae: 1.7618 - mse: 5.4178 - val_loss: 25.3617 - val_mae: 3.6012 - val_mse: 25.3617\n",
      "Epoch 83/500\n",
      "243/243 [==============================] - 0s 88us/sample - loss: 6.0570 - mae: 1.9138 - mse: 6.0570 - val_loss: 24.6699 - val_mae: 3.5938 - val_mse: 24.6699\n",
      "Epoch 84/500\n",
      "243/243 [==============================] - 0s 86us/sample - loss: 6.5989 - mae: 1.9695 - mse: 6.5989 - val_loss: 27.6594 - val_mae: 3.8457 - val_mse: 27.6594\n",
      "Epoch 85/500\n",
      "243/243 [==============================] - 0s 88us/sample - loss: 5.7394 - mae: 1.8252 - mse: 5.7394 - val_loss: 30.7076 - val_mae: 4.0520 - val_mse: 30.7076\n",
      "Epoch 86/500\n",
      "243/243 [==============================] - 0s 88us/sample - loss: 5.8665 - mae: 1.8706 - mse: 5.8665 - val_loss: 25.3280 - val_mae: 3.5307 - val_mse: 25.3280\n",
      "Epoch 87/500\n",
      "243/243 [==============================] - 0s 90us/sample - loss: 5.1523 - mae: 1.7432 - mse: 5.1523 - val_loss: 27.7162 - val_mae: 3.8329 - val_mse: 27.7162\n",
      "Epoch 88/500\n",
      "243/243 [==============================] - 0s 92us/sample - loss: 5.9591 - mae: 1.8720 - mse: 5.9591 - val_loss: 25.0189 - val_mae: 3.6088 - val_mse: 25.0189\n",
      "Epoch 89/500\n",
      "243/243 [==============================] - 0s 93us/sample - loss: 5.7301 - mae: 1.8356 - mse: 5.7301 - val_loss: 25.8825 - val_mae: 3.6903 - val_mse: 25.8825\n",
      "Epoch 90/500\n",
      "243/243 [==============================] - 0s 91us/sample - loss: 5.8983 - mae: 1.8558 - mse: 5.8983 - val_loss: 24.2245 - val_mae: 3.5318 - val_mse: 24.2245\n",
      "Epoch 91/500\n",
      "243/243 [==============================] - 0s 90us/sample - loss: 5.5970 - mae: 1.7925 - mse: 5.5970 - val_loss: 28.0094 - val_mae: 3.9211 - val_mse: 28.0094\n",
      "Epoch 92/500\n",
      "243/243 [==============================] - 0s 86us/sample - loss: 4.7169 - mae: 1.6794 - mse: 4.7169 - val_loss: 22.1408 - val_mae: 3.2423 - val_mse: 22.1408\n",
      "Epoch 93/500\n",
      "243/243 [==============================] - 0s 98us/sample - loss: 4.5433 - mae: 1.6656 - mse: 4.5433 - val_loss: 31.0564 - val_mae: 4.2401 - val_mse: 31.0564\n",
      "Epoch 94/500\n",
      "243/243 [==============================] - 0s 93us/sample - loss: 5.6028 - mae: 1.8135 - mse: 5.6028 - val_loss: 23.1790 - val_mae: 3.4523 - val_mse: 23.1790\n",
      "Epoch 95/500\n",
      "243/243 [==============================] - 0s 92us/sample - loss: 5.5364 - mae: 1.8194 - mse: 5.5364 - val_loss: 21.6465 - val_mae: 3.1884 - val_mse: 21.6465\n",
      "Epoch 96/500\n",
      "243/243 [==============================] - 0s 86us/sample - loss: 4.8766 - mae: 1.7074 - mse: 4.8766 - val_loss: 22.2514 - val_mae: 3.3175 - val_mse: 22.2514\n",
      "Epoch 97/500\n",
      "243/243 [==============================] - 0s 86us/sample - loss: 5.6705 - mae: 1.8444 - mse: 5.6705 - val_loss: 26.7754 - val_mae: 3.7990 - val_mse: 26.7754\n",
      "Epoch 98/500\n",
      "243/243 [==============================] - 0s 87us/sample - loss: 5.3433 - mae: 1.8195 - mse: 5.3433 - val_loss: 22.6142 - val_mae: 3.3392 - val_mse: 22.6142\n",
      "Epoch 99/500\n",
      "243/243 [==============================] - 0s 88us/sample - loss: 4.9262 - mae: 1.7272 - mse: 4.9262 - val_loss: 23.4445 - val_mae: 3.4113 - val_mse: 23.4445\n",
      "Epoch 100/500\n",
      "243/243 [==============================] - 0s 94us/sample - loss: 5.3012 - mae: 1.7762 - mse: 5.3012 - val_loss: 25.8681 - val_mae: 3.6880 - val_mse: 25.8681\n",
      "Epoch 101/500\n",
      "243/243 [==============================] - 0s 92us/sample - loss: 4.7384 - mae: 1.6663 - mse: 4.7384 - val_loss: 23.5487 - val_mae: 3.4551 - val_mse: 23.5487\n",
      "Epoch 102/500\n",
      "243/243 [==============================] - 0s 90us/sample - loss: 5.8298 - mae: 1.9149 - mse: 5.8298 - val_loss: 21.3816 - val_mae: 3.2181 - val_mse: 21.3816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/500\n",
      "243/243 [==============================] - 0s 93us/sample - loss: 4.5410 - mae: 1.6163 - mse: 4.5410 - val_loss: 20.0999 - val_mae: 3.1860 - val_mse: 20.0999\n",
      "Epoch 104/500\n",
      "243/243 [==============================] - 0s 85us/sample - loss: 5.7151 - mae: 1.8628 - mse: 5.7151 - val_loss: 21.7200 - val_mae: 3.3009 - val_mse: 21.7200\n",
      "Epoch 105/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 4.5253 - mae: 1.6564 - mse: 4.5253 - val_loss: 21.4053 - val_mae: 3.2192 - val_mse: 21.4053\n",
      "Epoch 106/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 4.4544 - mae: 1.6546 - mse: 4.4544 - val_loss: 21.7496 - val_mae: 3.3177 - val_mse: 21.7496\n",
      "Epoch 107/500\n",
      "243/243 [==============================] - 0s 87us/sample - loss: 6.1349 - mae: 1.9638 - mse: 6.1349 - val_loss: 21.0335 - val_mae: 3.2419 - val_mse: 21.0335\n",
      "Epoch 108/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 4.2741 - mae: 1.5890 - mse: 4.2741 - val_loss: 22.7193 - val_mae: 3.3379 - val_mse: 22.7193\n",
      "Epoch 109/500\n",
      "243/243 [==============================] - 0s 86us/sample - loss: 4.5625 - mae: 1.6577 - mse: 4.5625 - val_loss: 25.3999 - val_mae: 3.6162 - val_mse: 25.3999\n",
      "Epoch 110/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 4.6807 - mae: 1.6914 - mse: 4.6807 - val_loss: 29.0389 - val_mae: 4.0506 - val_mse: 29.0389\n",
      "Epoch 111/500\n",
      "243/243 [==============================] - 0s 94us/sample - loss: 4.8695 - mae: 1.7176 - mse: 4.8695 - val_loss: 21.6415 - val_mae: 3.2878 - val_mse: 21.6415\n",
      "Epoch 112/500\n",
      "243/243 [==============================] - ETA: 0s - loss: 3.5264 - mae: 1.3249 - mse: 3.526 - 0s 92us/sample - loss: 4.6938 - mae: 1.6677 - mse: 4.6938 - val_loss: 29.1065 - val_mae: 4.0526 - val_mse: 29.1065\n",
      "Epoch 113/500\n",
      "243/243 [==============================] - 0s 86us/sample - loss: 5.0129 - mae: 1.7188 - mse: 5.0129 - val_loss: 22.5006 - val_mae: 3.3666 - val_mse: 22.5006\n",
      "Epoch 114/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 4.0061 - mae: 1.5592 - mse: 4.0061 - val_loss: 20.2441 - val_mae: 3.1122 - val_mse: 20.2441\n",
      "Epoch 115/500\n",
      "243/243 [==============================] - 0s 94us/sample - loss: 4.6513 - mae: 1.6939 - mse: 4.6513 - val_loss: 21.0923 - val_mae: 3.2020 - val_mse: 21.0923\n",
      "Epoch 116/500\n",
      "243/243 [==============================] - 0s 95us/sample - loss: 5.1066 - mae: 1.7424 - mse: 5.1066 - val_loss: 28.4822 - val_mae: 3.9927 - val_mse: 28.4822\n",
      "Epoch 117/500\n",
      "243/243 [==============================] - 0s 86us/sample - loss: 4.0007 - mae: 1.5621 - mse: 4.0007 - val_loss: 20.9861 - val_mae: 3.2460 - val_mse: 20.9861\n",
      "Epoch 118/500\n",
      "243/243 [==============================] - 0s 87us/sample - loss: 4.7499 - mae: 1.7422 - mse: 4.7499 - val_loss: 20.3249 - val_mae: 3.1241 - val_mse: 20.3249\n",
      "Epoch 119/500\n",
      "243/243 [==============================] - 0s 83us/sample - loss: 4.0432 - mae: 1.5784 - mse: 4.0432 - val_loss: 27.5054 - val_mae: 3.9295 - val_mse: 27.5054\n",
      "Epoch 120/500\n",
      "243/243 [==============================] - 0s 88us/sample - loss: 5.0140 - mae: 1.7571 - mse: 5.0140 - val_loss: 22.6633 - val_mae: 3.4384 - val_mse: 22.6633\n",
      "Epoch 121/500\n",
      "243/243 [==============================] - 0s 92us/sample - loss: 3.7142 - mae: 1.4856 - mse: 3.7142 - val_loss: 20.1508 - val_mae: 3.1342 - val_mse: 20.1508\n",
      "Epoch 122/500\n",
      "243/243 [==============================] - 0s 90us/sample - loss: 5.0017 - mae: 1.7208 - mse: 5.0017 - val_loss: 22.1416 - val_mae: 3.3715 - val_mse: 22.1416\n",
      "Epoch 123/500\n",
      "243/243 [==============================] - 0s 93us/sample - loss: 4.2094 - mae: 1.6072 - mse: 4.2094 - val_loss: 21.9257 - val_mae: 3.3235 - val_mse: 21.9257\n",
      "Epoch 124/500\n",
      "243/243 [==============================] - 0s 87us/sample - loss: 4.2646 - mae: 1.6048 - mse: 4.2646 - val_loss: 24.5306 - val_mae: 3.6096 - val_mse: 24.5306\n",
      "Epoch 125/500\n",
      "243/243 [==============================] - 0s 90us/sample - loss: 5.1095 - mae: 1.7851 - mse: 5.1095 - val_loss: 22.7562 - val_mae: 3.4601 - val_mse: 22.7562\n",
      "Epoch 126/500\n",
      "243/243 [==============================] - 0s 86us/sample - loss: 3.8241 - mae: 1.5375 - mse: 3.8241 - val_loss: 22.9694 - val_mae: 3.4080 - val_mse: 22.9694\n",
      "Epoch 127/500\n",
      "243/243 [==============================] - 0s 90us/sample - loss: 3.6699 - mae: 1.5026 - mse: 3.6699 - val_loss: 24.4230 - val_mae: 3.6572 - val_mse: 24.4230\n",
      "Epoch 128/500\n",
      "243/243 [==============================] - 0s 93us/sample - loss: 4.1136 - mae: 1.5863 - mse: 4.1136 - val_loss: 20.2381 - val_mae: 3.1251 - val_mse: 20.2381\n",
      "Epoch 129/500\n",
      "243/243 [==============================] - 0s 87us/sample - loss: 4.8796 - mae: 1.7349 - mse: 4.8796 - val_loss: 21.0680 - val_mae: 3.2232 - val_mse: 21.0680\n",
      "Epoch 130/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 4.0366 - mae: 1.5959 - mse: 4.0366 - val_loss: 25.9746 - val_mae: 3.8247 - val_mse: 25.9746\n",
      "Epoch 131/500\n",
      "243/243 [==============================] - 0s 88us/sample - loss: 3.7858 - mae: 1.5356 - mse: 3.7858 - val_loss: 20.1536 - val_mae: 3.1155 - val_mse: 20.1535\n",
      "Epoch 132/500\n",
      "243/243 [==============================] - 0s 90us/sample - loss: 5.0128 - mae: 1.7551 - mse: 5.0128 - val_loss: 23.5838 - val_mae: 3.5504 - val_mse: 23.5838\n",
      "Epoch 133/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 4.3057 - mae: 1.6596 - mse: 4.3057 - val_loss: 21.1805 - val_mae: 3.2533 - val_mse: 21.1805\n",
      "Epoch 134/500\n",
      "243/243 [==============================] - 0s 93us/sample - loss: 3.5851 - mae: 1.4887 - mse: 3.5851 - val_loss: 21.3861 - val_mae: 3.2317 - val_mse: 21.3861\n",
      "Epoch 135/500\n",
      "243/243 [==============================] - 0s 94us/sample - loss: 3.7470 - mae: 1.4987 - mse: 3.7470 - val_loss: 22.2953 - val_mae: 3.3652 - val_mse: 22.2953\n",
      "Epoch 136/500\n",
      "243/243 [==============================] - 0s 91us/sample - loss: 4.8427 - mae: 1.7199 - mse: 4.8427 - val_loss: 23.9733 - val_mae: 3.5460 - val_mse: 23.9733\n",
      "Epoch 137/500\n",
      "243/243 [==============================] - 0s 94us/sample - loss: 4.1885 - mae: 1.6093 - mse: 4.1885 - val_loss: 22.5752 - val_mae: 3.3471 - val_mse: 22.5752\n",
      "Epoch 138/500\n",
      "243/243 [==============================] - 0s 90us/sample - loss: 3.1118 - mae: 1.3514 - mse: 3.1118 - val_loss: 22.0335 - val_mae: 3.4612 - val_mse: 22.0335\n",
      "Epoch 139/500\n",
      "243/243 [==============================] - 0s 92us/sample - loss: 4.3793 - mae: 1.6342 - mse: 4.3793 - val_loss: 22.7634 - val_mae: 3.4002 - val_mse: 22.7634\n",
      "Epoch 140/500\n",
      "243/243 [==============================] - 0s 101us/sample - loss: 4.6448 - mae: 1.6640 - mse: 4.6448 - val_loss: 20.4395 - val_mae: 3.2252 - val_mse: 20.4395\n",
      "Epoch 141/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 3.4514 - mae: 1.4276 - mse: 3.4514 - val_loss: 22.0597 - val_mae: 3.3329 - val_mse: 22.0597\n",
      "Epoch 142/500\n",
      "243/243 [==============================] - 0s 93us/sample - loss: 3.9501 - mae: 1.5946 - mse: 3.9501 - val_loss: 20.9503 - val_mae: 3.1767 - val_mse: 20.9503\n",
      "Epoch 143/500\n",
      "243/243 [==============================] - 0s 90us/sample - loss: 3.6580 - mae: 1.4771 - mse: 3.6580 - val_loss: 27.6450 - val_mae: 3.9483 - val_mse: 27.6450\n",
      "Epoch 144/500\n",
      "243/243 [==============================] - 0s 88us/sample - loss: 4.6707 - mae: 1.6856 - mse: 4.6707 - val_loss: 21.0764 - val_mae: 3.2450 - val_mse: 21.0764\n",
      "Epoch 145/500\n",
      "243/243 [==============================] - 0s 85us/sample - loss: 3.3370 - mae: 1.4104 - mse: 3.3370 - val_loss: 24.8885 - val_mae: 3.7379 - val_mse: 24.8885\n",
      "Epoch 146/500\n",
      "243/243 [==============================] - 0s 90us/sample - loss: 4.6908 - mae: 1.6841 - mse: 4.6908 - val_loss: 21.5943 - val_mae: 3.2648 - val_mse: 21.5943\n",
      "Epoch 147/500\n",
      "243/243 [==============================] - 0s 94us/sample - loss: 3.2160 - mae: 1.3861 - mse: 3.2160 - val_loss: 24.2118 - val_mae: 3.5148 - val_mse: 24.2118\n",
      "Epoch 148/500\n",
      "243/243 [==============================] - 0s 91us/sample - loss: 3.6802 - mae: 1.4845 - mse: 3.6802 - val_loss: 23.6019 - val_mae: 3.4834 - val_mse: 23.6019\n",
      "Epoch 149/500\n",
      "243/243 [==============================] - 0s 97us/sample - loss: 4.0178 - mae: 1.5640 - mse: 4.0178 - val_loss: 21.4788 - val_mae: 3.2293 - val_mse: 21.4788\n",
      "Epoch 150/500\n",
      "243/243 [==============================] - 0s 84us/sample - loss: 2.9590 - mae: 1.3451 - mse: 2.9590 - val_loss: 26.9315 - val_mae: 3.9402 - val_mse: 26.9315\n",
      "Epoch 151/500\n",
      "243/243 [==============================] - 0s 87us/sample - loss: 3.6386 - mae: 1.4845 - mse: 3.6386 - val_loss: 21.9607 - val_mae: 3.3004 - val_mse: 21.9607\n",
      "Epoch 152/500\n",
      "243/243 [==============================] - 0s 85us/sample - loss: 4.4943 - mae: 1.6740 - mse: 4.4943 - val_loss: 20.8319 - val_mae: 3.1726 - val_mse: 20.8319\n",
      "Epoch 153/500\n",
      "243/243 [==============================] - 0s 89us/sample - loss: 3.7425 - mae: 1.4839 - mse: 3.7425 - val_loss: 22.5462 - val_mae: 3.4146 - val_mse: 22.5462\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 325 samples, validate on 108 samples\n",
      "Epoch 1/500\n",
      "325/325 [==============================] - 0s 1ms/sample - loss: 576.7498 - mae: 18.4140 - mse: 576.7498 - val_loss: 364.2015 - val_mae: 15.0696 - val_mse: 364.2015\n",
      "Epoch 2/500\n",
      "325/325 [==============================] - 0s 118us/sample - loss: 135.4810 - mae: 8.5189 - mse: 135.4810 - val_loss: 314.1413 - val_mae: 13.9979 - val_mse: 314.1414\n",
      "Epoch 3/500\n",
      "325/325 [==============================] - 0s 113us/sample - loss: 112.9091 - mae: 7.7134 - mse: 112.9091 - val_loss: 269.7378 - val_mae: 13.0516 - val_mse: 269.7378\n",
      "Epoch 4/500\n",
      "325/325 [==============================] - 0s 113us/sample - loss: 97.6957 - mae: 7.3173 - mse: 97.6957 - val_loss: 227.2731 - val_mae: 11.5311 - val_mse: 227.2731\n",
      "Epoch 5/500\n",
      "325/325 [==============================] - 0s 86us/sample - loss: 84.7547 - mae: 6.7997 - mse: 84.7547 - val_loss: 196.1551 - val_mae: 10.3839 - val_mse: 196.1551\n",
      "Epoch 6/500\n",
      "325/325 [==============================] - 0s 74us/sample - loss: 75.5127 - mae: 6.4237 - mse: 75.5127 - val_loss: 193.5748 - val_mae: 11.1282 - val_mse: 193.5748\n",
      "Epoch 7/500\n",
      "325/325 [==============================] - 0s 83us/sample - loss: 61.9658 - mae: 5.7858 - mse: 61.9658 - val_loss: 132.5931 - val_mae: 8.4679 - val_mse: 132.5931\n",
      "Epoch 8/500\n",
      "325/325 [==============================] - 0s 73us/sample - loss: 47.1803 - mae: 4.9822 - mse: 47.1803 - val_loss: 121.9788 - val_mae: 7.6811 - val_mse: 121.9788\n",
      "Epoch 9/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 39.6421 - mae: 4.4967 - mse: 39.6421 - val_loss: 104.1964 - val_mae: 7.3199 - val_mse: 104.1964\n",
      "Epoch 10/500\n",
      "325/325 [==============================] - 0s 78us/sample - loss: 33.6094 - mae: 4.1128 - mse: 33.6094 - val_loss: 104.6777 - val_mae: 6.9891 - val_mse: 104.6777\n",
      "Epoch 11/500\n",
      "325/325 [==============================] - 0s 74us/sample - loss: 30.5839 - mae: 3.9304 - mse: 30.5839 - val_loss: 90.2306 - val_mae: 6.9512 - val_mse: 90.2306\n",
      "Epoch 12/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 27.4840 - mae: 3.7859 - mse: 27.4840 - val_loss: 85.1007 - val_mae: 6.6980 - val_mse: 85.1007\n",
      "Epoch 13/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 23.7600 - mae: 3.4931 - mse: 23.7600 - val_loss: 81.0274 - val_mae: 6.4082 - val_mse: 81.0275\n",
      "Epoch 14/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 23.1719 - mae: 3.4926 - mse: 23.1719 - val_loss: 92.4521 - val_mae: 6.6825 - val_mse: 92.4521\n",
      "Epoch 15/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 21.6836 - mae: 3.4326 - mse: 21.6836 - val_loss: 74.3745 - val_mae: 5.8442 - val_mse: 74.3745\n",
      "Epoch 16/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 18.8321 - mae: 3.1725 - mse: 18.8321 - val_loss: 69.4166 - val_mae: 5.7835 - val_mse: 69.4166\n",
      "Epoch 17/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 16.5507 - mae: 2.9633 - mse: 16.5507 - val_loss: 71.7252 - val_mae: 5.6389 - val_mse: 71.7252\n",
      "Epoch 18/500\n",
      "325/325 [==============================] - 0s 78us/sample - loss: 17.3644 - mae: 3.0829 - mse: 17.3644 - val_loss: 66.9344 - val_mae: 5.4432 - val_mse: 66.9344\n",
      "Epoch 19/500\n",
      "325/325 [==============================] - 0s 73us/sample - loss: 15.1266 - mae: 2.8356 - mse: 15.1266 - val_loss: 63.5879 - val_mae: 5.3956 - val_mse: 63.5879\n",
      "Epoch 20/500\n",
      "325/325 [==============================] - 0s 83us/sample - loss: 13.3745 - mae: 2.6560 - mse: 13.3745 - val_loss: 67.5094 - val_mae: 5.8361 - val_mse: 67.5094\n",
      "Epoch 21/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 13.9277 - mae: 2.7789 - mse: 13.9277 - val_loss: 69.6475 - val_mae: 5.8770 - val_mse: 69.6475\n",
      "Epoch 22/500\n",
      "325/325 [==============================] - 0s 74us/sample - loss: 13.5157 - mae: 2.7541 - mse: 13.5157 - val_loss: 57.2869 - val_mae: 5.1792 - val_mse: 57.2869\n",
      "Epoch 23/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 11.2544 - mae: 2.4841 - mse: 11.2544 - val_loss: 78.4680 - val_mae: 6.2173 - val_mse: 78.4680\n",
      "Epoch 24/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 10.9028 - mae: 2.4291 - mse: 10.9028 - val_loss: 57.3360 - val_mae: 5.1163 - val_mse: 57.3360\n",
      "Epoch 25/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 10.9213 - mae: 2.4722 - mse: 10.9213 - val_loss: 56.0575 - val_mae: 4.9699 - val_mse: 56.0574\n",
      "Epoch 26/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 10.8485 - mae: 2.4748 - mse: 10.8485 - val_loss: 66.3755 - val_mae: 5.5051 - val_mse: 66.3755\n",
      "Epoch 27/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 9.9908 - mae: 2.3532 - mse: 9.9908 - val_loss: 51.6834 - val_mae: 5.0538 - val_mse: 51.6834\n",
      "Epoch 28/500\n",
      "325/325 [==============================] - 0s 92us/sample - loss: 9.3179 - mae: 2.3182 - mse: 9.3179 - val_loss: 56.3317 - val_mae: 5.2225 - val_mse: 56.3317\n",
      "Epoch 29/500\n",
      "325/325 [==============================] - 0s 87us/sample - loss: 9.5548 - mae: 2.3185 - mse: 9.5548 - val_loss: 53.0241 - val_mae: 5.0490 - val_mse: 53.0241\n",
      "Epoch 30/500\n",
      "325/325 [==============================] - 0s 97us/sample - loss: 8.9962 - mae: 2.2135 - mse: 8.9962 - val_loss: 73.4589 - val_mae: 6.2325 - val_mse: 73.4589\n",
      "Epoch 31/500\n",
      "325/325 [==============================] - 0s 89us/sample - loss: 9.4220 - mae: 2.2645 - mse: 9.4220 - val_loss: 49.8518 - val_mae: 4.7408 - val_mse: 49.8518\n",
      "Epoch 32/500\n",
      "325/325 [==============================] - 0s 90us/sample - loss: 8.3136 - mae: 2.2219 - mse: 8.3136 - val_loss: 54.1814 - val_mae: 4.9885 - val_mse: 54.1814\n",
      "Epoch 33/500\n",
      "325/325 [==============================] - 0s 92us/sample - loss: 8.0758 - mae: 2.1549 - mse: 8.0758 - val_loss: 48.0532 - val_mae: 4.9454 - val_mse: 48.0532\n",
      "Epoch 34/500\n",
      "325/325 [==============================] - 0s 89us/sample - loss: 7.9240 - mae: 2.1089 - mse: 7.9240 - val_loss: 47.4473 - val_mae: 4.5768 - val_mse: 47.4473\n",
      "Epoch 35/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 7.6820 - mae: 2.1068 - mse: 7.6820 - val_loss: 59.2666 - val_mae: 5.4902 - val_mse: 59.2666\n",
      "Epoch 36/500\n",
      "325/325 [==============================] - 0s 90us/sample - loss: 8.0156 - mae: 2.1428 - mse: 8.0156 - val_loss: 43.0783 - val_mae: 4.3890 - val_mse: 43.0783\n",
      "Epoch 37/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 7.3302 - mae: 2.0642 - mse: 7.3302 - val_loss: 53.8950 - val_mae: 4.9400 - val_mse: 53.8950\n",
      "Epoch 38/500\n",
      "325/325 [==============================] - 0s 84us/sample - loss: 6.5429 - mae: 1.9522 - mse: 6.5429 - val_loss: 53.3732 - val_mae: 4.9410 - val_mse: 53.3732\n",
      "Epoch 39/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 8.3417 - mae: 2.2546 - mse: 8.3417 - val_loss: 42.0128 - val_mae: 4.3081 - val_mse: 42.0128\n",
      "Epoch 40/500\n",
      "325/325 [==============================] - 0s 83us/sample - loss: 6.4222 - mae: 1.9250 - mse: 6.4222 - val_loss: 41.4255 - val_mae: 4.3231 - val_mse: 41.4255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/500\n",
      "325/325 [==============================] - 0s 74us/sample - loss: 7.5226 - mae: 2.1589 - mse: 7.5226 - val_loss: 53.6464 - val_mae: 4.9440 - val_mse: 53.6464\n",
      "Epoch 42/500\n",
      "325/325 [==============================] - 0s 78us/sample - loss: 6.0883 - mae: 1.8758 - mse: 6.0883 - val_loss: 53.1973 - val_mae: 4.9397 - val_mse: 53.1973\n",
      "Epoch 43/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 7.5358 - mae: 2.1349 - mse: 7.5358 - val_loss: 48.2457 - val_mae: 4.5812 - val_mse: 48.2457\n",
      "Epoch 44/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 6.0812 - mae: 1.9316 - mse: 6.0812 - val_loss: 51.3871 - val_mae: 4.9866 - val_mse: 51.3871\n",
      "Epoch 45/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 7.1850 - mae: 2.0515 - mse: 7.1850 - val_loss: 44.5169 - val_mae: 4.3673 - val_mse: 44.5169\n",
      "Epoch 46/500\n",
      "325/325 [==============================] - 0s 83us/sample - loss: 5.0813 - mae: 1.7019 - mse: 5.0813 - val_loss: 47.7012 - val_mae: 4.5661 - val_mse: 47.7012\n",
      "Epoch 47/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 6.8158 - mae: 2.0605 - mse: 6.8158 - val_loss: 42.4467 - val_mae: 4.1603 - val_mse: 42.4467\n",
      "Epoch 48/500\n",
      "325/325 [==============================] - 0s 82us/sample - loss: 5.8957 - mae: 1.8770 - mse: 5.8957 - val_loss: 47.2677 - val_mae: 4.5317 - val_mse: 47.2677\n",
      "Epoch 49/500\n",
      "325/325 [==============================] - 0s 93us/sample - loss: 5.6534 - mae: 1.8650 - mse: 5.6534 - val_loss: 38.0740 - val_mae: 4.0208 - val_mse: 38.0740\n",
      "Epoch 50/500\n",
      "325/325 [==============================] - 0s 90us/sample - loss: 5.8799 - mae: 1.8711 - mse: 5.8799 - val_loss: 40.0480 - val_mae: 4.2581 - val_mse: 40.0480\n",
      "Epoch 51/500\n",
      "325/325 [==============================] - 0s 106us/sample - loss: 4.9744 - mae: 1.7327 - mse: 4.9743 - val_loss: 43.5425 - val_mae: 4.7758 - val_mse: 43.5425\n",
      "Epoch 52/500\n",
      "325/325 [==============================] - 0s 90us/sample - loss: 6.4183 - mae: 1.9063 - mse: 6.4183 - val_loss: 39.2257 - val_mae: 4.2334 - val_mse: 39.2257\n",
      "Epoch 53/500\n",
      "325/325 [==============================] - 0s 98us/sample - loss: 6.2446 - mae: 1.9564 - mse: 6.2446 - val_loss: 39.4584 - val_mae: 4.1540 - val_mse: 39.4584\n",
      "Epoch 54/500\n",
      "325/325 [==============================] - 0s 114us/sample - loss: 5.3325 - mae: 1.7988 - mse: 5.3325 - val_loss: 53.7525 - val_mae: 5.0012 - val_mse: 53.7525\n",
      "Epoch 55/500\n",
      "325/325 [==============================] - 0s 129us/sample - loss: 5.1710 - mae: 1.7722 - mse: 5.1710 - val_loss: 38.4980 - val_mae: 4.2154 - val_mse: 38.4980\n",
      "Epoch 56/500\n",
      "325/325 [==============================] - 0s 123us/sample - loss: 5.7365 - mae: 1.8587 - mse: 5.7365 - val_loss: 37.1387 - val_mae: 4.0628 - val_mse: 37.1387\n",
      "Epoch 57/500\n",
      "325/325 [==============================] - 0s 107us/sample - loss: 5.4821 - mae: 1.8306 - mse: 5.4821 - val_loss: 41.5953 - val_mae: 4.1385 - val_mse: 41.5953\n",
      "Epoch 58/500\n",
      "325/325 [==============================] - 0s 93us/sample - loss: 5.9902 - mae: 1.9273 - mse: 5.9902 - val_loss: 46.3324 - val_mae: 4.5013 - val_mse: 46.3324\n",
      "Epoch 59/500\n",
      "325/325 [==============================] - 0s 104us/sample - loss: 4.6616 - mae: 1.6878 - mse: 4.6616 - val_loss: 41.7812 - val_mae: 4.1182 - val_mse: 41.7812\n",
      "Epoch 60/500\n",
      "325/325 [==============================] - 0s 98us/sample - loss: 4.7639 - mae: 1.7128 - mse: 4.7639 - val_loss: 40.6010 - val_mae: 4.0903 - val_mse: 40.6010\n",
      "Epoch 61/500\n",
      "325/325 [==============================] - 0s 92us/sample - loss: 6.0783 - mae: 1.9254 - mse: 6.0783 - val_loss: 36.6271 - val_mae: 3.8772 - val_mse: 36.6271\n",
      "Epoch 62/500\n",
      "325/325 [==============================] - 0s 101us/sample - loss: 4.9913 - mae: 1.7852 - mse: 4.9913 - val_loss: 39.8549 - val_mae: 3.9986 - val_mse: 39.8549\n",
      "Epoch 63/500\n",
      "325/325 [==============================] - 0s 91us/sample - loss: 5.3451 - mae: 1.8331 - mse: 5.3451 - val_loss: 38.9358 - val_mae: 3.9187 - val_mse: 38.9358\n",
      "Epoch 64/500\n",
      "325/325 [==============================] - 0s 92us/sample - loss: 4.9451 - mae: 1.7530 - mse: 4.9451 - val_loss: 41.1874 - val_mae: 4.2692 - val_mse: 41.1874\n",
      "Epoch 65/500\n",
      "325/325 [==============================] - 0s 82us/sample - loss: 5.1905 - mae: 1.7725 - mse: 5.1905 - val_loss: 38.5797 - val_mae: 4.1519 - val_mse: 38.5797\n",
      "Epoch 66/500\n",
      "325/325 [==============================] - 0s 83us/sample - loss: 4.6241 - mae: 1.6830 - mse: 4.6241 - val_loss: 49.1130 - val_mae: 4.6548 - val_mse: 49.1130\n",
      "Epoch 67/500\n",
      "325/325 [==============================] - 0s 83us/sample - loss: 5.5951 - mae: 1.8413 - mse: 5.5951 - val_loss: 36.9782 - val_mae: 3.8193 - val_mse: 36.9782\n",
      "Epoch 68/500\n",
      "325/325 [==============================] - 0s 87us/sample - loss: 5.3228 - mae: 1.8300 - mse: 5.3228 - val_loss: 40.8905 - val_mae: 4.0835 - val_mse: 40.8905\n",
      "Epoch 69/500\n",
      "325/325 [==============================] - 0s 91us/sample - loss: 4.6447 - mae: 1.7228 - mse: 4.6447 - val_loss: 34.5523 - val_mae: 3.7315 - val_mse: 34.5523\n",
      "Epoch 70/500\n",
      "325/325 [==============================] - 0s 84us/sample - loss: 5.2549 - mae: 1.8369 - mse: 5.2549 - val_loss: 35.0722 - val_mae: 3.9403 - val_mse: 35.0722\n",
      "Epoch 71/500\n",
      "325/325 [==============================] - 0s 93us/sample - loss: 5.3656 - mae: 1.8000 - mse: 5.3656 - val_loss: 35.0980 - val_mae: 3.7108 - val_mse: 35.0980\n",
      "Epoch 72/500\n",
      "325/325 [==============================] - 0s 93us/sample - loss: 4.7693 - mae: 1.7524 - mse: 4.7693 - val_loss: 48.9143 - val_mae: 4.7685 - val_mse: 48.9143\n",
      "Epoch 73/500\n",
      "325/325 [==============================] - 0s 80us/sample - loss: 4.3921 - mae: 1.6480 - mse: 4.3921 - val_loss: 38.0579 - val_mae: 4.0655 - val_mse: 38.0579\n",
      "Epoch 74/500\n",
      "325/325 [==============================] - 0s 102us/sample - loss: 5.2362 - mae: 1.7993 - mse: 5.2362 - val_loss: 44.1898 - val_mae: 4.3468 - val_mse: 44.1898\n",
      "Epoch 75/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 4.8369 - mae: 1.7117 - mse: 4.8369 - val_loss: 37.9807 - val_mae: 3.9781 - val_mse: 37.9807\n",
      "Epoch 76/500\n",
      "325/325 [==============================] - 0s 101us/sample - loss: 4.7003 - mae: 1.7168 - mse: 4.7003 - val_loss: 40.1307 - val_mae: 4.2748 - val_mse: 40.1307\n",
      "Epoch 77/500\n",
      "325/325 [==============================] - 0s 92us/sample - loss: 4.9859 - mae: 1.7603 - mse: 4.9859 - val_loss: 40.1505 - val_mae: 4.1013 - val_mse: 40.1505\n",
      "Epoch 78/500\n",
      "325/325 [==============================] - 0s 103us/sample - loss: 3.9959 - mae: 1.5815 - mse: 3.9959 - val_loss: 34.7177 - val_mae: 3.9414 - val_mse: 34.7177\n",
      "Epoch 79/500\n",
      "325/325 [==============================] - 0s 99us/sample - loss: 4.2226 - mae: 1.5897 - mse: 4.2226 - val_loss: 33.4799 - val_mae: 3.7216 - val_mse: 33.4799\n",
      "Epoch 80/500\n",
      "325/325 [==============================] - 0s 110us/sample - loss: 5.7159 - mae: 1.8263 - mse: 5.7159 - val_loss: 34.9316 - val_mae: 3.6741 - val_mse: 34.9316\n",
      "Epoch 81/500\n",
      "325/325 [==============================] - 0s 94us/sample - loss: 3.5644 - mae: 1.5061 - mse: 3.5644 - val_loss: 34.8098 - val_mae: 3.8197 - val_mse: 34.8098\n",
      "Epoch 82/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 5.0789 - mae: 1.7603 - mse: 5.0789 - val_loss: 34.9073 - val_mae: 3.7191 - val_mse: 34.9073\n",
      "Epoch 83/500\n",
      "325/325 [==============================] - 0s 84us/sample - loss: 4.7427 - mae: 1.7322 - mse: 4.7427 - val_loss: 35.4619 - val_mae: 3.8210 - val_mse: 35.4619\n",
      "Epoch 84/500\n",
      "325/325 [==============================] - 0s 74us/sample - loss: 3.7141 - mae: 1.4999 - mse: 3.7141 - val_loss: 40.4423 - val_mae: 4.1112 - val_mse: 40.4423\n",
      "Epoch 85/500\n",
      "325/325 [==============================] - 0s 82us/sample - loss: 4.4694 - mae: 1.6617 - mse: 4.4694 - val_loss: 48.2488 - val_mae: 4.7977 - val_mse: 48.2488\n",
      "Epoch 86/500\n",
      "325/325 [==============================] - 0s 80us/sample - loss: 3.7729 - mae: 1.5306 - mse: 3.7729 - val_loss: 40.1368 - val_mae: 4.0713 - val_mse: 40.1368\n",
      "Epoch 87/500\n",
      "325/325 [==============================] - 0s 88us/sample - loss: 5.4290 - mae: 1.8408 - mse: 5.4290 - val_loss: 39.8642 - val_mae: 4.0425 - val_mse: 39.8642\n",
      "Epoch 88/500\n",
      "325/325 [==============================] - 0s 97us/sample - loss: 3.7341 - mae: 1.5329 - mse: 3.7341 - val_loss: 33.5074 - val_mae: 3.9464 - val_mse: 33.5074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500\n",
      "325/325 [==============================] - 0s 82us/sample - loss: 3.9332 - mae: 1.5278 - mse: 3.9332 - val_loss: 33.9054 - val_mae: 3.7428 - val_mse: 33.9054\n",
      "Epoch 90/500\n",
      "325/325 [==============================] - 0s 90us/sample - loss: 5.2911 - mae: 1.8198 - mse: 5.2911 - val_loss: 45.7952 - val_mae: 4.5054 - val_mse: 45.7952\n",
      "Epoch 91/500\n",
      "325/325 [==============================] - 0s 85us/sample - loss: 3.4660 - mae: 1.4284 - mse: 3.4660 - val_loss: 41.6857 - val_mae: 4.2127 - val_mse: 41.6856\n",
      "Epoch 92/500\n",
      "325/325 [==============================] - 0s 87us/sample - loss: 4.0113 - mae: 1.5957 - mse: 4.0113 - val_loss: 33.8260 - val_mae: 3.6003 - val_mse: 33.8260\n",
      "Epoch 93/500\n",
      "325/325 [==============================] - 0s 91us/sample - loss: 5.3120 - mae: 1.7974 - mse: 5.3120 - val_loss: 33.8519 - val_mae: 3.6538 - val_mse: 33.8519\n",
      "Epoch 94/500\n",
      "325/325 [==============================] - 0s 89us/sample - loss: 3.4218 - mae: 1.4524 - mse: 3.4218 - val_loss: 42.9201 - val_mae: 4.4652 - val_mse: 42.9201\n",
      "Epoch 95/500\n",
      "325/325 [==============================] - 0s 85us/sample - loss: 3.9448 - mae: 1.5747 - mse: 3.9448 - val_loss: 37.0989 - val_mae: 3.8281 - val_mse: 37.0989\n",
      "Epoch 96/500\n",
      "325/325 [==============================] - 0s 96us/sample - loss: 4.5989 - mae: 1.6878 - mse: 4.5989 - val_loss: 34.4689 - val_mae: 3.7403 - val_mse: 34.4689\n",
      "Epoch 97/500\n",
      "325/325 [==============================] - 0s 105us/sample - loss: 4.6396 - mae: 1.7209 - mse: 4.6396 - val_loss: 36.2553 - val_mae: 3.9001 - val_mse: 36.2554\n",
      "Epoch 98/500\n",
      "325/325 [==============================] - 0s 96us/sample - loss: 3.1257 - mae: 1.4178 - mse: 3.1257 - val_loss: 32.7748 - val_mae: 3.6028 - val_mse: 32.7748\n",
      "Epoch 99/500\n",
      "325/325 [==============================] - 0s 98us/sample - loss: 4.7990 - mae: 1.6937 - mse: 4.7990 - val_loss: 31.8072 - val_mae: 3.5770 - val_mse: 31.8072\n",
      "Epoch 100/500\n",
      "325/325 [==============================] - 0s 87us/sample - loss: 4.1037 - mae: 1.6181 - mse: 4.1037 - val_loss: 32.4434 - val_mae: 3.6462 - val_mse: 32.4434\n",
      "Epoch 101/500\n",
      "325/325 [==============================] - 0s 84us/sample - loss: 4.1029 - mae: 1.6104 - mse: 4.1029 - val_loss: 31.5987 - val_mae: 3.5620 - val_mse: 31.5987\n",
      "Epoch 102/500\n",
      "325/325 [==============================] - 0s 106us/sample - loss: 5.0118 - mae: 1.7843 - mse: 5.0118 - val_loss: 31.9142 - val_mae: 3.6661 - val_mse: 31.9142\n",
      "Epoch 103/500\n",
      "325/325 [==============================] - 0s 88us/sample - loss: 3.5810 - mae: 1.4964 - mse: 3.5810 - val_loss: 34.7716 - val_mae: 3.9125 - val_mse: 34.7716\n",
      "Epoch 104/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 4.0745 - mae: 1.5947 - mse: 4.0745 - val_loss: 35.7255 - val_mae: 4.1186 - val_mse: 35.7255\n",
      "Epoch 105/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 3.8050 - mae: 1.5132 - mse: 3.8050 - val_loss: 38.1933 - val_mae: 4.0314 - val_mse: 38.1933\n",
      "Epoch 106/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 3.9390 - mae: 1.5553 - mse: 3.9390 - val_loss: 31.9750 - val_mae: 3.6014 - val_mse: 31.9750\n",
      "Epoch 107/500\n",
      "325/325 [==============================] - 0s 74us/sample - loss: 3.2335 - mae: 1.4337 - mse: 3.2335 - val_loss: 32.6342 - val_mae: 3.8670 - val_mse: 32.6342\n",
      "Epoch 108/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 4.2542 - mae: 1.6096 - mse: 4.2542 - val_loss: 37.8192 - val_mae: 3.9402 - val_mse: 37.8192\n",
      "Epoch 109/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 3.7952 - mae: 1.5712 - mse: 3.7952 - val_loss: 43.8617 - val_mae: 4.4447 - val_mse: 43.8617\n",
      "Epoch 110/500\n",
      "325/325 [==============================] - 0s 74us/sample - loss: 4.1372 - mae: 1.5812 - mse: 4.1372 - val_loss: 31.3178 - val_mae: 3.5743 - val_mse: 31.3178\n",
      "Epoch 111/500\n",
      "325/325 [==============================] - 0s 78us/sample - loss: 3.2443 - mae: 1.4458 - mse: 3.2443 - val_loss: 30.9923 - val_mae: 3.8312 - val_mse: 30.9922\n",
      "Epoch 112/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 3.8757 - mae: 1.5510 - mse: 3.8757 - val_loss: 39.1368 - val_mae: 4.2041 - val_mse: 39.1368\n",
      "Epoch 113/500\n",
      "325/325 [==============================] - 0s 73us/sample - loss: 3.6590 - mae: 1.5090 - mse: 3.6590 - val_loss: 30.9018 - val_mae: 3.4767 - val_mse: 30.9018\n",
      "Epoch 114/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 3.3015 - mae: 1.4282 - mse: 3.3015 - val_loss: 34.5390 - val_mae: 3.7877 - val_mse: 34.5390\n",
      "Epoch 115/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 4.2145 - mae: 1.6539 - mse: 4.2145 - val_loss: 29.3532 - val_mae: 3.4834 - val_mse: 29.3532\n",
      "Epoch 116/500\n",
      "325/325 [==============================] - 0s 74us/sample - loss: 3.4931 - mae: 1.4603 - mse: 3.4931 - val_loss: 31.4002 - val_mae: 3.4788 - val_mse: 31.4002\n",
      "Epoch 117/500\n",
      "325/325 [==============================] - 0s 89us/sample - loss: 4.7635 - mae: 1.7121 - mse: 4.7635 - val_loss: 33.0775 - val_mae: 3.5812 - val_mse: 33.0775\n",
      "Epoch 118/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 2.9055 - mae: 1.3298 - mse: 2.9054 - val_loss: 32.4591 - val_mae: 3.7226 - val_mse: 32.4591\n",
      "Epoch 119/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 3.6292 - mae: 1.5227 - mse: 3.6292 - val_loss: 35.5931 - val_mae: 3.9469 - val_mse: 35.5931\n",
      "Epoch 120/500\n",
      "325/325 [==============================] - 0s 82us/sample - loss: 4.2307 - mae: 1.6496 - mse: 4.2307 - val_loss: 31.0663 - val_mae: 3.5306 - val_mse: 31.0663\n",
      "Epoch 121/500\n",
      "325/325 [==============================] - 0s 84us/sample - loss: 3.8483 - mae: 1.5421 - mse: 3.8483 - val_loss: 34.4721 - val_mae: 3.7575 - val_mse: 34.4721\n",
      "Epoch 122/500\n",
      "325/325 [==============================] - 0s 90us/sample - loss: 2.9039 - mae: 1.3366 - mse: 2.9039 - val_loss: 41.3077 - val_mae: 4.2885 - val_mse: 41.3077\n",
      "Epoch 123/500\n",
      "325/325 [==============================] - 0s 91us/sample - loss: 3.3729 - mae: 1.4344 - mse: 3.3729 - val_loss: 29.8648 - val_mae: 3.4137 - val_mse: 29.8647\n",
      "Epoch 124/500\n",
      "325/325 [==============================] - 0s 95us/sample - loss: 3.6619 - mae: 1.5340 - mse: 3.6619 - val_loss: 36.1024 - val_mae: 3.8363 - val_mse: 36.1024\n",
      "Epoch 125/500\n",
      "325/325 [==============================] - 0s 108us/sample - loss: 3.6479 - mae: 1.4933 - mse: 3.6479 - val_loss: 31.7363 - val_mae: 3.6474 - val_mse: 31.7363\n",
      "Epoch 126/500\n",
      "325/325 [==============================] - 0s 95us/sample - loss: 3.7639 - mae: 1.5498 - mse: 3.7639 - val_loss: 37.1096 - val_mae: 3.9797 - val_mse: 37.1096\n",
      "Epoch 127/500\n",
      "325/325 [==============================] - 0s 109us/sample - loss: 3.1677 - mae: 1.4052 - mse: 3.1677 - val_loss: 28.7553 - val_mae: 3.3856 - val_mse: 28.7553\n",
      "Epoch 128/500\n",
      "325/325 [==============================] - 0s 98us/sample - loss: 3.4105 - mae: 1.4819 - mse: 3.4105 - val_loss: 29.5425 - val_mae: 3.5321 - val_mse: 29.5425\n",
      "Epoch 129/500\n",
      "325/325 [==============================] - 0s 110us/sample - loss: 3.4606 - mae: 1.4712 - mse: 3.4606 - val_loss: 30.9586 - val_mae: 3.5422 - val_mse: 30.9586\n",
      "Epoch 130/500\n",
      "325/325 [==============================] - 0s 90us/sample - loss: 3.3367 - mae: 1.4495 - mse: 3.3367 - val_loss: 29.6042 - val_mae: 3.6910 - val_mse: 29.6042\n",
      "Epoch 131/500\n",
      "325/325 [==============================] - 0s 93us/sample - loss: 4.0823 - mae: 1.6362 - mse: 4.0823 - val_loss: 32.7048 - val_mae: 3.7534 - val_mse: 32.7048\n",
      "Epoch 132/500\n",
      "325/325 [==============================] - 0s 109us/sample - loss: 3.5451 - mae: 1.4864 - mse: 3.5451 - val_loss: 31.7444 - val_mae: 3.7710 - val_mse: 31.7444\n",
      "Epoch 133/500\n",
      "325/325 [==============================] - 0s 84us/sample - loss: 3.2253 - mae: 1.4227 - mse: 3.2253 - val_loss: 32.4657 - val_mae: 3.8149 - val_mse: 32.4657\n",
      "Epoch 134/500\n",
      "325/325 [==============================] - 0s 101us/sample - loss: 3.2825 - mae: 1.4644 - mse: 3.2825 - val_loss: 31.1620 - val_mae: 3.5791 - val_mse: 31.1620\n",
      "Epoch 135/500\n",
      "325/325 [==============================] - 0s 86us/sample - loss: 4.0559 - mae: 1.6105 - mse: 4.0559 - val_loss: 27.5540 - val_mae: 3.3728 - val_mse: 27.5540\n",
      "Epoch 136/500\n",
      "325/325 [==============================] - 0s 88us/sample - loss: 2.8292 - mae: 1.3608 - mse: 2.8292 - val_loss: 30.0228 - val_mae: 3.5077 - val_mse: 30.0228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/500\n",
      "325/325 [==============================] - 0s 92us/sample - loss: 3.7493 - mae: 1.5402 - mse: 3.7493 - val_loss: 30.9235 - val_mae: 3.5882 - val_mse: 30.9235\n",
      "Epoch 138/500\n",
      "325/325 [==============================] - 0s 85us/sample - loss: 4.1782 - mae: 1.6329 - mse: 4.1782 - val_loss: 30.3296 - val_mae: 3.4639 - val_mse: 30.3296\n",
      "Epoch 139/500\n",
      "325/325 [==============================] - 0s 84us/sample - loss: 3.4196 - mae: 1.4803 - mse: 3.4196 - val_loss: 28.2016 - val_mae: 3.2756 - val_mse: 28.2016\n",
      "Epoch 140/500\n",
      "325/325 [==============================] - 0s 86us/sample - loss: 3.2046 - mae: 1.4249 - mse: 3.2046 - val_loss: 31.2325 - val_mae: 3.5376 - val_mse: 31.2325\n",
      "Epoch 141/500\n",
      "325/325 [==============================] - 0s 73us/sample - loss: 3.7422 - mae: 1.5231 - mse: 3.7422 - val_loss: 29.2510 - val_mae: 3.3823 - val_mse: 29.2510\n",
      "Epoch 142/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 2.8609 - mae: 1.3456 - mse: 2.8609 - val_loss: 30.1585 - val_mae: 3.7263 - val_mse: 30.1585\n",
      "Epoch 143/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 3.1011 - mae: 1.4025 - mse: 3.1011 - val_loss: 29.0622 - val_mae: 3.4161 - val_mse: 29.0622\n",
      "Epoch 144/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 3.3741 - mae: 1.4327 - mse: 3.3741 - val_loss: 29.8784 - val_mae: 3.6065 - val_mse: 29.8784\n",
      "Epoch 145/500\n",
      "325/325 [==============================] - 0s 73us/sample - loss: 3.7064 - mae: 1.5430 - mse: 3.7064 - val_loss: 31.3457 - val_mae: 3.6299 - val_mse: 31.3457\n",
      "Epoch 146/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 3.4286 - mae: 1.4774 - mse: 3.4286 - val_loss: 28.4640 - val_mae: 3.4573 - val_mse: 28.4640\n",
      "Epoch 147/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 2.9529 - mae: 1.3356 - mse: 2.9529 - val_loss: 26.9652 - val_mae: 3.3567 - val_mse: 26.9652\n",
      "Epoch 148/500\n",
      "325/325 [==============================] - 0s 83us/sample - loss: 3.2197 - mae: 1.4405 - mse: 3.2197 - val_loss: 40.8495 - val_mae: 4.3290 - val_mse: 40.8495\n",
      "Epoch 149/500\n",
      "325/325 [==============================] - 0s 78us/sample - loss: 3.3554 - mae: 1.4067 - mse: 3.3554 - val_loss: 30.2986 - val_mae: 3.5906 - val_mse: 30.2986\n",
      "Epoch 150/500\n",
      "325/325 [==============================] - 0s 83us/sample - loss: 3.2427 - mae: 1.4316 - mse: 3.2427 - val_loss: 33.1398 - val_mae: 3.9817 - val_mse: 33.1398\n",
      "Epoch 151/500\n",
      "325/325 [==============================] - 0s 73us/sample - loss: 4.1461 - mae: 1.6430 - mse: 4.1461 - val_loss: 27.3000 - val_mae: 3.2621 - val_mse: 27.3000\n",
      "Epoch 152/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 2.4124 - mae: 1.2283 - mse: 2.4124 - val_loss: 31.0950 - val_mae: 3.9603 - val_mse: 31.0950\n",
      "Epoch 153/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 3.4749 - mae: 1.4489 - mse: 3.4749 - val_loss: 27.9759 - val_mae: 3.5433 - val_mse: 27.9759\n",
      "Epoch 154/500\n",
      "325/325 [==============================] - 0s 80us/sample - loss: 3.3707 - mae: 1.4458 - mse: 3.3707 - val_loss: 34.4158 - val_mae: 3.8347 - val_mse: 34.4158\n",
      "Epoch 155/500\n",
      "325/325 [==============================] - 0s 73us/sample - loss: 2.7921 - mae: 1.3192 - mse: 2.7921 - val_loss: 28.4727 - val_mae: 3.5885 - val_mse: 28.4727\n",
      "Epoch 156/500\n",
      "325/325 [==============================] - 0s 78us/sample - loss: 3.5207 - mae: 1.4981 - mse: 3.5207 - val_loss: 28.7916 - val_mae: 3.6131 - val_mse: 28.7916\n",
      "Epoch 157/500\n",
      "325/325 [==============================] - 0s 102us/sample - loss: 3.0017 - mae: 1.3499 - mse: 3.0017 - val_loss: 27.6356 - val_mae: 3.3884 - val_mse: 27.6356\n",
      "Epoch 158/500\n",
      "325/325 [==============================] - 0s 104us/sample - loss: 3.0286 - mae: 1.3980 - mse: 3.0286 - val_loss: 30.0907 - val_mae: 3.4882 - val_mse: 30.0907\n",
      "Epoch 159/500\n",
      "325/325 [==============================] - 0s 111us/sample - loss: 3.0598 - mae: 1.3892 - mse: 3.0598 - val_loss: 28.3930 - val_mae: 3.6238 - val_mse: 28.3930\n",
      "Epoch 160/500\n",
      "325/325 [==============================] - 0s 107us/sample - loss: 3.4100 - mae: 1.4398 - mse: 3.4100 - val_loss: 28.1533 - val_mae: 3.3908 - val_mse: 28.1533\n",
      "Epoch 161/500\n",
      "325/325 [==============================] - 0s 104us/sample - loss: 3.7571 - mae: 1.5351 - mse: 3.7571 - val_loss: 29.7500 - val_mae: 3.4759 - val_mse: 29.7500\n",
      "Epoch 162/500\n",
      "325/325 [==============================] - 0s 82us/sample - loss: 3.2583 - mae: 1.4418 - mse: 3.2583 - val_loss: 26.5953 - val_mae: 3.3456 - val_mse: 26.5953\n",
      "Epoch 163/500\n",
      "325/325 [==============================] - 0s 95us/sample - loss: 3.0469 - mae: 1.3384 - mse: 3.0469 - val_loss: 34.8379 - val_mae: 3.8994 - val_mse: 34.8379\n",
      "Epoch 164/500\n",
      "325/325 [==============================] - 0s 112us/sample - loss: 3.2762 - mae: 1.4396 - mse: 3.2762 - val_loss: 27.5505 - val_mae: 3.3061 - val_mse: 27.5505\n",
      "Epoch 165/500\n",
      "325/325 [==============================] - 0s 95us/sample - loss: 2.2357 - mae: 1.1933 - mse: 2.2357 - val_loss: 26.8458 - val_mae: 3.5109 - val_mse: 26.8458\n",
      "Epoch 166/500\n",
      "325/325 [==============================] - 0s 91us/sample - loss: 3.7519 - mae: 1.5446 - mse: 3.7519 - val_loss: 33.8773 - val_mae: 3.7683 - val_mse: 33.8773\n",
      "Epoch 167/500\n",
      "325/325 [==============================] - 0s 91us/sample - loss: 2.7395 - mae: 1.3271 - mse: 2.7395 - val_loss: 28.5984 - val_mae: 3.3855 - val_mse: 28.5984\n",
      "Epoch 168/500\n",
      "325/325 [==============================] - 0s 87us/sample - loss: 3.2538 - mae: 1.4250 - mse: 3.2538 - val_loss: 32.5666 - val_mae: 3.9939 - val_mse: 32.5666\n",
      "Epoch 169/500\n",
      "325/325 [==============================] - 0s 90us/sample - loss: 2.9765 - mae: 1.3478 - mse: 2.9765 - val_loss: 26.7435 - val_mae: 3.3863 - val_mse: 26.7435\n",
      "Epoch 170/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 3.4155 - mae: 1.4735 - mse: 3.4155 - val_loss: 31.0124 - val_mae: 3.5486 - val_mse: 31.0124\n",
      "Epoch 171/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 3.5909 - mae: 1.4921 - mse: 3.5909 - val_loss: 27.6259 - val_mae: 3.5016 - val_mse: 27.6259\n",
      "Epoch 172/500\n",
      "325/325 [==============================] - 0s 73us/sample - loss: 3.1106 - mae: 1.4081 - mse: 3.1106 - val_loss: 29.0276 - val_mae: 3.3728 - val_mse: 29.0276\n",
      "Epoch 173/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 3.1738 - mae: 1.4145 - mse: 3.1738 - val_loss: 28.8392 - val_mae: 3.4020 - val_mse: 28.8392\n",
      "Epoch 174/500\n",
      "325/325 [==============================] - 0s 80us/sample - loss: 2.5292 - mae: 1.2467 - mse: 2.5292 - val_loss: 34.2827 - val_mae: 3.8709 - val_mse: 34.2827\n",
      "Epoch 175/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 3.6658 - mae: 1.5078 - mse: 3.6658 - val_loss: 26.7468 - val_mae: 3.5154 - val_mse: 26.7468\n",
      "Epoch 176/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 2.7456 - mae: 1.3172 - mse: 2.7456 - val_loss: 28.5280 - val_mae: 3.3735 - val_mse: 28.5280\n",
      "Epoch 177/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 3.4632 - mae: 1.4691 - mse: 3.4632 - val_loss: 29.2666 - val_mae: 3.4681 - val_mse: 29.2666\n",
      "Epoch 178/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 2.9317 - mae: 1.3667 - mse: 2.9317 - val_loss: 28.7659 - val_mae: 3.5562 - val_mse: 28.7659\n",
      "Epoch 179/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 3.2553 - mae: 1.4404 - mse: 3.2553 - val_loss: 26.5867 - val_mae: 3.2885 - val_mse: 26.5867\n",
      "Epoch 180/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 3.1710 - mae: 1.3792 - mse: 3.1710 - val_loss: 27.1765 - val_mae: 3.4626 - val_mse: 27.1765\n",
      "Epoch 181/500\n",
      "325/325 [==============================] - 0s 78us/sample - loss: 2.5750 - mae: 1.2890 - mse: 2.5750 - val_loss: 26.6133 - val_mae: 3.3681 - val_mse: 26.6133\n",
      "Epoch 182/500\n",
      "325/325 [==============================] - 0s 82us/sample - loss: 2.6139 - mae: 1.3066 - mse: 2.6139 - val_loss: 29.6030 - val_mae: 3.5252 - val_mse: 29.6030\n",
      "Epoch 183/500\n",
      "325/325 [==============================] - 0s 85us/sample - loss: 3.7319 - mae: 1.5550 - mse: 3.7319 - val_loss: 29.3443 - val_mae: 3.4660 - val_mse: 29.3443\n",
      "Epoch 184/500\n",
      "325/325 [==============================] - 0s 100us/sample - loss: 2.6652 - mae: 1.2877 - mse: 2.6652 - val_loss: 27.0004 - val_mae: 3.4191 - val_mse: 27.0004\n",
      "Epoch 185/500\n",
      "325/325 [==============================] - 0s 94us/sample - loss: 3.1530 - mae: 1.4099 - mse: 3.1530 - val_loss: 28.8091 - val_mae: 3.4096 - val_mse: 28.8091\n",
      "Epoch 186/500\n",
      "325/325 [==============================] - 0s 90us/sample - loss: 2.3782 - mae: 1.2306 - mse: 2.3782 - val_loss: 34.2244 - val_mae: 3.8145 - val_mse: 34.2244\n",
      "Epoch 187/500\n",
      "325/325 [==============================] - 0s 95us/sample - loss: 3.4731 - mae: 1.5010 - mse: 3.4731 - val_loss: 28.9120 - val_mae: 3.4704 - val_mse: 28.9120\n",
      "Epoch 188/500\n",
      "325/325 [==============================] - 0s 89us/sample - loss: 3.1321 - mae: 1.4103 - mse: 3.1321 - val_loss: 27.9100 - val_mae: 3.4172 - val_mse: 27.9100\n",
      "Epoch 189/500\n",
      "325/325 [==============================] - 0s 104us/sample - loss: 2.4517 - mae: 1.2422 - mse: 2.4517 - val_loss: 28.1115 - val_mae: 3.7424 - val_mse: 28.1115\n",
      "Epoch 190/500\n",
      "325/325 [==============================] - 0s 88us/sample - loss: 3.1849 - mae: 1.3470 - mse: 3.1849 - val_loss: 34.2927 - val_mae: 3.8762 - val_mse: 34.2928\n",
      "Epoch 191/500\n",
      "325/325 [==============================] - 0s 96us/sample - loss: 2.7151 - mae: 1.2972 - mse: 2.7151 - val_loss: 26.4720 - val_mae: 3.5208 - val_mse: 26.4720\n",
      "Epoch 192/500\n",
      "325/325 [==============================] - 0s 97us/sample - loss: 3.7185 - mae: 1.4734 - mse: 3.7185 - val_loss: 30.2940 - val_mae: 3.5067 - val_mse: 30.2940\n",
      "Epoch 193/500\n",
      "325/325 [==============================] - 0s 80us/sample - loss: 3.2178 - mae: 1.4172 - mse: 3.2178 - val_loss: 27.2872 - val_mae: 3.3884 - val_mse: 27.2872\n",
      "Epoch 194/500\n",
      "325/325 [==============================] - 0s 95us/sample - loss: 2.8671 - mae: 1.3320 - mse: 2.8671 - val_loss: 29.7911 - val_mae: 3.4662 - val_mse: 29.7911\n",
      "Epoch 195/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 2.2299 - mae: 1.2023 - mse: 2.2299 - val_loss: 31.3302 - val_mae: 3.6379 - val_mse: 31.3302\n",
      "Epoch 196/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 3.5216 - mae: 1.4993 - mse: 3.5216 - val_loss: 27.0333 - val_mae: 3.3607 - val_mse: 27.0333\n",
      "Epoch 197/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 2.7452 - mae: 1.3084 - mse: 2.7452 - val_loss: 29.6362 - val_mae: 3.5904 - val_mse: 29.6362\n",
      "Epoch 198/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 2.3005 - mae: 1.2179 - mse: 2.3005 - val_loss: 30.5673 - val_mae: 3.5661 - val_mse: 30.5673\n",
      "Epoch 199/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 3.4634 - mae: 1.4934 - mse: 3.4634 - val_loss: 25.6015 - val_mae: 3.3377 - val_mse: 25.6015\n",
      "Epoch 200/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 2.4319 - mae: 1.2480 - mse: 2.4319 - val_loss: 26.3966 - val_mae: 3.3063 - val_mse: 26.3966\n",
      "Epoch 201/500\n",
      "325/325 [==============================] - 0s 80us/sample - loss: 3.4326 - mae: 1.4936 - mse: 3.4326 - val_loss: 27.8820 - val_mae: 3.4143 - val_mse: 27.8820\n",
      "Epoch 202/500\n",
      "325/325 [==============================] - 0s 71us/sample - loss: 2.0037 - mae: 1.1320 - mse: 2.0037 - val_loss: 32.1125 - val_mae: 3.7546 - val_mse: 32.1125\n",
      "Epoch 203/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 3.2710 - mae: 1.4171 - mse: 3.2710 - val_loss: 25.6860 - val_mae: 3.3897 - val_mse: 25.6860\n",
      "Epoch 204/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 2.5584 - mae: 1.2787 - mse: 2.5584 - val_loss: 25.4838 - val_mae: 3.4224 - val_mse: 25.4838\n",
      "Epoch 205/500\n",
      "325/325 [==============================] - 0s 80us/sample - loss: 3.1819 - mae: 1.4103 - mse: 3.1819 - val_loss: 27.1921 - val_mae: 3.3882 - val_mse: 27.1921\n",
      "Epoch 206/500\n",
      "325/325 [==============================] - 0s 78us/sample - loss: 2.2579 - mae: 1.1712 - mse: 2.2579 - val_loss: 32.1112 - val_mae: 3.6861 - val_mse: 32.1112\n",
      "Epoch 207/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 3.1549 - mae: 1.4197 - mse: 3.1549 - val_loss: 29.5369 - val_mae: 3.4969 - val_mse: 29.5369\n",
      "Epoch 208/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 2.0128 - mae: 1.1306 - mse: 2.0128 - val_loss: 29.4710 - val_mae: 3.4856 - val_mse: 29.4710\n",
      "Epoch 209/500\n",
      "325/325 [==============================] - 0s 92us/sample - loss: 3.4120 - mae: 1.4507 - mse: 3.4120 - val_loss: 31.2547 - val_mae: 3.6078 - val_mse: 31.2547\n",
      "Epoch 210/500\n",
      "325/325 [==============================] - 0s 115us/sample - loss: 2.7279 - mae: 1.2908 - mse: 2.7279 - val_loss: 24.8366 - val_mae: 3.2055 - val_mse: 24.8366\n",
      "Epoch 211/500\n",
      "325/325 [==============================] - 0s 112us/sample - loss: 2.8840 - mae: 1.3373 - mse: 2.8840 - val_loss: 28.0664 - val_mae: 3.4176 - val_mse: 28.0664\n",
      "Epoch 212/500\n",
      "325/325 [==============================] - 0s 114us/sample - loss: 2.2721 - mae: 1.2203 - mse: 2.2721 - val_loss: 29.0006 - val_mae: 3.4812 - val_mse: 29.0006\n",
      "Epoch 213/500\n",
      "325/325 [==============================] - 0s 102us/sample - loss: 2.8970 - mae: 1.3580 - mse: 2.8970 - val_loss: 26.5159 - val_mae: 3.2416 - val_mse: 26.5159\n",
      "Epoch 214/500\n",
      "325/325 [==============================] - 0s 85us/sample - loss: 2.9626 - mae: 1.3739 - mse: 2.9626 - val_loss: 25.1675 - val_mae: 3.3430 - val_mse: 25.1675\n",
      "Epoch 215/500\n",
      "325/325 [==============================] - 0s 94us/sample - loss: 2.5225 - mae: 1.2857 - mse: 2.5225 - val_loss: 25.2800 - val_mae: 3.3197 - val_mse: 25.2800\n",
      "Epoch 216/500\n",
      "325/325 [==============================] - 0s 86us/sample - loss: 3.0957 - mae: 1.4103 - mse: 3.0957 - val_loss: 25.5419 - val_mae: 3.4498 - val_mse: 25.5419\n",
      "Epoch 217/500\n",
      "325/325 [==============================] - 0s 84us/sample - loss: 2.2998 - mae: 1.2096 - mse: 2.2998 - val_loss: 31.6441 - val_mae: 3.7703 - val_mse: 31.6441\n",
      "Epoch 218/500\n",
      "325/325 [==============================] - 0s 94us/sample - loss: 2.3870 - mae: 1.2086 - mse: 2.3870 - val_loss: 29.0026 - val_mae: 3.5517 - val_mse: 29.0026\n",
      "Epoch 219/500\n",
      "325/325 [==============================] - 0s 88us/sample - loss: 3.1330 - mae: 1.4242 - mse: 3.1330 - val_loss: 25.3043 - val_mae: 3.4174 - val_mse: 25.3043\n",
      "Epoch 220/500\n",
      "325/325 [==============================] - 0s 85us/sample - loss: 2.3678 - mae: 1.2180 - mse: 2.3678 - val_loss: 30.1305 - val_mae: 3.7095 - val_mse: 30.1305\n",
      "Epoch 221/500\n",
      "325/325 [==============================] - 0s 82us/sample - loss: 2.9274 - mae: 1.3653 - mse: 2.9274 - val_loss: 24.5182 - val_mae: 3.2615 - val_mse: 24.5182\n",
      "Epoch 222/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 2.5175 - mae: 1.2629 - mse: 2.5175 - val_loss: 28.1771 - val_mae: 3.3600 - val_mse: 28.1771\n",
      "Epoch 223/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 2.3065 - mae: 1.1996 - mse: 2.3065 - val_loss: 26.4814 - val_mae: 3.2614 - val_mse: 26.4814\n",
      "Epoch 224/500\n",
      "325/325 [==============================] - 0s 80us/sample - loss: 2.7935 - mae: 1.3191 - mse: 2.7935 - val_loss: 28.4078 - val_mae: 3.4414 - val_mse: 28.4078\n",
      "Epoch 225/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 2.5201 - mae: 1.2672 - mse: 2.5201 - val_loss: 26.0989 - val_mae: 3.6344 - val_mse: 26.0989\n",
      "Epoch 226/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 2.9289 - mae: 1.3082 - mse: 2.9289 - val_loss: 25.2671 - val_mae: 3.5338 - val_mse: 25.2671\n",
      "Epoch 227/500\n",
      "325/325 [==============================] - 0s 73us/sample - loss: 2.8157 - mae: 1.3321 - mse: 2.8157 - val_loss: 24.6729 - val_mae: 3.2347 - val_mse: 24.6729\n",
      "Epoch 228/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 2.9670 - mae: 1.3616 - mse: 2.9670 - val_loss: 25.0132 - val_mae: 3.2221 - val_mse: 25.0132\n",
      "Epoch 229/500\n",
      "325/325 [==============================] - 0s 78us/sample - loss: 2.6823 - mae: 1.2753 - mse: 2.6823 - val_loss: 25.3790 - val_mae: 3.2637 - val_mse: 25.3790\n",
      "Epoch 230/500\n",
      "325/325 [==============================] - 0s 80us/sample - loss: 3.0705 - mae: 1.4035 - mse: 3.0705 - val_loss: 28.8082 - val_mae: 3.5257 - val_mse: 28.8082\n",
      "Epoch 231/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 2.3254 - mae: 1.2106 - mse: 2.3254 - val_loss: 26.0063 - val_mae: 3.3005 - val_mse: 26.0063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 3.0657 - mae: 1.3809 - mse: 3.0657 - val_loss: 25.1155 - val_mae: 3.3481 - val_mse: 25.1155\n",
      "Epoch 233/500\n",
      "325/325 [==============================] - 0s 73us/sample - loss: 2.2257 - mae: 1.1766 - mse: 2.2257 - val_loss: 28.9509 - val_mae: 3.4529 - val_mse: 28.9509\n",
      "Epoch 234/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 2.9465 - mae: 1.3856 - mse: 2.9465 - val_loss: 24.8046 - val_mae: 3.2995 - val_mse: 24.8046\n",
      "Epoch 235/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 2.7231 - mae: 1.3474 - mse: 2.7231 - val_loss: 27.5411 - val_mae: 3.3653 - val_mse: 27.5410\n",
      "Epoch 236/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 2.2784 - mae: 1.1869 - mse: 2.2784 - val_loss: 31.1607 - val_mae: 3.7920 - val_mse: 31.1607\n",
      "Epoch 237/500\n",
      "325/325 [==============================] - 0s 78us/sample - loss: 2.1298 - mae: 1.1489 - mse: 2.1298 - val_loss: 25.3209 - val_mae: 3.1846 - val_mse: 25.3209\n",
      "Epoch 238/500\n",
      "325/325 [==============================] - 0s 73us/sample - loss: 2.9492 - mae: 1.3414 - mse: 2.9492 - val_loss: 25.0826 - val_mae: 3.2451 - val_mse: 25.0826\n",
      "Epoch 239/500\n",
      "325/325 [==============================] - 0s 74us/sample - loss: 2.5918 - mae: 1.2795 - mse: 2.5918 - val_loss: 25.3106 - val_mae: 3.3775 - val_mse: 25.3106\n",
      "Epoch 240/500\n",
      "325/325 [==============================] - 0s 82us/sample - loss: 2.7979 - mae: 1.3274 - mse: 2.7979 - val_loss: 27.5508 - val_mae: 3.5078 - val_mse: 27.5508\n",
      "Epoch 241/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 2.8844 - mae: 1.3415 - mse: 2.8844 - val_loss: 27.1577 - val_mae: 3.4008 - val_mse: 27.1577\n",
      "Epoch 242/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 2.2901 - mae: 1.2104 - mse: 2.2901 - val_loss: 25.0675 - val_mae: 3.3829 - val_mse: 25.0675\n",
      "Epoch 243/500\n",
      "325/325 [==============================] - 0s 83us/sample - loss: 2.6974 - mae: 1.3047 - mse: 2.6974 - val_loss: 32.2669 - val_mae: 3.8498 - val_mse: 32.2669\n",
      "Epoch 244/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 2.6770 - mae: 1.2943 - mse: 2.6770 - val_loss: 24.8723 - val_mae: 3.3912 - val_mse: 24.8723\n",
      "Epoch 245/500\n",
      "325/325 [==============================] - 0s 94us/sample - loss: 2.6720 - mae: 1.2902 - mse: 2.6720 - val_loss: 34.4936 - val_mae: 4.0460 - val_mse: 34.4936\n",
      "Epoch 246/500\n",
      "325/325 [==============================] - 0s 90us/sample - loss: 2.7920 - mae: 1.3347 - mse: 2.7920 - val_loss: 29.1962 - val_mae: 3.5934 - val_mse: 29.1962\n",
      "Epoch 247/500\n",
      "325/325 [==============================] - 0s 93us/sample - loss: 1.9358 - mae: 1.0722 - mse: 1.9358 - val_loss: 28.8415 - val_mae: 3.4745 - val_mse: 28.8415\n",
      "Epoch 248/500\n",
      "325/325 [==============================] - 0s 101us/sample - loss: 2.9105 - mae: 1.3417 - mse: 2.9105 - val_loss: 25.1868 - val_mae: 3.4071 - val_mse: 25.1868\n",
      "Epoch 249/500\n",
      "325/325 [==============================] - 0s 87us/sample - loss: 3.0573 - mae: 1.3820 - mse: 3.0573 - val_loss: 24.5992 - val_mae: 3.3015 - val_mse: 24.5992\n",
      "Epoch 250/500\n",
      "325/325 [==============================] - 0s 91us/sample - loss: 2.5491 - mae: 1.2858 - mse: 2.5491 - val_loss: 29.0199 - val_mae: 3.4913 - val_mse: 29.0199\n",
      "Epoch 251/500\n",
      "325/325 [==============================] - 0s 92us/sample - loss: 2.1018 - mae: 1.1219 - mse: 2.1018 - val_loss: 33.3755 - val_mae: 3.9334 - val_mse: 33.3755\n",
      "Epoch 252/500\n",
      "325/325 [==============================] - 0s 84us/sample - loss: 2.3636 - mae: 1.1909 - mse: 2.3636 - val_loss: 25.5625 - val_mae: 3.3460 - val_mse: 25.5625\n",
      "Epoch 253/500\n",
      "325/325 [==============================] - 0s 103us/sample - loss: 2.9811 - mae: 1.3746 - mse: 2.9811 - val_loss: 30.4361 - val_mae: 3.8508 - val_mse: 30.4361\n",
      "Epoch 254/500\n",
      "325/325 [==============================] - 0s 90us/sample - loss: 2.5001 - mae: 1.2542 - mse: 2.5001 - val_loss: 24.7467 - val_mae: 3.3836 - val_mse: 24.7467\n",
      "Epoch 255/500\n",
      "325/325 [==============================] - 0s 86us/sample - loss: 2.3474 - mae: 1.2249 - mse: 2.3474 - val_loss: 24.1414 - val_mae: 3.2804 - val_mse: 24.1413\n",
      "Epoch 256/500\n",
      "325/325 [==============================] - 0s 94us/sample - loss: 2.1999 - mae: 1.1707 - mse: 2.1999 - val_loss: 24.5948 - val_mae: 3.4243 - val_mse: 24.5948\n",
      "Epoch 257/500\n",
      "325/325 [==============================] - 0s 84us/sample - loss: 2.4109 - mae: 1.2371 - mse: 2.4109 - val_loss: 30.5336 - val_mae: 3.6347 - val_mse: 30.5336\n",
      "Epoch 258/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 2.3099 - mae: 1.1803 - mse: 2.3099 - val_loss: 24.8086 - val_mae: 3.4968 - val_mse: 24.8086\n",
      "Epoch 259/500\n",
      "325/325 [==============================] - 0s 104us/sample - loss: 3.0986 - mae: 1.3973 - mse: 3.0986 - val_loss: 30.7852 - val_mae: 3.7139 - val_mse: 30.7852\n",
      "Epoch 260/500\n",
      "325/325 [==============================] - 0s 90us/sample - loss: 2.4308 - mae: 1.2413 - mse: 2.4308 - val_loss: 27.6848 - val_mae: 3.4851 - val_mse: 27.6848\n",
      "Epoch 261/500\n",
      "325/325 [==============================] - 0s 82us/sample - loss: 2.3448 - mae: 1.2306 - mse: 2.3448 - val_loss: 25.6107 - val_mae: 3.5793 - val_mse: 25.6107\n",
      "Epoch 262/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 2.5274 - mae: 1.2346 - mse: 2.5274 - val_loss: 23.9589 - val_mae: 3.2474 - val_mse: 23.9589\n",
      "Epoch 263/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 1.8238 - mae: 1.0893 - mse: 1.8238 - val_loss: 25.2084 - val_mae: 3.2006 - val_mse: 25.2084\n",
      "Epoch 264/500\n",
      "325/325 [==============================] - 0s 74us/sample - loss: 3.1788 - mae: 1.3995 - mse: 3.1788 - val_loss: 24.5847 - val_mae: 3.2265 - val_mse: 24.5847\n",
      "Epoch 265/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 2.2402 - mae: 1.1808 - mse: 2.2402 - val_loss: 25.5270 - val_mae: 3.2584 - val_mse: 25.5270\n",
      "Epoch 266/500\n",
      "325/325 [==============================] - 0s 74us/sample - loss: 1.8162 - mae: 1.0592 - mse: 1.8162 - val_loss: 27.1569 - val_mae: 3.8266 - val_mse: 27.1569\n",
      "Epoch 267/500\n",
      "325/325 [==============================] - 0s 78us/sample - loss: 2.7958 - mae: 1.2470 - mse: 2.7958 - val_loss: 24.1982 - val_mae: 3.1502 - val_mse: 24.1982\n",
      "Epoch 268/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 2.4817 - mae: 1.2629 - mse: 2.4817 - val_loss: 24.4873 - val_mae: 3.1994 - val_mse: 24.4873\n",
      "Epoch 269/500\n",
      "325/325 [==============================] - 0s 78us/sample - loss: 2.4115 - mae: 1.2443 - mse: 2.4115 - val_loss: 26.0471 - val_mae: 3.2725 - val_mse: 26.0471\n",
      "Epoch 270/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 2.4690 - mae: 1.2279 - mse: 2.4690 - val_loss: 24.4025 - val_mae: 3.3997 - val_mse: 24.4025\n",
      "Epoch 271/500\n",
      "325/325 [==============================] - 0s 82us/sample - loss: 2.5563 - mae: 1.2861 - mse: 2.5563 - val_loss: 25.4077 - val_mae: 3.2136 - val_mse: 25.4077\n",
      "Epoch 272/500\n",
      "325/325 [==============================] - 0s 83us/sample - loss: 2.9399 - mae: 1.3067 - mse: 2.9399 - val_loss: 25.9213 - val_mae: 3.2827 - val_mse: 25.9213\n",
      "Epoch 273/500\n",
      "325/325 [==============================] - 0s 91us/sample - loss: 2.4034 - mae: 1.2394 - mse: 2.4034 - val_loss: 23.8060 - val_mae: 3.1694 - val_mse: 23.8060\n",
      "Epoch 274/500\n",
      "325/325 [==============================] - 0s 102us/sample - loss: 2.3926 - mae: 1.2151 - mse: 2.3926 - val_loss: 24.3862 - val_mae: 3.1557 - val_mse: 24.3862\n",
      "Epoch 275/500\n",
      "325/325 [==============================] - 0s 86us/sample - loss: 2.8042 - mae: 1.3509 - mse: 2.8042 - val_loss: 29.0611 - val_mae: 3.5029 - val_mse: 29.0611\n",
      "Epoch 276/500\n",
      "325/325 [==============================] - 0s 90us/sample - loss: 1.9928 - mae: 1.0910 - mse: 1.9928 - val_loss: 24.8584 - val_mae: 3.2370 - val_mse: 24.8584\n",
      "Epoch 277/500\n",
      "325/325 [==============================] - 0s 111us/sample - loss: 3.0254 - mae: 1.3915 - mse: 3.0254 - val_loss: 24.8063 - val_mae: 3.1983 - val_mse: 24.8063\n",
      "Epoch 278/500\n",
      "325/325 [==============================] - 0s 102us/sample - loss: 2.4288 - mae: 1.2266 - mse: 2.4288 - val_loss: 32.0577 - val_mae: 3.7798 - val_mse: 32.0577\n",
      "Epoch 279/500\n",
      "325/325 [==============================] - 0s 97us/sample - loss: 2.3411 - mae: 1.1726 - mse: 2.3411 - val_loss: 23.9357 - val_mae: 3.1639 - val_mse: 23.9357\n",
      "Epoch 280/500\n",
      "325/325 [==============================] - 0s 113us/sample - loss: 2.5303 - mae: 1.2633 - mse: 2.5303 - val_loss: 28.9600 - val_mae: 3.5199 - val_mse: 28.9600\n",
      "Epoch 281/500\n",
      "325/325 [==============================] - 0s 113us/sample - loss: 2.5653 - mae: 1.2694 - mse: 2.5653 - val_loss: 26.0942 - val_mae: 3.2660 - val_mse: 26.0942\n",
      "Epoch 282/500\n",
      "325/325 [==============================] - 0s 97us/sample - loss: 2.7391 - mae: 1.3122 - mse: 2.7391 - val_loss: 23.8421 - val_mae: 3.2236 - val_mse: 23.8421\n",
      "Epoch 283/500\n",
      "325/325 [==============================] - 0s 93us/sample - loss: 1.6553 - mae: 0.9925 - mse: 1.6553 - val_loss: 27.9335 - val_mae: 3.4238 - val_mse: 27.9335\n",
      "Epoch 284/500\n",
      "325/325 [==============================] - 0s 97us/sample - loss: 2.6094 - mae: 1.2632 - mse: 2.6094 - val_loss: 24.9405 - val_mae: 3.1997 - val_mse: 24.9405\n",
      "Epoch 285/500\n",
      "325/325 [==============================] - 0s 86us/sample - loss: 2.7897 - mae: 1.3481 - mse: 2.7897 - val_loss: 23.9928 - val_mae: 3.1569 - val_mse: 23.9928\n",
      "Epoch 286/500\n",
      "325/325 [==============================] - 0s 80us/sample - loss: 2.1745 - mae: 1.1487 - mse: 2.1745 - val_loss: 27.8783 - val_mae: 3.5726 - val_mse: 27.8783\n",
      "Epoch 287/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 1.9765 - mae: 1.1036 - mse: 1.9765 - val_loss: 23.7362 - val_mae: 3.1601 - val_mse: 23.7362\n",
      "Epoch 288/500\n",
      "325/325 [==============================] - 0s 77us/sample - loss: 2.7272 - mae: 1.3220 - mse: 2.7272 - val_loss: 28.4719 - val_mae: 3.5092 - val_mse: 28.4719\n",
      "Epoch 289/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 1.8402 - mae: 1.0567 - mse: 1.8402 - val_loss: 24.9103 - val_mae: 3.3839 - val_mse: 24.9103\n",
      "Epoch 290/500\n",
      "325/325 [==============================] - 0s 80us/sample - loss: 3.1711 - mae: 1.3932 - mse: 3.1711 - val_loss: 23.8594 - val_mae: 3.1627 - val_mse: 23.8594\n",
      "Epoch 291/500\n",
      "325/325 [==============================] - 0s 80us/sample - loss: 1.6699 - mae: 1.0152 - mse: 1.6699 - val_loss: 28.4490 - val_mae: 3.4967 - val_mse: 28.4490\n",
      "Epoch 292/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 2.3857 - mae: 1.2155 - mse: 2.3857 - val_loss: 25.9756 - val_mae: 3.2617 - val_mse: 25.9756\n",
      "Epoch 293/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 2.8513 - mae: 1.3474 - mse: 2.8513 - val_loss: 25.2693 - val_mae: 3.4552 - val_mse: 25.2693\n",
      "Epoch 294/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 1.9313 - mae: 1.0865 - mse: 1.9313 - val_loss: 24.4213 - val_mae: 3.2284 - val_mse: 24.4213\n",
      "Epoch 295/500\n",
      "325/325 [==============================] - 0s 74us/sample - loss: 2.7711 - mae: 1.3107 - mse: 2.7711 - val_loss: 25.3787 - val_mae: 3.2820 - val_mse: 25.3787\n",
      "Epoch 296/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 2.3515 - mae: 1.2385 - mse: 2.3515 - val_loss: 27.8568 - val_mae: 3.4517 - val_mse: 27.8568\n",
      "Epoch 297/500\n",
      "325/325 [==============================] - 0s 80us/sample - loss: 2.0422 - mae: 1.1110 - mse: 2.0422 - val_loss: 27.6177 - val_mae: 3.5918 - val_mse: 27.6177\n",
      "Epoch 298/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 2.0474 - mae: 1.1319 - mse: 2.0474 - val_loss: 25.5620 - val_mae: 3.2041 - val_mse: 25.5620\n",
      "Epoch 299/500\n",
      "325/325 [==============================] - 0s 74us/sample - loss: 2.7614 - mae: 1.3437 - mse: 2.7614 - val_loss: 24.3453 - val_mae: 3.1589 - val_mse: 24.3453\n",
      "Epoch 300/500\n",
      "325/325 [==============================] - 0s 82us/sample - loss: 2.3526 - mae: 1.2161 - mse: 2.3526 - val_loss: 23.4152 - val_mae: 3.2109 - val_mse: 23.4152\n",
      "Epoch 301/500\n",
      "325/325 [==============================] - 0s 78us/sample - loss: 2.1134 - mae: 1.1289 - mse: 2.1134 - val_loss: 23.9492 - val_mae: 3.3661 - val_mse: 23.9492\n",
      "Epoch 302/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 1.8454 - mae: 1.0563 - mse: 1.8454 - val_loss: 24.9742 - val_mae: 3.5371 - val_mse: 24.9742\n",
      "Epoch 303/500\n",
      "325/325 [==============================] - 0s 75us/sample - loss: 2.6366 - mae: 1.2562 - mse: 2.6366 - val_loss: 23.7695 - val_mae: 3.2332 - val_mse: 23.7695\n",
      "Epoch 304/500\n",
      "325/325 [==============================] - 0s 82us/sample - loss: 2.4397 - mae: 1.2617 - mse: 2.4397 - val_loss: 31.7192 - val_mae: 3.8159 - val_mse: 31.7192\n",
      "Epoch 305/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 1.9799 - mae: 1.1032 - mse: 1.9799 - val_loss: 26.7009 - val_mae: 3.3668 - val_mse: 26.7009\n",
      "Epoch 306/500\n",
      "325/325 [==============================] - 0s 108us/sample - loss: 2.3583 - mae: 1.2247 - mse: 2.3583 - val_loss: 24.2129 - val_mae: 3.2369 - val_mse: 24.2129\n",
      "Epoch 307/500\n",
      "325/325 [==============================] - 0s 106us/sample - loss: 2.3320 - mae: 1.2302 - mse: 2.3320 - val_loss: 24.2949 - val_mae: 3.2990 - val_mse: 24.2949\n",
      "Epoch 308/500\n",
      "325/325 [==============================] - 0s 118us/sample - loss: 2.1461 - mae: 1.1564 - mse: 2.1461 - val_loss: 27.1309 - val_mae: 3.3211 - val_mse: 27.1309\n",
      "Epoch 309/500\n",
      "325/325 [==============================] - 0s 103us/sample - loss: 2.2168 - mae: 1.1810 - mse: 2.2168 - val_loss: 24.9618 - val_mae: 3.2475 - val_mse: 24.9618\n",
      "Epoch 310/500\n",
      "325/325 [==============================] - 0s 93us/sample - loss: 2.6546 - mae: 1.2751 - mse: 2.6546 - val_loss: 25.2281 - val_mae: 3.3235 - val_mse: 25.2281\n",
      "Epoch 311/500\n",
      "325/325 [==============================] - 0s 95us/sample - loss: 2.0556 - mae: 1.1214 - mse: 2.0556 - val_loss: 29.3879 - val_mae: 3.5847 - val_mse: 29.3879\n",
      "Epoch 312/500\n",
      "325/325 [==============================] - 0s 111us/sample - loss: 2.0733 - mae: 1.1166 - mse: 2.0733 - val_loss: 28.0662 - val_mae: 3.4353 - val_mse: 28.0662\n",
      "Epoch 313/500\n",
      "325/325 [==============================] - 0s 96us/sample - loss: 2.2520 - mae: 1.2003 - mse: 2.2520 - val_loss: 24.8944 - val_mae: 3.3702 - val_mse: 24.8944\n",
      "Epoch 314/500\n",
      "325/325 [==============================] - 0s 94us/sample - loss: 1.9819 - mae: 1.1092 - mse: 1.9819 - val_loss: 30.3431 - val_mae: 3.6295 - val_mse: 30.3431\n",
      "Epoch 315/500\n",
      "325/325 [==============================] - 0s 86us/sample - loss: 2.6393 - mae: 1.2752 - mse: 2.6393 - val_loss: 25.0072 - val_mae: 3.2712 - val_mse: 25.0072\n",
      "Epoch 316/500\n",
      "325/325 [==============================] - 0s 82us/sample - loss: 2.0143 - mae: 1.1205 - mse: 2.0143 - val_loss: 26.9955 - val_mae: 3.2982 - val_mse: 26.9955\n",
      "Epoch 317/500\n",
      "325/325 [==============================] - 0s 78us/sample - loss: 2.1087 - mae: 1.1579 - mse: 2.1087 - val_loss: 26.0706 - val_mae: 3.2393 - val_mse: 26.0706\n",
      "Epoch 318/500\n",
      "325/325 [==============================] - 0s 89us/sample - loss: 2.4106 - mae: 1.2259 - mse: 2.4106 - val_loss: 24.0795 - val_mae: 3.1721 - val_mse: 24.0795\n",
      "Epoch 319/500\n",
      "325/325 [==============================] - 0s 92us/sample - loss: 1.9615 - mae: 1.0883 - mse: 1.9615 - val_loss: 24.7187 - val_mae: 3.2448 - val_mse: 24.7187\n",
      "Epoch 320/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 1.9955 - mae: 1.1275 - mse: 1.9955 - val_loss: 25.5265 - val_mae: 3.4793 - val_mse: 25.5265\n",
      "Epoch 321/500\n",
      "325/325 [==============================] - 0s 80us/sample - loss: 2.1414 - mae: 1.1361 - mse: 2.1414 - val_loss: 26.1077 - val_mae: 3.3049 - val_mse: 26.1077\n",
      "Epoch 322/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 2.4939 - mae: 1.2650 - mse: 2.4939 - val_loss: 24.6194 - val_mae: 3.4506 - val_mse: 24.6194\n",
      "Epoch 323/500\n",
      "325/325 [==============================] - 0s 83us/sample - loss: 2.0261 - mae: 1.0956 - mse: 2.0261 - val_loss: 24.6996 - val_mae: 3.3770 - val_mse: 24.6996\n",
      "Epoch 324/500\n",
      "325/325 [==============================] - 0s 93us/sample - loss: 2.0775 - mae: 1.1411 - mse: 2.0775 - val_loss: 24.4498 - val_mae: 3.1994 - val_mse: 24.4498\n",
      "Epoch 325/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 2.1183 - mae: 1.1414 - mse: 2.1183 - val_loss: 24.4220 - val_mae: 3.3337 - val_mse: 24.4220\n",
      "Epoch 326/500\n",
      "325/325 [==============================] - 0s 88us/sample - loss: 1.8709 - mae: 1.0888 - mse: 1.8709 - val_loss: 24.1572 - val_mae: 3.3652 - val_mse: 24.1572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/500\n",
      "325/325 [==============================] - 0s 76us/sample - loss: 2.1891 - mae: 1.1803 - mse: 2.1891 - val_loss: 25.3919 - val_mae: 3.4289 - val_mse: 25.3919\n",
      "Epoch 328/500\n",
      "325/325 [==============================] - 0s 79us/sample - loss: 2.5117 - mae: 1.2659 - mse: 2.5117 - val_loss: 23.5132 - val_mae: 3.1727 - val_mse: 23.5132\n",
      "Epoch 329/500\n",
      "325/325 [==============================] - 0s 83us/sample - loss: 1.8464 - mae: 1.0617 - mse: 1.8464 - val_loss: 29.7413 - val_mae: 3.6350 - val_mse: 29.7413\n",
      "Epoch 330/500\n",
      "325/325 [==============================] - 0s 95us/sample - loss: 2.3277 - mae: 1.2433 - mse: 2.3277 - val_loss: 25.3324 - val_mae: 3.3261 - val_mse: 25.3324\n",
      "Epoch 331/500\n",
      "325/325 [==============================] - 0s 98us/sample - loss: 1.3736 - mae: 0.9115 - mse: 1.3736 - val_loss: 25.0154 - val_mae: 3.2637 - val_mse: 25.0154\n",
      "Epoch 332/500\n",
      "325/325 [==============================] - 0s 89us/sample - loss: 2.5498 - mae: 1.2373 - mse: 2.5498 - val_loss: 28.1397 - val_mae: 3.4107 - val_mse: 28.1397\n",
      "Epoch 333/500\n",
      "325/325 [==============================] - 0s 93us/sample - loss: 1.7027 - mae: 1.0237 - mse: 1.7027 - val_loss: 24.6953 - val_mae: 3.1696 - val_mse: 24.6953\n",
      "Epoch 334/500\n",
      "325/325 [==============================] - 0s 97us/sample - loss: 2.5888 - mae: 1.2822 - mse: 2.5888 - val_loss: 25.8855 - val_mae: 3.4158 - val_mse: 25.8855\n",
      "Epoch 335/500\n",
      "325/325 [==============================] - 0s 93us/sample - loss: 2.2033 - mae: 1.1694 - mse: 2.2033 - val_loss: 27.8015 - val_mae: 3.4052 - val_mse: 27.8015\n",
      "Epoch 336/500\n",
      "325/325 [==============================] - 0s 97us/sample - loss: 1.6701 - mae: 1.0068 - mse: 1.6701 - val_loss: 23.8368 - val_mae: 3.2963 - val_mse: 23.8368\n",
      "Epoch 337/500\n",
      "325/325 [==============================] - 0s 88us/sample - loss: 2.4863 - mae: 1.2328 - mse: 2.4863 - val_loss: 30.4155 - val_mae: 3.6237 - val_mse: 30.4156\n",
      "Epoch 338/500\n",
      "325/325 [==============================] - 0s 86us/sample - loss: 2.0347 - mae: 1.0911 - mse: 2.0347 - val_loss: 26.1000 - val_mae: 3.2344 - val_mse: 26.1000\n",
      "Epoch 339/500\n",
      "325/325 [==============================] - 0s 96us/sample - loss: 2.4475 - mae: 1.2226 - mse: 2.4475 - val_loss: 24.0331 - val_mae: 3.2663 - val_mse: 24.0332\n",
      "Epoch 340/500\n",
      "325/325 [==============================] - 0s 83us/sample - loss: 1.9502 - mae: 1.1132 - mse: 1.9502 - val_loss: 31.1275 - val_mae: 3.7539 - val_mse: 31.1275\n",
      "Epoch 341/500\n",
      "325/325 [==============================] - 0s 91us/sample - loss: 2.4943 - mae: 1.2724 - mse: 2.4943 - val_loss: 25.2689 - val_mae: 3.2327 - val_mse: 25.2689\n",
      "Epoch 342/500\n",
      "325/325 [==============================] - 0s 81us/sample - loss: 1.9251 - mae: 1.0965 - mse: 1.9251 - val_loss: 26.5912 - val_mae: 3.4687 - val_mse: 26.5912\n",
      "Epoch 343/500\n",
      "325/325 [==============================] - 0s 88us/sample - loss: 2.0715 - mae: 1.1445 - mse: 2.0715 - val_loss: 26.5395 - val_mae: 3.2602 - val_mse: 26.5395\n",
      "Epoch 344/500\n",
      "325/325 [==============================] - 0s 94us/sample - loss: 1.9507 - mae: 1.1246 - mse: 1.9507 - val_loss: 24.4852 - val_mae: 3.3502 - val_mse: 24.4852\n",
      "Epoch 345/500\n",
      "325/325 [==============================] - 0s 89us/sample - loss: 2.2378 - mae: 1.1840 - mse: 2.2378 - val_loss: 25.7394 - val_mae: 3.2321 - val_mse: 25.7394\n",
      "Epoch 346/500\n",
      "325/325 [==============================] - 0s 87us/sample - loss: 1.8942 - mae: 1.0741 - mse: 1.8942 - val_loss: 23.8304 - val_mae: 3.2539 - val_mse: 23.8304\n",
      "Epoch 347/500\n",
      "325/325 [==============================] - 0s 94us/sample - loss: 1.9345 - mae: 1.0944 - mse: 1.9345 - val_loss: 25.7002 - val_mae: 3.3391 - val_mse: 25.7002\n",
      "Epoch 348/500\n",
      "325/325 [==============================] - 0s 87us/sample - loss: 2.7277 - mae: 1.3336 - mse: 2.7277 - val_loss: 24.2633 - val_mae: 3.3231 - val_mse: 24.2633\n",
      "Epoch 349/500\n",
      "325/325 [==============================] - 0s 87us/sample - loss: 1.7454 - mae: 1.0272 - mse: 1.7454 - val_loss: 24.0751 - val_mae: 3.2215 - val_mse: 24.0751\n",
      "Epoch 350/500\n",
      "325/325 [==============================] - 0s 101us/sample - loss: 2.3566 - mae: 1.1803 - mse: 2.3566 - val_loss: 24.4698 - val_mae: 3.2801 - val_mse: 24.4698\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 406 samples, validate on 135 samples\n",
      "Epoch 1/500\n",
      "406/406 [==============================] - 0s 945us/sample - loss: 231.4072 - mae: 11.1521 - mse: 231.4072 - val_loss: 223.1938 - val_mae: 11.9159 - val_mse: 223.1938\n",
      "Epoch 2/500\n",
      "406/406 [==============================] - 0s 74us/sample - loss: 163.7817 - mae: 9.3740 - mse: 163.7817 - val_loss: 162.1914 - val_mae: 9.5410 - val_mse: 162.1914\n",
      "Epoch 3/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 139.7026 - mae: 8.6440 - mse: 139.7026 - val_loss: 173.0735 - val_mae: 10.5034 - val_mse: 173.0735\n",
      "Epoch 4/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 118.1158 - mae: 7.9231 - mse: 118.1158 - val_loss: 162.7235 - val_mae: 10.0723 - val_mse: 162.7235\n",
      "Epoch 5/500\n",
      "406/406 [==============================] - 0s 65us/sample - loss: 103.5055 - mae: 7.4475 - mse: 103.5055 - val_loss: 107.5564 - val_mae: 7.3612 - val_mse: 107.5564\n",
      "Epoch 6/500\n",
      "406/406 [==============================] - 0s 97us/sample - loss: 83.0125 - mae: 6.6741 - mse: 83.0125 - val_loss: 102.2612 - val_mae: 7.7759 - val_mse: 102.2612\n",
      "Epoch 7/500\n",
      "406/406 [==============================] - 0s 100us/sample - loss: 73.2595 - mae: 6.4169 - mse: 73.2595 - val_loss: 89.6158 - val_mae: 7.2943 - val_mse: 89.6158\n",
      "Epoch 8/500\n",
      "406/406 [==============================] - 0s 101us/sample - loss: 66.5465 - mae: 6.1648 - mse: 66.5465 - val_loss: 76.6771 - val_mae: 6.2124 - val_mse: 76.6771\n",
      "Epoch 9/500\n",
      "406/406 [==============================] - 0s 96us/sample - loss: 56.7829 - mae: 5.7050 - mse: 56.7829 - val_loss: 73.4099 - val_mae: 6.3337 - val_mse: 73.4099\n",
      "Epoch 10/500\n",
      "406/406 [==============================] - 0s 90us/sample - loss: 53.8708 - mae: 5.6442 - mse: 53.8708 - val_loss: 68.1185 - val_mae: 6.0159 - val_mse: 68.1185\n",
      "Epoch 11/500\n",
      "406/406 [==============================] - 0s 75us/sample - loss: 47.6083 - mae: 5.3231 - mse: 47.6083 - val_loss: 65.0747 - val_mae: 6.0586 - val_mse: 65.0747\n",
      "Epoch 12/500\n",
      "406/406 [==============================] - 0s 76us/sample - loss: 42.9264 - mae: 5.0326 - mse: 42.9264 - val_loss: 59.0155 - val_mae: 5.6252 - val_mse: 59.0155\n",
      "Epoch 13/500\n",
      "406/406 [==============================] - 0s 86us/sample - loss: 38.2775 - mae: 4.8215 - mse: 38.2775 - val_loss: 64.2803 - val_mae: 6.2252 - val_mse: 64.2803\n",
      "Epoch 14/500\n",
      "406/406 [==============================] - 0s 76us/sample - loss: 36.8657 - mae: 4.6422 - mse: 36.8657 - val_loss: 53.2061 - val_mae: 5.3532 - val_mse: 53.2061\n",
      "Epoch 15/500\n",
      "406/406 [==============================] - 0s 76us/sample - loss: 31.2393 - mae: 4.3520 - mse: 31.2393 - val_loss: 48.6131 - val_mae: 5.1668 - val_mse: 48.6131\n",
      "Epoch 16/500\n",
      "406/406 [==============================] - 0s 85us/sample - loss: 31.0761 - mae: 4.3967 - mse: 31.0761 - val_loss: 49.2329 - val_mae: 5.2931 - val_mse: 49.2329\n",
      "Epoch 17/500\n",
      "406/406 [==============================] - 0s 92us/sample - loss: 28.6331 - mae: 4.2119 - mse: 28.6331 - val_loss: 51.2404 - val_mae: 5.4330 - val_mse: 51.2404\n",
      "Epoch 18/500\n",
      "406/406 [==============================] - 0s 98us/sample - loss: 26.5591 - mae: 4.0538 - mse: 26.5591 - val_loss: 46.9419 - val_mae: 5.2260 - val_mse: 46.9419\n",
      "Epoch 19/500\n",
      "406/406 [==============================] - 0s 97us/sample - loss: 24.9012 - mae: 3.9491 - mse: 24.9012 - val_loss: 39.7556 - val_mae: 4.5042 - val_mse: 39.7556\n",
      "Epoch 20/500\n",
      "406/406 [==============================] - 0s 100us/sample - loss: 22.5577 - mae: 3.7726 - mse: 22.5577 - val_loss: 40.0140 - val_mae: 4.8536 - val_mse: 40.0140\n",
      "Epoch 21/500\n",
      "406/406 [==============================] - 0s 90us/sample - loss: 22.9660 - mae: 3.8115 - mse: 22.9660 - val_loss: 48.1601 - val_mae: 5.4097 - val_mse: 48.1601\n",
      "Epoch 22/500\n",
      "406/406 [==============================] - 0s 83us/sample - loss: 19.0948 - mae: 3.4639 - mse: 19.0948 - val_loss: 36.6308 - val_mae: 4.5874 - val_mse: 36.6308\n",
      "Epoch 23/500\n",
      "406/406 [==============================] - 0s 87us/sample - loss: 20.6553 - mae: 3.6352 - mse: 20.6553 - val_loss: 33.6611 - val_mae: 4.2467 - val_mse: 33.6611\n",
      "Epoch 24/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 17.5596 - mae: 3.3402 - mse: 17.5596 - val_loss: 33.5536 - val_mae: 4.3522 - val_mse: 33.5536\n",
      "Epoch 25/500\n",
      "406/406 [==============================] - 0s 75us/sample - loss: 15.8082 - mae: 3.2015 - mse: 15.8082 - val_loss: 31.4518 - val_mae: 4.0082 - val_mse: 31.4518\n",
      "Epoch 26/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 15.3673 - mae: 3.0987 - mse: 15.3673 - val_loss: 31.3066 - val_mae: 4.1222 - val_mse: 31.3066\n",
      "Epoch 27/500\n",
      "406/406 [==============================] - 0s 78us/sample - loss: 14.8200 - mae: 3.0555 - mse: 14.8200 - val_loss: 31.8539 - val_mae: 4.1863 - val_mse: 31.8539\n",
      "Epoch 28/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 14.8127 - mae: 3.0558 - mse: 14.8127 - val_loss: 31.9670 - val_mae: 3.9905 - val_mse: 31.9670\n",
      "Epoch 29/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 14.2706 - mae: 3.0470 - mse: 14.2706 - val_loss: 33.8258 - val_mae: 4.3131 - val_mse: 33.8258\n",
      "Epoch 30/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 13.2920 - mae: 2.9505 - mse: 13.2920 - val_loss: 31.7440 - val_mae: 3.9290 - val_mse: 31.7440\n",
      "Epoch 31/500\n",
      "406/406 [==============================] - 0s 64us/sample - loss: 12.2276 - mae: 2.7617 - mse: 12.2276 - val_loss: 30.7272 - val_mae: 3.9925 - val_mse: 30.7272\n",
      "Epoch 32/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 13.3043 - mae: 2.9296 - mse: 13.3043 - val_loss: 27.7702 - val_mae: 3.7031 - val_mse: 27.7702\n",
      "Epoch 33/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 10.1457 - mae: 2.5545 - mse: 10.1457 - val_loss: 26.8060 - val_mae: 3.5531 - val_mse: 26.8060\n",
      "Epoch 34/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 11.5064 - mae: 2.7168 - mse: 11.5064 - val_loss: 32.3265 - val_mae: 4.1936 - val_mse: 32.3265\n",
      "Epoch 35/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 11.1206 - mae: 2.6586 - mse: 11.1206 - val_loss: 33.0146 - val_mae: 4.2127 - val_mse: 33.0146\n",
      "Epoch 36/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 10.7215 - mae: 2.6253 - mse: 10.7215 - val_loss: 28.8941 - val_mae: 3.8775 - val_mse: 28.8941\n",
      "Epoch 37/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 9.1335 - mae: 2.4275 - mse: 9.1335 - val_loss: 25.8071 - val_mae: 3.4544 - val_mse: 25.8071\n",
      "Epoch 38/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 10.3972 - mae: 2.5794 - mse: 10.3972 - val_loss: 27.3405 - val_mae: 3.7138 - val_mse: 27.3405\n",
      "Epoch 39/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 9.1050 - mae: 2.4004 - mse: 9.1050 - val_loss: 28.9658 - val_mae: 3.7737 - val_mse: 28.9658\n",
      "Epoch 40/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 10.1395 - mae: 2.5408 - mse: 10.1395 - val_loss: 26.0447 - val_mae: 3.4375 - val_mse: 26.0447\n",
      "Epoch 41/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 8.5525 - mae: 2.3276 - mse: 8.5525 - val_loss: 38.6112 - val_mae: 4.6783 - val_mse: 38.6112\n",
      "Epoch 42/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 8.6628 - mae: 2.3329 - mse: 8.6628 - val_loss: 28.4750 - val_mae: 3.6315 - val_mse: 28.4750\n",
      "Epoch 43/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 7.6223 - mae: 2.2026 - mse: 7.6223 - val_loss: 31.9820 - val_mae: 4.0832 - val_mse: 31.9820\n",
      "Epoch 44/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 9.2673 - mae: 2.4692 - mse: 9.2673 - val_loss: 29.5643 - val_mae: 3.7335 - val_mse: 29.5643\n",
      "Epoch 45/500\n",
      "406/406 [==============================] - 0s 77us/sample - loss: 7.7843 - mae: 2.2594 - mse: 7.7843 - val_loss: 26.8932 - val_mae: 3.5482 - val_mse: 26.8932\n",
      "Epoch 46/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 7.0068 - mae: 2.1453 - mse: 7.0068 - val_loss: 24.3106 - val_mae: 3.3897 - val_mse: 24.3106\n",
      "Epoch 47/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 8.7147 - mae: 2.4237 - mse: 8.7147 - val_loss: 25.8049 - val_mae: 3.4114 - val_mse: 25.8049\n",
      "Epoch 48/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 6.7354 - mae: 2.0889 - mse: 6.7354 - val_loss: 33.0864 - val_mae: 4.1684 - val_mse: 33.0864\n",
      "Epoch 49/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 6.9408 - mae: 2.1104 - mse: 6.9408 - val_loss: 25.5266 - val_mae: 3.4681 - val_mse: 25.5266\n",
      "Epoch 50/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 7.2187 - mae: 2.1258 - mse: 7.2187 - val_loss: 24.7850 - val_mae: 3.2719 - val_mse: 24.7850\n",
      "Epoch 51/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 5.9995 - mae: 1.9693 - mse: 5.9995 - val_loss: 24.6365 - val_mae: 3.4121 - val_mse: 24.6365\n",
      "Epoch 52/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 7.3929 - mae: 2.2155 - mse: 7.3929 - val_loss: 22.4685 - val_mae: 3.0692 - val_mse: 22.4685\n",
      "Epoch 53/500\n",
      "406/406 [==============================] - 0s 65us/sample - loss: 6.3867 - mae: 2.0315 - mse: 6.3867 - val_loss: 26.2461 - val_mae: 3.5498 - val_mse: 26.2461\n",
      "Epoch 54/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 6.6858 - mae: 2.0772 - mse: 6.6858 - val_loss: 24.6560 - val_mae: 3.3901 - val_mse: 24.6560\n",
      "Epoch 55/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 7.8521 - mae: 2.2427 - mse: 7.8521 - val_loss: 23.9012 - val_mae: 3.3077 - val_mse: 23.9012\n",
      "Epoch 56/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 6.6240 - mae: 2.0656 - mse: 6.6240 - val_loss: 22.5812 - val_mae: 3.1774 - val_mse: 22.5812\n",
      "Epoch 57/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 6.7104 - mae: 2.1167 - mse: 6.7104 - val_loss: 24.1528 - val_mae: 3.2982 - val_mse: 24.1528\n",
      "Epoch 58/500\n",
      "406/406 [==============================] - 0s 65us/sample - loss: 4.9059 - mae: 1.7549 - mse: 4.9059 - val_loss: 22.3584 - val_mae: 3.0998 - val_mse: 22.3584\n",
      "Epoch 59/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 7.3193 - mae: 2.1526 - mse: 7.3193 - val_loss: 27.4444 - val_mae: 3.6586 - val_mse: 27.4444\n",
      "Epoch 60/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 6.1742 - mae: 2.0363 - mse: 6.1742 - val_loss: 21.0678 - val_mae: 3.0074 - val_mse: 21.0678\n",
      "Epoch 61/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 6.2012 - mae: 2.0399 - mse: 6.2012 - val_loss: 25.2506 - val_mae: 3.4705 - val_mse: 25.2506\n",
      "Epoch 62/500\n",
      "406/406 [==============================] - 0s 89us/sample - loss: 5.2409 - mae: 1.8502 - mse: 5.2409 - val_loss: 27.2039 - val_mae: 3.9588 - val_mse: 27.2039\n",
      "Epoch 63/500\n",
      "406/406 [==============================] - 0s 74us/sample - loss: 5.9582 - mae: 1.9915 - mse: 5.9582 - val_loss: 29.9034 - val_mae: 3.9599 - val_mse: 29.9034\n",
      "Epoch 64/500\n",
      "406/406 [==============================] - 0s 84us/sample - loss: 6.8254 - mae: 2.1057 - mse: 6.8254 - val_loss: 20.9250 - val_mae: 3.0770 - val_mse: 20.9250\n",
      "Epoch 65/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 4.7916 - mae: 1.7488 - mse: 4.7916 - val_loss: 25.1759 - val_mae: 3.7021 - val_mse: 25.1759\n",
      "Epoch 66/500\n",
      "406/406 [==============================] - 0s 91us/sample - loss: 6.7716 - mae: 2.1179 - mse: 6.7716 - val_loss: 22.0753 - val_mae: 3.1328 - val_mse: 22.0753\n",
      "Epoch 67/500\n",
      "406/406 [==============================] - 0s 85us/sample - loss: 6.1304 - mae: 2.0007 - mse: 6.1304 - val_loss: 23.4177 - val_mae: 3.3439 - val_mse: 23.4177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/500\n",
      "406/406 [==============================] - 0s 78us/sample - loss: 5.3799 - mae: 1.8729 - mse: 5.3799 - val_loss: 25.3847 - val_mae: 3.4596 - val_mse: 25.3847\n",
      "Epoch 69/500\n",
      "406/406 [==============================] - 0s 85us/sample - loss: 5.0680 - mae: 1.8018 - mse: 5.0680 - val_loss: 22.5337 - val_mae: 3.1711 - val_mse: 22.5337\n",
      "Epoch 70/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 6.2821 - mae: 2.0506 - mse: 6.2821 - val_loss: 22.0065 - val_mae: 3.1894 - val_mse: 22.0065\n",
      "Epoch 71/500\n",
      "406/406 [==============================] - 0s 78us/sample - loss: 5.0834 - mae: 1.8370 - mse: 5.0834 - val_loss: 26.6238 - val_mae: 4.0024 - val_mse: 26.6238\n",
      "Epoch 72/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 5.7352 - mae: 1.9537 - mse: 5.7352 - val_loss: 20.4781 - val_mae: 2.9635 - val_mse: 20.4781\n",
      "Epoch 73/500\n",
      "406/406 [==============================] - 0s 85us/sample - loss: 5.8913 - mae: 1.9338 - mse: 5.8913 - val_loss: 24.2940 - val_mae: 3.3438 - val_mse: 24.2940\n",
      "Epoch 74/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 6.0107 - mae: 2.0260 - mse: 6.0107 - val_loss: 20.6447 - val_mae: 3.0840 - val_mse: 20.6447\n",
      "Epoch 75/500\n",
      "406/406 [==============================] - 0s 77us/sample - loss: 4.3147 - mae: 1.6490 - mse: 4.3147 - val_loss: 25.4197 - val_mae: 3.7618 - val_mse: 25.4197\n",
      "Epoch 76/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 5.9634 - mae: 1.9848 - mse: 5.9634 - val_loss: 21.4143 - val_mae: 3.1704 - val_mse: 21.4143\n",
      "Epoch 77/500\n",
      "406/406 [==============================] - 0s 83us/sample - loss: 5.6964 - mae: 1.9627 - mse: 5.6964 - val_loss: 20.4588 - val_mae: 3.0032 - val_mse: 20.4588\n",
      "Epoch 78/500\n",
      "406/406 [==============================] - 0s 87us/sample - loss: 5.8446 - mae: 1.9804 - mse: 5.8446 - val_loss: 18.8285 - val_mae: 2.8362 - val_mse: 18.8285\n",
      "Epoch 79/500\n",
      "406/406 [==============================] - 0s 94us/sample - loss: 4.8677 - mae: 1.7885 - mse: 4.8677 - val_loss: 22.7695 - val_mae: 3.2437 - val_mse: 22.7695\n",
      "Epoch 80/500\n",
      "406/406 [==============================] - 0s 93us/sample - loss: 5.0040 - mae: 1.8126 - mse: 5.0040 - val_loss: 23.2686 - val_mae: 3.3626 - val_mse: 23.2686\n",
      "Epoch 81/500\n",
      "406/406 [==============================] - 0s 92us/sample - loss: 5.2930 - mae: 1.8860 - mse: 5.2930 - val_loss: 21.0329 - val_mae: 3.2404 - val_mse: 21.0329\n",
      "Epoch 82/500\n",
      "406/406 [==============================] - 0s 88us/sample - loss: 5.1127 - mae: 1.8353 - mse: 5.1127 - val_loss: 19.7869 - val_mae: 2.9853 - val_mse: 19.7869\n",
      "Epoch 83/500\n",
      "406/406 [==============================] - 0s 82us/sample - loss: 5.5311 - mae: 1.9244 - mse: 5.5311 - val_loss: 20.2071 - val_mae: 3.0452 - val_mse: 20.2071\n",
      "Epoch 84/500\n",
      "406/406 [==============================] - 0s 78us/sample - loss: 5.3292 - mae: 1.8595 - mse: 5.3292 - val_loss: 21.2983 - val_mae: 3.2743 - val_mse: 21.2983\n",
      "Epoch 85/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 4.9075 - mae: 1.7325 - mse: 4.9075 - val_loss: 27.8292 - val_mae: 3.8428 - val_mse: 27.8292\n",
      "Epoch 86/500\n",
      "406/406 [==============================] - 0s 81us/sample - loss: 5.2513 - mae: 1.8665 - mse: 5.2513 - val_loss: 19.7635 - val_mae: 3.0096 - val_mse: 19.7635\n",
      "Epoch 87/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 4.4421 - mae: 1.7099 - mse: 4.4421 - val_loss: 22.4225 - val_mae: 3.2887 - val_mse: 22.4225\n",
      "Epoch 88/500\n",
      "406/406 [==============================] - 0s 79us/sample - loss: 5.5959 - mae: 1.9125 - mse: 5.5959 - val_loss: 20.8032 - val_mae: 3.0941 - val_mse: 20.8032\n",
      "Epoch 89/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 4.6584 - mae: 1.7596 - mse: 4.6584 - val_loss: 21.3986 - val_mae: 3.1351 - val_mse: 21.3986\n",
      "Epoch 90/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 5.0354 - mae: 1.8360 - mse: 5.0354 - val_loss: 19.2184 - val_mae: 2.9551 - val_mse: 19.2184\n",
      "Epoch 91/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 4.8656 - mae: 1.8043 - mse: 4.8656 - val_loss: 18.9238 - val_mae: 2.8642 - val_mse: 18.9238\n",
      "Epoch 92/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 4.6147 - mae: 1.7084 - mse: 4.6147 - val_loss: 23.3496 - val_mae: 3.5648 - val_mse: 23.3496\n",
      "Epoch 93/500\n",
      "406/406 [==============================] - 0s 65us/sample - loss: 5.3514 - mae: 1.8492 - mse: 5.3514 - val_loss: 24.8106 - val_mae: 3.5972 - val_mse: 24.8106\n",
      "Epoch 94/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 4.8652 - mae: 1.7702 - mse: 4.8652 - val_loss: 17.9802 - val_mae: 2.7749 - val_mse: 17.9802\n",
      "Epoch 95/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 5.3335 - mae: 1.8195 - mse: 5.3335 - val_loss: 20.7377 - val_mae: 3.0601 - val_mse: 20.7377\n",
      "Epoch 96/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 3.5970 - mae: 1.5394 - mse: 3.5970 - val_loss: 19.7619 - val_mae: 3.0003 - val_mse: 19.7619\n",
      "Epoch 97/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 5.0901 - mae: 1.8009 - mse: 5.0901 - val_loss: 17.9868 - val_mae: 2.8369 - val_mse: 17.9868\n",
      "Epoch 98/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 5.3960 - mae: 1.8999 - mse: 5.3960 - val_loss: 18.3513 - val_mae: 2.8174 - val_mse: 18.3513\n",
      "Epoch 99/500\n",
      "406/406 [==============================] - 0s 74us/sample - loss: 4.4416 - mae: 1.7093 - mse: 4.4416 - val_loss: 19.5404 - val_mae: 2.9577 - val_mse: 19.5404\n",
      "Epoch 100/500\n",
      "406/406 [==============================] - 0s 65us/sample - loss: 4.6534 - mae: 1.7404 - mse: 4.6534 - val_loss: 18.9910 - val_mae: 2.9720 - val_mse: 18.9910\n",
      "Epoch 101/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 4.8367 - mae: 1.8218 - mse: 4.8367 - val_loss: 18.8280 - val_mae: 2.8889 - val_mse: 18.8280\n",
      "Epoch 102/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 4.4975 - mae: 1.7056 - mse: 4.4975 - val_loss: 18.8631 - val_mae: 2.8706 - val_mse: 18.8631\n",
      "Epoch 103/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 5.1760 - mae: 1.8595 - mse: 5.1760 - val_loss: 17.1217 - val_mae: 2.7527 - val_mse: 17.1217\n",
      "Epoch 104/500\n",
      "406/406 [==============================] - 0s 80us/sample - loss: 3.1182 - mae: 1.4026 - mse: 3.1182 - val_loss: 21.5192 - val_mae: 3.2187 - val_mse: 21.5193\n",
      "Epoch 105/500\n",
      "406/406 [==============================] - 0s 101us/sample - loss: 6.2719 - mae: 2.0049 - mse: 6.2719 - val_loss: 18.7745 - val_mae: 2.8791 - val_mse: 18.7745\n",
      "Epoch 106/500\n",
      "406/406 [==============================] - 0s 102us/sample - loss: 3.8033 - mae: 1.5457 - mse: 3.8033 - val_loss: 22.4615 - val_mae: 3.5751 - val_mse: 22.4615\n",
      "Epoch 107/500\n",
      "406/406 [==============================] - 0s 88us/sample - loss: 4.6068 - mae: 1.7128 - mse: 4.6068 - val_loss: 17.1537 - val_mae: 2.7544 - val_mse: 17.1537\n",
      "Epoch 108/500\n",
      "406/406 [==============================] - 0s 85us/sample - loss: 4.7405 - mae: 1.7166 - mse: 4.7405 - val_loss: 19.0872 - val_mae: 3.0297 - val_mse: 19.0872\n",
      "Epoch 109/500\n",
      "406/406 [==============================] - 0s 95us/sample - loss: 4.6774 - mae: 1.7287 - mse: 4.6774 - val_loss: 18.2872 - val_mae: 2.9341 - val_mse: 18.2872\n",
      "Epoch 110/500\n",
      "406/406 [==============================] - 0s 92us/sample - loss: 4.0571 - mae: 1.6299 - mse: 4.0571 - val_loss: 20.8271 - val_mae: 3.1966 - val_mse: 20.8271\n",
      "Epoch 111/500\n",
      "406/406 [==============================] - 0s 89us/sample - loss: 4.0638 - mae: 1.6382 - mse: 4.0638 - val_loss: 21.1173 - val_mae: 3.1402 - val_mse: 21.1173\n",
      "Epoch 112/500\n",
      "406/406 [==============================] - 0s 97us/sample - loss: 4.7724 - mae: 1.7671 - mse: 4.7724 - val_loss: 22.0665 - val_mae: 3.3152 - val_mse: 22.0665\n",
      "Epoch 113/500\n",
      "406/406 [==============================] - 0s 77us/sample - loss: 4.4794 - mae: 1.7058 - mse: 4.4794 - val_loss: 16.8423 - val_mae: 2.8115 - val_mse: 16.8423\n",
      "Epoch 114/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 4.6051 - mae: 1.7298 - mse: 4.6051 - val_loss: 24.9862 - val_mae: 3.6248 - val_mse: 24.9862\n",
      "Epoch 115/500\n",
      "406/406 [==============================] - 0s 74us/sample - loss: 4.4648 - mae: 1.7170 - mse: 4.4648 - val_loss: 20.9523 - val_mae: 3.3085 - val_mse: 20.9523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 4.7471 - mae: 1.7427 - mse: 4.7471 - val_loss: 15.6755 - val_mae: 2.5681 - val_mse: 15.6755\n",
      "Epoch 117/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 3.5445 - mae: 1.4979 - mse: 3.5445 - val_loss: 16.6803 - val_mae: 2.6845 - val_mse: 16.6803\n",
      "Epoch 118/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 4.3059 - mae: 1.6391 - mse: 4.3059 - val_loss: 17.1465 - val_mae: 2.7611 - val_mse: 17.1465\n",
      "Epoch 119/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 5.3221 - mae: 1.8090 - mse: 5.3221 - val_loss: 20.0867 - val_mae: 3.0622 - val_mse: 20.0867\n",
      "Epoch 120/500\n",
      "406/406 [==============================] - 0s 74us/sample - loss: 3.6067 - mae: 1.5325 - mse: 3.6067 - val_loss: 16.0256 - val_mae: 2.5622 - val_mse: 16.0256\n",
      "Epoch 121/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 5.0033 - mae: 1.7817 - mse: 5.0033 - val_loss: 19.6969 - val_mae: 2.9842 - val_mse: 19.6969\n",
      "Epoch 122/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 4.4032 - mae: 1.6592 - mse: 4.4032 - val_loss: 18.0157 - val_mae: 2.9229 - val_mse: 18.0157\n",
      "Epoch 123/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 3.9533 - mae: 1.5845 - mse: 3.9533 - val_loss: 17.4423 - val_mae: 2.9186 - val_mse: 17.4423\n",
      "Epoch 124/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 4.1310 - mae: 1.5927 - mse: 4.1310 - val_loss: 19.1695 - val_mae: 3.0998 - val_mse: 19.1695\n",
      "Epoch 125/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 5.1300 - mae: 1.8356 - mse: 5.1300 - val_loss: 17.5639 - val_mae: 2.7263 - val_mse: 17.5639\n",
      "Epoch 126/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.7333 - mae: 1.5586 - mse: 3.7333 - val_loss: 20.5306 - val_mae: 3.1295 - val_mse: 20.5306\n",
      "Epoch 127/500\n",
      "406/406 [==============================] - 0s 63us/sample - loss: 3.9643 - mae: 1.5877 - mse: 3.9643 - val_loss: 26.0775 - val_mae: 3.8021 - val_mse: 26.0775\n",
      "Epoch 128/500\n",
      "406/406 [==============================] - 0s 75us/sample - loss: 4.3566 - mae: 1.6741 - mse: 4.3566 - val_loss: 20.8188 - val_mae: 3.1356 - val_mse: 20.8188\n",
      "Epoch 129/500\n",
      "406/406 [==============================] - 0s 79us/sample - loss: 3.8882 - mae: 1.5981 - mse: 3.8882 - val_loss: 22.7963 - val_mae: 3.4627 - val_mse: 22.7963\n",
      "Epoch 130/500\n",
      "406/406 [==============================] - 0s 85us/sample - loss: 4.7714 - mae: 1.7527 - mse: 4.7714 - val_loss: 15.3724 - val_mae: 2.5708 - val_mse: 15.3724\n",
      "Epoch 131/500\n",
      "406/406 [==============================] - 0s 75us/sample - loss: 4.5542 - mae: 1.7189 - mse: 4.5542 - val_loss: 15.1653 - val_mae: 2.5204 - val_mse: 15.1653\n",
      "Epoch 132/500\n",
      "406/406 [==============================] - 0s 85us/sample - loss: 4.2915 - mae: 1.6597 - mse: 4.2915 - val_loss: 15.4162 - val_mae: 2.6201 - val_mse: 15.4162\n",
      "Epoch 133/500\n",
      "406/406 [==============================] - 0s 76us/sample - loss: 4.3635 - mae: 1.6873 - mse: 4.3635 - val_loss: 18.3646 - val_mae: 2.8570 - val_mse: 18.3646\n",
      "Epoch 134/500\n",
      "406/406 [==============================] - 0s 86us/sample - loss: 4.3755 - mae: 1.7036 - mse: 4.3755 - val_loss: 21.8967 - val_mae: 3.3794 - val_mse: 21.8967\n",
      "Epoch 135/500\n",
      "406/406 [==============================] - 0s 88us/sample - loss: 3.5409 - mae: 1.5233 - mse: 3.5409 - val_loss: 16.6152 - val_mae: 2.7752 - val_mse: 16.6152\n",
      "Epoch 136/500\n",
      "406/406 [==============================] - 0s 74us/sample - loss: 4.7128 - mae: 1.7547 - mse: 4.7128 - val_loss: 20.0537 - val_mae: 3.0590 - val_mse: 20.0537\n",
      "Epoch 137/500\n",
      "406/406 [==============================] - 0s 85us/sample - loss: 4.4467 - mae: 1.6973 - mse: 4.4467 - val_loss: 15.0999 - val_mae: 2.5113 - val_mse: 15.0999\n",
      "Epoch 138/500\n",
      "406/406 [==============================] - 0s 79us/sample - loss: 3.4412 - mae: 1.4904 - mse: 3.4412 - val_loss: 14.8058 - val_mae: 2.4612 - val_mse: 14.8058\n",
      "Epoch 139/500\n",
      "406/406 [==============================] - 0s 88us/sample - loss: 4.9295 - mae: 1.7891 - mse: 4.9295 - val_loss: 16.8235 - val_mae: 2.6975 - val_mse: 16.8235\n",
      "Epoch 140/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 3.3038 - mae: 1.4894 - mse: 3.3038 - val_loss: 17.2113 - val_mae: 2.8009 - val_mse: 17.2113\n",
      "Epoch 141/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.8980 - mae: 1.5952 - mse: 3.8980 - val_loss: 19.0838 - val_mae: 3.0696 - val_mse: 19.0838\n",
      "Epoch 142/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 4.4274 - mae: 1.6771 - mse: 4.4274 - val_loss: 15.7399 - val_mae: 2.6860 - val_mse: 15.7399\n",
      "Epoch 143/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 4.0554 - mae: 1.6343 - mse: 4.0554 - val_loss: 20.8683 - val_mae: 3.1924 - val_mse: 20.8683\n",
      "Epoch 144/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 3.6779 - mae: 1.5436 - mse: 3.6779 - val_loss: 15.1879 - val_mae: 2.5476 - val_mse: 15.1879\n",
      "Epoch 145/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 4.9482 - mae: 1.7800 - mse: 4.9482 - val_loss: 15.9741 - val_mae: 2.5946 - val_mse: 15.9741\n",
      "Epoch 146/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 3.3981 - mae: 1.4881 - mse: 3.3981 - val_loss: 14.7618 - val_mae: 2.5022 - val_mse: 14.7618\n",
      "Epoch 147/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 4.0462 - mae: 1.6136 - mse: 4.0462 - val_loss: 17.0624 - val_mae: 2.7451 - val_mse: 17.0624\n",
      "Epoch 148/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 4.8454 - mae: 1.7859 - mse: 4.8454 - val_loss: 15.4112 - val_mae: 2.5927 - val_mse: 15.4112\n",
      "Epoch 149/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.8364 - mae: 1.5557 - mse: 3.8364 - val_loss: 13.9665 - val_mae: 2.4322 - val_mse: 13.9665\n",
      "Epoch 150/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 4.1528 - mae: 1.6461 - mse: 4.1528 - val_loss: 17.7912 - val_mae: 2.8408 - val_mse: 17.7912\n",
      "Epoch 151/500\n",
      "406/406 [==============================] - 0s 82us/sample - loss: 4.0937 - mae: 1.6544 - mse: 4.0937 - val_loss: 19.6861 - val_mae: 3.1484 - val_mse: 19.6861\n",
      "Epoch 152/500\n",
      "406/406 [==============================] - 0s 79us/sample - loss: 3.4343 - mae: 1.4750 - mse: 3.4343 - val_loss: 18.8793 - val_mae: 3.0677 - val_mse: 18.8793\n",
      "Epoch 153/500\n",
      "406/406 [==============================] - 0s 95us/sample - loss: 3.8970 - mae: 1.5649 - mse: 3.8970 - val_loss: 14.7181 - val_mae: 2.5310 - val_mse: 14.7181\n",
      "Epoch 154/500\n",
      "406/406 [==============================] - 0s 94us/sample - loss: 4.3976 - mae: 1.6959 - mse: 4.3976 - val_loss: 19.9769 - val_mae: 3.1482 - val_mse: 19.9769\n",
      "Epoch 155/500\n",
      "406/406 [==============================] - 0s 90us/sample - loss: 3.6272 - mae: 1.5498 - mse: 3.6272 - val_loss: 17.3326 - val_mae: 2.8925 - val_mse: 17.3326\n",
      "Epoch 156/500\n",
      "406/406 [==============================] - 0s 97us/sample - loss: 4.6971 - mae: 1.7824 - mse: 4.6971 - val_loss: 13.9950 - val_mae: 2.3926 - val_mse: 13.9950\n",
      "Epoch 157/500\n",
      "406/406 [==============================] - 0s 98us/sample - loss: 3.8022 - mae: 1.6013 - mse: 3.8022 - val_loss: 17.0681 - val_mae: 2.7794 - val_mse: 17.0681\n",
      "Epoch 158/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 3.6507 - mae: 1.5550 - mse: 3.6507 - val_loss: 18.8897 - val_mae: 3.1145 - val_mse: 18.8897\n",
      "Epoch 159/500\n",
      "406/406 [==============================] - 0s 77us/sample - loss: 3.8132 - mae: 1.5813 - mse: 3.8132 - val_loss: 14.0601 - val_mae: 2.5205 - val_mse: 14.0601\n",
      "Epoch 160/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 4.3964 - mae: 1.7390 - mse: 4.3964 - val_loss: 21.4164 - val_mae: 3.3775 - val_mse: 21.4164\n",
      "Epoch 161/500\n",
      "406/406 [==============================] - 0s 64us/sample - loss: 3.6557 - mae: 1.5638 - mse: 3.6557 - val_loss: 18.2399 - val_mae: 2.9204 - val_mse: 18.2399\n",
      "Epoch 162/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 3.5056 - mae: 1.5043 - mse: 3.5056 - val_loss: 18.3654 - val_mae: 3.2641 - val_mse: 18.3654\n",
      "Epoch 163/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 3.9372 - mae: 1.6095 - mse: 3.9372 - val_loss: 13.7307 - val_mae: 2.4379 - val_mse: 13.7307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 3.9549 - mae: 1.6047 - mse: 3.9549 - val_loss: 16.6122 - val_mae: 2.8407 - val_mse: 16.6122\n",
      "Epoch 165/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 3.8304 - mae: 1.5669 - mse: 3.8304 - val_loss: 19.0312 - val_mae: 3.0283 - val_mse: 19.0312\n",
      "Epoch 166/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 3.5283 - mae: 1.4873 - mse: 3.5283 - val_loss: 17.0514 - val_mae: 2.7821 - val_mse: 17.0514\n",
      "Epoch 167/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 3.2066 - mae: 1.4341 - mse: 3.2066 - val_loss: 16.0838 - val_mae: 2.8129 - val_mse: 16.0838\n",
      "Epoch 168/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 4.0836 - mae: 1.5898 - mse: 4.0836 - val_loss: 13.8995 - val_mae: 2.4122 - val_mse: 13.8995\n",
      "Epoch 169/500\n",
      "406/406 [==============================] - 0s 65us/sample - loss: 4.1613 - mae: 1.5800 - mse: 4.1613 - val_loss: 15.9647 - val_mae: 2.8477 - val_mse: 15.9647\n",
      "Epoch 170/500\n",
      "406/406 [==============================] - 0s 75us/sample - loss: 3.2641 - mae: 1.4468 - mse: 3.2641 - val_loss: 19.1985 - val_mae: 3.1752 - val_mse: 19.1985\n",
      "Epoch 171/500\n",
      "406/406 [==============================] - 0s 84us/sample - loss: 3.2706 - mae: 1.4335 - mse: 3.2706 - val_loss: 15.7885 - val_mae: 2.7453 - val_mse: 15.7885\n",
      "Epoch 172/500\n",
      "406/406 [==============================] - 0s 102us/sample - loss: 3.9981 - mae: 1.5765 - mse: 3.9981 - val_loss: 15.5501 - val_mae: 2.7622 - val_mse: 15.5500\n",
      "Epoch 173/500\n",
      "406/406 [==============================] - 0s 91us/sample - loss: 3.9419 - mae: 1.5943 - mse: 3.9419 - val_loss: 13.4194 - val_mae: 2.3965 - val_mse: 13.4194\n",
      "Epoch 174/500\n",
      "406/406 [==============================] - 0s 91us/sample - loss: 3.4952 - mae: 1.4701 - mse: 3.4952 - val_loss: 14.9752 - val_mae: 2.6697 - val_mse: 14.9752\n",
      "Epoch 175/500\n",
      "406/406 [==============================] - 0s 91us/sample - loss: 3.4795 - mae: 1.4859 - mse: 3.4795 - val_loss: 14.9623 - val_mae: 2.5346 - val_mse: 14.9623\n",
      "Epoch 176/500\n",
      "406/406 [==============================] - 0s 88us/sample - loss: 3.8833 - mae: 1.5588 - mse: 3.8833 - val_loss: 18.2524 - val_mae: 2.9994 - val_mse: 18.2524\n",
      "Epoch 177/500\n",
      "406/406 [==============================] - 0s 88us/sample - loss: 3.6768 - mae: 1.5444 - mse: 3.6768 - val_loss: 15.2295 - val_mae: 2.7527 - val_mse: 15.2295\n",
      "Epoch 178/500\n",
      "406/406 [==============================] - 0s 93us/sample - loss: 2.9462 - mae: 1.3685 - mse: 2.9462 - val_loss: 17.6094 - val_mae: 2.9333 - val_mse: 17.6094\n",
      "Epoch 179/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 3.9249 - mae: 1.6005 - mse: 3.9249 - val_loss: 13.6547 - val_mae: 2.4145 - val_mse: 13.6547\n",
      "Epoch 180/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 3.0598 - mae: 1.3943 - mse: 3.0598 - val_loss: 14.8163 - val_mae: 2.6177 - val_mse: 14.8163\n",
      "Epoch 181/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 3.6383 - mae: 1.4901 - mse: 3.6383 - val_loss: 13.7968 - val_mae: 2.4071 - val_mse: 13.7968\n",
      "Epoch 182/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 4.2888 - mae: 1.5811 - mse: 4.2888 - val_loss: 15.1385 - val_mae: 2.5955 - val_mse: 15.1385\n",
      "Epoch 183/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 3.1778 - mae: 1.4174 - mse: 3.1778 - val_loss: 17.7190 - val_mae: 2.9174 - val_mse: 17.7190\n",
      "Epoch 184/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 3.9519 - mae: 1.6438 - mse: 3.9519 - val_loss: 13.1919 - val_mae: 2.4820 - val_mse: 13.1919\n",
      "Epoch 185/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 3.5525 - mae: 1.5291 - mse: 3.5525 - val_loss: 13.0974 - val_mae: 2.2998 - val_mse: 13.0974\n",
      "Epoch 186/500\n",
      "406/406 [==============================] - 0s 74us/sample - loss: 3.2455 - mae: 1.4147 - mse: 3.2455 - val_loss: 16.5076 - val_mae: 2.8147 - val_mse: 16.5076\n",
      "Epoch 187/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.7842 - mae: 1.3375 - mse: 2.7842 - val_loss: 16.2183 - val_mae: 3.0231 - val_mse: 16.2183\n",
      "Epoch 188/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 4.6027 - mae: 1.7718 - mse: 4.6027 - val_loss: 16.5883 - val_mae: 2.7289 - val_mse: 16.5883\n",
      "Epoch 189/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 3.5273 - mae: 1.5252 - mse: 3.5273 - val_loss: 13.8119 - val_mae: 2.5335 - val_mse: 13.8119\n",
      "Epoch 190/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 3.3674 - mae: 1.4786 - mse: 3.3674 - val_loss: 13.0181 - val_mae: 2.4399 - val_mse: 13.0181\n",
      "Epoch 191/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 3.0519 - mae: 1.3739 - mse: 3.0519 - val_loss: 15.1864 - val_mae: 2.7516 - val_mse: 15.1864\n",
      "Epoch 192/500\n",
      "406/406 [==============================] - 0s 86us/sample - loss: 3.9479 - mae: 1.6094 - mse: 3.9479 - val_loss: 13.6705 - val_mae: 2.4672 - val_mse: 13.6705\n",
      "Epoch 193/500\n",
      "406/406 [==============================] - 0s 94us/sample - loss: 3.8896 - mae: 1.5906 - mse: 3.8896 - val_loss: 14.4928 - val_mae: 2.6303 - val_mse: 14.4928\n",
      "Epoch 194/500\n",
      "406/406 [==============================] - 0s 95us/sample - loss: 3.2250 - mae: 1.4453 - mse: 3.2250 - val_loss: 16.3934 - val_mae: 2.7696 - val_mse: 16.3934\n",
      "Epoch 195/500\n",
      "406/406 [==============================] - 0s 92us/sample - loss: 3.6368 - mae: 1.5425 - mse: 3.6368 - val_loss: 12.3988 - val_mae: 2.3172 - val_mse: 12.3988\n",
      "Epoch 196/500\n",
      "406/406 [==============================] - 0s 95us/sample - loss: 3.4436 - mae: 1.4865 - mse: 3.4436 - val_loss: 13.4158 - val_mae: 2.4344 - val_mse: 13.4158\n",
      "Epoch 197/500\n",
      "406/406 [==============================] - 0s 90us/sample - loss: 3.8403 - mae: 1.5161 - mse: 3.8403 - val_loss: 13.8784 - val_mae: 2.4060 - val_mse: 13.8784\n",
      "Epoch 198/500\n",
      "406/406 [==============================] - 0s 96us/sample - loss: 3.1926 - mae: 1.4535 - mse: 3.1926 - val_loss: 12.6498 - val_mae: 2.3108 - val_mse: 12.6498\n",
      "Epoch 199/500\n",
      "406/406 [==============================] - 0s 90us/sample - loss: 3.5562 - mae: 1.5276 - mse: 3.5562 - val_loss: 13.3726 - val_mae: 2.3946 - val_mse: 13.3726\n",
      "Epoch 200/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 3.3585 - mae: 1.4978 - mse: 3.3585 - val_loss: 12.3166 - val_mae: 2.3050 - val_mse: 12.3166\n",
      "Epoch 201/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 3.8745 - mae: 1.5855 - mse: 3.8745 - val_loss: 12.9552 - val_mae: 2.3219 - val_mse: 12.9552\n",
      "Epoch 202/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 2.9477 - mae: 1.3692 - mse: 2.9477 - val_loss: 13.1092 - val_mae: 2.5056 - val_mse: 13.1092\n",
      "Epoch 203/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 3.6119 - mae: 1.5205 - mse: 3.6119 - val_loss: 14.9624 - val_mae: 2.7395 - val_mse: 14.9624\n",
      "Epoch 204/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 3.1073 - mae: 1.3782 - mse: 3.1073 - val_loss: 14.6165 - val_mae: 2.5525 - val_mse: 14.6165\n",
      "Epoch 205/500\n",
      "406/406 [==============================] - 0s 77us/sample - loss: 3.5120 - mae: 1.5210 - mse: 3.5120 - val_loss: 12.0794 - val_mae: 2.2805 - val_mse: 12.0794\n",
      "Epoch 206/500\n",
      "406/406 [==============================] - 0s 79us/sample - loss: 3.3539 - mae: 1.4777 - mse: 3.3539 - val_loss: 12.6530 - val_mae: 2.4028 - val_mse: 12.6530\n",
      "Epoch 207/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 3.8465 - mae: 1.5633 - mse: 3.8465 - val_loss: 12.1495 - val_mae: 2.2155 - val_mse: 12.1495\n",
      "Epoch 208/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 2.4409 - mae: 1.2311 - mse: 2.4409 - val_loss: 16.2637 - val_mae: 2.7475 - val_mse: 16.2637\n",
      "Epoch 209/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 3.6771 - mae: 1.5199 - mse: 3.6771 - val_loss: 13.1979 - val_mae: 2.4972 - val_mse: 13.1979\n",
      "Epoch 210/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 3.5873 - mae: 1.5392 - mse: 3.5873 - val_loss: 13.9302 - val_mae: 2.3980 - val_mse: 13.9302\n",
      "Epoch 211/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 3.6082 - mae: 1.5158 - mse: 3.6082 - val_loss: 13.0632 - val_mae: 2.5699 - val_mse: 13.0632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 212/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 3.4221 - mae: 1.4958 - mse: 3.4221 - val_loss: 16.1055 - val_mae: 2.7248 - val_mse: 16.1055\n",
      "Epoch 213/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 3.1243 - mae: 1.4048 - mse: 3.1243 - val_loss: 12.6925 - val_mae: 2.3422 - val_mse: 12.6925\n",
      "Epoch 214/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.0139 - mae: 1.3942 - mse: 3.0139 - val_loss: 14.1292 - val_mae: 2.4885 - val_mse: 14.1292\n",
      "Epoch 215/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 4.1227 - mae: 1.6201 - mse: 4.1227 - val_loss: 12.0680 - val_mae: 2.2432 - val_mse: 12.0680\n",
      "Epoch 216/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 3.2358 - mae: 1.4416 - mse: 3.2358 - val_loss: 12.9452 - val_mae: 2.3480 - val_mse: 12.9452\n",
      "Epoch 217/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 3.6955 - mae: 1.5488 - mse: 3.6955 - val_loss: 14.8708 - val_mae: 2.5364 - val_mse: 14.8708\n",
      "Epoch 218/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 3.2909 - mae: 1.4749 - mse: 3.2909 - val_loss: 12.3548 - val_mae: 2.3663 - val_mse: 12.3548\n",
      "Epoch 219/500\n",
      "406/406 [==============================] - 0s 76us/sample - loss: 3.3965 - mae: 1.4955 - mse: 3.3965 - val_loss: 12.3254 - val_mae: 2.2704 - val_mse: 12.3254\n",
      "Epoch 220/500\n",
      "406/406 [==============================] - 0s 74us/sample - loss: 2.6696 - mae: 1.3145 - mse: 2.6696 - val_loss: 18.9608 - val_mae: 3.3376 - val_mse: 18.9608\n",
      "Epoch 221/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 3.9160 - mae: 1.6149 - mse: 3.9160 - val_loss: 11.7392 - val_mae: 2.2647 - val_mse: 11.7392\n",
      "Epoch 222/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 3.0044 - mae: 1.3916 - mse: 3.0044 - val_loss: 12.9859 - val_mae: 2.4276 - val_mse: 12.9859\n",
      "Epoch 223/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 3.5399 - mae: 1.5212 - mse: 3.5399 - val_loss: 11.8025 - val_mae: 2.2491 - val_mse: 11.8025\n",
      "Epoch 224/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.1752 - mae: 1.3917 - mse: 3.1752 - val_loss: 11.5280 - val_mae: 2.1901 - val_mse: 11.5280\n",
      "Epoch 225/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 3.3394 - mae: 1.4812 - mse: 3.3394 - val_loss: 13.5177 - val_mae: 2.4859 - val_mse: 13.5177\n",
      "Epoch 226/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 3.3606 - mae: 1.4877 - mse: 3.3606 - val_loss: 11.4985 - val_mae: 2.2216 - val_mse: 11.4985\n",
      "Epoch 227/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.3930 - mae: 1.2408 - mse: 2.3930 - val_loss: 13.2152 - val_mae: 2.5701 - val_mse: 13.2152\n",
      "Epoch 228/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.4141 - mae: 1.4609 - mse: 3.4141 - val_loss: 13.5974 - val_mae: 2.5615 - val_mse: 13.5974\n",
      "Epoch 229/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 3.4257 - mae: 1.4795 - mse: 3.4257 - val_loss: 14.0291 - val_mae: 2.4536 - val_mse: 14.0291\n",
      "Epoch 230/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 3.4377 - mae: 1.4828 - mse: 3.4377 - val_loss: 12.1429 - val_mae: 2.2691 - val_mse: 12.1429\n",
      "Epoch 231/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 3.3008 - mae: 1.4453 - mse: 3.3008 - val_loss: 17.2879 - val_mae: 2.9890 - val_mse: 17.2879\n",
      "Epoch 232/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 2.6379 - mae: 1.2902 - mse: 2.6379 - val_loss: 13.0497 - val_mae: 2.3292 - val_mse: 13.0497\n",
      "Epoch 233/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.3579 - mae: 1.4856 - mse: 3.3579 - val_loss: 13.0347 - val_mae: 2.5060 - val_mse: 13.0347\n",
      "Epoch 234/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.3727 - mae: 1.4667 - mse: 3.3727 - val_loss: 15.3177 - val_mae: 2.6583 - val_mse: 15.3177\n",
      "Epoch 235/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.2883 - mae: 1.4528 - mse: 3.2883 - val_loss: 12.0610 - val_mae: 2.2747 - val_mse: 12.0610\n",
      "Epoch 236/500\n",
      "406/406 [==============================] - 0s 74us/sample - loss: 3.4784 - mae: 1.4749 - mse: 3.4784 - val_loss: 11.7877 - val_mae: 2.2347 - val_mse: 11.7877\n",
      "Epoch 237/500\n",
      "406/406 [==============================] - 0s 108us/sample - loss: 3.4518 - mae: 1.4405 - mse: 3.4518 - val_loss: 12.9005 - val_mae: 2.4315 - val_mse: 12.9005\n",
      "Epoch 238/500\n",
      "406/406 [==============================] - 0s 107us/sample - loss: 2.4848 - mae: 1.2252 - mse: 2.4848 - val_loss: 11.7317 - val_mae: 2.2366 - val_mse: 11.7317\n",
      "Epoch 239/500\n",
      "406/406 [==============================] - 0s 94us/sample - loss: 3.2990 - mae: 1.4749 - mse: 3.2990 - val_loss: 12.8098 - val_mae: 2.4774 - val_mse: 12.8098\n",
      "Epoch 240/500\n",
      "406/406 [==============================] - 0s 94us/sample - loss: 2.5902 - mae: 1.2888 - mse: 2.5902 - val_loss: 12.8308 - val_mae: 2.4829 - val_mse: 12.8308\n",
      "Epoch 241/500\n",
      "406/406 [==============================] - 0s 93us/sample - loss: 3.4244 - mae: 1.4735 - mse: 3.4244 - val_loss: 12.5174 - val_mae: 2.3792 - val_mse: 12.5174\n",
      "Epoch 242/500\n",
      "406/406 [==============================] - 0s 83us/sample - loss: 3.1495 - mae: 1.3749 - mse: 3.1495 - val_loss: 11.4669 - val_mae: 2.2109 - val_mse: 11.4669\n",
      "Epoch 243/500\n",
      "406/406 [==============================] - 0s 81us/sample - loss: 3.6723 - mae: 1.5449 - mse: 3.6723 - val_loss: 13.2457 - val_mae: 2.3620 - val_mse: 13.2457\n",
      "Epoch 244/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 3.2329 - mae: 1.4473 - mse: 3.2329 - val_loss: 13.2776 - val_mae: 2.5155 - val_mse: 13.2776\n",
      "Epoch 245/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 2.6982 - mae: 1.3134 - mse: 2.6982 - val_loss: 11.6346 - val_mae: 2.1922 - val_mse: 11.6346\n",
      "Epoch 246/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 4.1196 - mae: 1.6205 - mse: 4.1196 - val_loss: 12.3836 - val_mae: 2.3030 - val_mse: 12.3836\n",
      "Epoch 247/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 3.0216 - mae: 1.4027 - mse: 3.0216 - val_loss: 14.0380 - val_mae: 2.6524 - val_mse: 14.0380\n",
      "Epoch 248/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 3.1961 - mae: 1.4169 - mse: 3.1961 - val_loss: 13.7408 - val_mae: 2.4478 - val_mse: 13.7408\n",
      "Epoch 249/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.7538 - mae: 1.5804 - mse: 3.7538 - val_loss: 12.6524 - val_mae: 2.3258 - val_mse: 12.6524\n",
      "Epoch 250/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 2.9705 - mae: 1.3918 - mse: 2.9705 - val_loss: 12.0053 - val_mae: 2.3524 - val_mse: 12.0053\n",
      "Epoch 251/500\n",
      "406/406 [==============================] - 0s 76us/sample - loss: 3.1376 - mae: 1.4260 - mse: 3.1376 - val_loss: 16.5317 - val_mae: 2.7602 - val_mse: 16.5317\n",
      "Epoch 252/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 2.7871 - mae: 1.3426 - mse: 2.7871 - val_loss: 11.8624 - val_mae: 2.2653 - val_mse: 11.8624\n",
      "Epoch 253/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 3.5739 - mae: 1.5156 - mse: 3.5739 - val_loss: 11.6946 - val_mae: 2.2363 - val_mse: 11.6946\n",
      "Epoch 254/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.0249 - mae: 1.3941 - mse: 3.0249 - val_loss: 11.1954 - val_mae: 2.1906 - val_mse: 11.1954\n",
      "Epoch 255/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 2.8615 - mae: 1.3454 - mse: 2.8615 - val_loss: 14.9603 - val_mae: 2.6222 - val_mse: 14.9603\n",
      "Epoch 256/500\n",
      "406/406 [==============================] - 0s 78us/sample - loss: 3.0039 - mae: 1.4082 - mse: 3.0039 - val_loss: 12.8909 - val_mae: 2.4689 - val_mse: 12.8909\n",
      "Epoch 257/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 3.5331 - mae: 1.4576 - mse: 3.5331 - val_loss: 11.1814 - val_mae: 2.1145 - val_mse: 11.1814\n",
      "Epoch 258/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 3.1417 - mae: 1.4094 - mse: 3.1417 - val_loss: 11.3087 - val_mae: 2.1670 - val_mse: 11.3087\n",
      "Epoch 259/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.0022 - mae: 1.3875 - mse: 3.0022 - val_loss: 14.8939 - val_mae: 2.6003 - val_mse: 14.8939\n",
      "Epoch 260/500\n",
      "406/406 [==============================] - 0s 76us/sample - loss: 3.0922 - mae: 1.4141 - mse: 3.0922 - val_loss: 12.2057 - val_mae: 2.4329 - val_mse: 12.2057\n",
      "Epoch 261/500\n",
      "406/406 [==============================] - 0s 103us/sample - loss: 3.0640 - mae: 1.3620 - mse: 3.0640 - val_loss: 10.7169 - val_mae: 2.1186 - val_mse: 10.7169\n",
      "Epoch 262/500\n",
      "406/406 [==============================] - 0s 91us/sample - loss: 3.3809 - mae: 1.4658 - mse: 3.3809 - val_loss: 11.4983 - val_mae: 2.3000 - val_mse: 11.4983\n",
      "Epoch 263/500\n",
      "406/406 [==============================] - 0s 92us/sample - loss: 2.3810 - mae: 1.2395 - mse: 2.3810 - val_loss: 13.5512 - val_mae: 2.4479 - val_mse: 13.5512\n",
      "Epoch 264/500\n",
      "406/406 [==============================] - 0s 87us/sample - loss: 3.3146 - mae: 1.4628 - mse: 3.3146 - val_loss: 12.3317 - val_mae: 2.4225 - val_mse: 12.3317\n",
      "Epoch 265/500\n",
      "406/406 [==============================] - 0s 92us/sample - loss: 3.6246 - mae: 1.5107 - mse: 3.6246 - val_loss: 10.8106 - val_mae: 2.1315 - val_mse: 10.8106\n",
      "Epoch 266/500\n",
      "406/406 [==============================] - 0s 100us/sample - loss: 1.8480 - mae: 1.0755 - mse: 1.8480 - val_loss: 12.7971 - val_mae: 2.6034 - val_mse: 12.7971\n",
      "Epoch 267/500\n",
      "406/406 [==============================] - 0s 93us/sample - loss: 3.8654 - mae: 1.6406 - mse: 3.8654 - val_loss: 13.4626 - val_mae: 2.3821 - val_mse: 13.4626\n",
      "Epoch 268/500\n",
      "406/406 [==============================] - 0s 74us/sample - loss: 2.9993 - mae: 1.4051 - mse: 2.9993 - val_loss: 11.7141 - val_mae: 2.3578 - val_mse: 11.7141\n",
      "Epoch 269/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 2.7952 - mae: 1.3416 - mse: 2.7952 - val_loss: 10.9350 - val_mae: 2.0896 - val_mse: 10.9350\n",
      "Epoch 270/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 3.4480 - mae: 1.4716 - mse: 3.4480 - val_loss: 11.0821 - val_mae: 2.1980 - val_mse: 11.0821\n",
      "Epoch 271/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 2.3701 - mae: 1.2415 - mse: 2.3701 - val_loss: 13.9553 - val_mae: 2.7266 - val_mse: 13.9553\n",
      "Epoch 272/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 3.3963 - mae: 1.4590 - mse: 3.3963 - val_loss: 13.9543 - val_mae: 2.5062 - val_mse: 13.9543\n",
      "Epoch 273/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 3.6227 - mae: 1.5341 - mse: 3.6227 - val_loss: 12.8107 - val_mae: 2.3032 - val_mse: 12.8107\n",
      "Epoch 274/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 2.4192 - mae: 1.2393 - mse: 2.4192 - val_loss: 14.6147 - val_mae: 2.5155 - val_mse: 14.6147\n",
      "Epoch 275/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 3.5712 - mae: 1.5161 - mse: 3.5712 - val_loss: 13.2911 - val_mae: 2.5111 - val_mse: 13.2911\n",
      "Epoch 276/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 2.8511 - mae: 1.3202 - mse: 2.8511 - val_loss: 12.0982 - val_mae: 2.3642 - val_mse: 12.0982\n",
      "Epoch 277/500\n",
      "406/406 [==============================] - 0s 64us/sample - loss: 2.5266 - mae: 1.2524 - mse: 2.5266 - val_loss: 12.1415 - val_mae: 2.3054 - val_mse: 12.1415\n",
      "Epoch 278/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 3.5416 - mae: 1.4835 - mse: 3.5416 - val_loss: 12.0710 - val_mae: 2.3745 - val_mse: 12.0711\n",
      "Epoch 279/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 2.4972 - mae: 1.2645 - mse: 2.4972 - val_loss: 12.2737 - val_mae: 2.2651 - val_mse: 12.2737\n",
      "Epoch 280/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 3.0392 - mae: 1.4052 - mse: 3.0392 - val_loss: 11.4090 - val_mae: 2.2099 - val_mse: 11.4090\n",
      "Epoch 281/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 3.4343 - mae: 1.5072 - mse: 3.4343 - val_loss: 11.2003 - val_mae: 2.2732 - val_mse: 11.2003\n",
      "Epoch 282/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.8844 - mae: 1.3606 - mse: 2.8844 - val_loss: 18.4785 - val_mae: 2.9768 - val_mse: 18.4785\n",
      "Epoch 283/500\n",
      "406/406 [==============================] - 0s 74us/sample - loss: 2.8591 - mae: 1.3568 - mse: 2.8591 - val_loss: 13.1146 - val_mae: 2.6397 - val_mse: 13.1146\n",
      "Epoch 284/500\n",
      "406/406 [==============================] - 0s 83us/sample - loss: 3.0281 - mae: 1.4022 - mse: 3.0281 - val_loss: 15.1752 - val_mae: 2.7498 - val_mse: 15.1752\n",
      "Epoch 285/500\n",
      "406/406 [==============================] - 0s 82us/sample - loss: 2.7784 - mae: 1.3490 - mse: 2.7784 - val_loss: 11.2629 - val_mae: 2.1443 - val_mse: 11.2629\n",
      "Epoch 286/500\n",
      "406/406 [==============================] - 0s 88us/sample - loss: 3.2295 - mae: 1.4284 - mse: 3.2295 - val_loss: 11.8182 - val_mae: 2.2597 - val_mse: 11.8182\n",
      "Epoch 287/500\n",
      "406/406 [==============================] - 0s 83us/sample - loss: 3.3664 - mae: 1.4821 - mse: 3.3664 - val_loss: 11.8853 - val_mae: 2.3692 - val_mse: 11.8853\n",
      "Epoch 288/500\n",
      "406/406 [==============================] - 0s 91us/sample - loss: 2.3973 - mae: 1.2328 - mse: 2.3973 - val_loss: 12.8635 - val_mae: 2.3449 - val_mse: 12.8635\n",
      "Epoch 289/500\n",
      "406/406 [==============================] - 0s 81us/sample - loss: 3.2716 - mae: 1.4575 - mse: 3.2716 - val_loss: 11.1427 - val_mae: 2.1921 - val_mse: 11.1427\n",
      "Epoch 290/500\n",
      "406/406 [==============================] - 0s 91us/sample - loss: 3.3146 - mae: 1.4593 - mse: 3.3146 - val_loss: 12.0075 - val_mae: 2.3561 - val_mse: 12.0075\n",
      "Epoch 291/500\n",
      "406/406 [==============================] - 0s 78us/sample - loss: 2.4325 - mae: 1.2325 - mse: 2.4325 - val_loss: 13.1953 - val_mae: 2.4970 - val_mse: 13.1953\n",
      "Epoch 292/500\n",
      "406/406 [==============================] - 0s 76us/sample - loss: 2.9110 - mae: 1.3749 - mse: 2.9110 - val_loss: 10.6776 - val_mae: 2.1086 - val_mse: 10.6776\n",
      "Epoch 293/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.4109 - mae: 1.4862 - mse: 3.4109 - val_loss: 11.7814 - val_mae: 2.2424 - val_mse: 11.7814\n",
      "Epoch 294/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 2.6553 - mae: 1.3228 - mse: 2.6553 - val_loss: 11.2238 - val_mae: 2.2417 - val_mse: 11.2238\n",
      "Epoch 295/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 3.1763 - mae: 1.4392 - mse: 3.1763 - val_loss: 11.3300 - val_mae: 2.2642 - val_mse: 11.3300\n",
      "Epoch 296/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 3.0793 - mae: 1.4225 - mse: 3.0793 - val_loss: 11.1524 - val_mae: 2.1632 - val_mse: 11.1524\n",
      "Epoch 297/500\n",
      "406/406 [==============================] - 0s 80us/sample - loss: 3.1005 - mae: 1.4076 - mse: 3.1005 - val_loss: 12.2279 - val_mae: 2.5416 - val_mse: 12.2279\n",
      "Epoch 298/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 2.6737 - mae: 1.3396 - mse: 2.6737 - val_loss: 10.9884 - val_mae: 2.2141 - val_mse: 10.9884\n",
      "Epoch 299/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 2.7330 - mae: 1.3252 - mse: 2.7330 - val_loss: 16.4788 - val_mae: 2.8161 - val_mse: 16.4788\n",
      "Epoch 300/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 2.9940 - mae: 1.3951 - mse: 2.9940 - val_loss: 15.0695 - val_mae: 2.6290 - val_mse: 15.0695\n",
      "Epoch 301/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 2.6425 - mae: 1.2925 - mse: 2.6425 - val_loss: 10.7198 - val_mae: 2.0971 - val_mse: 10.7198\n",
      "Epoch 302/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 2.7442 - mae: 1.2925 - mse: 2.7442 - val_loss: 15.0794 - val_mae: 2.6386 - val_mse: 15.0794\n",
      "Epoch 303/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.8644 - mae: 1.3706 - mse: 2.8644 - val_loss: 11.0578 - val_mae: 2.2478 - val_mse: 11.0578\n",
      "Epoch 304/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 3.1175 - mae: 1.4148 - mse: 3.1175 - val_loss: 11.8881 - val_mae: 2.3770 - val_mse: 11.8881\n",
      "Epoch 305/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 3.2334 - mae: 1.4467 - mse: 3.2334 - val_loss: 10.9625 - val_mae: 2.2417 - val_mse: 10.9625\n",
      "Epoch 306/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 2.6016 - mae: 1.2918 - mse: 2.6016 - val_loss: 12.0540 - val_mae: 2.2663 - val_mse: 12.0540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 3.0124 - mae: 1.4004 - mse: 3.0124 - val_loss: 10.5563 - val_mae: 2.1624 - val_mse: 10.5563\n",
      "Epoch 308/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 2.4410 - mae: 1.2390 - mse: 2.4410 - val_loss: 11.7390 - val_mae: 2.3305 - val_mse: 11.7390\n",
      "Epoch 309/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 3.4142 - mae: 1.4809 - mse: 3.4142 - val_loss: 10.9014 - val_mae: 2.2208 - val_mse: 10.9014\n",
      "Epoch 310/500\n",
      "406/406 [==============================] - 0s 75us/sample - loss: 2.2859 - mae: 1.2220 - mse: 2.2859 - val_loss: 11.5061 - val_mae: 2.1947 - val_mse: 11.5061\n",
      "Epoch 311/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 2.8869 - mae: 1.3734 - mse: 2.8869 - val_loss: 10.7006 - val_mae: 2.1804 - val_mse: 10.7006\n",
      "Epoch 312/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 3.2431 - mae: 1.4789 - mse: 3.2431 - val_loss: 10.9109 - val_mae: 2.1113 - val_mse: 10.9109\n",
      "Epoch 313/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.3757 - mae: 1.2314 - mse: 2.3757 - val_loss: 16.6690 - val_mae: 2.8655 - val_mse: 16.6690\n",
      "Epoch 314/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.4132 - mae: 1.2271 - mse: 2.4132 - val_loss: 10.9668 - val_mae: 2.1519 - val_mse: 10.9668\n",
      "Epoch 315/500\n",
      "406/406 [==============================] - 0s 75us/sample - loss: 3.4618 - mae: 1.4814 - mse: 3.4618 - val_loss: 10.8838 - val_mae: 2.1199 - val_mse: 10.8838\n",
      "Epoch 316/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.3438 - mae: 1.2169 - mse: 2.3438 - val_loss: 15.0034 - val_mae: 2.6078 - val_mse: 15.0034\n",
      "Epoch 317/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 2.7684 - mae: 1.3169 - mse: 2.7684 - val_loss: 11.1683 - val_mae: 2.1634 - val_mse: 11.1683\n",
      "Epoch 318/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 2.6126 - mae: 1.2968 - mse: 2.6126 - val_loss: 10.7229 - val_mae: 2.1671 - val_mse: 10.7229\n",
      "Epoch 319/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.0976 - mae: 1.4245 - mse: 3.0976 - val_loss: 12.1152 - val_mae: 2.4115 - val_mse: 12.1152\n",
      "Epoch 320/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.7470 - mae: 1.3334 - mse: 2.7470 - val_loss: 14.1139 - val_mae: 2.6186 - val_mse: 14.1139\n",
      "Epoch 321/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 3.2863 - mae: 1.4591 - mse: 3.2863 - val_loss: 10.0746 - val_mae: 2.0287 - val_mse: 10.0746\n",
      "Epoch 322/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 2.5813 - mae: 1.2870 - mse: 2.5813 - val_loss: 12.8379 - val_mae: 2.5006 - val_mse: 12.8379\n",
      "Epoch 323/500\n",
      "406/406 [==============================] - 0s 74us/sample - loss: 2.6998 - mae: 1.3209 - mse: 2.6998 - val_loss: 14.6529 - val_mae: 2.7493 - val_mse: 14.6529\n",
      "Epoch 324/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 2.8347 - mae: 1.3587 - mse: 2.8347 - val_loss: 10.4903 - val_mae: 2.1631 - val_mse: 10.4903\n",
      "Epoch 325/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.0877 - mae: 1.4215 - mse: 3.0877 - val_loss: 11.3488 - val_mae: 2.1494 - val_mse: 11.3488\n",
      "Epoch 326/500\n",
      "406/406 [==============================] - 0s 75us/sample - loss: 2.5752 - mae: 1.2778 - mse: 2.5752 - val_loss: 9.9153 - val_mae: 2.0380 - val_mse: 9.9153\n",
      "Epoch 327/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 2.8085 - mae: 1.3404 - mse: 2.8085 - val_loss: 13.3679 - val_mae: 2.5159 - val_mse: 13.3679\n",
      "Epoch 328/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 2.6356 - mae: 1.3205 - mse: 2.6356 - val_loss: 13.8638 - val_mae: 2.6040 - val_mse: 13.8638\n",
      "Epoch 329/500\n",
      "406/406 [==============================] - 0s 77us/sample - loss: 2.4722 - mae: 1.2477 - mse: 2.4722 - val_loss: 11.5445 - val_mae: 2.2550 - val_mse: 11.5445\n",
      "Epoch 330/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 2.7724 - mae: 1.3327 - mse: 2.7724 - val_loss: 13.3346 - val_mae: 2.5710 - val_mse: 13.3346\n",
      "Epoch 331/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 3.0460 - mae: 1.4133 - mse: 3.0460 - val_loss: 10.4299 - val_mae: 2.1492 - val_mse: 10.4299\n",
      "Epoch 332/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.7691 - mae: 1.3358 - mse: 2.7691 - val_loss: 11.7236 - val_mae: 2.3442 - val_mse: 11.7236\n",
      "Epoch 333/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 2.6735 - mae: 1.2998 - mse: 2.6735 - val_loss: 11.7062 - val_mae: 2.3742 - val_mse: 11.7062\n",
      "Epoch 334/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 3.0688 - mae: 1.3810 - mse: 3.0688 - val_loss: 9.7107 - val_mae: 1.9971 - val_mse: 9.7107\n",
      "Epoch 335/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.6726 - mae: 1.3158 - mse: 2.6726 - val_loss: 12.2191 - val_mae: 2.4711 - val_mse: 12.2191\n",
      "Epoch 336/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 2.3947 - mae: 1.2202 - mse: 2.3947 - val_loss: 10.4918 - val_mae: 2.0961 - val_mse: 10.4918\n",
      "Epoch 337/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 2.6948 - mae: 1.3272 - mse: 2.6948 - val_loss: 10.4297 - val_mae: 2.0731 - val_mse: 10.4297\n",
      "Epoch 338/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 3.2053 - mae: 1.4382 - mse: 3.2053 - val_loss: 15.0428 - val_mae: 2.8265 - val_mse: 15.0428\n",
      "Epoch 339/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 2.5097 - mae: 1.2737 - mse: 2.5097 - val_loss: 11.9111 - val_mae: 2.3808 - val_mse: 11.9111\n",
      "Epoch 340/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.7626 - mae: 1.3207 - mse: 2.7626 - val_loss: 12.1990 - val_mae: 2.2827 - val_mse: 12.1990\n",
      "Epoch 341/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.6466 - mae: 1.2979 - mse: 2.6466 - val_loss: 12.1626 - val_mae: 2.4562 - val_mse: 12.1626\n",
      "Epoch 342/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 2.7236 - mae: 1.3310 - mse: 2.7236 - val_loss: 11.4191 - val_mae: 2.2703 - val_mse: 11.4191\n",
      "Epoch 343/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 2.7805 - mae: 1.3478 - mse: 2.7805 - val_loss: 10.2839 - val_mae: 2.0457 - val_mse: 10.2839\n",
      "Epoch 344/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 2.7339 - mae: 1.3269 - mse: 2.7339 - val_loss: 12.1061 - val_mae: 2.3728 - val_mse: 12.1061\n",
      "Epoch 345/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 2.8042 - mae: 1.3504 - mse: 2.8042 - val_loss: 10.0737 - val_mae: 2.1070 - val_mse: 10.0737\n",
      "Epoch 346/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.8473 - mae: 1.3755 - mse: 2.8473 - val_loss: 10.5113 - val_mae: 2.0989 - val_mse: 10.5113\n",
      "Epoch 347/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 2.9995 - mae: 1.3892 - mse: 2.9995 - val_loss: 10.8726 - val_mae: 2.1409 - val_mse: 10.8726\n",
      "Epoch 348/500\n",
      "406/406 [==============================] - 0s 63us/sample - loss: 2.5900 - mae: 1.2900 - mse: 2.5900 - val_loss: 10.9015 - val_mae: 2.2959 - val_mse: 10.9015\n",
      "Epoch 349/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.3294 - mae: 1.2358 - mse: 2.3294 - val_loss: 10.5652 - val_mae: 2.1980 - val_mse: 10.5652\n",
      "Epoch 350/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 3.1732 - mae: 1.3942 - mse: 3.1732 - val_loss: 10.1349 - val_mae: 2.1107 - val_mse: 10.1349\n",
      "Epoch 351/500\n",
      "406/406 [==============================] - 0s 70us/sample - loss: 2.3064 - mae: 1.2300 - mse: 2.3064 - val_loss: 14.7928 - val_mae: 2.6721 - val_mse: 14.7928\n",
      "Epoch 352/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 2.6502 - mae: 1.3023 - mse: 2.6502 - val_loss: 11.0199 - val_mae: 2.2123 - val_mse: 11.0199\n",
      "Epoch 353/500\n",
      "406/406 [==============================] - 0s 76us/sample - loss: 2.9680 - mae: 1.3787 - mse: 2.9680 - val_loss: 11.9389 - val_mae: 2.2110 - val_mse: 11.9389\n",
      "Epoch 354/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 2.7146 - mae: 1.3436 - mse: 2.7146 - val_loss: 10.3393 - val_mae: 2.1076 - val_mse: 10.3393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 2.7075 - mae: 1.3223 - mse: 2.7075 - val_loss: 11.8916 - val_mae: 2.2648 - val_mse: 11.8916\n",
      "Epoch 356/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 2.6028 - mae: 1.2731 - mse: 2.6028 - val_loss: 13.1358 - val_mae: 2.3992 - val_mse: 13.1358\n",
      "Epoch 357/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 2.0522 - mae: 1.1456 - mse: 2.0522 - val_loss: 11.3227 - val_mae: 2.2682 - val_mse: 11.3227\n",
      "Epoch 358/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 2.2090 - mae: 1.1728 - mse: 2.2090 - val_loss: 16.0465 - val_mae: 3.0172 - val_mse: 16.0465\n",
      "Epoch 359/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 3.2041 - mae: 1.4439 - mse: 3.2041 - val_loss: 11.0055 - val_mae: 2.2311 - val_mse: 11.0055\n",
      "Epoch 360/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 2.3909 - mae: 1.2332 - mse: 2.3909 - val_loss: 10.7870 - val_mae: 2.1810 - val_mse: 10.7870\n",
      "Epoch 361/500\n",
      "406/406 [==============================] - 0s 67us/sample - loss: 2.9671 - mae: 1.3672 - mse: 2.9671 - val_loss: 10.7969 - val_mae: 2.2485 - val_mse: 10.7969\n",
      "Epoch 362/500\n",
      "406/406 [==============================] - 0s 73us/sample - loss: 2.6528 - mae: 1.3207 - mse: 2.6528 - val_loss: 11.5819 - val_mae: 2.3102 - val_mse: 11.5819\n",
      "Epoch 363/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 2.5679 - mae: 1.2746 - mse: 2.5679 - val_loss: 12.8636 - val_mae: 2.3560 - val_mse: 12.8636\n",
      "Epoch 364/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 2.5145 - mae: 1.2474 - mse: 2.5145 - val_loss: 11.8785 - val_mae: 2.4605 - val_mse: 11.8785\n",
      "Epoch 365/500\n",
      "406/406 [==============================] - 0s 66us/sample - loss: 2.9264 - mae: 1.3544 - mse: 2.9264 - val_loss: 11.5740 - val_mae: 2.4169 - val_mse: 11.5740\n",
      "Epoch 366/500\n",
      "406/406 [==============================] - 0s 71us/sample - loss: 2.5619 - mae: 1.2892 - mse: 2.5619 - val_loss: 11.6096 - val_mae: 2.2208 - val_mse: 11.6096\n",
      "Epoch 367/500\n",
      "406/406 [==============================] - 0s 68us/sample - loss: 2.7441 - mae: 1.3322 - mse: 2.7441 - val_loss: 11.1037 - val_mae: 2.2863 - val_mse: 11.1037\n",
      "Epoch 368/500\n",
      "406/406 [==============================] - 0s 69us/sample - loss: 2.6511 - mae: 1.2690 - mse: 2.6511 - val_loss: 10.3390 - val_mae: 2.1361 - val_mse: 10.3390\n",
      "Epoch 369/500\n",
      "406/406 [==============================] - 0s 72us/sample - loss: 2.3447 - mae: 1.2340 - mse: 2.3447 - val_loss: 10.2283 - val_mae: 2.1464 - val_mse: 10.2283\n",
      "Epoch 370/500\n",
      "406/406 [==============================] - 0s 96us/sample - loss: 2.7621 - mae: 1.3659 - mse: 2.7621 - val_loss: 11.9756 - val_mae: 2.2386 - val_mse: 11.9756\n",
      "Epoch 371/500\n",
      "406/406 [==============================] - 0s 99us/sample - loss: 2.4081 - mae: 1.2534 - mse: 2.4081 - val_loss: 10.9518 - val_mae: 2.1962 - val_mse: 10.9518\n",
      "Epoch 372/500\n",
      "406/406 [==============================] - 0s 106us/sample - loss: 2.8182 - mae: 1.3680 - mse: 2.8182 - val_loss: 11.1455 - val_mae: 2.3788 - val_mse: 11.1455\n",
      "Epoch 373/500\n",
      "406/406 [==============================] - 0s 93us/sample - loss: 2.7396 - mae: 1.3271 - mse: 2.7396 - val_loss: 11.0593 - val_mae: 2.3078 - val_mse: 11.0593\n",
      "Epoch 374/500\n",
      "406/406 [==============================] - 0s 91us/sample - loss: 2.4423 - mae: 1.2465 - mse: 2.4423 - val_loss: 11.0726 - val_mae: 2.2515 - val_mse: 11.0726\n",
      "Epoch 375/500\n",
      "406/406 [==============================] - 0s 86us/sample - loss: 2.5177 - mae: 1.2698 - mse: 2.5177 - val_loss: 10.3709 - val_mae: 2.1605 - val_mse: 10.3709\n",
      "Epoch 376/500\n",
      "406/406 [==============================] - 0s 94us/sample - loss: 2.3717 - mae: 1.2200 - mse: 2.3717 - val_loss: 11.3868 - val_mae: 2.2883 - val_mse: 11.3868\n",
      "Epoch 377/500\n",
      "406/406 [==============================] - 0s 89us/sample - loss: 2.6840 - mae: 1.3256 - mse: 2.6840 - val_loss: 10.4025 - val_mae: 2.1449 - val_mse: 10.4025\n",
      "Epoch 378/500\n",
      "406/406 [==============================] - 0s 89us/sample - loss: 2.7860 - mae: 1.3572 - mse: 2.7860 - val_loss: 14.7204 - val_mae: 2.6930 - val_mse: 14.7204\n",
      "Epoch 379/500\n",
      "406/406 [==============================] - 0s 86us/sample - loss: 2.2598 - mae: 1.2080 - mse: 2.2598 - val_loss: 10.0958 - val_mae: 2.1056 - val_mse: 10.0958\n",
      "Epoch 380/500\n",
      "406/406 [==============================] - 0s 90us/sample - loss: 2.3553 - mae: 1.2115 - mse: 2.3553 - val_loss: 11.1750 - val_mae: 2.2775 - val_mse: 11.1750\n",
      "Epoch 381/500\n",
      "406/406 [==============================] - 0s 89us/sample - loss: 2.6346 - mae: 1.2964 - mse: 2.6346 - val_loss: 11.3466 - val_mae: 2.2577 - val_mse: 11.3466\n",
      "Epoch 382/500\n",
      "406/406 [==============================] - 0s 91us/sample - loss: 3.1247 - mae: 1.4163 - mse: 3.1247 - val_loss: 10.2815 - val_mae: 2.1447 - val_mse: 10.2815\n",
      "Epoch 383/500\n",
      "406/406 [==============================] - 0s 93us/sample - loss: 2.0412 - mae: 1.1353 - mse: 2.0412 - val_loss: 10.8856 - val_mae: 2.2298 - val_mse: 10.8856\n",
      "Epoch 384/500\n",
      "406/406 [==============================] - 0s 77us/sample - loss: 2.8245 - mae: 1.3489 - mse: 2.8245 - val_loss: 10.5396 - val_mae: 2.1489 - val_mse: 10.5396\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 487 samples, validate on 162 samples\n",
      "Epoch 1/500\n",
      "487/487 [==============================] - 0s 763us/sample - loss: 995.7282 - mae: 21.6832 - mse: 995.7282 - val_loss: 503.3948 - val_mae: 14.3256 - val_mse: 503.3948\n",
      "Epoch 2/500\n",
      "487/487 [==============================] - 0s 72us/sample - loss: 253.8201 - mae: 9.4584 - mse: 253.8201 - val_loss: 412.7521 - val_mae: 13.9067 - val_mse: 412.7520\n",
      "Epoch 3/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 212.3722 - mae: 8.9518 - mse: 212.3722 - val_loss: 492.9526 - val_mae: 15.8986 - val_mse: 492.9526\n",
      "Epoch 4/500\n",
      "487/487 [==============================] - 0s 67us/sample - loss: 180.6390 - mae: 8.3975 - mse: 180.6390 - val_loss: 320.3283 - val_mae: 12.0837 - val_mse: 320.3283\n",
      "Epoch 5/500\n",
      "487/487 [==============================] - 0s 67us/sample - loss: 136.2003 - mae: 7.4857 - mse: 136.2003 - val_loss: 318.8290 - val_mae: 12.7896 - val_mse: 318.8290\n",
      "Epoch 6/500\n",
      "487/487 [==============================] - 0s 67us/sample - loss: 112.9709 - mae: 7.0240 - mse: 112.9709 - val_loss: 211.5964 - val_mae: 10.1545 - val_mse: 211.5964\n",
      "Epoch 7/500\n",
      "487/487 [==============================] - 0s 61us/sample - loss: 89.2285 - mae: 6.5478 - mse: 89.2285 - val_loss: 198.4841 - val_mae: 9.8348 - val_mse: 198.4841\n",
      "Epoch 8/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 69.4611 - mae: 5.8026 - mse: 69.4611 - val_loss: 167.5619 - val_mae: 8.6124 - val_mse: 167.5618\n",
      "Epoch 9/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 65.1466 - mae: 5.7971 - mse: 65.1466 - val_loss: 150.9484 - val_mae: 8.0531 - val_mse: 150.9484\n",
      "Epoch 10/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 51.0958 - mae: 5.0394 - mse: 51.0958 - val_loss: 148.0121 - val_mae: 7.7755 - val_mse: 148.0121\n",
      "Epoch 11/500\n",
      "487/487 [==============================] - 0s 79us/sample - loss: 47.7829 - mae: 4.8084 - mse: 47.7829 - val_loss: 151.2037 - val_mae: 8.4225 - val_mse: 151.2037\n",
      "Epoch 12/500\n",
      "487/487 [==============================] - 0s 75us/sample - loss: 40.8943 - mae: 4.5128 - mse: 40.8943 - val_loss: 148.5259 - val_mae: 8.5292 - val_mse: 148.5259\n",
      "Epoch 13/500\n",
      "487/487 [==============================] - 0s 105us/sample - loss: 41.1910 - mae: 4.4292 - mse: 41.1910 - val_loss: 143.9851 - val_mae: 7.8140 - val_mse: 143.9851\n",
      "Epoch 14/500\n",
      "487/487 [==============================] - 0s 99us/sample - loss: 42.2090 - mae: 4.7090 - mse: 42.2090 - val_loss: 121.8019 - val_mae: 7.1394 - val_mse: 121.8019\n",
      "Epoch 15/500\n",
      "487/487 [==============================] - 0s 79us/sample - loss: 39.0543 - mae: 4.4117 - mse: 39.0543 - val_loss: 121.1047 - val_mae: 6.8217 - val_mse: 121.1047\n",
      "Epoch 16/500\n",
      "487/487 [==============================] - 0s 90us/sample - loss: 34.6225 - mae: 4.1299 - mse: 34.6225 - val_loss: 114.1790 - val_mae: 6.4643 - val_mse: 114.1790\n",
      "Epoch 17/500\n",
      "487/487 [==============================] - 0s 88us/sample - loss: 35.0496 - mae: 4.1424 - mse: 35.0496 - val_loss: 106.6121 - val_mae: 6.1613 - val_mse: 106.6121\n",
      "Epoch 18/500\n",
      "487/487 [==============================] - 0s 92us/sample - loss: 31.6335 - mae: 3.9102 - mse: 31.6335 - val_loss: 140.6580 - val_mae: 8.2120 - val_mse: 140.6580\n",
      "Epoch 19/500\n",
      "487/487 [==============================] - 0s 84us/sample - loss: 32.1422 - mae: 3.8978 - mse: 32.1422 - val_loss: 113.2955 - val_mae: 7.2222 - val_mse: 113.2955\n",
      "Epoch 20/500\n",
      "487/487 [==============================] - 0s 68us/sample - loss: 29.9574 - mae: 3.7858 - mse: 29.9574 - val_loss: 99.0994 - val_mae: 6.0306 - val_mse: 99.0994\n",
      "Epoch 21/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 27.5166 - mae: 3.6574 - mse: 27.5166 - val_loss: 101.4377 - val_mae: 5.9251 - val_mse: 101.4377\n",
      "Epoch 22/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 28.8926 - mae: 3.8617 - mse: 28.8926 - val_loss: 93.3251 - val_mae: 5.6408 - val_mse: 93.3251\n",
      "Epoch 23/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 24.5270 - mae: 3.4640 - mse: 24.5270 - val_loss: 105.9049 - val_mae: 6.3619 - val_mse: 105.9049\n",
      "Epoch 24/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 26.2115 - mae: 3.6823 - mse: 26.2115 - val_loss: 105.4355 - val_mae: 6.3590 - val_mse: 105.4355\n",
      "Epoch 25/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 29.4151 - mae: 3.9066 - mse: 29.4151 - val_loss: 86.9095 - val_mae: 5.5199 - val_mse: 86.9095\n",
      "Epoch 26/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 24.4587 - mae: 3.5342 - mse: 24.4587 - val_loss: 91.1907 - val_mae: 5.6050 - val_mse: 91.1907\n",
      "Epoch 27/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 27.1837 - mae: 3.7756 - mse: 27.1837 - val_loss: 85.1523 - val_mae: 5.4452 - val_mse: 85.1523\n",
      "Epoch 28/500\n",
      "487/487 [==============================] - 0s 61us/sample - loss: 24.6477 - mae: 3.6468 - mse: 24.6477 - val_loss: 84.7153 - val_mae: 5.4103 - val_mse: 84.7153\n",
      "Epoch 29/500\n",
      "487/487 [==============================] - 0s 69us/sample - loss: 24.4914 - mae: 3.5331 - mse: 24.4914 - val_loss: 85.0940 - val_mae: 5.7720 - val_mse: 85.0940\n",
      "Epoch 30/500\n",
      "487/487 [==============================] - 0s 60us/sample - loss: 21.0314 - mae: 3.3067 - mse: 21.0314 - val_loss: 80.4435 - val_mae: 5.4161 - val_mse: 80.4435\n",
      "Epoch 31/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 23.2184 - mae: 3.4626 - mse: 23.2184 - val_loss: 78.7838 - val_mae: 5.2859 - val_mse: 78.7838\n",
      "Epoch 32/500\n",
      "487/487 [==============================] - 0s 60us/sample - loss: 22.2494 - mae: 3.4585 - mse: 22.2494 - val_loss: 79.7613 - val_mae: 5.1651 - val_mse: 79.7613\n",
      "Epoch 33/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 18.4749 - mae: 3.0123 - mse: 18.4749 - val_loss: 82.3328 - val_mae: 5.3512 - val_mse: 82.3328\n",
      "Epoch 34/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 23.7244 - mae: 3.6469 - mse: 23.7244 - val_loss: 76.6470 - val_mae: 5.1640 - val_mse: 76.6470\n",
      "Epoch 35/500\n",
      "487/487 [==============================] - 0s 71us/sample - loss: 19.7276 - mae: 3.1007 - mse: 19.7276 - val_loss: 74.0195 - val_mae: 5.2173 - val_mse: 74.0195\n",
      "Epoch 36/500\n",
      "487/487 [==============================] - 0s 92us/sample - loss: 20.3845 - mae: 3.2910 - mse: 20.3845 - val_loss: 72.1868 - val_mae: 4.8748 - val_mse: 72.1868\n",
      "Epoch 37/500\n",
      "487/487 [==============================] - 0s 83us/sample - loss: 20.2615 - mae: 3.3091 - mse: 20.2615 - val_loss: 79.1572 - val_mae: 5.3051 - val_mse: 79.1572\n",
      "Epoch 38/500\n",
      "487/487 [==============================] - 0s 84us/sample - loss: 19.1522 - mae: 3.2131 - mse: 19.1522 - val_loss: 81.0604 - val_mae: 5.5725 - val_mse: 81.0604\n",
      "Epoch 39/500\n",
      "487/487 [==============================] - 0s 84us/sample - loss: 17.3203 - mae: 2.9780 - mse: 17.3203 - val_loss: 93.7748 - val_mae: 7.2818 - val_mse: 93.7748\n",
      "Epoch 40/500\n",
      "487/487 [==============================] - 0s 90us/sample - loss: 17.8369 - mae: 3.0143 - mse: 17.8369 - val_loss: 71.0102 - val_mae: 5.3575 - val_mse: 71.0102\n",
      "Epoch 41/500\n",
      "487/487 [==============================] - 0s 79us/sample - loss: 15.5068 - mae: 2.8486 - mse: 15.5068 - val_loss: 67.5784 - val_mae: 4.7018 - val_mse: 67.5784\n",
      "Epoch 42/500\n",
      "487/487 [==============================] - 0s 83us/sample - loss: 18.3924 - mae: 3.1116 - mse: 18.3924 - val_loss: 66.6636 - val_mae: 4.6654 - val_mse: 66.6636\n",
      "Epoch 43/500\n",
      "487/487 [==============================] - 0s 82us/sample - loss: 16.9656 - mae: 2.8837 - mse: 16.9656 - val_loss: 62.5698 - val_mae: 4.6056 - val_mse: 62.5698\n",
      "Epoch 44/500\n",
      "487/487 [==============================] - 0s 70us/sample - loss: 16.6648 - mae: 2.9648 - mse: 16.6648 - val_loss: 61.1585 - val_mae: 4.5498 - val_mse: 61.1585\n",
      "Epoch 45/500\n",
      "487/487 [==============================] - 0s 70us/sample - loss: 15.5441 - mae: 2.8228 - mse: 15.5441 - val_loss: 64.3019 - val_mae: 4.7386 - val_mse: 64.3019\n",
      "Epoch 46/500\n",
      "487/487 [==============================] - 0s 60us/sample - loss: 17.4479 - mae: 3.1490 - mse: 17.4479 - val_loss: 68.3408 - val_mae: 5.1397 - val_mse: 68.3408\n",
      "Epoch 47/500\n",
      "487/487 [==============================] - 0s 61us/sample - loss: 16.2112 - mae: 2.9774 - mse: 16.2112 - val_loss: 64.6335 - val_mae: 5.3481 - val_mse: 64.6335\n",
      "Epoch 48/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 13.6150 - mae: 2.6622 - mse: 13.6150 - val_loss: 57.1868 - val_mae: 4.3041 - val_mse: 57.1868\n",
      "Epoch 49/500\n",
      "487/487 [==============================] - 0s 68us/sample - loss: 14.9987 - mae: 2.8183 - mse: 14.9987 - val_loss: 60.6174 - val_mae: 4.9576 - val_mse: 60.6174\n",
      "Epoch 50/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 16.0570 - mae: 2.9840 - mse: 16.0570 - val_loss: 57.7862 - val_mae: 4.4789 - val_mse: 57.7862\n",
      "Epoch 51/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 14.9582 - mae: 2.8960 - mse: 14.9582 - val_loss: 69.3229 - val_mae: 5.2717 - val_mse: 69.3229\n",
      "Epoch 52/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 16.4381 - mae: 3.0275 - mse: 16.4381 - val_loss: 57.2231 - val_mae: 4.3950 - val_mse: 57.2231\n",
      "Epoch 53/500\n",
      "487/487 [==============================] - 0s 70us/sample - loss: 13.7055 - mae: 2.6659 - mse: 13.7055 - val_loss: 54.6415 - val_mae: 4.2299 - val_mse: 54.6415\n",
      "Epoch 54/500\n",
      "487/487 [==============================] - 0s 72us/sample - loss: 13.9734 - mae: 2.8114 - mse: 13.9734 - val_loss: 62.3462 - val_mae: 4.7731 - val_mse: 62.3462\n",
      "Epoch 55/500\n",
      "487/487 [==============================] - 0s 78us/sample - loss: 14.0436 - mae: 2.8365 - mse: 14.0436 - val_loss: 63.5782 - val_mae: 4.9110 - val_mse: 63.5782\n",
      "Epoch 56/500\n",
      "487/487 [==============================] - 0s 99us/sample - loss: 15.5962 - mae: 2.9699 - mse: 15.5962 - val_loss: 54.3156 - val_mae: 4.2007 - val_mse: 54.3156\n",
      "Epoch 57/500\n",
      "487/487 [==============================] - 0s 95us/sample - loss: 12.4355 - mae: 2.6206 - mse: 12.4355 - val_loss: 53.3648 - val_mae: 4.4606 - val_mse: 53.3648\n",
      "Epoch 58/500\n",
      "487/487 [==============================] - 0s 85us/sample - loss: 12.6503 - mae: 2.6882 - mse: 12.6503 - val_loss: 51.8626 - val_mae: 4.2032 - val_mse: 51.8626\n",
      "Epoch 59/500\n",
      "487/487 [==============================] - 0s 90us/sample - loss: 14.3592 - mae: 2.8429 - mse: 14.3592 - val_loss: 52.6450 - val_mae: 4.4904 - val_mse: 52.6451\n",
      "Epoch 60/500\n",
      "487/487 [==============================] - 0s 84us/sample - loss: 12.0574 - mae: 2.4987 - mse: 12.0574 - val_loss: 58.8653 - val_mae: 4.6670 - val_mse: 58.8653\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 0s 85us/sample - loss: 11.8254 - mae: 2.5011 - mse: 11.8254 - val_loss: 51.1079 - val_mae: 4.2557 - val_mse: 51.1079\n",
      "Epoch 62/500\n",
      "487/487 [==============================] - 0s 87us/sample - loss: 13.4109 - mae: 2.7120 - mse: 13.4109 - val_loss: 48.6445 - val_mae: 4.0015 - val_mse: 48.6445\n",
      "Epoch 63/500\n",
      "487/487 [==============================] - 0s 84us/sample - loss: 11.9365 - mae: 2.5932 - mse: 11.9365 - val_loss: 49.0144 - val_mae: 4.0493 - val_mse: 49.0144\n",
      "Epoch 64/500\n",
      "487/487 [==============================] - 0s 87us/sample - loss: 12.4901 - mae: 2.6266 - mse: 12.4901 - val_loss: 48.6998 - val_mae: 3.8795 - val_mse: 48.6998\n",
      "Epoch 65/500\n",
      "487/487 [==============================] - 0s 90us/sample - loss: 11.8768 - mae: 2.5886 - mse: 11.8768 - val_loss: 57.3801 - val_mae: 4.7282 - val_mse: 57.3801\n",
      "Epoch 66/500\n",
      "487/487 [==============================] - 0s 91us/sample - loss: 12.8878 - mae: 2.6824 - mse: 12.8878 - val_loss: 50.2041 - val_mae: 4.3630 - val_mse: 50.2041\n",
      "Epoch 67/500\n",
      "487/487 [==============================] - 0s 82us/sample - loss: 10.2135 - mae: 2.3471 - mse: 10.2135 - val_loss: 49.3700 - val_mae: 4.4814 - val_mse: 49.3700\n",
      "Epoch 68/500\n",
      "487/487 [==============================] - 0s 73us/sample - loss: 13.2775 - mae: 2.8291 - mse: 13.2775 - val_loss: 50.1943 - val_mae: 4.3552 - val_mse: 50.1943\n",
      "Epoch 69/500\n",
      "487/487 [==============================] - 0s 74us/sample - loss: 11.1619 - mae: 2.5186 - mse: 11.1619 - val_loss: 60.8689 - val_mae: 5.2290 - val_mse: 60.8689\n",
      "Epoch 70/500\n",
      "487/487 [==============================] - 0s 75us/sample - loss: 11.8549 - mae: 2.6612 - mse: 11.8549 - val_loss: 55.6610 - val_mae: 5.3529 - val_mse: 55.6610\n",
      "Epoch 71/500\n",
      "487/487 [==============================] - 0s 68us/sample - loss: 12.1744 - mae: 2.6536 - mse: 12.1744 - val_loss: 46.5775 - val_mae: 4.1946 - val_mse: 46.5775\n",
      "Epoch 72/500\n",
      "487/487 [==============================] - 0s 67us/sample - loss: 9.4307 - mae: 2.3627 - mse: 9.4307 - val_loss: 74.8253 - val_mae: 6.3391 - val_mse: 74.8253\n",
      "Epoch 73/500\n",
      "487/487 [==============================] - 0s 68us/sample - loss: 10.2721 - mae: 2.3686 - mse: 10.2721 - val_loss: 61.4449 - val_mae: 5.3932 - val_mse: 61.4449\n",
      "Epoch 74/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 10.8406 - mae: 2.4910 - mse: 10.8406 - val_loss: 61.6102 - val_mae: 5.4412 - val_mse: 61.6102\n",
      "Epoch 75/500\n",
      "487/487 [==============================] - 0s 60us/sample - loss: 10.5455 - mae: 2.4774 - mse: 10.5455 - val_loss: 49.4370 - val_mae: 4.1995 - val_mse: 49.4370\n",
      "Epoch 76/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 10.1296 - mae: 2.4822 - mse: 10.1296 - val_loss: 45.5846 - val_mae: 3.8390 - val_mse: 45.5846\n",
      "Epoch 77/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 12.0945 - mae: 2.7408 - mse: 12.0945 - val_loss: 42.6860 - val_mae: 3.5772 - val_mse: 42.6860\n",
      "Epoch 78/500\n",
      "487/487 [==============================] - 0s 67us/sample - loss: 10.6237 - mae: 2.4390 - mse: 10.6237 - val_loss: 43.0545 - val_mae: 3.6754 - val_mse: 43.0545\n",
      "Epoch 79/500\n",
      "487/487 [==============================] - 0s 60us/sample - loss: 9.9444 - mae: 2.3710 - mse: 9.9444 - val_loss: 43.9735 - val_mae: 3.6902 - val_mse: 43.9735\n",
      "Epoch 80/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 11.4545 - mae: 2.5582 - mse: 11.4545 - val_loss: 43.8906 - val_mae: 3.7888 - val_mse: 43.8906\n",
      "Epoch 81/500\n",
      "487/487 [==============================] - 0s 60us/sample - loss: 6.9432 - mae: 1.9164 - mse: 6.9432 - val_loss: 57.8780 - val_mae: 5.0841 - val_mse: 57.8780\n",
      "Epoch 82/500\n",
      "487/487 [==============================] - 0s 69us/sample - loss: 9.9373 - mae: 2.3839 - mse: 9.9373 - val_loss: 40.7148 - val_mae: 3.5723 - val_mse: 40.7149\n",
      "Epoch 83/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 10.7840 - mae: 2.4513 - mse: 10.7840 - val_loss: 42.7731 - val_mae: 3.7684 - val_mse: 42.7731\n",
      "Epoch 84/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 10.1794 - mae: 2.3950 - mse: 10.1794 - val_loss: 50.7873 - val_mae: 5.1857 - val_mse: 50.7873\n",
      "Epoch 85/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 7.1025 - mae: 1.8961 - mse: 7.1025 - val_loss: 52.3127 - val_mae: 5.3138 - val_mse: 52.3127\n",
      "Epoch 86/500\n",
      "487/487 [==============================] - 0s 68us/sample - loss: 11.7933 - mae: 2.6355 - mse: 11.7933 - val_loss: 48.6122 - val_mae: 4.6661 - val_mse: 48.6122\n",
      "Epoch 87/500\n",
      "487/487 [==============================] - 0s 79us/sample - loss: 7.3805 - mae: 1.9959 - mse: 7.3805 - val_loss: 44.1711 - val_mae: 4.2994 - val_mse: 44.1711\n",
      "Epoch 88/500\n",
      "487/487 [==============================] - 0s 93us/sample - loss: 12.6996 - mae: 2.7849 - mse: 12.6996 - val_loss: 40.1146 - val_mae: 3.7156 - val_mse: 40.1146\n",
      "Epoch 89/500\n",
      "487/487 [==============================] - 0s 92us/sample - loss: 8.9769 - mae: 2.3090 - mse: 8.9769 - val_loss: 38.7637 - val_mae: 3.3861 - val_mse: 38.7637\n",
      "Epoch 90/500\n",
      "487/487 [==============================] - 0s 72us/sample - loss: 9.0493 - mae: 2.3108 - mse: 9.0493 - val_loss: 40.7933 - val_mae: 3.5721 - val_mse: 40.7933\n",
      "Epoch 91/500\n",
      "487/487 [==============================] - 0s 75us/sample - loss: 9.0580 - mae: 2.3102 - mse: 9.0580 - val_loss: 40.6074 - val_mae: 3.8578 - val_mse: 40.6074\n",
      "Epoch 92/500\n",
      "487/487 [==============================] - 0s 90us/sample - loss: 9.5865 - mae: 2.3568 - mse: 9.5865 - val_loss: 39.2567 - val_mae: 3.6652 - val_mse: 39.2567\n",
      "Epoch 93/500\n",
      "487/487 [==============================] - 0s 84us/sample - loss: 6.9527 - mae: 2.0011 - mse: 6.9527 - val_loss: 55.9509 - val_mae: 5.1872 - val_mse: 55.9509\n",
      "Epoch 94/500\n",
      "487/487 [==============================] - 0s 84us/sample - loss: 11.0700 - mae: 2.6553 - mse: 11.0700 - val_loss: 39.2105 - val_mae: 3.4119 - val_mse: 39.2105\n",
      "Epoch 95/500\n",
      "487/487 [==============================] - 0s 90us/sample - loss: 7.6203 - mae: 2.1117 - mse: 7.6203 - val_loss: 38.7247 - val_mae: 3.5235 - val_mse: 38.7247\n",
      "Epoch 96/500\n",
      "487/487 [==============================] - 0s 84us/sample - loss: 10.7168 - mae: 2.6081 - mse: 10.7168 - val_loss: 41.3369 - val_mae: 4.0083 - val_mse: 41.3368\n",
      "Epoch 97/500\n",
      "487/487 [==============================] - 0s 80us/sample - loss: 7.7585 - mae: 2.1544 - mse: 7.7585 - val_loss: 45.7395 - val_mae: 4.6088 - val_mse: 45.7395\n",
      "Epoch 98/500\n",
      "487/487 [==============================] - 0s 75us/sample - loss: 9.4923 - mae: 2.4414 - mse: 9.4923 - val_loss: 37.9421 - val_mae: 3.3072 - val_mse: 37.9421\n",
      "Epoch 99/500\n",
      "487/487 [==============================] - 0s 67us/sample - loss: 7.3145 - mae: 2.0555 - mse: 7.3145 - val_loss: 40.1278 - val_mae: 3.7954 - val_mse: 40.1278\n",
      "Epoch 100/500\n",
      "487/487 [==============================] - 0s 89us/sample - loss: 9.4548 - mae: 2.4356 - mse: 9.4548 - val_loss: 42.1010 - val_mae: 4.2607 - val_mse: 42.1010\n",
      "Epoch 101/500\n",
      "487/487 [==============================] - 0s 82us/sample - loss: 6.4289 - mae: 1.9376 - mse: 6.4289 - val_loss: 40.3994 - val_mae: 4.0225 - val_mse: 40.3994\n",
      "Epoch 102/500\n",
      "487/487 [==============================] - 0s 73us/sample - loss: 9.2791 - mae: 2.4276 - mse: 9.2791 - val_loss: 37.0071 - val_mae: 3.3587 - val_mse: 37.0071\n",
      "Epoch 103/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 8.2130 - mae: 2.2414 - mse: 8.2130 - val_loss: 39.4792 - val_mae: 3.7507 - val_mse: 39.4792\n",
      "Epoch 104/500\n",
      "487/487 [==============================] - 0s 61us/sample - loss: 9.0157 - mae: 2.3914 - mse: 9.0157 - val_loss: 37.5840 - val_mae: 3.5396 - val_mse: 37.5840\n",
      "Epoch 105/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 8.4103 - mae: 2.1830 - mse: 8.4103 - val_loss: 37.1201 - val_mae: 3.2620 - val_mse: 37.1201\n",
      "Epoch 106/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 7.0919 - mae: 1.9998 - mse: 7.0919 - val_loss: 43.3218 - val_mae: 4.4286 - val_mse: 43.3218\n",
      "Epoch 107/500\n",
      "487/487 [==============================] - 0s 67us/sample - loss: 6.6200 - mae: 1.9839 - mse: 6.6200 - val_loss: 42.4150 - val_mae: 3.8443 - val_mse: 42.4150\n",
      "Epoch 108/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 8.5998 - mae: 2.3559 - mse: 8.5998 - val_loss: 49.6252 - val_mae: 4.6548 - val_mse: 49.6252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 6.5410 - mae: 1.9411 - mse: 6.5410 - val_loss: 41.2712 - val_mae: 4.3331 - val_mse: 41.2712\n",
      "Epoch 110/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 8.0198 - mae: 2.1453 - mse: 8.0198 - val_loss: 53.7337 - val_mae: 5.2038 - val_mse: 53.7337\n",
      "Epoch 111/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 9.8946 - mae: 2.5234 - mse: 9.8946 - val_loss: 37.9049 - val_mae: 3.7545 - val_mse: 37.9049\n",
      "Epoch 112/500\n",
      "487/487 [==============================] - 0s 70us/sample - loss: 8.1238 - mae: 2.1989 - mse: 8.1238 - val_loss: 38.4894 - val_mae: 3.8858 - val_mse: 38.4894\n",
      "Epoch 113/500\n",
      "487/487 [==============================] - 0s 73us/sample - loss: 7.3704 - mae: 2.1002 - mse: 7.3704 - val_loss: 36.1921 - val_mae: 3.5533 - val_mse: 36.1921\n",
      "Epoch 114/500\n",
      "487/487 [==============================] - 0s 85us/sample - loss: 7.1614 - mae: 2.0294 - mse: 7.1614 - val_loss: 35.8761 - val_mae: 3.4723 - val_mse: 35.8761\n",
      "Epoch 115/500\n",
      "487/487 [==============================] - 0s 99us/sample - loss: 7.3649 - mae: 2.1188 - mse: 7.3649 - val_loss: 38.7358 - val_mae: 4.1165 - val_mse: 38.7358\n",
      "Epoch 116/500\n",
      "487/487 [==============================] - 0s 85us/sample - loss: 6.5953 - mae: 2.0144 - mse: 6.5953 - val_loss: 36.5644 - val_mae: 3.5763 - val_mse: 36.5644\n",
      "Epoch 117/500\n",
      "487/487 [==============================] - 0s 83us/sample - loss: 8.6516 - mae: 2.3256 - mse: 8.6516 - val_loss: 36.7069 - val_mae: 3.7224 - val_mse: 36.7069\n",
      "Epoch 118/500\n",
      "487/487 [==============================] - 0s 92us/sample - loss: 6.0479 - mae: 1.8497 - mse: 6.0479 - val_loss: 42.7948 - val_mae: 4.1512 - val_mse: 42.7948\n",
      "Epoch 119/500\n",
      "487/487 [==============================] - 0s 88us/sample - loss: 8.2245 - mae: 2.2761 - mse: 8.2245 - val_loss: 34.5494 - val_mae: 3.1363 - val_mse: 34.5494\n",
      "Epoch 120/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 7.1293 - mae: 1.9487 - mse: 7.1293 - val_loss: 35.2743 - val_mae: 3.5372 - val_mse: 35.2743\n",
      "Epoch 121/500\n",
      "487/487 [==============================] - 0s 68us/sample - loss: 7.1147 - mae: 2.0669 - mse: 7.1147 - val_loss: 33.8821 - val_mae: 3.0970 - val_mse: 33.8821\n",
      "Epoch 122/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 7.6731 - mae: 2.2354 - mse: 7.6731 - val_loss: 35.5843 - val_mae: 3.2443 - val_mse: 35.5843\n",
      "Epoch 123/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 6.0410 - mae: 1.8515 - mse: 6.0410 - val_loss: 35.0213 - val_mae: 3.1900 - val_mse: 35.0213\n",
      "Epoch 124/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 7.3907 - mae: 2.1868 - mse: 7.3907 - val_loss: 39.1780 - val_mae: 3.7099 - val_mse: 39.1780\n",
      "Epoch 125/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 7.7177 - mae: 2.2202 - mse: 7.7177 - val_loss: 34.1160 - val_mae: 3.1901 - val_mse: 34.1160\n",
      "Epoch 126/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 7.2797 - mae: 2.0173 - mse: 7.2797 - val_loss: 38.6517 - val_mae: 3.6481 - val_mse: 38.6517\n",
      "Epoch 127/500\n",
      "487/487 [==============================] - 0s 67us/sample - loss: 7.1768 - mae: 2.1350 - mse: 7.1768 - val_loss: 35.0025 - val_mae: 3.2175 - val_mse: 35.0025\n",
      "Epoch 128/500\n",
      "487/487 [==============================] - 0s 69us/sample - loss: 6.9586 - mae: 1.9142 - mse: 6.9586 - val_loss: 34.5170 - val_mae: 3.3773 - val_mse: 34.5170\n",
      "Epoch 129/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 6.9111 - mae: 2.0109 - mse: 6.9111 - val_loss: 33.7401 - val_mae: 3.2397 - val_mse: 33.7401\n",
      "Epoch 130/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 6.3843 - mae: 1.9993 - mse: 6.3843 - val_loss: 38.6705 - val_mae: 3.7463 - val_mse: 38.6705\n",
      "Epoch 131/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 6.8802 - mae: 2.0524 - mse: 6.8802 - val_loss: 44.0189 - val_mae: 4.3658 - val_mse: 44.0189\n",
      "Epoch 132/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 6.7292 - mae: 2.0917 - mse: 6.7292 - val_loss: 39.0596 - val_mae: 3.8197 - val_mse: 39.0596\n",
      "Epoch 133/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 7.2834 - mae: 2.1622 - mse: 7.2834 - val_loss: 34.7239 - val_mae: 3.2233 - val_mse: 34.7239\n",
      "Epoch 134/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 6.5712 - mae: 2.0023 - mse: 6.5712 - val_loss: 35.0918 - val_mae: 3.2434 - val_mse: 35.0918\n",
      "Epoch 135/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 6.5282 - mae: 2.0530 - mse: 6.5282 - val_loss: 38.7113 - val_mae: 3.7879 - val_mse: 38.7113\n",
      "Epoch 136/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 5.4177 - mae: 1.7757 - mse: 5.4177 - val_loss: 41.9079 - val_mae: 4.1778 - val_mse: 41.9079\n",
      "Epoch 137/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 6.8268 - mae: 2.0050 - mse: 6.8268 - val_loss: 39.6816 - val_mae: 4.4156 - val_mse: 39.6816\n",
      "Epoch 138/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 6.8746 - mae: 1.9620 - mse: 6.8746 - val_loss: 33.1364 - val_mae: 3.1736 - val_mse: 33.1364\n",
      "Epoch 139/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 6.4229 - mae: 1.9222 - mse: 6.4229 - val_loss: 33.1272 - val_mae: 3.1122 - val_mse: 33.1273\n",
      "Epoch 140/500\n",
      "487/487 [==============================] - 0s 70us/sample - loss: 7.2553 - mae: 2.0899 - mse: 7.2553 - val_loss: 32.6549 - val_mae: 3.0184 - val_mse: 32.6549\n",
      "Epoch 141/500\n",
      "487/487 [==============================] - 0s 61us/sample - loss: 6.5297 - mae: 1.9409 - mse: 6.5297 - val_loss: 33.7556 - val_mae: 3.3338 - val_mse: 33.7556\n",
      "Epoch 142/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 6.4553 - mae: 2.0546 - mse: 6.4553 - val_loss: 32.5406 - val_mae: 3.1090 - val_mse: 32.5406\n",
      "Epoch 143/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 6.0270 - mae: 1.8814 - mse: 6.0270 - val_loss: 38.9716 - val_mae: 3.8643 - val_mse: 38.9716\n",
      "Epoch 144/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 6.6942 - mae: 2.0869 - mse: 6.6942 - val_loss: 36.3935 - val_mae: 3.5785 - val_mse: 36.3935\n",
      "Epoch 145/500\n",
      "487/487 [==============================] - 0s 67us/sample - loss: 6.0541 - mae: 1.9072 - mse: 6.0541 - val_loss: 40.7295 - val_mae: 4.0753 - val_mse: 40.7295\n",
      "Epoch 146/500\n",
      "487/487 [==============================] - 0s 71us/sample - loss: 5.4573 - mae: 1.8456 - mse: 5.4573 - val_loss: 33.1060 - val_mae: 3.4310 - val_mse: 33.1060\n",
      "Epoch 147/500\n",
      "487/487 [==============================] - 0s 67us/sample - loss: 5.4626 - mae: 1.8222 - mse: 5.4626 - val_loss: 41.2822 - val_mae: 4.7724 - val_mse: 41.2822\n",
      "Epoch 148/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 6.1389 - mae: 1.9548 - mse: 6.1389 - val_loss: 40.1639 - val_mae: 4.0487 - val_mse: 40.1639\n",
      "Epoch 149/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 6.1082 - mae: 1.9300 - mse: 6.1082 - val_loss: 37.5513 - val_mae: 3.7273 - val_mse: 37.5513\n",
      "Epoch 150/500\n",
      "487/487 [==============================] - 0s 69us/sample - loss: 5.4753 - mae: 1.8209 - mse: 5.4753 - val_loss: 34.3204 - val_mae: 3.6093 - val_mse: 34.3204\n",
      "Epoch 151/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 5.8761 - mae: 1.9220 - mse: 5.8761 - val_loss: 33.8773 - val_mae: 3.6237 - val_mse: 33.8773\n",
      "Epoch 152/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 6.2079 - mae: 2.0047 - mse: 6.2079 - val_loss: 34.9706 - val_mae: 3.7596 - val_mse: 34.9706\n",
      "Epoch 153/500\n",
      "487/487 [==============================] - 0s 67us/sample - loss: 4.9028 - mae: 1.7423 - mse: 4.9028 - val_loss: 32.0816 - val_mae: 3.1863 - val_mse: 32.0816\n",
      "Epoch 154/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 6.5617 - mae: 2.0266 - mse: 6.5617 - val_loss: 35.7055 - val_mae: 3.4902 - val_mse: 35.7055\n",
      "Epoch 155/500\n",
      "487/487 [==============================] - 0s 61us/sample - loss: 6.2305 - mae: 2.0077 - mse: 6.2305 - val_loss: 36.0965 - val_mae: 3.5261 - val_mse: 36.0965\n",
      "Epoch 156/500\n",
      "487/487 [==============================] - 0s 68us/sample - loss: 6.3595 - mae: 2.0511 - mse: 6.3595 - val_loss: 35.2096 - val_mae: 3.3996 - val_mse: 35.2096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/500\n",
      "487/487 [==============================] - 0s 67us/sample - loss: 5.4207 - mae: 1.8226 - mse: 5.4207 - val_loss: 31.0540 - val_mae: 2.8830 - val_mse: 31.0540\n",
      "Epoch 158/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 6.7721 - mae: 2.0639 - mse: 6.7721 - val_loss: 41.3681 - val_mae: 4.2593 - val_mse: 41.3681\n",
      "Epoch 159/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.2018 - mae: 1.5764 - mse: 4.2018 - val_loss: 36.1589 - val_mae: 3.6061 - val_mse: 36.1589\n",
      "Epoch 160/500\n",
      "487/487 [==============================] - 0s 68us/sample - loss: 6.1321 - mae: 1.8444 - mse: 6.1321 - val_loss: 33.5156 - val_mae: 3.2108 - val_mse: 33.5156\n",
      "Epoch 161/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 6.1875 - mae: 1.9644 - mse: 6.1875 - val_loss: 30.6615 - val_mae: 2.9126 - val_mse: 30.6615\n",
      "Epoch 162/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 6.0498 - mae: 1.9813 - mse: 6.0498 - val_loss: 33.2321 - val_mae: 3.2393 - val_mse: 33.2321\n",
      "Epoch 163/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 5.8864 - mae: 1.8920 - mse: 5.8864 - val_loss: 34.9137 - val_mae: 3.5355 - val_mse: 34.9137\n",
      "Epoch 164/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 5.9346 - mae: 1.9822 - mse: 5.9346 - val_loss: 36.2746 - val_mae: 3.6611 - val_mse: 36.2746\n",
      "Epoch 165/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 4.9303 - mae: 1.7415 - mse: 4.9303 - val_loss: 44.7560 - val_mae: 4.6494 - val_mse: 44.7560\n",
      "Epoch 166/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 6.7337 - mae: 2.0871 - mse: 6.7337 - val_loss: 34.3189 - val_mae: 3.3838 - val_mse: 34.3189\n",
      "Epoch 167/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.9841 - mae: 1.7749 - mse: 4.9841 - val_loss: 32.8025 - val_mae: 3.1519 - val_mse: 32.8025\n",
      "Epoch 168/500\n",
      "487/487 [==============================] - 0s 68us/sample - loss: 6.3278 - mae: 1.9984 - mse: 6.3278 - val_loss: 36.5737 - val_mae: 3.6826 - val_mse: 36.5737\n",
      "Epoch 169/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 5.2412 - mae: 1.8535 - mse: 5.2412 - val_loss: 35.5453 - val_mae: 3.5090 - val_mse: 35.5453\n",
      "Epoch 170/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 6.0111 - mae: 1.9117 - mse: 6.0111 - val_loss: 37.6186 - val_mae: 3.8357 - val_mse: 37.6186\n",
      "Epoch 171/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 5.8336 - mae: 1.9588 - mse: 5.8336 - val_loss: 32.1150 - val_mae: 3.1558 - val_mse: 32.1150\n",
      "Epoch 172/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 5.7503 - mae: 1.9373 - mse: 5.7503 - val_loss: 33.6693 - val_mae: 3.3618 - val_mse: 33.6693\n",
      "Epoch 173/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.5079 - mae: 1.6568 - mse: 4.5079 - val_loss: 31.3947 - val_mae: 3.0122 - val_mse: 31.3947\n",
      "Epoch 174/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 6.3186 - mae: 2.0304 - mse: 6.3186 - val_loss: 32.5246 - val_mae: 3.0578 - val_mse: 32.5246\n",
      "Epoch 175/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 5.6165 - mae: 1.8936 - mse: 5.6165 - val_loss: 30.8222 - val_mae: 2.9783 - val_mse: 30.8222\n",
      "Epoch 176/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 5.7775 - mae: 1.8622 - mse: 5.7775 - val_loss: 39.3203 - val_mae: 4.0465 - val_mse: 39.3203\n",
      "Epoch 177/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 5.3340 - mae: 1.8761 - mse: 5.3340 - val_loss: 37.8428 - val_mae: 3.8762 - val_mse: 37.8428\n",
      "Epoch 178/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 5.9277 - mae: 1.9663 - mse: 5.9277 - val_loss: 36.0628 - val_mae: 3.6429 - val_mse: 36.0628\n",
      "Epoch 179/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.8836 - mae: 1.7795 - mse: 4.8836 - val_loss: 38.6291 - val_mae: 4.0151 - val_mse: 38.6291\n",
      "Epoch 180/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 5.4139 - mae: 1.8403 - mse: 5.4139 - val_loss: 40.5750 - val_mae: 4.1995 - val_mse: 40.5750\n",
      "Epoch 181/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 4.7151 - mae: 1.6718 - mse: 4.7151 - val_loss: 36.0948 - val_mae: 3.7097 - val_mse: 36.0948\n",
      "Epoch 182/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 5.0685 - mae: 1.8244 - mse: 5.0685 - val_loss: 33.2215 - val_mae: 3.2620 - val_mse: 33.2215\n",
      "Epoch 183/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 5.6044 - mae: 1.8597 - mse: 5.6044 - val_loss: 35.0589 - val_mae: 3.6025 - val_mse: 35.0589\n",
      "Epoch 184/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 5.9384 - mae: 1.9743 - mse: 5.9384 - val_loss: 35.2636 - val_mae: 3.5959 - val_mse: 35.2636\n",
      "Epoch 185/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 4.6203 - mae: 1.7089 - mse: 4.6203 - val_loss: 32.4261 - val_mae: 3.1571 - val_mse: 32.4261\n",
      "Epoch 186/500\n",
      "487/487 [==============================] - 0s 71us/sample - loss: 5.1764 - mae: 1.8147 - mse: 5.1764 - val_loss: 35.9075 - val_mae: 3.6571 - val_mse: 35.9075\n",
      "Epoch 187/500\n",
      "487/487 [==============================] - 0s 88us/sample - loss: 5.1529 - mae: 1.8532 - mse: 5.1529 - val_loss: 30.3843 - val_mae: 2.8044 - val_mse: 30.3843\n",
      "Epoch 188/500\n",
      "487/487 [==============================] - 0s 94us/sample - loss: 5.0884 - mae: 1.8129 - mse: 5.0884 - val_loss: 30.0403 - val_mae: 2.8025 - val_mse: 30.0403\n",
      "Epoch 189/500\n",
      "487/487 [==============================] - 0s 86us/sample - loss: 5.2813 - mae: 1.8057 - mse: 5.2813 - val_loss: 30.2317 - val_mae: 2.8677 - val_mse: 30.2317\n",
      "Epoch 190/500\n",
      "487/487 [==============================] - 0s 83us/sample - loss: 4.8412 - mae: 1.7424 - mse: 4.8412 - val_loss: 30.3972 - val_mae: 3.0296 - val_mse: 30.3972\n",
      "Epoch 191/500\n",
      "487/487 [==============================] - 0s 68us/sample - loss: 5.0389 - mae: 1.7997 - mse: 5.0389 - val_loss: 34.4862 - val_mae: 3.4347 - val_mse: 34.4862\n",
      "Epoch 192/500\n",
      "487/487 [==============================] - 0s 89us/sample - loss: 5.9810 - mae: 1.9727 - mse: 5.9810 - val_loss: 32.3525 - val_mae: 3.2099 - val_mse: 32.3525\n",
      "Epoch 193/500\n",
      "487/487 [==============================] - 0s 72us/sample - loss: 4.5010 - mae: 1.6988 - mse: 4.5010 - val_loss: 38.3220 - val_mae: 3.9826 - val_mse: 38.3220\n",
      "Epoch 194/500\n",
      "487/487 [==============================] - 0s 74us/sample - loss: 5.0628 - mae: 1.8250 - mse: 5.0628 - val_loss: 32.3405 - val_mae: 3.1545 - val_mse: 32.3405\n",
      "Epoch 195/500\n",
      "487/487 [==============================] - 0s 75us/sample - loss: 4.9709 - mae: 1.7774 - mse: 4.9709 - val_loss: 30.0536 - val_mae: 2.7892 - val_mse: 30.0536\n",
      "Epoch 196/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 4.9592 - mae: 1.7401 - mse: 4.9592 - val_loss: 36.9830 - val_mae: 3.8029 - val_mse: 36.9830\n",
      "Epoch 197/500\n",
      "487/487 [==============================] - 0s 81us/sample - loss: 4.8626 - mae: 1.7378 - mse: 4.8626 - val_loss: 36.8430 - val_mae: 3.8023 - val_mse: 36.8430\n",
      "Epoch 198/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 5.1393 - mae: 1.8659 - mse: 5.1393 - val_loss: 32.1943 - val_mae: 3.0643 - val_mse: 32.1943\n",
      "Epoch 199/500\n",
      "487/487 [==============================] - 0s 70us/sample - loss: 4.8244 - mae: 1.7599 - mse: 4.8244 - val_loss: 36.6227 - val_mae: 3.6642 - val_mse: 36.6227\n",
      "Epoch 200/500\n",
      "487/487 [==============================] - 0s 61us/sample - loss: 3.2468 - mae: 1.3517 - mse: 3.2468 - val_loss: 52.5083 - val_mae: 5.6201 - val_mse: 52.5083\n",
      "Epoch 201/500\n",
      "487/487 [==============================] - 0s 73us/sample - loss: 5.5619 - mae: 1.8559 - mse: 5.5619 - val_loss: 30.3176 - val_mae: 2.8496 - val_mse: 30.3176\n",
      "Epoch 202/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 4.5411 - mae: 1.6943 - mse: 4.5411 - val_loss: 38.1012 - val_mae: 4.0643 - val_mse: 38.1012\n",
      "Epoch 203/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 5.0402 - mae: 1.7766 - mse: 5.0402 - val_loss: 30.8487 - val_mae: 2.9495 - val_mse: 30.8487\n",
      "Epoch 204/500\n",
      "487/487 [==============================] - 0s 78us/sample - loss: 5.7807 - mae: 1.9614 - mse: 5.7807 - val_loss: 31.6368 - val_mae: 3.0995 - val_mse: 31.6368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 4.1507 - mae: 1.5627 - mse: 4.1507 - val_loss: 40.9161 - val_mae: 4.4641 - val_mse: 40.9161\n",
      "Epoch 206/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 3.4525 - mae: 1.4017 - mse: 3.4525 - val_loss: 31.6550 - val_mae: 3.3685 - val_mse: 31.6550\n",
      "Epoch 207/500\n",
      "487/487 [==============================] - 0s 61us/sample - loss: 5.5291 - mae: 1.8730 - mse: 5.5291 - val_loss: 33.4345 - val_mae: 3.6371 - val_mse: 33.4345\n",
      "Epoch 208/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.4507 - mae: 1.6842 - mse: 4.4507 - val_loss: 29.5753 - val_mae: 2.8400 - val_mse: 29.5753\n",
      "Epoch 209/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 5.3487 - mae: 1.8804 - mse: 5.3487 - val_loss: 29.6934 - val_mae: 2.7689 - val_mse: 29.6934\n",
      "Epoch 210/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 4.4532 - mae: 1.6559 - mse: 4.4532 - val_loss: 30.8113 - val_mae: 2.9603 - val_mse: 30.8113\n",
      "Epoch 211/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.6104 - mae: 1.7194 - mse: 4.6104 - val_loss: 30.3426 - val_mae: 2.8245 - val_mse: 30.3426\n",
      "Epoch 212/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 5.0260 - mae: 1.7582 - mse: 5.0260 - val_loss: 33.1517 - val_mae: 3.2587 - val_mse: 33.1517\n",
      "Epoch 213/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.0933 - mae: 1.6462 - mse: 4.0933 - val_loss: 32.8386 - val_mae: 3.6942 - val_mse: 32.8386\n",
      "Epoch 214/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 4.7198 - mae: 1.8040 - mse: 4.7198 - val_loss: 30.6840 - val_mae: 2.9058 - val_mse: 30.6840\n",
      "Epoch 215/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 4.6955 - mae: 1.6416 - mse: 4.6955 - val_loss: 30.1102 - val_mae: 2.9963 - val_mse: 30.1102\n",
      "Epoch 216/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 4.8831 - mae: 1.7523 - mse: 4.8831 - val_loss: 32.9183 - val_mae: 3.3219 - val_mse: 32.9183\n",
      "Epoch 217/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 4.9639 - mae: 1.7972 - mse: 4.9639 - val_loss: 30.8961 - val_mae: 3.0588 - val_mse: 30.8961\n",
      "Epoch 218/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 4.3629 - mae: 1.6985 - mse: 4.3629 - val_loss: 34.6921 - val_mae: 3.7973 - val_mse: 34.6921\n",
      "Epoch 219/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 5.1430 - mae: 1.7871 - mse: 5.1430 - val_loss: 29.5657 - val_mae: 2.7904 - val_mse: 29.5657\n",
      "Epoch 220/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.2671 - mae: 1.5808 - mse: 4.2671 - val_loss: 35.5760 - val_mae: 3.6895 - val_mse: 35.5760\n",
      "Epoch 221/500\n",
      "487/487 [==============================] - 0s 61us/sample - loss: 4.2753 - mae: 1.6300 - mse: 4.2753 - val_loss: 29.6280 - val_mae: 2.8351 - val_mse: 29.6280\n",
      "Epoch 222/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 3.9985 - mae: 1.6130 - mse: 3.9985 - val_loss: 31.0545 - val_mae: 3.2786 - val_mse: 31.0545\n",
      "Epoch 223/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 4.4343 - mae: 1.6719 - mse: 4.4343 - val_loss: 32.5298 - val_mae: 3.4962 - val_mse: 32.5298\n",
      "Epoch 224/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 3.4883 - mae: 1.4902 - mse: 3.4883 - val_loss: 31.7800 - val_mae: 3.3805 - val_mse: 31.7800\n",
      "Epoch 225/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 5.1843 - mae: 1.8077 - mse: 5.1843 - val_loss: 31.1873 - val_mae: 3.1684 - val_mse: 31.1873\n",
      "Epoch 226/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.6893 - mae: 1.7262 - mse: 4.6893 - val_loss: 30.1754 - val_mae: 2.9770 - val_mse: 30.1754\n",
      "Epoch 227/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 4.5222 - mae: 1.7069 - mse: 4.5222 - val_loss: 29.9781 - val_mae: 2.9559 - val_mse: 29.9781\n",
      "Epoch 228/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 4.2147 - mae: 1.6184 - mse: 4.2147 - val_loss: 29.8853 - val_mae: 2.8920 - val_mse: 29.8853\n",
      "Epoch 229/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 4.3283 - mae: 1.6284 - mse: 4.3283 - val_loss: 31.0323 - val_mae: 3.0708 - val_mse: 31.0323\n",
      "Epoch 230/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.4369 - mae: 1.6523 - mse: 4.4369 - val_loss: 34.0277 - val_mae: 3.3505 - val_mse: 34.0277\n",
      "Epoch 231/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 4.4831 - mae: 1.6483 - mse: 4.4831 - val_loss: 32.1877 - val_mae: 3.1760 - val_mse: 32.1877\n",
      "Epoch 232/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.8257 - mae: 1.7513 - mse: 4.8257 - val_loss: 37.9001 - val_mae: 3.9927 - val_mse: 37.9001\n",
      "Epoch 233/500\n",
      "487/487 [==============================] - 0s 61us/sample - loss: 4.8545 - mae: 1.7647 - mse: 4.8545 - val_loss: 31.8723 - val_mae: 3.0192 - val_mse: 31.8723\n",
      "Epoch 234/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 4.3353 - mae: 1.6376 - mse: 4.3353 - val_loss: 34.5988 - val_mae: 3.5734 - val_mse: 34.5988\n",
      "Epoch 235/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 3.4485 - mae: 1.4036 - mse: 3.4485 - val_loss: 32.4614 - val_mae: 3.3385 - val_mse: 32.4614\n",
      "Epoch 236/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 4.3457 - mae: 1.6533 - mse: 4.3457 - val_loss: 30.0386 - val_mae: 2.9948 - val_mse: 30.0386\n",
      "Epoch 237/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.1937 - mae: 1.6618 - mse: 4.1937 - val_loss: 30.2142 - val_mae: 2.8909 - val_mse: 30.2142\n",
      "Epoch 238/500\n",
      "487/487 [==============================] - 0s 62us/sample - loss: 4.5372 - mae: 1.6762 - mse: 4.5372 - val_loss: 30.7942 - val_mae: 2.9433 - val_mse: 30.7942\n",
      "Epoch 239/500\n",
      "487/487 [==============================] - 0s 61us/sample - loss: 4.2916 - mae: 1.6548 - mse: 4.2916 - val_loss: 33.8212 - val_mae: 3.3306 - val_mse: 33.8212\n",
      "Epoch 240/500\n",
      "487/487 [==============================] - 0s 68us/sample - loss: 4.5992 - mae: 1.7187 - mse: 4.5992 - val_loss: 32.7574 - val_mae: 3.4661 - val_mse: 32.7574\n",
      "Epoch 241/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 4.4254 - mae: 1.7069 - mse: 4.4254 - val_loss: 32.5125 - val_mae: 3.4902 - val_mse: 32.5125\n",
      "Epoch 242/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 3.8683 - mae: 1.5216 - mse: 3.8683 - val_loss: 29.9760 - val_mae: 2.7661 - val_mse: 29.9760\n",
      "Epoch 243/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 4.4560 - mae: 1.7059 - mse: 4.4560 - val_loss: 30.9796 - val_mae: 3.1680 - val_mse: 30.9796\n",
      "Epoch 244/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 4.4250 - mae: 1.6721 - mse: 4.4250 - val_loss: 31.1968 - val_mae: 3.1446 - val_mse: 31.1968\n",
      "Epoch 245/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.2826 - mae: 1.6477 - mse: 4.2826 - val_loss: 32.0668 - val_mae: 3.4394 - val_mse: 32.0668\n",
      "Epoch 246/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 3.8481 - mae: 1.5505 - mse: 3.8481 - val_loss: 30.3198 - val_mae: 3.0539 - val_mse: 30.3198\n",
      "Epoch 247/500\n",
      "487/487 [==============================] - 0s 61us/sample - loss: 3.8882 - mae: 1.5752 - mse: 3.8882 - val_loss: 29.6727 - val_mae: 2.8265 - val_mse: 29.6727\n",
      "Epoch 248/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.3673 - mae: 1.6787 - mse: 4.3673 - val_loss: 29.9535 - val_mae: 2.9771 - val_mse: 29.9535\n",
      "Epoch 249/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 4.2692 - mae: 1.7003 - mse: 4.2692 - val_loss: 32.2042 - val_mae: 3.3052 - val_mse: 32.2042\n",
      "Epoch 250/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.3497 - mae: 1.6941 - mse: 4.3497 - val_loss: 30.0874 - val_mae: 2.7591 - val_mse: 30.0874\n",
      "Epoch 251/500\n",
      "487/487 [==============================] - 0s 61us/sample - loss: 3.7642 - mae: 1.5706 - mse: 3.7642 - val_loss: 31.9439 - val_mae: 3.0960 - val_mse: 31.9439\n",
      "Epoch 252/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 4.3477 - mae: 1.6648 - mse: 4.3477 - val_loss: 30.7701 - val_mae: 2.9635 - val_mse: 30.7701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 4.4466 - mae: 1.6645 - mse: 4.4466 - val_loss: 30.0520 - val_mae: 2.7911 - val_mse: 30.0520\n",
      "Epoch 254/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.0699 - mae: 1.5540 - mse: 4.0699 - val_loss: 31.5612 - val_mae: 3.1590 - val_mse: 31.5612\n",
      "Epoch 255/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 3.8573 - mae: 1.5360 - mse: 3.8573 - val_loss: 31.8545 - val_mae: 3.1765 - val_mse: 31.8545\n",
      "Epoch 256/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 4.0772 - mae: 1.6003 - mse: 4.0772 - val_loss: 35.9429 - val_mae: 3.7628 - val_mse: 35.9429\n",
      "Epoch 257/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 4.5213 - mae: 1.6955 - mse: 4.5213 - val_loss: 30.2395 - val_mae: 2.9748 - val_mse: 30.2395\n",
      "Epoch 258/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 3.2359 - mae: 1.4023 - mse: 3.2359 - val_loss: 34.9729 - val_mae: 3.6185 - val_mse: 34.9729\n",
      "Epoch 259/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 4.3617 - mae: 1.6571 - mse: 4.3617 - val_loss: 40.1720 - val_mae: 4.4309 - val_mse: 40.1720\n",
      "Epoch 260/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 4.4035 - mae: 1.6518 - mse: 4.4035 - val_loss: 34.8929 - val_mae: 3.6040 - val_mse: 34.8929\n",
      "Epoch 261/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 4.1370 - mae: 1.6496 - mse: 4.1370 - val_loss: 31.5454 - val_mae: 3.0747 - val_mse: 31.5454\n",
      "Epoch 262/500\n",
      "487/487 [==============================] - 0s 63us/sample - loss: 4.2205 - mae: 1.6870 - mse: 4.2205 - val_loss: 36.4405 - val_mae: 3.8461 - val_mse: 36.4405\n",
      "Epoch 263/500\n",
      "487/487 [==============================] - 0s 66us/sample - loss: 3.1026 - mae: 1.3752 - mse: 3.1026 - val_loss: 32.3952 - val_mae: 3.2096 - val_mse: 32.3952\n",
      "Epoch 264/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 3.9078 - mae: 1.5483 - mse: 3.9078 - val_loss: 31.8363 - val_mae: 3.4500 - val_mse: 31.8363\n",
      "Epoch 265/500\n",
      "487/487 [==============================] - 0s 64us/sample - loss: 4.3948 - mae: 1.6828 - mse: 4.3948 - val_loss: 32.0610 - val_mae: 3.1468 - val_mse: 32.0610\n",
      "Epoch 266/500\n",
      "487/487 [==============================] - 0s 71us/sample - loss: 4.2365 - mae: 1.6721 - mse: 4.2365 - val_loss: 31.5210 - val_mae: 3.0448 - val_mse: 31.5210\n",
      "Epoch 267/500\n",
      "487/487 [==============================] - 0s 68us/sample - loss: 4.6117 - mae: 1.7089 - mse: 4.6117 - val_loss: 29.7437 - val_mae: 2.8654 - val_mse: 29.7437\n",
      "Epoch 268/500\n",
      "487/487 [==============================] - 0s 61us/sample - loss: 3.6018 - mae: 1.4989 - mse: 3.6018 - val_loss: 35.8823 - val_mae: 3.7182 - val_mse: 35.8823\n",
      "Epoch 269/500\n",
      "487/487 [==============================] - 0s 65us/sample - loss: 3.5330 - mae: 1.5184 - mse: 3.5330 - val_loss: 33.2897 - val_mae: 3.3506 - val_mse: 33.2897\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 568 samples, validate on 190 samples\n",
      "Epoch 1/500\n",
      "568/568 [==============================] - 0s 662us/sample - loss: 105.2402 - mae: 6.6925 - mse: 105.2402 - val_loss: 150.1756 - val_mae: 8.3779 - val_mse: 150.1756\n",
      "Epoch 2/500\n",
      "568/568 [==============================] - 0s 64us/sample - loss: 50.0991 - mae: 4.8573 - mse: 50.0991 - val_loss: 134.4318 - val_mae: 7.8226 - val_mse: 134.4318\n",
      "Epoch 3/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 44.5210 - mae: 4.6974 - mse: 44.5210 - val_loss: 111.6848 - val_mae: 7.2389 - val_mse: 111.6848\n",
      "Epoch 4/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 39.0108 - mae: 4.4488 - mse: 39.0108 - val_loss: 101.7966 - val_mae: 6.8125 - val_mse: 101.7966\n",
      "Epoch 5/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 33.4630 - mae: 4.1642 - mse: 33.4630 - val_loss: 86.2933 - val_mae: 6.5742 - val_mse: 86.2933\n",
      "Epoch 6/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 28.1872 - mae: 3.7642 - mse: 28.1872 - val_loss: 81.9774 - val_mae: 6.3826 - val_mse: 81.9774\n",
      "Epoch 7/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 28.6015 - mae: 3.8749 - mse: 28.6015 - val_loss: 70.3555 - val_mae: 5.5618 - val_mse: 70.3555\n",
      "Epoch 8/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 23.2381 - mae: 3.5053 - mse: 23.2381 - val_loss: 81.0370 - val_mae: 6.1735 - val_mse: 81.0369\n",
      "Epoch 9/500\n",
      "568/568 [==============================] - 0s 56us/sample - loss: 22.4049 - mae: 3.4331 - mse: 22.4049 - val_loss: 61.8499 - val_mae: 5.1356 - val_mse: 61.8499\n",
      "Epoch 10/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 20.8008 - mae: 3.3534 - mse: 20.8008 - val_loss: 54.2938 - val_mae: 4.9276 - val_mse: 54.2938\n",
      "Epoch 11/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 19.6241 - mae: 3.2015 - mse: 19.6241 - val_loss: 52.4898 - val_mae: 4.8550 - val_mse: 52.4898\n",
      "Epoch 12/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 15.9941 - mae: 2.9104 - mse: 15.9941 - val_loss: 48.7245 - val_mae: 4.7720 - val_mse: 48.7245\n",
      "Epoch 13/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 16.3967 - mae: 2.9774 - mse: 16.3967 - val_loss: 56.4345 - val_mae: 5.1656 - val_mse: 56.4345\n",
      "Epoch 14/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 15.2302 - mae: 2.9209 - mse: 15.2302 - val_loss: 52.5096 - val_mae: 4.9333 - val_mse: 52.5096\n",
      "Epoch 15/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 14.5843 - mae: 2.7759 - mse: 14.5843 - val_loss: 42.8008 - val_mae: 4.5560 - val_mse: 42.8008\n",
      "Epoch 16/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 13.7057 - mae: 2.7956 - mse: 13.7057 - val_loss: 44.9392 - val_mae: 4.7426 - val_mse: 44.9392\n",
      "Epoch 17/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 13.1982 - mae: 2.7206 - mse: 13.1982 - val_loss: 42.8604 - val_mae: 4.2263 - val_mse: 42.8604\n",
      "Epoch 18/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 12.0746 - mae: 2.6298 - mse: 12.0746 - val_loss: 44.6904 - val_mae: 4.4192 - val_mse: 44.6904\n",
      "Epoch 19/500\n",
      "568/568 [==============================] - 0s 64us/sample - loss: 12.5174 - mae: 2.7056 - mse: 12.5174 - val_loss: 37.5661 - val_mae: 3.9634 - val_mse: 37.5661\n",
      "Epoch 20/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 10.3075 - mae: 2.4102 - mse: 10.3075 - val_loss: 36.1673 - val_mae: 3.9891 - val_mse: 36.1673\n",
      "Epoch 21/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 10.8922 - mae: 2.5160 - mse: 10.8922 - val_loss: 36.3750 - val_mae: 4.1568 - val_mse: 36.3750\n",
      "Epoch 22/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 11.4033 - mae: 2.6303 - mse: 11.4033 - val_loss: 33.5725 - val_mae: 3.7993 - val_mse: 33.5725\n",
      "Epoch 23/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 10.5035 - mae: 2.4622 - mse: 10.5035 - val_loss: 32.0847 - val_mae: 3.6388 - val_mse: 32.0847\n",
      "Epoch 24/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 9.8542 - mae: 2.3791 - mse: 9.8542 - val_loss: 31.9130 - val_mae: 3.8254 - val_mse: 31.9130\n",
      "Epoch 25/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 9.8055 - mae: 2.3857 - mse: 9.8055 - val_loss: 34.5243 - val_mae: 3.8833 - val_mse: 34.5243\n",
      "Epoch 26/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 9.5880 - mae: 2.3693 - mse: 9.5880 - val_loss: 29.2777 - val_mae: 3.3442 - val_mse: 29.2777\n",
      "Epoch 27/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 9.5578 - mae: 2.3433 - mse: 9.5578 - val_loss: 29.4402 - val_mae: 3.3695 - val_mse: 29.4402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 9.1603 - mae: 2.3240 - mse: 9.1603 - val_loss: 28.0077 - val_mae: 3.3544 - val_mse: 28.0077\n",
      "Epoch 29/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 8.3013 - mae: 2.1973 - mse: 8.3013 - val_loss: 33.8928 - val_mae: 3.8652 - val_mse: 33.8928\n",
      "Epoch 30/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 9.2493 - mae: 2.3278 - mse: 9.2493 - val_loss: 28.8146 - val_mae: 3.4720 - val_mse: 28.8146\n",
      "Epoch 31/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 8.7066 - mae: 2.2949 - mse: 8.7066 - val_loss: 26.9192 - val_mae: 3.2287 - val_mse: 26.9192\n",
      "Epoch 32/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 8.1429 - mae: 2.1810 - mse: 8.1429 - val_loss: 27.1059 - val_mae: 3.1805 - val_mse: 27.1059\n",
      "Epoch 33/500\n",
      "568/568 [==============================] - 0s 68us/sample - loss: 8.4945 - mae: 2.2741 - mse: 8.4945 - val_loss: 27.0055 - val_mae: 3.5109 - val_mse: 27.0055\n",
      "Epoch 34/500\n",
      "568/568 [==============================] - 0s 81us/sample - loss: 8.4758 - mae: 2.2946 - mse: 8.4758 - val_loss: 27.0490 - val_mae: 3.4678 - val_mse: 27.0490\n",
      "Epoch 35/500\n",
      "568/568 [==============================] - 0s 83us/sample - loss: 7.7752 - mae: 2.1551 - mse: 7.7752 - val_loss: 25.2504 - val_mae: 3.1519 - val_mse: 25.2504\n",
      "Epoch 36/500\n",
      "568/568 [==============================] - 0s 83us/sample - loss: 7.2460 - mae: 2.1182 - mse: 7.2460 - val_loss: 25.8901 - val_mae: 3.4197 - val_mse: 25.8901\n",
      "Epoch 37/500\n",
      "568/568 [==============================] - 0s 81us/sample - loss: 7.8039 - mae: 2.1610 - mse: 7.8039 - val_loss: 24.9019 - val_mae: 3.1456 - val_mse: 24.9018\n",
      "Epoch 38/500\n",
      "568/568 [==============================] - 0s 66us/sample - loss: 7.6037 - mae: 2.1625 - mse: 7.6037 - val_loss: 25.2722 - val_mae: 3.3022 - val_mse: 25.2722\n",
      "Epoch 39/500\n",
      "568/568 [==============================] - 0s 72us/sample - loss: 7.8716 - mae: 2.2249 - mse: 7.8716 - val_loss: 25.5848 - val_mae: 3.3625 - val_mse: 25.5848\n",
      "Epoch 40/500\n",
      "568/568 [==============================] - 0s 80us/sample - loss: 6.8549 - mae: 2.0372 - mse: 6.8549 - val_loss: 23.4280 - val_mae: 2.8810 - val_mse: 23.4280\n",
      "Epoch 41/500\n",
      "568/568 [==============================] - 0s 77us/sample - loss: 7.4843 - mae: 2.1323 - mse: 7.4843 - val_loss: 28.3141 - val_mae: 3.3597 - val_mse: 28.3141\n",
      "Epoch 42/500\n",
      "568/568 [==============================] - 0s 80us/sample - loss: 7.7588 - mae: 2.1916 - mse: 7.7588 - val_loss: 27.8101 - val_mae: 3.7214 - val_mse: 27.8101\n",
      "Epoch 43/500\n",
      "568/568 [==============================] - 0s 81us/sample - loss: 7.0349 - mae: 2.1024 - mse: 7.0349 - val_loss: 24.6871 - val_mae: 3.1006 - val_mse: 24.6871\n",
      "Epoch 44/500\n",
      "568/568 [==============================] - 0s 76us/sample - loss: 6.7331 - mae: 2.0507 - mse: 6.7331 - val_loss: 29.9544 - val_mae: 3.8742 - val_mse: 29.9544\n",
      "Epoch 45/500\n",
      "568/568 [==============================] - 0s 78us/sample - loss: 6.2439 - mae: 1.9743 - mse: 6.2439 - val_loss: 29.9126 - val_mae: 4.0059 - val_mse: 29.9126\n",
      "Epoch 46/500\n",
      "568/568 [==============================] - 0s 78us/sample - loss: 6.9366 - mae: 2.0940 - mse: 6.9366 - val_loss: 26.6573 - val_mae: 3.3993 - val_mse: 26.6573\n",
      "Epoch 47/500\n",
      "568/568 [==============================] - 0s 83us/sample - loss: 6.7290 - mae: 2.0794 - mse: 6.7290 - val_loss: 23.9430 - val_mae: 2.8602 - val_mse: 23.9430\n",
      "Epoch 48/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 6.9653 - mae: 2.1133 - mse: 6.9653 - val_loss: 25.5980 - val_mae: 3.2358 - val_mse: 25.5980\n",
      "Epoch 49/500\n",
      "568/568 [==============================] - 0s 55us/sample - loss: 6.5519 - mae: 2.0588 - mse: 6.5519 - val_loss: 23.2106 - val_mae: 2.9552 - val_mse: 23.2106\n",
      "Epoch 50/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 6.5251 - mae: 2.0048 - mse: 6.5251 - val_loss: 25.2050 - val_mae: 3.2212 - val_mse: 25.2050\n",
      "Epoch 51/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 6.1329 - mae: 1.9623 - mse: 6.1329 - val_loss: 25.2504 - val_mae: 3.3671 - val_mse: 25.2504\n",
      "Epoch 52/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 6.0768 - mae: 1.9658 - mse: 6.0768 - val_loss: 28.5914 - val_mae: 3.4295 - val_mse: 28.5914\n",
      "Epoch 53/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 6.5394 - mae: 1.9757 - mse: 6.5394 - val_loss: 29.3049 - val_mae: 3.6524 - val_mse: 29.3049\n",
      "Epoch 54/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 6.5229 - mae: 2.0080 - mse: 6.5229 - val_loss: 27.2838 - val_mae: 3.2989 - val_mse: 27.2838\n",
      "Epoch 55/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 6.2239 - mae: 1.9752 - mse: 6.2239 - val_loss: 21.7808 - val_mae: 2.7327 - val_mse: 21.7808\n",
      "Epoch 56/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 5.6476 - mae: 1.8710 - mse: 5.6476 - val_loss: 21.3632 - val_mae: 2.6305 - val_mse: 21.3632\n",
      "Epoch 57/500\n",
      "568/568 [==============================] - 0s 55us/sample - loss: 5.5631 - mae: 1.8729 - mse: 5.5631 - val_loss: 24.3656 - val_mae: 3.1736 - val_mse: 24.3656\n",
      "Epoch 58/500\n",
      "568/568 [==============================] - 0s 62us/sample - loss: 5.9577 - mae: 1.9293 - mse: 5.9577 - val_loss: 21.8573 - val_mae: 2.7309 - val_mse: 21.8573\n",
      "Epoch 59/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 5.6772 - mae: 1.8719 - mse: 5.6772 - val_loss: 25.5066 - val_mae: 3.5014 - val_mse: 25.5066\n",
      "Epoch 60/500\n",
      "568/568 [==============================] - 0s 92us/sample - loss: 6.2326 - mae: 1.9930 - mse: 6.2326 - val_loss: 27.3050 - val_mae: 3.4531 - val_mse: 27.3050\n",
      "Epoch 61/500\n",
      "568/568 [==============================] - 0s 88us/sample - loss: 5.7592 - mae: 1.8495 - mse: 5.7592 - val_loss: 22.7043 - val_mae: 3.0185 - val_mse: 22.7043\n",
      "Epoch 62/500\n",
      "568/568 [==============================] - 0s 79us/sample - loss: 5.6522 - mae: 1.8932 - mse: 5.6522 - val_loss: 25.7849 - val_mae: 3.6227 - val_mse: 25.7849\n",
      "Epoch 63/500\n",
      "568/568 [==============================] - 0s 84us/sample - loss: 5.2798 - mae: 1.8630 - mse: 5.2798 - val_loss: 20.2312 - val_mae: 2.6339 - val_mse: 20.2312\n",
      "Epoch 64/500\n",
      "568/568 [==============================] - 0s 78us/sample - loss: 5.4767 - mae: 1.8564 - mse: 5.4767 - val_loss: 21.8339 - val_mae: 2.9984 - val_mse: 21.8339\n",
      "Epoch 65/500\n",
      "568/568 [==============================] - 0s 72us/sample - loss: 5.6056 - mae: 1.8630 - mse: 5.6056 - val_loss: 26.6195 - val_mae: 3.7178 - val_mse: 26.6195\n",
      "Epoch 66/500\n",
      "568/568 [==============================] - 0s 70us/sample - loss: 5.6883 - mae: 1.9248 - mse: 5.6883 - val_loss: 21.9681 - val_mae: 3.1690 - val_mse: 21.9681\n",
      "Epoch 67/500\n",
      "568/568 [==============================] - 0s 55us/sample - loss: 5.1101 - mae: 1.8302 - mse: 5.1101 - val_loss: 21.3019 - val_mae: 2.8320 - val_mse: 21.3019\n",
      "Epoch 68/500\n",
      "568/568 [==============================] - 0s 62us/sample - loss: 5.3841 - mae: 1.8428 - mse: 5.3841 - val_loss: 19.2145 - val_mae: 2.5458 - val_mse: 19.2145\n",
      "Epoch 69/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 5.6247 - mae: 1.8823 - mse: 5.6247 - val_loss: 21.3173 - val_mae: 2.7825 - val_mse: 21.3173\n",
      "Epoch 70/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 5.9084 - mae: 1.9713 - mse: 5.9084 - val_loss: 22.1700 - val_mae: 3.1389 - val_mse: 22.1700\n",
      "Epoch 71/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 5.2840 - mae: 1.8738 - mse: 5.2840 - val_loss: 24.6505 - val_mae: 3.6654 - val_mse: 24.6505\n",
      "Epoch 72/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 5.7598 - mae: 1.9583 - mse: 5.7598 - val_loss: 20.1412 - val_mae: 2.8582 - val_mse: 20.1412\n",
      "Epoch 73/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 5.9470 - mae: 1.9794 - mse: 5.9470 - val_loss: 18.4721 - val_mae: 2.4710 - val_mse: 18.4721\n",
      "Epoch 74/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 4.3057 - mae: 1.6078 - mse: 4.3057 - val_loss: 19.8391 - val_mae: 2.5585 - val_mse: 19.8391\n",
      "Epoch 75/500\n",
      "568/568 [==============================] - 0s 62us/sample - loss: 5.6843 - mae: 1.9124 - mse: 5.6843 - val_loss: 18.3857 - val_mae: 2.4619 - val_mse: 18.3857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 4.5986 - mae: 1.6850 - mse: 4.5986 - val_loss: 24.2391 - val_mae: 3.3977 - val_mse: 24.2391\n",
      "Epoch 77/500\n",
      "568/568 [==============================] - 0s 63us/sample - loss: 5.2680 - mae: 1.8490 - mse: 5.2680 - val_loss: 23.9595 - val_mae: 3.2512 - val_mse: 23.9595\n",
      "Epoch 78/500\n",
      "568/568 [==============================] - 0s 86us/sample - loss: 5.1368 - mae: 1.8178 - mse: 5.1368 - val_loss: 20.4133 - val_mae: 2.7395 - val_mse: 20.4133\n",
      "Epoch 79/500\n",
      "568/568 [==============================] - 0s 81us/sample - loss: 5.0825 - mae: 1.8175 - mse: 5.0825 - val_loss: 20.3129 - val_mae: 2.8551 - val_mse: 20.3129\n",
      "Epoch 80/500\n",
      "568/568 [==============================] - 0s 82us/sample - loss: 4.9921 - mae: 1.8390 - mse: 4.9921 - val_loss: 20.5352 - val_mae: 3.1430 - val_mse: 20.5352\n",
      "Epoch 81/500\n",
      "568/568 [==============================] - 0s 77us/sample - loss: 5.0399 - mae: 1.8002 - mse: 5.0399 - val_loss: 24.3236 - val_mae: 3.3172 - val_mse: 24.3236\n",
      "Epoch 82/500\n",
      "568/568 [==============================] - 0s 84us/sample - loss: 4.7704 - mae: 1.7482 - mse: 4.7704 - val_loss: 19.9912 - val_mae: 2.7038 - val_mse: 19.9912\n",
      "Epoch 83/500\n",
      "568/568 [==============================] - 0s 71us/sample - loss: 5.1689 - mae: 1.8543 - mse: 5.1689 - val_loss: 21.4759 - val_mae: 3.2786 - val_mse: 21.4759\n",
      "Epoch 84/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 4.2390 - mae: 1.5990 - mse: 4.2390 - val_loss: 19.8075 - val_mae: 2.7537 - val_mse: 19.8075\n",
      "Epoch 85/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 5.0773 - mae: 1.8108 - mse: 5.0773 - val_loss: 20.4495 - val_mae: 2.9640 - val_mse: 20.4495\n",
      "Epoch 86/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 5.1662 - mae: 1.8604 - mse: 5.1662 - val_loss: 21.3434 - val_mae: 2.9593 - val_mse: 21.3434\n",
      "Epoch 87/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 4.7735 - mae: 1.7949 - mse: 4.7735 - val_loss: 19.9539 - val_mae: 3.0425 - val_mse: 19.9539\n",
      "Epoch 88/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 5.2831 - mae: 1.8970 - mse: 5.2831 - val_loss: 19.4708 - val_mae: 2.6661 - val_mse: 19.4708\n",
      "Epoch 89/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 4.0908 - mae: 1.6352 - mse: 4.0908 - val_loss: 22.3758 - val_mae: 3.4948 - val_mse: 22.3758\n",
      "Epoch 90/500\n",
      "568/568 [==============================] - 0s 65us/sample - loss: 4.1859 - mae: 1.6098 - mse: 4.1859 - val_loss: 18.6249 - val_mae: 2.6907 - val_mse: 18.6249\n",
      "Epoch 91/500\n",
      "568/568 [==============================] - 0s 63us/sample - loss: 5.1207 - mae: 1.7727 - mse: 5.1207 - val_loss: 21.1789 - val_mae: 3.3284 - val_mse: 21.1789\n",
      "Epoch 92/500\n",
      "568/568 [==============================] - 0s 64us/sample - loss: 5.1414 - mae: 1.7755 - mse: 5.1414 - val_loss: 20.5219 - val_mae: 2.9979 - val_mse: 20.5219\n",
      "Epoch 93/500\n",
      "568/568 [==============================] - 0s 73us/sample - loss: 4.4434 - mae: 1.6875 - mse: 4.4434 - val_loss: 21.0976 - val_mae: 3.3617 - val_mse: 21.0976\n",
      "Epoch 94/500\n",
      "568/568 [==============================] - 0s 74us/sample - loss: 4.3913 - mae: 1.6168 - mse: 4.3913 - val_loss: 24.1430 - val_mae: 3.5581 - val_mse: 24.1430\n",
      "Epoch 95/500\n",
      "568/568 [==============================] - 0s 81us/sample - loss: 4.4206 - mae: 1.6811 - mse: 4.4206 - val_loss: 17.8010 - val_mae: 2.5676 - val_mse: 17.8010\n",
      "Epoch 96/500\n",
      "568/568 [==============================] - 0s 80us/sample - loss: 4.5026 - mae: 1.6999 - mse: 4.5026 - val_loss: 17.4494 - val_mae: 2.5703 - val_mse: 17.4494\n",
      "Epoch 97/500\n",
      "568/568 [==============================] - 0s 78us/sample - loss: 4.8911 - mae: 1.8134 - mse: 4.8911 - val_loss: 18.9578 - val_mae: 2.8699 - val_mse: 18.9578\n",
      "Epoch 98/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 4.9361 - mae: 1.8068 - mse: 4.9361 - val_loss: 16.8147 - val_mae: 2.5125 - val_mse: 16.8147\n",
      "Epoch 99/500\n",
      "568/568 [==============================] - 0s 55us/sample - loss: 4.1851 - mae: 1.6371 - mse: 4.1851 - val_loss: 17.4930 - val_mae: 2.6480 - val_mse: 17.4930\n",
      "Epoch 100/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 4.6556 - mae: 1.7432 - mse: 4.6556 - val_loss: 19.8609 - val_mae: 2.8528 - val_mse: 19.8609\n",
      "Epoch 101/500\n",
      "568/568 [==============================] - 0s 56us/sample - loss: 4.1960 - mae: 1.6165 - mse: 4.1960 - val_loss: 20.9663 - val_mae: 2.9272 - val_mse: 20.9663\n",
      "Epoch 102/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 4.3193 - mae: 1.6569 - mse: 4.3193 - val_loss: 16.9110 - val_mae: 2.4327 - val_mse: 16.9110\n",
      "Epoch 103/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 4.6333 - mae: 1.7331 - mse: 4.6333 - val_loss: 16.5013 - val_mae: 2.4315 - val_mse: 16.5013\n",
      "Epoch 104/500\n",
      "568/568 [==============================] - 0s 63us/sample - loss: 4.6103 - mae: 1.7191 - mse: 4.6103 - val_loss: 17.1225 - val_mae: 2.6348 - val_mse: 17.1225\n",
      "Epoch 105/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 4.2619 - mae: 1.6861 - mse: 4.2619 - val_loss: 17.8846 - val_mae: 2.6105 - val_mse: 17.8846\n",
      "Epoch 106/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 4.6044 - mae: 1.7377 - mse: 4.6044 - val_loss: 17.5405 - val_mae: 2.7016 - val_mse: 17.5405\n",
      "Epoch 107/500\n",
      "568/568 [==============================] - 0s 86us/sample - loss: 3.5846 - mae: 1.5388 - mse: 3.5846 - val_loss: 21.8553 - val_mae: 3.3877 - val_mse: 21.8553\n",
      "Epoch 108/500\n",
      "568/568 [==============================] - 0s 90us/sample - loss: 5.0529 - mae: 1.8108 - mse: 5.0529 - val_loss: 17.8193 - val_mae: 2.6455 - val_mse: 17.8193\n",
      "Epoch 109/500\n",
      "568/568 [==============================] - 0s 80us/sample - loss: 4.0248 - mae: 1.6027 - mse: 4.0248 - val_loss: 17.8652 - val_mae: 2.5869 - val_mse: 17.8652\n",
      "Epoch 110/500\n",
      "568/568 [==============================] - 0s 76us/sample - loss: 4.6394 - mae: 1.7101 - mse: 4.6394 - val_loss: 16.6317 - val_mae: 2.5732 - val_mse: 16.6317\n",
      "Epoch 111/500\n",
      "568/568 [==============================] - 0s 66us/sample - loss: 4.6042 - mae: 1.7896 - mse: 4.6042 - val_loss: 17.7989 - val_mae: 2.5897 - val_mse: 17.7989\n",
      "Epoch 112/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.6096 - mae: 1.5210 - mse: 3.6096 - val_loss: 15.9505 - val_mae: 2.3790 - val_mse: 15.9505\n",
      "Epoch 113/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 4.7707 - mae: 1.6930 - mse: 4.7707 - val_loss: 15.3457 - val_mae: 2.3103 - val_mse: 15.3457\n",
      "Epoch 114/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.9208 - mae: 1.5693 - mse: 3.9208 - val_loss: 20.9276 - val_mae: 3.3240 - val_mse: 20.9276\n",
      "Epoch 115/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 4.0675 - mae: 1.6456 - mse: 4.0675 - val_loss: 21.2953 - val_mae: 3.2080 - val_mse: 21.2953\n",
      "Epoch 116/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.8842 - mae: 1.5674 - mse: 3.8842 - val_loss: 18.0994 - val_mae: 2.7102 - val_mse: 18.0994\n",
      "Epoch 117/500\n",
      "568/568 [==============================] - 0s 63us/sample - loss: 4.3626 - mae: 1.7362 - mse: 4.3626 - val_loss: 18.0338 - val_mae: 2.6958 - val_mse: 18.0338\n",
      "Epoch 118/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 4.1453 - mae: 1.6865 - mse: 4.1453 - val_loss: 17.4806 - val_mae: 2.6189 - val_mse: 17.4806\n",
      "Epoch 119/500\n",
      "568/568 [==============================] - 0s 67us/sample - loss: 4.3796 - mae: 1.7098 - mse: 4.3796 - val_loss: 15.9743 - val_mae: 2.5629 - val_mse: 15.9743\n",
      "Epoch 120/500\n",
      "568/568 [==============================] - 0s 71us/sample - loss: 3.8074 - mae: 1.5858 - mse: 3.8074 - val_loss: 16.6760 - val_mae: 2.6886 - val_mse: 16.6760\n",
      "Epoch 121/500\n",
      "568/568 [==============================] - 0s 81us/sample - loss: 3.4244 - mae: 1.4745 - mse: 3.4244 - val_loss: 19.8399 - val_mae: 3.1130 - val_mse: 19.8399\n",
      "Epoch 122/500\n",
      "568/568 [==============================] - 0s 80us/sample - loss: 4.7430 - mae: 1.7880 - mse: 4.7429 - val_loss: 16.0855 - val_mae: 2.6280 - val_mse: 16.0855\n",
      "Epoch 123/500\n",
      "568/568 [==============================] - 0s 81us/sample - loss: 4.2242 - mae: 1.6744 - mse: 4.2242 - val_loss: 16.7489 - val_mae: 2.4857 - val_mse: 16.7489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/500\n",
      "568/568 [==============================] - 0s 63us/sample - loss: 3.5969 - mae: 1.5477 - mse: 3.5969 - val_loss: 19.2666 - val_mae: 3.0439 - val_mse: 19.2666\n",
      "Epoch 125/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 4.1484 - mae: 1.6509 - mse: 4.1484 - val_loss: 18.7660 - val_mae: 3.1247 - val_mse: 18.7660\n",
      "Epoch 126/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 4.3163 - mae: 1.7130 - mse: 4.3163 - val_loss: 18.2682 - val_mae: 2.7628 - val_mse: 18.2682\n",
      "Epoch 127/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 4.2729 - mae: 1.7030 - mse: 4.2729 - val_loss: 17.4972 - val_mae: 2.5914 - val_mse: 17.4972\n",
      "Epoch 128/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.4430 - mae: 1.4672 - mse: 3.4430 - val_loss: 15.2662 - val_mae: 2.3118 - val_mse: 15.2662\n",
      "Epoch 129/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 4.1852 - mae: 1.6720 - mse: 4.1852 - val_loss: 17.9627 - val_mae: 2.8254 - val_mse: 17.9627\n",
      "Epoch 130/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.3814 - mae: 1.4461 - mse: 3.3814 - val_loss: 18.4233 - val_mae: 2.7508 - val_mse: 18.4233\n",
      "Epoch 131/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 4.1359 - mae: 1.6423 - mse: 4.1359 - val_loss: 17.2976 - val_mae: 2.6579 - val_mse: 17.2976\n",
      "Epoch 132/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 4.2714 - mae: 1.6452 - mse: 4.2714 - val_loss: 19.7652 - val_mae: 3.0101 - val_mse: 19.7652\n",
      "Epoch 133/500\n",
      "568/568 [==============================] - 0s 78us/sample - loss: 3.4402 - mae: 1.4810 - mse: 3.4402 - val_loss: 15.3987 - val_mae: 2.3395 - val_mse: 15.3987\n",
      "Epoch 134/500\n",
      "568/568 [==============================] - 0s 85us/sample - loss: 4.6138 - mae: 1.7414 - mse: 4.6138 - val_loss: 16.1513 - val_mae: 2.5055 - val_mse: 16.1513\n",
      "Epoch 135/500\n",
      "568/568 [==============================] - 0s 80us/sample - loss: 3.5128 - mae: 1.4993 - mse: 3.5128 - val_loss: 17.7379 - val_mae: 2.6882 - val_mse: 17.7379\n",
      "Epoch 136/500\n",
      "568/568 [==============================] - 0s 90us/sample - loss: 3.8146 - mae: 1.5521 - mse: 3.8146 - val_loss: 18.5639 - val_mae: 2.8884 - val_mse: 18.5639\n",
      "Epoch 137/500\n",
      "568/568 [==============================] - 0s 75us/sample - loss: 4.3685 - mae: 1.6970 - mse: 4.3685 - val_loss: 16.9759 - val_mae: 2.6635 - val_mse: 16.9759\n",
      "Epoch 138/500\n",
      "568/568 [==============================] - 0s 75us/sample - loss: 3.7296 - mae: 1.5792 - mse: 3.7296 - val_loss: 16.8734 - val_mae: 2.7668 - val_mse: 16.8734\n",
      "Epoch 139/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 4.2283 - mae: 1.6640 - mse: 4.2283 - val_loss: 15.0003 - val_mae: 2.2927 - val_mse: 15.0003\n",
      "Epoch 140/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 4.0984 - mae: 1.6476 - mse: 4.0984 - val_loss: 15.6865 - val_mae: 2.4861 - val_mse: 15.6865\n",
      "Epoch 141/500\n",
      "568/568 [==============================] - 0s 63us/sample - loss: 3.7032 - mae: 1.5628 - mse: 3.7032 - val_loss: 16.8169 - val_mae: 2.5279 - val_mse: 16.8169\n",
      "Epoch 142/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 4.1555 - mae: 1.6690 - mse: 4.1555 - val_loss: 15.5005 - val_mae: 2.4605 - val_mse: 15.5005\n",
      "Epoch 143/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 3.9260 - mae: 1.6086 - mse: 3.9260 - val_loss: 17.4879 - val_mae: 2.6781 - val_mse: 17.4879\n",
      "Epoch 144/500\n",
      "568/568 [==============================] - 0s 63us/sample - loss: 3.1354 - mae: 1.3871 - mse: 3.1354 - val_loss: 15.7771 - val_mae: 2.4072 - val_mse: 15.7771\n",
      "Epoch 145/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 4.0153 - mae: 1.6207 - mse: 4.0153 - val_loss: 15.3002 - val_mae: 2.4457 - val_mse: 15.3002\n",
      "Epoch 146/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.9010 - mae: 1.6088 - mse: 3.9010 - val_loss: 18.0184 - val_mae: 2.9068 - val_mse: 18.0184\n",
      "Epoch 147/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 4.0328 - mae: 1.6272 - mse: 4.0328 - val_loss: 17.8680 - val_mae: 2.9251 - val_mse: 17.8680\n",
      "Epoch 148/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.5189 - mae: 1.5501 - mse: 3.5189 - val_loss: 17.5772 - val_mae: 2.8256 - val_mse: 17.5772\n",
      "Epoch 149/500\n",
      "568/568 [==============================] - 0s 73us/sample - loss: 4.2366 - mae: 1.6672 - mse: 4.2366 - val_loss: 14.7170 - val_mae: 2.3681 - val_mse: 14.7170\n",
      "Epoch 150/500\n",
      "568/568 [==============================] - 0s 86us/sample - loss: 3.7677 - mae: 1.5830 - mse: 3.7677 - val_loss: 15.8324 - val_mae: 2.4249 - val_mse: 15.8324\n",
      "Epoch 151/500\n",
      "568/568 [==============================] - 0s 81us/sample - loss: 3.9656 - mae: 1.6078 - mse: 3.9656 - val_loss: 16.8226 - val_mae: 2.6071 - val_mse: 16.8226\n",
      "Epoch 152/500\n",
      "568/568 [==============================] - 0s 79us/sample - loss: 3.6972 - mae: 1.5640 - mse: 3.6972 - val_loss: 17.1310 - val_mae: 2.6277 - val_mse: 17.1310\n",
      "Epoch 153/500\n",
      "568/568 [==============================] - 0s 77us/sample - loss: 3.5317 - mae: 1.5330 - mse: 3.5317 - val_loss: 14.6132 - val_mae: 2.3693 - val_mse: 14.6132\n",
      "Epoch 154/500\n",
      "568/568 [==============================] - 0s 78us/sample - loss: 4.0741 - mae: 1.6475 - mse: 4.0741 - val_loss: 16.5963 - val_mae: 2.6002 - val_mse: 16.5963\n",
      "Epoch 155/500\n",
      "568/568 [==============================] - 0s 63us/sample - loss: 3.6665 - mae: 1.5596 - mse: 3.6665 - val_loss: 16.7923 - val_mae: 2.6093 - val_mse: 16.7923\n",
      "Epoch 156/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 3.6376 - mae: 1.5595 - mse: 3.6376 - val_loss: 16.2670 - val_mae: 2.6952 - val_mse: 16.2670\n",
      "Epoch 157/500\n",
      "568/568 [==============================] - 0s 56us/sample - loss: 3.3656 - mae: 1.4875 - mse: 3.3656 - val_loss: 15.7235 - val_mae: 2.4316 - val_mse: 15.7235\n",
      "Epoch 158/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.6986 - mae: 1.5219 - mse: 3.6986 - val_loss: 16.0343 - val_mae: 2.7344 - val_mse: 16.0343\n",
      "Epoch 159/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 4.0864 - mae: 1.6700 - mse: 4.0864 - val_loss: 15.0640 - val_mae: 2.3256 - val_mse: 15.0640\n",
      "Epoch 160/500\n",
      "568/568 [==============================] - 0s 55us/sample - loss: 3.6418 - mae: 1.5329 - mse: 3.6418 - val_loss: 14.6497 - val_mae: 2.3501 - val_mse: 14.6497\n",
      "Epoch 161/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 3.2942 - mae: 1.4390 - mse: 3.2942 - val_loss: 15.6242 - val_mae: 2.3919 - val_mse: 15.6242\n",
      "Epoch 162/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.3471 - mae: 1.4875 - mse: 3.3471 - val_loss: 18.9601 - val_mae: 2.9260 - val_mse: 18.9601\n",
      "Epoch 163/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 3.8623 - mae: 1.5645 - mse: 3.8623 - val_loss: 15.1534 - val_mae: 2.4819 - val_mse: 15.1534\n",
      "Epoch 164/500\n",
      "568/568 [==============================] - 0s 63us/sample - loss: 3.2324 - mae: 1.4454 - mse: 3.2324 - val_loss: 18.8203 - val_mae: 3.0772 - val_mse: 18.8203\n",
      "Epoch 165/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.7142 - mae: 1.5673 - mse: 3.7142 - val_loss: 16.4610 - val_mae: 2.5858 - val_mse: 16.4610\n",
      "Epoch 166/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.1387 - mae: 1.4141 - mse: 3.1387 - val_loss: 18.7398 - val_mae: 2.8907 - val_mse: 18.7398\n",
      "Epoch 167/500\n",
      "568/568 [==============================] - 0s 77us/sample - loss: 3.6039 - mae: 1.5310 - mse: 3.6039 - val_loss: 14.8418 - val_mae: 2.3128 - val_mse: 14.8418\n",
      "Epoch 168/500\n",
      "568/568 [==============================] - 0s 90us/sample - loss: 3.4315 - mae: 1.4811 - mse: 3.4315 - val_loss: 14.7607 - val_mae: 2.4145 - val_mse: 14.7607\n",
      "Epoch 169/500\n",
      "568/568 [==============================] - 0s 81us/sample - loss: 3.4756 - mae: 1.5171 - mse: 3.4756 - val_loss: 15.1852 - val_mae: 2.5146 - val_mse: 15.1852\n",
      "Epoch 170/500\n",
      "568/568 [==============================] - 0s 78us/sample - loss: 3.8970 - mae: 1.5880 - mse: 3.8970 - val_loss: 16.6905 - val_mae: 2.6667 - val_mse: 16.6905\n",
      "Epoch 171/500\n",
      "568/568 [==============================] - 0s 84us/sample - loss: 3.7373 - mae: 1.5755 - mse: 3.7373 - val_loss: 16.7506 - val_mae: 2.6230 - val_mse: 16.7506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "568/568 [==============================] - 0s 85us/sample - loss: 3.9018 - mae: 1.6138 - mse: 3.9018 - val_loss: 15.4208 - val_mae: 2.3459 - val_mse: 15.4208\n",
      "Epoch 173/500\n",
      "568/568 [==============================] - 0s 79us/sample - loss: 3.2585 - mae: 1.4534 - mse: 3.2585 - val_loss: 15.3244 - val_mae: 2.5762 - val_mse: 15.3244\n",
      "Epoch 174/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.2529 - mae: 1.4555 - mse: 3.2529 - val_loss: 17.0444 - val_mae: 2.8348 - val_mse: 17.0444\n",
      "Epoch 175/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.5037 - mae: 1.5189 - mse: 3.5037 - val_loss: 17.4635 - val_mae: 2.9858 - val_mse: 17.4635\n",
      "Epoch 176/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.5025 - mae: 1.5131 - mse: 3.5025 - val_loss: 14.9468 - val_mae: 2.5572 - val_mse: 14.9468\n",
      "Epoch 177/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.3710 - mae: 1.4709 - mse: 3.3710 - val_loss: 14.8421 - val_mae: 2.2981 - val_mse: 14.8421\n",
      "Epoch 178/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.5653 - mae: 1.5024 - mse: 3.5653 - val_loss: 13.9336 - val_mae: 2.2899 - val_mse: 13.9336\n",
      "Epoch 179/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.1146 - mae: 1.4017 - mse: 3.1146 - val_loss: 14.5160 - val_mae: 2.2921 - val_mse: 14.5160\n",
      "Epoch 180/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.5335 - mae: 1.5201 - mse: 3.5335 - val_loss: 16.0103 - val_mae: 2.5765 - val_mse: 16.0103\n",
      "Epoch 181/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.5642 - mae: 1.5525 - mse: 3.5642 - val_loss: 17.5295 - val_mae: 2.7729 - val_mse: 17.5295\n",
      "Epoch 182/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.3243 - mae: 1.4463 - mse: 3.3243 - val_loss: 16.1079 - val_mae: 2.5386 - val_mse: 16.1079\n",
      "Epoch 183/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 3.8518 - mae: 1.6047 - mse: 3.8518 - val_loss: 14.3767 - val_mae: 2.3627 - val_mse: 14.3767\n",
      "Epoch 184/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.4698 - mae: 1.4844 - mse: 3.4698 - val_loss: 15.0799 - val_mae: 2.4579 - val_mse: 15.0799\n",
      "Epoch 185/500\n",
      "568/568 [==============================] - 0s 56us/sample - loss: 3.4399 - mae: 1.5237 - mse: 3.4399 - val_loss: 15.1423 - val_mae: 2.5145 - val_mse: 15.1423\n",
      "Epoch 186/500\n",
      "568/568 [==============================] - 0s 64us/sample - loss: 3.4164 - mae: 1.4517 - mse: 3.4164 - val_loss: 16.6983 - val_mae: 2.6597 - val_mse: 16.6983\n",
      "Epoch 187/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.1327 - mae: 1.4377 - mse: 3.1327 - val_loss: 14.5118 - val_mae: 2.4244 - val_mse: 14.5118\n",
      "Epoch 188/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.6705 - mae: 1.5731 - mse: 3.6705 - val_loss: 15.3027 - val_mae: 2.3668 - val_mse: 15.3027\n",
      "Epoch 189/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.0417 - mae: 1.3970 - mse: 3.0417 - val_loss: 14.7615 - val_mae: 2.4221 - val_mse: 14.7615\n",
      "Epoch 190/500\n",
      "568/568 [==============================] - 0s 62us/sample - loss: 3.5430 - mae: 1.5515 - mse: 3.5430 - val_loss: 14.5884 - val_mae: 2.3895 - val_mse: 14.5884\n",
      "Epoch 191/500\n",
      "568/568 [==============================] - 0s 87us/sample - loss: 3.1535 - mae: 1.4309 - mse: 3.1535 - val_loss: 15.9672 - val_mae: 2.7188 - val_mse: 15.9672\n",
      "Epoch 192/500\n",
      "568/568 [==============================] - 0s 78us/sample - loss: 3.0671 - mae: 1.3938 - mse: 3.0671 - val_loss: 14.6043 - val_mae: 2.4711 - val_mse: 14.6043\n",
      "Epoch 193/500\n",
      "568/568 [==============================] - 0s 87us/sample - loss: 3.3371 - mae: 1.4715 - mse: 3.3371 - val_loss: 16.6098 - val_mae: 2.5883 - val_mse: 16.6098\n",
      "Epoch 194/500\n",
      "568/568 [==============================] - 0s 77us/sample - loss: 3.1050 - mae: 1.4308 - mse: 3.1050 - val_loss: 14.8917 - val_mae: 2.5181 - val_mse: 14.8917\n",
      "Epoch 195/500\n",
      "568/568 [==============================] - 0s 75us/sample - loss: 3.0791 - mae: 1.4059 - mse: 3.0791 - val_loss: 15.7045 - val_mae: 2.7477 - val_mse: 15.7045\n",
      "Epoch 196/500\n",
      "568/568 [==============================] - 0s 79us/sample - loss: 3.8141 - mae: 1.5711 - mse: 3.8141 - val_loss: 15.9350 - val_mae: 2.5397 - val_mse: 15.9350\n",
      "Epoch 197/500\n",
      "568/568 [==============================] - 0s 66us/sample - loss: 2.8584 - mae: 1.3334 - mse: 2.8584 - val_loss: 16.5774 - val_mae: 2.7640 - val_mse: 16.5774\n",
      "Epoch 198/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.6029 - mae: 1.5463 - mse: 3.6029 - val_loss: 15.3278 - val_mae: 2.5484 - val_mse: 15.3278\n",
      "Epoch 199/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.7796 - mae: 1.3612 - mse: 2.7796 - val_loss: 15.5703 - val_mae: 2.6908 - val_mse: 15.5703\n",
      "Epoch 200/500\n",
      "568/568 [==============================] - 0s 62us/sample - loss: 3.6620 - mae: 1.5315 - mse: 3.6620 - val_loss: 19.2523 - val_mae: 2.9947 - val_mse: 19.2523\n",
      "Epoch 201/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.1539 - mae: 1.4409 - mse: 3.1539 - val_loss: 15.2577 - val_mae: 2.5732 - val_mse: 15.2577\n",
      "Epoch 202/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.2440 - mae: 1.4708 - mse: 3.2440 - val_loss: 14.9872 - val_mae: 2.4800 - val_mse: 14.9872\n",
      "Epoch 203/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 3.4413 - mae: 1.4986 - mse: 3.4413 - val_loss: 14.9068 - val_mae: 2.4272 - val_mse: 14.9068\n",
      "Epoch 204/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.5823 - mae: 1.5446 - mse: 3.5823 - val_loss: 17.4969 - val_mae: 2.6771 - val_mse: 17.4969\n",
      "Epoch 205/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.1433 - mae: 1.4346 - mse: 3.1433 - val_loss: 16.4549 - val_mae: 2.5319 - val_mse: 16.4549\n",
      "Epoch 206/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 3.2489 - mae: 1.4651 - mse: 3.2489 - val_loss: 14.8383 - val_mae: 2.2970 - val_mse: 14.8383\n",
      "Epoch 207/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.1282 - mae: 1.4012 - mse: 3.1282 - val_loss: 14.3753 - val_mae: 2.4024 - val_mse: 14.3753\n",
      "Epoch 208/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.2292 - mae: 1.4274 - mse: 3.2292 - val_loss: 14.2377 - val_mae: 2.3632 - val_mse: 14.2377\n",
      "Epoch 209/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.2168 - mae: 1.4836 - mse: 3.2168 - val_loss: 16.4715 - val_mae: 2.9013 - val_mse: 16.4715\n",
      "Epoch 210/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.4057 - mae: 1.5126 - mse: 3.4057 - val_loss: 16.8480 - val_mae: 2.7932 - val_mse: 16.8480\n",
      "Epoch 211/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.0321 - mae: 1.4074 - mse: 3.0321 - val_loss: 14.6185 - val_mae: 2.3055 - val_mse: 14.6185\n",
      "Epoch 212/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 3.5912 - mae: 1.4823 - mse: 3.5912 - val_loss: 16.6279 - val_mae: 2.8455 - val_mse: 16.6279\n",
      "Epoch 213/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.2198 - mae: 1.4627 - mse: 3.2198 - val_loss: 15.0313 - val_mae: 2.6188 - val_mse: 15.0313\n",
      "Epoch 214/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.0268 - mae: 1.3993 - mse: 3.0268 - val_loss: 17.9004 - val_mae: 2.8177 - val_mse: 17.9004\n",
      "Epoch 215/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.4601 - mae: 1.5156 - mse: 3.4601 - val_loss: 15.1211 - val_mae: 2.6231 - val_mse: 15.1211\n",
      "Epoch 216/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.6251 - mae: 1.3204 - mse: 2.6251 - val_loss: 16.1765 - val_mae: 2.5615 - val_mse: 16.1765\n",
      "Epoch 217/500\n",
      "568/568 [==============================] - 0s 63us/sample - loss: 3.2461 - mae: 1.4220 - mse: 3.2461 - val_loss: 14.2809 - val_mae: 2.2611 - val_mse: 14.2809\n",
      "Epoch 218/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.8071 - mae: 1.3023 - mse: 2.8071 - val_loss: 13.8881 - val_mae: 2.3462 - val_mse: 13.8881\n",
      "Epoch 219/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.6057 - mae: 1.5396 - mse: 3.6057 - val_loss: 14.8036 - val_mae: 2.2841 - val_mse: 14.8036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.2955 - mae: 1.4723 - mse: 3.2955 - val_loss: 14.0224 - val_mae: 2.2673 - val_mse: 14.0224\n",
      "Epoch 221/500\n",
      "568/568 [==============================] - 0s 63us/sample - loss: 3.1749 - mae: 1.4163 - mse: 3.1749 - val_loss: 14.1838 - val_mae: 2.3726 - val_mse: 14.1838\n",
      "Epoch 222/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.5950 - mae: 1.2795 - mse: 2.5950 - val_loss: 14.1471 - val_mae: 2.3879 - val_mse: 14.1471\n",
      "Epoch 223/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 3.3284 - mae: 1.4658 - mse: 3.3284 - val_loss: 14.8062 - val_mae: 2.4820 - val_mse: 14.8062\n",
      "Epoch 224/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.8165 - mae: 1.3547 - mse: 2.8165 - val_loss: 14.5261 - val_mae: 2.5136 - val_mse: 14.5261\n",
      "Epoch 225/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.0441 - mae: 1.3620 - mse: 3.0441 - val_loss: 16.9527 - val_mae: 2.6994 - val_mse: 16.9527\n",
      "Epoch 226/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.7857 - mae: 1.3312 - mse: 2.7857 - val_loss: 16.6493 - val_mae: 2.6210 - val_mse: 16.6493\n",
      "Epoch 227/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.1543 - mae: 1.4311 - mse: 3.1543 - val_loss: 14.3630 - val_mae: 2.3016 - val_mse: 14.3630\n",
      "Epoch 228/500\n",
      "568/568 [==============================] - 0s 56us/sample - loss: 3.2965 - mae: 1.4682 - mse: 3.2965 - val_loss: 15.1366 - val_mae: 2.4164 - val_mse: 15.1366\n",
      "Epoch 229/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.6982 - mae: 1.3273 - mse: 2.6982 - val_loss: 14.1188 - val_mae: 2.2485 - val_mse: 14.1188\n",
      "Epoch 230/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.1206 - mae: 1.4446 - mse: 3.1206 - val_loss: 14.3368 - val_mae: 2.4722 - val_mse: 14.3368\n",
      "Epoch 231/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.6090 - mae: 1.2955 - mse: 2.6090 - val_loss: 15.0276 - val_mae: 2.4787 - val_mse: 15.0276\n",
      "Epoch 232/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.0549 - mae: 1.4008 - mse: 3.0549 - val_loss: 14.1744 - val_mae: 2.3088 - val_mse: 14.1744\n",
      "Epoch 233/500\n",
      "568/568 [==============================] - 0s 54us/sample - loss: 3.0526 - mae: 1.4209 - mse: 3.0526 - val_loss: 14.5111 - val_mae: 2.5338 - val_mse: 14.5111\n",
      "Epoch 234/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.7935 - mae: 1.3300 - mse: 2.7935 - val_loss: 15.3237 - val_mae: 2.4241 - val_mse: 15.3237\n",
      "Epoch 235/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 3.1479 - mae: 1.4544 - mse: 3.1479 - val_loss: 14.2792 - val_mae: 2.4167 - val_mse: 14.2792\n",
      "Epoch 236/500\n",
      "568/568 [==============================] - 0s 65us/sample - loss: 2.7711 - mae: 1.3485 - mse: 2.7711 - val_loss: 14.5552 - val_mae: 2.4399 - val_mse: 14.5552\n",
      "Epoch 237/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 3.3888 - mae: 1.5063 - mse: 3.3888 - val_loss: 15.1232 - val_mae: 2.6559 - val_mse: 15.1232\n",
      "Epoch 238/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.8365 - mae: 1.3498 - mse: 2.8365 - val_loss: 14.0403 - val_mae: 2.4157 - val_mse: 14.0403\n",
      "Epoch 239/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.8234 - mae: 1.3658 - mse: 2.8234 - val_loss: 14.3467 - val_mae: 2.4063 - val_mse: 14.3467\n",
      "Epoch 240/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.8732 - mae: 1.3511 - mse: 2.8732 - val_loss: 13.9560 - val_mae: 2.3783 - val_mse: 13.9560\n",
      "Epoch 241/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.8853 - mae: 1.3714 - mse: 2.8853 - val_loss: 14.6956 - val_mae: 2.3458 - val_mse: 14.6956\n",
      "Epoch 242/500\n",
      "568/568 [==============================] - 0s 62us/sample - loss: 2.9643 - mae: 1.3685 - mse: 2.9643 - val_loss: 13.8531 - val_mae: 2.2794 - val_mse: 13.8531\n",
      "Epoch 243/500\n",
      "568/568 [==============================] - 0s 65us/sample - loss: 2.8323 - mae: 1.3373 - mse: 2.8323 - val_loss: 14.0826 - val_mae: 2.4533 - val_mse: 14.0826\n",
      "Epoch 244/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 3.0931 - mae: 1.4239 - mse: 3.0931 - val_loss: 15.0775 - val_mae: 2.3703 - val_mse: 15.0775\n",
      "Epoch 245/500\n",
      "568/568 [==============================] - 0s 64us/sample - loss: 2.5635 - mae: 1.2577 - mse: 2.5635 - val_loss: 14.0841 - val_mae: 2.2381 - val_mse: 14.0841\n",
      "Epoch 246/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.7965 - mae: 1.3595 - mse: 2.7965 - val_loss: 13.6443 - val_mae: 2.3365 - val_mse: 13.6443\n",
      "Epoch 247/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.7776 - mae: 1.3422 - mse: 2.7776 - val_loss: 14.2774 - val_mae: 2.3035 - val_mse: 14.2774\n",
      "Epoch 248/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.1771 - mae: 1.4336 - mse: 3.1771 - val_loss: 13.6735 - val_mae: 2.2487 - val_mse: 13.6735\n",
      "Epoch 249/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.6991 - mae: 1.3237 - mse: 2.6991 - val_loss: 13.7384 - val_mae: 2.2421 - val_mse: 13.7384\n",
      "Epoch 250/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.9167 - mae: 1.3866 - mse: 2.9167 - val_loss: 14.7491 - val_mae: 2.6398 - val_mse: 14.7491\n",
      "Epoch 251/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.7435 - mae: 1.3353 - mse: 2.7435 - val_loss: 15.1348 - val_mae: 2.4805 - val_mse: 15.1348\n",
      "Epoch 252/500\n",
      "568/568 [==============================] - 0s 62us/sample - loss: 3.0986 - mae: 1.4281 - mse: 3.0986 - val_loss: 16.3880 - val_mae: 2.6434 - val_mse: 16.3880\n",
      "Epoch 253/500\n",
      "568/568 [==============================] - 0s 62us/sample - loss: 2.7391 - mae: 1.3248 - mse: 2.7391 - val_loss: 14.8777 - val_mae: 2.5963 - val_mse: 14.8777\n",
      "Epoch 254/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.9210 - mae: 1.3770 - mse: 2.9210 - val_loss: 13.5273 - val_mae: 2.3438 - val_mse: 13.5273\n",
      "Epoch 255/500\n",
      "568/568 [==============================] - 0s 56us/sample - loss: 2.9341 - mae: 1.3848 - mse: 2.9341 - val_loss: 13.5870 - val_mae: 2.3019 - val_mse: 13.5870\n",
      "Epoch 256/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.6386 - mae: 1.3229 - mse: 2.6386 - val_loss: 16.6311 - val_mae: 2.6715 - val_mse: 16.6311\n",
      "Epoch 257/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.8654 - mae: 1.3503 - mse: 2.8654 - val_loss: 13.2659 - val_mae: 2.2053 - val_mse: 13.2659\n",
      "Epoch 258/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.5786 - mae: 1.2990 - mse: 2.5786 - val_loss: 14.1229 - val_mae: 2.5376 - val_mse: 14.1229\n",
      "Epoch 259/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.9299 - mae: 1.3989 - mse: 2.9299 - val_loss: 14.5434 - val_mae: 2.3704 - val_mse: 14.5434\n",
      "Epoch 260/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.6676 - mae: 1.3094 - mse: 2.6676 - val_loss: 14.6031 - val_mae: 2.4062 - val_mse: 14.6031\n",
      "Epoch 261/500\n",
      "568/568 [==============================] - 0s 64us/sample - loss: 2.6980 - mae: 1.3196 - mse: 2.6980 - val_loss: 13.6968 - val_mae: 2.2087 - val_mse: 13.6968\n",
      "Epoch 262/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.6115 - mae: 1.2985 - mse: 2.6115 - val_loss: 14.8637 - val_mae: 2.4113 - val_mse: 14.8637\n",
      "Epoch 263/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.9004 - mae: 1.3943 - mse: 2.9004 - val_loss: 16.7362 - val_mae: 2.6713 - val_mse: 16.7362\n",
      "Epoch 264/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.5852 - mae: 1.3058 - mse: 2.5852 - val_loss: 14.1985 - val_mae: 2.4628 - val_mse: 14.1985\n",
      "Epoch 265/500\n",
      "568/568 [==============================] - 0s 65us/sample - loss: 2.7708 - mae: 1.3344 - mse: 2.7708 - val_loss: 14.0918 - val_mae: 2.3786 - val_mse: 14.0918\n",
      "Epoch 266/500\n",
      "568/568 [==============================] - 0s 64us/sample - loss: 2.8084 - mae: 1.3469 - mse: 2.8084 - val_loss: 13.8458 - val_mae: 2.2853 - val_mse: 13.8458\n",
      "Epoch 267/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.3583 - mae: 1.2352 - mse: 2.3583 - val_loss: 14.2399 - val_mae: 2.2817 - val_mse: 14.2399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268/500\n",
      "568/568 [==============================] - 0s 62us/sample - loss: 2.4751 - mae: 1.2605 - mse: 2.4751 - val_loss: 17.1511 - val_mae: 2.7664 - val_mse: 17.1511\n",
      "Epoch 269/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 3.1631 - mae: 1.4266 - mse: 3.1631 - val_loss: 17.0659 - val_mae: 2.7652 - val_mse: 17.0659\n",
      "Epoch 270/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.4110 - mae: 1.2743 - mse: 2.4110 - val_loss: 16.1211 - val_mae: 2.6281 - val_mse: 16.1211\n",
      "Epoch 271/500\n",
      "568/568 [==============================] - 0s 55us/sample - loss: 2.3763 - mae: 1.2440 - mse: 2.3763 - val_loss: 16.4273 - val_mae: 2.9051 - val_mse: 16.4273\n",
      "Epoch 272/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.8410 - mae: 1.3681 - mse: 2.8410 - val_loss: 16.0692 - val_mae: 2.5754 - val_mse: 16.0692\n",
      "Epoch 273/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.8243 - mae: 1.3467 - mse: 2.8243 - val_loss: 17.4230 - val_mae: 2.7988 - val_mse: 17.4230\n",
      "Epoch 274/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.7364 - mae: 1.3260 - mse: 2.7364 - val_loss: 14.4696 - val_mae: 2.3574 - val_mse: 14.4696\n",
      "Epoch 275/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.8276 - mae: 1.3478 - mse: 2.8276 - val_loss: 15.7792 - val_mae: 2.5512 - val_mse: 15.7792\n",
      "Epoch 276/500\n",
      "568/568 [==============================] - 0s 66us/sample - loss: 2.4845 - mae: 1.2795 - mse: 2.4845 - val_loss: 15.3280 - val_mae: 2.4787 - val_mse: 15.3280\n",
      "Epoch 277/500\n",
      "568/568 [==============================] - 0s 63us/sample - loss: 2.7651 - mae: 1.3425 - mse: 2.7651 - val_loss: 14.2955 - val_mae: 2.2821 - val_mse: 14.2955\n",
      "Epoch 278/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.8810 - mae: 1.3718 - mse: 2.8810 - val_loss: 13.5359 - val_mae: 2.2697 - val_mse: 13.5359\n",
      "Epoch 279/500\n",
      "568/568 [==============================] - 0s 72us/sample - loss: 2.6563 - mae: 1.3022 - mse: 2.6563 - val_loss: 14.0770 - val_mae: 2.3254 - val_mse: 14.0770\n",
      "Epoch 280/500\n",
      "568/568 [==============================] - 0s 86us/sample - loss: 2.2601 - mae: 1.1989 - mse: 2.2601 - val_loss: 14.3035 - val_mae: 2.5216 - val_mse: 14.3035\n",
      "Epoch 281/500\n",
      "568/568 [==============================] - 0s 89us/sample - loss: 2.9662 - mae: 1.4064 - mse: 2.9662 - val_loss: 13.8136 - val_mae: 2.4597 - val_mse: 13.8136\n",
      "Epoch 282/500\n",
      "568/568 [==============================] - 0s 111us/sample - loss: 2.4655 - mae: 1.2718 - mse: 2.4655 - val_loss: 13.7094 - val_mae: 2.3995 - val_mse: 13.7094\n",
      "Epoch 283/500\n",
      "568/568 [==============================] - 0s 95us/sample - loss: 2.8664 - mae: 1.3950 - mse: 2.8664 - val_loss: 14.2714 - val_mae: 2.3690 - val_mse: 14.2714\n",
      "Epoch 284/500\n",
      "568/568 [==============================] - 0s 98us/sample - loss: 2.8539 - mae: 1.3565 - mse: 2.8539 - val_loss: 13.3756 - val_mae: 2.2458 - val_mse: 13.3756\n",
      "Epoch 285/500\n",
      "568/568 [==============================] - 0s 91us/sample - loss: 2.4453 - mae: 1.2385 - mse: 2.4453 - val_loss: 13.1753 - val_mae: 2.2730 - val_mse: 13.1753\n",
      "Epoch 286/500\n",
      "568/568 [==============================] - 0s 88us/sample - loss: 2.8812 - mae: 1.3795 - mse: 2.8812 - val_loss: 13.5083 - val_mae: 2.3676 - val_mse: 13.5083\n",
      "Epoch 287/500\n",
      "568/568 [==============================] - 0s 97us/sample - loss: 2.4345 - mae: 1.2590 - mse: 2.4345 - val_loss: 17.7169 - val_mae: 2.8806 - val_mse: 17.7169\n",
      "Epoch 288/500\n",
      "568/568 [==============================] - 0s 85us/sample - loss: 2.7180 - mae: 1.3138 - mse: 2.7180 - val_loss: 13.4795 - val_mae: 2.3185 - val_mse: 13.4795\n",
      "Epoch 289/500\n",
      "568/568 [==============================] - 0s 95us/sample - loss: 2.6472 - mae: 1.3216 - mse: 2.6472 - val_loss: 14.7538 - val_mae: 2.3692 - val_mse: 14.7538\n",
      "Epoch 290/500\n",
      "568/568 [==============================] - 0s 89us/sample - loss: 2.6137 - mae: 1.3104 - mse: 2.6137 - val_loss: 13.3782 - val_mae: 2.3230 - val_mse: 13.3782\n",
      "Epoch 291/500\n",
      "568/568 [==============================] - 0s 85us/sample - loss: 2.6343 - mae: 1.3291 - mse: 2.6343 - val_loss: 13.3783 - val_mae: 2.2527 - val_mse: 13.3783\n",
      "Epoch 292/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.2857 - mae: 1.2124 - mse: 2.2857 - val_loss: 13.4338 - val_mae: 2.2736 - val_mse: 13.4338\n",
      "Epoch 293/500\n",
      "568/568 [==============================] - 0s 63us/sample - loss: 2.6299 - mae: 1.3096 - mse: 2.6299 - val_loss: 14.1653 - val_mae: 2.4682 - val_mse: 14.1653\n",
      "Epoch 294/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.7059 - mae: 1.3353 - mse: 2.7059 - val_loss: 14.9287 - val_mae: 2.3969 - val_mse: 14.9287\n",
      "Epoch 295/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.7544 - mae: 1.3576 - mse: 2.7544 - val_loss: 13.1577 - val_mae: 2.3118 - val_mse: 13.1577\n",
      "Epoch 296/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.4472 - mae: 1.2609 - mse: 2.4472 - val_loss: 14.0792 - val_mae: 2.4931 - val_mse: 14.0792\n",
      "Epoch 297/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.5836 - mae: 1.2962 - mse: 2.5836 - val_loss: 13.4362 - val_mae: 2.2514 - val_mse: 13.4362\n",
      "Epoch 298/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.2567 - mae: 1.2236 - mse: 2.2567 - val_loss: 16.2687 - val_mae: 2.6221 - val_mse: 16.2687\n",
      "Epoch 299/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.4947 - mae: 1.2844 - mse: 2.4947 - val_loss: 13.3437 - val_mae: 2.1604 - val_mse: 13.3437\n",
      "Epoch 300/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.9552 - mae: 1.3948 - mse: 2.9552 - val_loss: 13.2503 - val_mae: 2.1481 - val_mse: 13.2503\n",
      "Epoch 301/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.7406 - mae: 1.2988 - mse: 2.7406 - val_loss: 14.0848 - val_mae: 2.4611 - val_mse: 14.0848\n",
      "Epoch 302/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.6368 - mae: 1.3068 - mse: 2.6368 - val_loss: 13.6596 - val_mae: 2.3978 - val_mse: 13.6596\n",
      "Epoch 303/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.3803 - mae: 1.2400 - mse: 2.3803 - val_loss: 14.9448 - val_mae: 2.3766 - val_mse: 14.9448\n",
      "Epoch 304/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.4308 - mae: 1.2534 - mse: 2.4308 - val_loss: 16.2793 - val_mae: 2.9359 - val_mse: 16.2793\n",
      "Epoch 305/500\n",
      "568/568 [==============================] - 0s 56us/sample - loss: 2.6650 - mae: 1.3144 - mse: 2.6650 - val_loss: 13.2282 - val_mae: 2.1681 - val_mse: 13.2282\n",
      "Epoch 306/500\n",
      "568/568 [==============================] - 0s 56us/sample - loss: 2.5271 - mae: 1.2796 - mse: 2.5271 - val_loss: 16.0200 - val_mae: 2.5998 - val_mse: 16.0200\n",
      "Epoch 307/500\n",
      "568/568 [==============================] - 0s 66us/sample - loss: 2.5442 - mae: 1.2922 - mse: 2.5442 - val_loss: 13.4196 - val_mae: 2.3394 - val_mse: 13.4196\n",
      "Epoch 308/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.4921 - mae: 1.2954 - mse: 2.4921 - val_loss: 13.2480 - val_mae: 2.3308 - val_mse: 13.2480\n",
      "Epoch 309/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.6617 - mae: 1.3248 - mse: 2.6617 - val_loss: 15.1961 - val_mae: 2.6053 - val_mse: 15.1961\n",
      "Epoch 310/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.6052 - mae: 1.2952 - mse: 2.6052 - val_loss: 15.8840 - val_mae: 2.5871 - val_mse: 15.8840\n",
      "Epoch 311/500\n",
      "568/568 [==============================] - 0s 56us/sample - loss: 2.1417 - mae: 1.1781 - mse: 2.1417 - val_loss: 14.0250 - val_mae: 2.2732 - val_mse: 14.0250\n",
      "Epoch 312/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.8102 - mae: 1.3538 - mse: 2.8102 - val_loss: 13.9299 - val_mae: 2.2915 - val_mse: 13.9299\n",
      "Epoch 313/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.2706 - mae: 1.2090 - mse: 2.2706 - val_loss: 13.2848 - val_mae: 2.2039 - val_mse: 13.2848\n",
      "Epoch 314/500\n",
      "568/568 [==============================] - 0s 55us/sample - loss: 2.4347 - mae: 1.2477 - mse: 2.4347 - val_loss: 13.1415 - val_mae: 2.2793 - val_mse: 13.1415\n",
      "Epoch 315/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.4181 - mae: 1.2728 - mse: 2.4181 - val_loss: 14.2520 - val_mae: 2.3600 - val_mse: 14.2520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.4518 - mae: 1.2769 - mse: 2.4518 - val_loss: 12.7463 - val_mae: 2.1405 - val_mse: 12.7463\n",
      "Epoch 317/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.4130 - mae: 1.2254 - mse: 2.4130 - val_loss: 16.0250 - val_mae: 2.5971 - val_mse: 16.0250\n",
      "Epoch 318/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.3332 - mae: 1.2378 - mse: 2.3332 - val_loss: 13.3386 - val_mae: 2.2268 - val_mse: 13.3386\n",
      "Epoch 319/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.5836 - mae: 1.3070 - mse: 2.5836 - val_loss: 14.4846 - val_mae: 2.3228 - val_mse: 14.4846\n",
      "Epoch 320/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.1402 - mae: 1.1668 - mse: 2.1402 - val_loss: 16.7936 - val_mae: 2.9908 - val_mse: 16.7936\n",
      "Epoch 321/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.5341 - mae: 1.2801 - mse: 2.5341 - val_loss: 14.4221 - val_mae: 2.3587 - val_mse: 14.4221\n",
      "Epoch 322/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.5461 - mae: 1.2951 - mse: 2.5461 - val_loss: 13.4872 - val_mae: 2.1956 - val_mse: 13.4872\n",
      "Epoch 323/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.2610 - mae: 1.2009 - mse: 2.2610 - val_loss: 14.4175 - val_mae: 2.2887 - val_mse: 14.4175\n",
      "Epoch 324/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.6082 - mae: 1.3185 - mse: 2.6082 - val_loss: 14.0670 - val_mae: 2.2577 - val_mse: 14.0670\n",
      "Epoch 325/500\n",
      "568/568 [==============================] - 0s 62us/sample - loss: 2.2802 - mae: 1.2109 - mse: 2.2802 - val_loss: 15.0589 - val_mae: 2.6012 - val_mse: 15.0589\n",
      "Epoch 326/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.6219 - mae: 1.2999 - mse: 2.6219 - val_loss: 13.5924 - val_mae: 2.1839 - val_mse: 13.5924\n",
      "Epoch 327/500\n",
      "568/568 [==============================] - 0s 56us/sample - loss: 2.5285 - mae: 1.2855 - mse: 2.5285 - val_loss: 14.4660 - val_mae: 2.5955 - val_mse: 14.4660\n",
      "Epoch 328/500\n",
      "568/568 [==============================] - 0s 55us/sample - loss: 2.4389 - mae: 1.2278 - mse: 2.4389 - val_loss: 13.2466 - val_mae: 2.2654 - val_mse: 13.2466\n",
      "Epoch 329/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.3851 - mae: 1.2110 - mse: 2.3851 - val_loss: 13.6354 - val_mae: 2.2842 - val_mse: 13.6354\n",
      "Epoch 330/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.3775 - mae: 1.2424 - mse: 2.3775 - val_loss: 14.2822 - val_mae: 2.2869 - val_mse: 14.2822\n",
      "Epoch 331/500\n",
      "568/568 [==============================] - 0s 62us/sample - loss: 2.3158 - mae: 1.2393 - mse: 2.3158 - val_loss: 13.3388 - val_mae: 2.3531 - val_mse: 13.3388\n",
      "Epoch 332/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.3552 - mae: 1.2251 - mse: 2.3552 - val_loss: 14.2780 - val_mae: 2.3174 - val_mse: 14.2780\n",
      "Epoch 333/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.9072 - mae: 1.3896 - mse: 2.9072 - val_loss: 13.3132 - val_mae: 2.1766 - val_mse: 13.3132\n",
      "Epoch 334/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.1173 - mae: 1.1694 - mse: 2.1173 - val_loss: 15.4142 - val_mae: 2.4709 - val_mse: 15.4142\n",
      "Epoch 335/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.1590 - mae: 1.1873 - mse: 2.1590 - val_loss: 14.0048 - val_mae: 2.2347 - val_mse: 14.0048\n",
      "Epoch 336/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.4751 - mae: 1.2788 - mse: 2.4751 - val_loss: 16.0228 - val_mae: 2.5719 - val_mse: 16.0228\n",
      "Epoch 337/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.7273 - mae: 1.3239 - mse: 2.7273 - val_loss: 12.8836 - val_mae: 2.2650 - val_mse: 12.8836\n",
      "Epoch 338/500\n",
      "568/568 [==============================] - 0s 55us/sample - loss: 2.1843 - mae: 1.1852 - mse: 2.1843 - val_loss: 14.3071 - val_mae: 2.5448 - val_mse: 14.3071\n",
      "Epoch 339/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.1079 - mae: 1.1576 - mse: 2.1079 - val_loss: 13.7633 - val_mae: 2.4099 - val_mse: 13.7633\n",
      "Epoch 340/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.4144 - mae: 1.2631 - mse: 2.4144 - val_loss: 13.1685 - val_mae: 2.2136 - val_mse: 13.1685\n",
      "Epoch 341/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.3638 - mae: 1.2298 - mse: 2.3638 - val_loss: 13.3233 - val_mae: 2.2249 - val_mse: 13.3233\n",
      "Epoch 342/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.4132 - mae: 1.2495 - mse: 2.4132 - val_loss: 12.8656 - val_mae: 2.2208 - val_mse: 12.8656\n",
      "Epoch 343/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.2308 - mae: 1.1883 - mse: 2.2308 - val_loss: 14.7511 - val_mae: 2.3888 - val_mse: 14.7511\n",
      "Epoch 344/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.2957 - mae: 1.2123 - mse: 2.2957 - val_loss: 13.2803 - val_mae: 2.1572 - val_mse: 13.2803\n",
      "Epoch 345/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.4202 - mae: 1.2679 - mse: 2.4202 - val_loss: 14.6055 - val_mae: 2.3186 - val_mse: 14.6055\n",
      "Epoch 346/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.4923 - mae: 1.2848 - mse: 2.4923 - val_loss: 13.5335 - val_mae: 2.1657 - val_mse: 13.5335\n",
      "Epoch 347/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.1338 - mae: 1.1597 - mse: 2.1338 - val_loss: 13.6293 - val_mae: 2.4299 - val_mse: 13.6293\n",
      "Epoch 348/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.6993 - mae: 1.3277 - mse: 2.6993 - val_loss: 14.3932 - val_mae: 2.3296 - val_mse: 14.3932\n",
      "Epoch 349/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.1995 - mae: 1.1961 - mse: 2.1995 - val_loss: 15.5232 - val_mae: 2.8179 - val_mse: 15.5232\n",
      "Epoch 350/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.5748 - mae: 1.2768 - mse: 2.5748 - val_loss: 13.3095 - val_mae: 2.3610 - val_mse: 13.3095\n",
      "Epoch 351/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.1329 - mae: 1.1614 - mse: 2.1329 - val_loss: 16.3210 - val_mae: 2.8306 - val_mse: 16.3210\n",
      "Epoch 352/500\n",
      "568/568 [==============================] - 0s 62us/sample - loss: 2.4484 - mae: 1.2421 - mse: 2.4484 - val_loss: 14.1740 - val_mae: 2.3032 - val_mse: 14.1740\n",
      "Epoch 353/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.0834 - mae: 1.1461 - mse: 2.0834 - val_loss: 13.6278 - val_mae: 2.4583 - val_mse: 13.6278\n",
      "Epoch 354/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.6631 - mae: 1.3182 - mse: 2.6631 - val_loss: 13.7790 - val_mae: 2.2450 - val_mse: 13.7790\n",
      "Epoch 355/500\n",
      "568/568 [==============================] - 0s 63us/sample - loss: 2.4968 - mae: 1.2867 - mse: 2.4968 - val_loss: 13.4109 - val_mae: 2.2735 - val_mse: 13.4109\n",
      "Epoch 356/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.3270 - mae: 1.2332 - mse: 2.3270 - val_loss: 13.6725 - val_mae: 2.2025 - val_mse: 13.6725\n",
      "Epoch 357/500\n",
      "568/568 [==============================] - 0s 60us/sample - loss: 2.4052 - mae: 1.2278 - mse: 2.4052 - val_loss: 13.3740 - val_mae: 2.3539 - val_mse: 13.3740\n",
      "Epoch 358/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.2664 - mae: 1.1914 - mse: 2.2664 - val_loss: 13.5001 - val_mae: 2.2422 - val_mse: 13.5001\n",
      "Epoch 359/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.2567 - mae: 1.2251 - mse: 2.2567 - val_loss: 13.5937 - val_mae: 2.3609 - val_mse: 13.5937\n",
      "Epoch 360/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.4471 - mae: 1.2845 - mse: 2.4471 - val_loss: 13.4194 - val_mae: 2.1622 - val_mse: 13.4194\n",
      "Epoch 361/500\n",
      "568/568 [==============================] - 0s 66us/sample - loss: 2.1489 - mae: 1.1883 - mse: 2.1489 - val_loss: 14.6393 - val_mae: 2.6529 - val_mse: 14.6393\n",
      "Epoch 362/500\n",
      "568/568 [==============================] - 0s 61us/sample - loss: 2.6850 - mae: 1.3165 - mse: 2.6850 - val_loss: 13.2332 - val_mae: 2.2944 - val_mse: 13.2332\n",
      "Epoch 363/500\n",
      "568/568 [==============================] - 0s 59us/sample - loss: 2.1335 - mae: 1.1558 - mse: 2.1335 - val_loss: 13.4074 - val_mae: 2.1591 - val_mse: 13.4074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.1854 - mae: 1.1734 - mse: 2.1854 - val_loss: 15.6415 - val_mae: 2.5907 - val_mse: 15.6415\n",
      "Epoch 365/500\n",
      "568/568 [==============================] - 0s 58us/sample - loss: 2.3687 - mae: 1.2342 - mse: 2.3687 - val_loss: 15.9274 - val_mae: 2.5753 - val_mse: 15.9274\n",
      "Epoch 366/500\n",
      "568/568 [==============================] - 0s 57us/sample - loss: 2.3576 - mae: 1.2349 - mse: 2.3576 - val_loss: 13.6113 - val_mae: 2.4349 - val_mse: 13.6113\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 649 samples, validate on 217 samples\n",
      "Epoch 1/500\n",
      "649/649 [==============================] - 0s 575us/sample - loss: 84.7864 - mae: 5.9362 - mse: 84.7864 - val_loss: 195.5609 - val_mae: 8.7527 - val_mse: 195.5609\n",
      "Epoch 2/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 56.9513 - mae: 4.9955 - mse: 56.9513 - val_loss: 197.6403 - val_mae: 8.4026 - val_mse: 197.6404\n",
      "Epoch 3/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 46.7917 - mae: 4.5104 - mse: 46.7917 - val_loss: 148.9522 - val_mae: 7.0491 - val_mse: 148.9522\n",
      "Epoch 4/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 37.3382 - mae: 4.0158 - mse: 37.3382 - val_loss: 122.5072 - val_mae: 6.6084 - val_mse: 122.5072\n",
      "Epoch 5/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 32.2855 - mae: 3.8404 - mse: 32.2855 - val_loss: 87.6283 - val_mae: 5.4072 - val_mse: 87.6283\n",
      "Epoch 6/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 27.3714 - mae: 3.6052 - mse: 27.3714 - val_loss: 85.3234 - val_mae: 6.3520 - val_mse: 85.3234\n",
      "Epoch 7/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 25.1122 - mae: 3.4875 - mse: 25.1122 - val_loss: 73.9711 - val_mae: 5.4465 - val_mse: 73.9711\n",
      "Epoch 8/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 23.4512 - mae: 3.3990 - mse: 23.4512 - val_loss: 70.1575 - val_mae: 6.1996 - val_mse: 70.1575\n",
      "Epoch 9/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 20.2771 - mae: 3.2170 - mse: 20.2771 - val_loss: 59.9363 - val_mae: 4.5743 - val_mse: 59.9363\n",
      "Epoch 10/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 18.8826 - mae: 3.0820 - mse: 18.8826 - val_loss: 53.4714 - val_mae: 4.3496 - val_mse: 53.4714\n",
      "Epoch 11/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 16.3820 - mae: 2.9130 - mse: 16.3820 - val_loss: 50.2269 - val_mae: 4.6176 - val_mse: 50.2269\n",
      "Epoch 12/500\n",
      "649/649 [==============================] - 0s 52us/sample - loss: 15.7615 - mae: 2.8572 - mse: 15.7615 - val_loss: 48.4212 - val_mae: 4.0438 - val_mse: 48.4212\n",
      "Epoch 13/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 13.6263 - mae: 2.6675 - mse: 13.6263 - val_loss: 46.3404 - val_mae: 4.5200 - val_mse: 46.3404\n",
      "Epoch 14/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 13.5250 - mae: 2.6921 - mse: 13.5250 - val_loss: 53.4431 - val_mae: 4.3648 - val_mse: 53.4431\n",
      "Epoch 15/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 13.4064 - mae: 2.7207 - mse: 13.4064 - val_loss: 50.4397 - val_mae: 4.4409 - val_mse: 50.4397\n",
      "Epoch 16/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 11.4944 - mae: 2.4861 - mse: 11.4944 - val_loss: 46.2782 - val_mae: 4.1977 - val_mse: 46.2782\n",
      "Epoch 17/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 11.1678 - mae: 2.4725 - mse: 11.1678 - val_loss: 39.2661 - val_mae: 3.5592 - val_mse: 39.2661\n",
      "Epoch 18/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 11.7786 - mae: 2.5617 - mse: 11.7786 - val_loss: 41.9277 - val_mae: 3.8365 - val_mse: 41.9277\n",
      "Epoch 19/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 10.0762 - mae: 2.3865 - mse: 10.0762 - val_loss: 37.2341 - val_mae: 3.5773 - val_mse: 37.2341\n",
      "Epoch 20/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 10.3098 - mae: 2.4494 - mse: 10.3098 - val_loss: 46.8170 - val_mae: 4.3036 - val_mse: 46.8170\n",
      "Epoch 21/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 8.5735 - mae: 2.2031 - mse: 8.5735 - val_loss: 37.4278 - val_mae: 3.7432 - val_mse: 37.4278\n",
      "Epoch 22/500\n",
      "649/649 [==============================] - 0s 60us/sample - loss: 9.8192 - mae: 2.4145 - mse: 9.8192 - val_loss: 36.6630 - val_mae: 4.1366 - val_mse: 36.6630\n",
      "Epoch 23/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 8.8082 - mae: 2.2614 - mse: 8.8082 - val_loss: 40.0542 - val_mae: 3.8858 - val_mse: 40.0542\n",
      "Epoch 24/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 9.0855 - mae: 2.3174 - mse: 9.0855 - val_loss: 34.9257 - val_mae: 3.3904 - val_mse: 34.9257\n",
      "Epoch 25/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 8.0573 - mae: 2.1787 - mse: 8.0573 - val_loss: 32.2492 - val_mae: 3.3664 - val_mse: 32.2492\n",
      "Epoch 26/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 8.4847 - mae: 2.2559 - mse: 8.4847 - val_loss: 43.0729 - val_mae: 4.3738 - val_mse: 43.0729\n",
      "Epoch 27/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 7.2452 - mae: 2.0370 - mse: 7.2452 - val_loss: 31.5590 - val_mae: 3.7245 - val_mse: 31.5590\n",
      "Epoch 28/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 8.7057 - mae: 2.2610 - mse: 8.7057 - val_loss: 30.3642 - val_mae: 3.3119 - val_mse: 30.3642\n",
      "Epoch 29/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 7.1665 - mae: 2.0259 - mse: 7.1665 - val_loss: 30.7432 - val_mae: 3.3579 - val_mse: 30.7432\n",
      "Epoch 30/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 7.3873 - mae: 2.0965 - mse: 7.3873 - val_loss: 33.0676 - val_mae: 4.1432 - val_mse: 33.0676\n",
      "Epoch 31/500\n",
      "649/649 [==============================] - 0s 53us/sample - loss: 7.5164 - mae: 2.1143 - mse: 7.5164 - val_loss: 35.0446 - val_mae: 3.6049 - val_mse: 35.0446\n",
      "Epoch 32/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 6.6670 - mae: 1.9753 - mse: 6.6670 - val_loss: 30.1961 - val_mae: 3.3092 - val_mse: 30.1961\n",
      "Epoch 33/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 7.3492 - mae: 2.0679 - mse: 7.3492 - val_loss: 29.2108 - val_mae: 3.6357 - val_mse: 29.2108\n",
      "Epoch 34/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 7.3442 - mae: 2.1340 - mse: 7.3442 - val_loss: 32.1413 - val_mae: 4.1414 - val_mse: 32.1413\n",
      "Epoch 35/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 5.9856 - mae: 1.8893 - mse: 5.9856 - val_loss: 28.7134 - val_mae: 3.6151 - val_mse: 28.7134\n",
      "Epoch 36/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 6.4093 - mae: 1.9490 - mse: 6.4093 - val_loss: 27.9406 - val_mae: 3.3967 - val_mse: 27.9406\n",
      "Epoch 37/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 7.2099 - mae: 2.1463 - mse: 7.2099 - val_loss: 28.5370 - val_mae: 3.2168 - val_mse: 28.5370\n",
      "Epoch 38/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 6.6483 - mae: 2.0070 - mse: 6.6483 - val_loss: 33.9001 - val_mae: 3.6695 - val_mse: 33.9002\n",
      "Epoch 39/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 7.0780 - mae: 2.0563 - mse: 7.0780 - val_loss: 29.0805 - val_mae: 3.7600 - val_mse: 29.0805\n",
      "Epoch 40/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 5.0265 - mae: 1.7312 - mse: 5.0265 - val_loss: 41.6867 - val_mae: 4.6986 - val_mse: 41.6867\n",
      "Epoch 41/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 6.4156 - mae: 1.9743 - mse: 6.4156 - val_loss: 34.7498 - val_mae: 3.8853 - val_mse: 34.7498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 6.1767 - mae: 1.9711 - mse: 6.1767 - val_loss: 31.2819 - val_mae: 4.2234 - val_mse: 31.2819\n",
      "Epoch 43/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 5.5572 - mae: 1.8545 - mse: 5.5572 - val_loss: 38.2406 - val_mae: 4.2712 - val_mse: 38.2406\n",
      "Epoch 44/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 7.0101 - mae: 2.1176 - mse: 7.0101 - val_loss: 26.9967 - val_mae: 2.9554 - val_mse: 26.9967\n",
      "Epoch 45/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 5.8396 - mae: 1.8856 - mse: 5.8396 - val_loss: 25.6224 - val_mae: 3.2926 - val_mse: 25.6224\n",
      "Epoch 46/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 6.0488 - mae: 1.9200 - mse: 6.0488 - val_loss: 25.6171 - val_mae: 3.2368 - val_mse: 25.6171\n",
      "Epoch 47/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 5.5935 - mae: 1.8497 - mse: 5.5935 - val_loss: 26.9531 - val_mae: 3.0735 - val_mse: 26.9531\n",
      "Epoch 48/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 6.2660 - mae: 2.0233 - mse: 6.2660 - val_loss: 26.4440 - val_mae: 3.4388 - val_mse: 26.4440\n",
      "Epoch 49/500\n",
      "649/649 [==============================] - 0s 53us/sample - loss: 5.9795 - mae: 1.9525 - mse: 5.9795 - val_loss: 25.0977 - val_mae: 3.0400 - val_mse: 25.0977\n",
      "Epoch 50/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 5.1256 - mae: 1.7529 - mse: 5.1256 - val_loss: 25.5888 - val_mae: 3.3520 - val_mse: 25.5888\n",
      "Epoch 51/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 5.4122 - mae: 1.8319 - mse: 5.4122 - val_loss: 24.4250 - val_mae: 2.8794 - val_mse: 24.4250\n",
      "Epoch 52/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 5.6899 - mae: 1.8915 - mse: 5.6899 - val_loss: 24.2271 - val_mae: 2.9661 - val_mse: 24.2271\n",
      "Epoch 53/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 5.7948 - mae: 1.9280 - mse: 5.7948 - val_loss: 23.5360 - val_mae: 2.7773 - val_mse: 23.5360\n",
      "Epoch 54/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 5.5502 - mae: 1.8696 - mse: 5.5502 - val_loss: 26.5403 - val_mae: 3.1320 - val_mse: 26.5403\n",
      "Epoch 55/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 5.2595 - mae: 1.7967 - mse: 5.2595 - val_loss: 30.8695 - val_mae: 3.7101 - val_mse: 30.8695\n",
      "Epoch 56/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 5.4739 - mae: 1.8543 - mse: 5.4739 - val_loss: 30.5221 - val_mae: 3.6208 - val_mse: 30.5221\n",
      "Epoch 57/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 5.6884 - mae: 1.9019 - mse: 5.6884 - val_loss: 25.1960 - val_mae: 3.3761 - val_mse: 25.1960\n",
      "Epoch 58/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 5.3879 - mae: 1.8718 - mse: 5.3879 - val_loss: 27.3234 - val_mae: 3.2596 - val_mse: 27.3234\n",
      "Epoch 59/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 4.9531 - mae: 1.7668 - mse: 4.9531 - val_loss: 25.2209 - val_mae: 3.3046 - val_mse: 25.2209\n",
      "Epoch 60/500\n",
      "649/649 [==============================] - 0s 76us/sample - loss: 5.5847 - mae: 1.8878 - mse: 5.5847 - val_loss: 28.7611 - val_mae: 3.4509 - val_mse: 28.7611\n",
      "Epoch 61/500\n",
      "649/649 [==============================] - 0s 87us/sample - loss: 4.9076 - mae: 1.7580 - mse: 4.9076 - val_loss: 24.5162 - val_mae: 2.8969 - val_mse: 24.5162\n",
      "Epoch 62/500\n",
      "649/649 [==============================] - 0s 85us/sample - loss: 5.2469 - mae: 1.8011 - mse: 5.2470 - val_loss: 29.1892 - val_mae: 3.5472 - val_mse: 29.1892\n",
      "Epoch 63/500\n",
      "649/649 [==============================] - 0s 105us/sample - loss: 4.7236 - mae: 1.7300 - mse: 4.7236 - val_loss: 24.0895 - val_mae: 3.0711 - val_mse: 24.0895\n",
      "Epoch 64/500\n",
      "649/649 [==============================] - 0s 87us/sample - loss: 5.0097 - mae: 1.7686 - mse: 5.0097 - val_loss: 24.1262 - val_mae: 2.8729 - val_mse: 24.1262\n",
      "Epoch 65/500\n",
      "649/649 [==============================] - 0s 93us/sample - loss: 5.6161 - mae: 1.8884 - mse: 5.6161 - val_loss: 23.4342 - val_mae: 3.1198 - val_mse: 23.4342\n",
      "Epoch 66/500\n",
      "649/649 [==============================] - 0s 92us/sample - loss: 5.1855 - mae: 1.8292 - mse: 5.1855 - val_loss: 26.5072 - val_mae: 3.3253 - val_mse: 26.5072\n",
      "Epoch 67/500\n",
      "649/649 [==============================] - 0s 67us/sample - loss: 5.0617 - mae: 1.7910 - mse: 5.0617 - val_loss: 24.1406 - val_mae: 2.9366 - val_mse: 24.1406\n",
      "Epoch 68/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 4.7509 - mae: 1.7231 - mse: 4.7509 - val_loss: 23.0660 - val_mae: 2.7724 - val_mse: 23.0660\n",
      "Epoch 69/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 5.0147 - mae: 1.7955 - mse: 5.0147 - val_loss: 22.9898 - val_mae: 3.1154 - val_mse: 22.9898\n",
      "Epoch 70/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 4.9165 - mae: 1.7631 - mse: 4.9165 - val_loss: 30.1400 - val_mae: 3.6642 - val_mse: 30.1400\n",
      "Epoch 71/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 4.7023 - mae: 1.7198 - mse: 4.7023 - val_loss: 23.2768 - val_mae: 3.0157 - val_mse: 23.2768\n",
      "Epoch 72/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 5.1698 - mae: 1.8493 - mse: 5.1698 - val_loss: 27.4223 - val_mae: 3.3700 - val_mse: 27.4223\n",
      "Epoch 73/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 4.7478 - mae: 1.7545 - mse: 4.7478 - val_loss: 22.2200 - val_mae: 2.8866 - val_mse: 22.2200\n",
      "Epoch 74/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 4.6348 - mae: 1.7275 - mse: 4.6348 - val_loss: 24.7332 - val_mae: 2.9814 - val_mse: 24.7332\n",
      "Epoch 75/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 4.9198 - mae: 1.7941 - mse: 4.9198 - val_loss: 21.7699 - val_mae: 2.8567 - val_mse: 21.7699\n",
      "Epoch 76/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 4.6933 - mae: 1.7562 - mse: 4.6933 - val_loss: 20.9116 - val_mae: 2.7243 - val_mse: 20.9116\n",
      "Epoch 77/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 4.5521 - mae: 1.6952 - mse: 4.5521 - val_loss: 20.8882 - val_mae: 2.6136 - val_mse: 20.8882\n",
      "Epoch 78/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 4.6536 - mae: 1.7202 - mse: 4.6536 - val_loss: 27.2601 - val_mae: 3.9425 - val_mse: 27.2601\n",
      "Epoch 79/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 4.3714 - mae: 1.6722 - mse: 4.3714 - val_loss: 24.1579 - val_mae: 3.0845 - val_mse: 24.1579\n",
      "Epoch 80/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 5.1145 - mae: 1.8133 - mse: 5.1145 - val_loss: 21.8880 - val_mae: 2.9861 - val_mse: 21.8880\n",
      "Epoch 81/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 4.4550 - mae: 1.6833 - mse: 4.4550 - val_loss: 21.0794 - val_mae: 2.7535 - val_mse: 21.0794\n",
      "Epoch 82/500\n",
      "649/649 [==============================] - 0s 63us/sample - loss: 4.8156 - mae: 1.7928 - mse: 4.8155 - val_loss: 21.5505 - val_mae: 2.6826 - val_mse: 21.5505\n",
      "Epoch 83/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 4.8755 - mae: 1.7692 - mse: 4.8755 - val_loss: 21.3175 - val_mae: 2.6827 - val_mse: 21.3175\n",
      "Epoch 84/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 4.7410 - mae: 1.7603 - mse: 4.7410 - val_loss: 21.4082 - val_mae: 2.6713 - val_mse: 21.4082\n",
      "Epoch 85/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 4.1850 - mae: 1.6201 - mse: 4.1850 - val_loss: 25.9042 - val_mae: 3.4311 - val_mse: 25.9042\n",
      "Epoch 86/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 4.5992 - mae: 1.7124 - mse: 4.5992 - val_loss: 28.6183 - val_mae: 4.1813 - val_mse: 28.6183\n",
      "Epoch 87/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 4.7065 - mae: 1.7060 - mse: 4.7065 - val_loss: 24.6030 - val_mae: 3.1613 - val_mse: 24.6030\n",
      "Epoch 88/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 4.5067 - mae: 1.7088 - mse: 4.5067 - val_loss: 20.0394 - val_mae: 2.6299 - val_mse: 20.0394\n",
      "Epoch 89/500\n",
      "649/649 [==============================] - 0s 60us/sample - loss: 4.6192 - mae: 1.7355 - mse: 4.6192 - val_loss: 23.6825 - val_mae: 3.0223 - val_mse: 23.6825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 4.7862 - mae: 1.7769 - mse: 4.7862 - val_loss: 23.0898 - val_mae: 3.2379 - val_mse: 23.0898\n",
      "Epoch 91/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 4.7941 - mae: 1.7701 - mse: 4.7941 - val_loss: 22.9950 - val_mae: 3.0381 - val_mse: 22.9950\n",
      "Epoch 92/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 4.4446 - mae: 1.7044 - mse: 4.4446 - val_loss: 18.9911 - val_mae: 2.4852 - val_mse: 18.9911\n",
      "Epoch 93/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 4.1161 - mae: 1.6105 - mse: 4.1161 - val_loss: 23.8178 - val_mae: 3.0505 - val_mse: 23.8178\n",
      "Epoch 94/500\n",
      "649/649 [==============================] - 0s 53us/sample - loss: 4.3595 - mae: 1.6704 - mse: 4.3595 - val_loss: 22.2781 - val_mae: 3.2850 - val_mse: 22.2781\n",
      "Epoch 95/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 4.9333 - mae: 1.8007 - mse: 4.9333 - val_loss: 21.1735 - val_mae: 2.7046 - val_mse: 21.1735\n",
      "Epoch 96/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 4.1898 - mae: 1.6519 - mse: 4.1898 - val_loss: 20.6359 - val_mae: 2.6542 - val_mse: 20.6359\n",
      "Epoch 97/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.9605 - mae: 1.5863 - mse: 3.9605 - val_loss: 19.0746 - val_mae: 2.5817 - val_mse: 19.0746\n",
      "Epoch 98/500\n",
      "649/649 [==============================] - 0s 53us/sample - loss: 4.5969 - mae: 1.7346 - mse: 4.5969 - val_loss: 26.3089 - val_mae: 3.5082 - val_mse: 26.3089\n",
      "Epoch 99/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 4.4199 - mae: 1.7107 - mse: 4.4199 - val_loss: 19.4473 - val_mae: 2.4966 - val_mse: 19.4473\n",
      "Epoch 100/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.9173 - mae: 1.5451 - mse: 3.9173 - val_loss: 23.2528 - val_mae: 3.2051 - val_mse: 23.2528\n",
      "Epoch 101/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 4.4806 - mae: 1.7122 - mse: 4.4806 - val_loss: 21.0035 - val_mae: 2.6939 - val_mse: 21.0035\n",
      "Epoch 102/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 4.3569 - mae: 1.6763 - mse: 4.3569 - val_loss: 21.8236 - val_mae: 2.8988 - val_mse: 21.8236\n",
      "Epoch 103/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 4.1118 - mae: 1.6416 - mse: 4.1118 - val_loss: 20.5972 - val_mae: 2.9251 - val_mse: 20.5972\n",
      "Epoch 104/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 4.2806 - mae: 1.6615 - mse: 4.2806 - val_loss: 18.6482 - val_mae: 2.4313 - val_mse: 18.6482\n",
      "Epoch 105/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.9260 - mae: 1.5335 - mse: 3.9260 - val_loss: 20.6356 - val_mae: 2.8107 - val_mse: 20.6356\n",
      "Epoch 106/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 4.0651 - mae: 1.6225 - mse: 4.0651 - val_loss: 21.2554 - val_mae: 2.9962 - val_mse: 21.2554\n",
      "Epoch 107/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 4.5883 - mae: 1.7677 - mse: 4.5883 - val_loss: 21.3162 - val_mae: 2.9287 - val_mse: 21.3162\n",
      "Epoch 108/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 4.6321 - mae: 1.7461 - mse: 4.6321 - val_loss: 18.4786 - val_mae: 2.4486 - val_mse: 18.4786\n",
      "Epoch 109/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.8814 - mae: 1.5808 - mse: 3.8814 - val_loss: 18.9899 - val_mae: 2.7230 - val_mse: 18.9899\n",
      "Epoch 110/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.9373 - mae: 1.5840 - mse: 3.9373 - val_loss: 23.8409 - val_mae: 3.5535 - val_mse: 23.8409\n",
      "Epoch 111/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 4.6434 - mae: 1.7496 - mse: 4.6434 - val_loss: 19.2194 - val_mae: 2.5558 - val_mse: 19.2194\n",
      "Epoch 112/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 4.0985 - mae: 1.6181 - mse: 4.0985 - val_loss: 22.4234 - val_mae: 3.0737 - val_mse: 22.4234\n",
      "Epoch 113/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.9950 - mae: 1.5919 - mse: 3.9950 - val_loss: 18.5949 - val_mae: 2.5186 - val_mse: 18.5949\n",
      "Epoch 114/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.4931 - mae: 1.4616 - mse: 3.4931 - val_loss: 17.4220 - val_mae: 2.3898 - val_mse: 17.4220\n",
      "Epoch 115/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 4.4810 - mae: 1.6662 - mse: 4.4810 - val_loss: 19.0225 - val_mae: 2.5708 - val_mse: 19.0225\n",
      "Epoch 116/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 4.2587 - mae: 1.6234 - mse: 4.2587 - val_loss: 17.8341 - val_mae: 2.4048 - val_mse: 17.8341\n",
      "Epoch 117/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.6310 - mae: 1.4877 - mse: 3.6310 - val_loss: 18.3885 - val_mae: 2.5301 - val_mse: 18.3885\n",
      "Epoch 118/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 3.7316 - mae: 1.5309 - mse: 3.7316 - val_loss: 17.3136 - val_mae: 2.4177 - val_mse: 17.3136\n",
      "Epoch 119/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.7868 - mae: 1.5277 - mse: 3.7868 - val_loss: 24.9161 - val_mae: 3.3704 - val_mse: 24.9161\n",
      "Epoch 120/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 4.3184 - mae: 1.6912 - mse: 4.3184 - val_loss: 24.3659 - val_mae: 3.4572 - val_mse: 24.3659\n",
      "Epoch 121/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.7822 - mae: 1.5664 - mse: 3.7822 - val_loss: 19.7467 - val_mae: 2.8962 - val_mse: 19.7467\n",
      "Epoch 122/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.9146 - mae: 1.5972 - mse: 3.9146 - val_loss: 17.3767 - val_mae: 2.3738 - val_mse: 17.3767\n",
      "Epoch 123/500\n",
      "649/649 [==============================] - 0s 53us/sample - loss: 3.6409 - mae: 1.5408 - mse: 3.6409 - val_loss: 24.9524 - val_mae: 3.8236 - val_mse: 24.9524\n",
      "Epoch 124/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 4.0144 - mae: 1.5942 - mse: 4.0144 - val_loss: 26.2562 - val_mae: 4.0852 - val_mse: 26.2562\n",
      "Epoch 125/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 3.6948 - mae: 1.5241 - mse: 3.6948 - val_loss: 17.2941 - val_mae: 2.4160 - val_mse: 17.2941\n",
      "Epoch 126/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 4.2643 - mae: 1.6636 - mse: 4.2643 - val_loss: 19.3419 - val_mae: 2.6406 - val_mse: 19.3419\n",
      "Epoch 127/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.8007 - mae: 1.5651 - mse: 3.8007 - val_loss: 17.4356 - val_mae: 2.3992 - val_mse: 17.4356\n",
      "Epoch 128/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.6634 - mae: 1.4945 - mse: 3.6634 - val_loss: 20.8718 - val_mae: 2.9581 - val_mse: 20.8718\n",
      "Epoch 129/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 4.5602 - mae: 1.7188 - mse: 4.5602 - val_loss: 17.5308 - val_mae: 2.5457 - val_mse: 17.5308\n",
      "Epoch 130/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.2929 - mae: 1.4381 - mse: 3.2929 - val_loss: 18.8818 - val_mae: 2.8373 - val_mse: 18.8818\n",
      "Epoch 131/500\n",
      "649/649 [==============================] - 0s 62us/sample - loss: 3.8355 - mae: 1.5749 - mse: 3.8355 - val_loss: 19.8768 - val_mae: 2.9382 - val_mse: 19.8769\n",
      "Epoch 132/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 3.8233 - mae: 1.5751 - mse: 3.8233 - val_loss: 16.8134 - val_mae: 2.3884 - val_mse: 16.8134\n",
      "Epoch 133/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.6376 - mae: 1.5301 - mse: 3.6376 - val_loss: 21.0816 - val_mae: 3.0200 - val_mse: 21.0816\n",
      "Epoch 134/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.8817 - mae: 1.5637 - mse: 3.8817 - val_loss: 19.5561 - val_mae: 2.8148 - val_mse: 19.5561\n",
      "Epoch 135/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.8414 - mae: 1.5802 - mse: 3.8414 - val_loss: 16.7979 - val_mae: 2.3492 - val_mse: 16.7979\n",
      "Epoch 136/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.9297 - mae: 1.6048 - mse: 3.9297 - val_loss: 16.8185 - val_mae: 2.4257 - val_mse: 16.8185\n",
      "Epoch 137/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.5155 - mae: 1.5202 - mse: 3.5155 - val_loss: 17.2723 - val_mae: 2.4280 - val_mse: 17.2723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.9857 - mae: 1.6279 - mse: 3.9857 - val_loss: 20.5720 - val_mae: 3.1901 - val_mse: 20.5720\n",
      "Epoch 139/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.4672 - mae: 1.4655 - mse: 3.4672 - val_loss: 17.4326 - val_mae: 2.5203 - val_mse: 17.4326\n",
      "Epoch 140/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.7941 - mae: 1.5559 - mse: 3.7941 - val_loss: 16.6888 - val_mae: 2.3776 - val_mse: 16.6888\n",
      "Epoch 141/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.9080 - mae: 1.5940 - mse: 3.9080 - val_loss: 21.3400 - val_mae: 2.8723 - val_mse: 21.3400\n",
      "Epoch 142/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.4369 - mae: 1.4842 - mse: 3.4369 - val_loss: 17.6736 - val_mae: 2.4717 - val_mse: 17.6736\n",
      "Epoch 143/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.5570 - mae: 1.4911 - mse: 3.5570 - val_loss: 20.9897 - val_mae: 3.0817 - val_mse: 20.9897\n",
      "Epoch 144/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 4.1183 - mae: 1.6152 - mse: 4.1183 - val_loss: 17.7960 - val_mae: 2.7184 - val_mse: 17.7959\n",
      "Epoch 145/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.9449 - mae: 1.5736 - mse: 3.9449 - val_loss: 16.9270 - val_mae: 2.4523 - val_mse: 16.9270\n",
      "Epoch 146/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.6695 - mae: 1.5329 - mse: 3.6695 - val_loss: 17.2336 - val_mae: 2.4682 - val_mse: 17.2336\n",
      "Epoch 147/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.3828 - mae: 1.4809 - mse: 3.3828 - val_loss: 20.3229 - val_mae: 3.3155 - val_mse: 20.3229\n",
      "Epoch 148/500\n",
      "649/649 [==============================] - 0s 60us/sample - loss: 4.3593 - mae: 1.7175 - mse: 4.3593 - val_loss: 16.0291 - val_mae: 2.2939 - val_mse: 16.0291\n",
      "Epoch 149/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.4779 - mae: 1.5039 - mse: 3.4779 - val_loss: 20.1720 - val_mae: 3.2510 - val_mse: 20.1720\n",
      "Epoch 150/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.7641 - mae: 1.3223 - mse: 2.7641 - val_loss: 16.6804 - val_mae: 2.5008 - val_mse: 16.6804\n",
      "Epoch 151/500\n",
      "649/649 [==============================] - 0s 53us/sample - loss: 3.5863 - mae: 1.5166 - mse: 3.5863 - val_loss: 16.4578 - val_mae: 2.4984 - val_mse: 16.4578\n",
      "Epoch 152/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.9528 - mae: 1.6137 - mse: 3.9528 - val_loss: 17.0022 - val_mae: 2.4298 - val_mse: 17.0022\n",
      "Epoch 153/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.9289 - mae: 1.6150 - mse: 3.9289 - val_loss: 17.2890 - val_mae: 2.6038 - val_mse: 17.2890\n",
      "Epoch 154/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.5505 - mae: 1.5046 - mse: 3.5505 - val_loss: 16.2274 - val_mae: 2.4574 - val_mse: 16.2274\n",
      "Epoch 155/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.4762 - mae: 1.5238 - mse: 3.4762 - val_loss: 16.8371 - val_mae: 2.5979 - val_mse: 16.8371\n",
      "Epoch 156/500\n",
      "649/649 [==============================] - 0s 53us/sample - loss: 3.4101 - mae: 1.4811 - mse: 3.4101 - val_loss: 18.0877 - val_mae: 2.8230 - val_mse: 18.0877\n",
      "Epoch 157/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 4.0018 - mae: 1.6133 - mse: 4.0018 - val_loss: 16.5452 - val_mae: 2.5946 - val_mse: 16.5452\n",
      "Epoch 158/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.3365 - mae: 1.4834 - mse: 3.3365 - val_loss: 17.8863 - val_mae: 2.7088 - val_mse: 17.8863\n",
      "Epoch 159/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.6251 - mae: 1.5195 - mse: 3.6251 - val_loss: 18.8520 - val_mae: 3.0323 - val_mse: 18.8520\n",
      "Epoch 160/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.5055 - mae: 1.5115 - mse: 3.5055 - val_loss: 19.5550 - val_mae: 3.0319 - val_mse: 19.5550\n",
      "Epoch 161/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 3.2111 - mae: 1.4190 - mse: 3.2111 - val_loss: 17.8666 - val_mae: 2.8201 - val_mse: 17.8666\n",
      "Epoch 162/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.6973 - mae: 1.5703 - mse: 3.6973 - val_loss: 16.8667 - val_mae: 2.3817 - val_mse: 16.8667\n",
      "Epoch 163/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.5108 - mae: 1.5420 - mse: 3.5108 - val_loss: 19.2338 - val_mae: 2.9779 - val_mse: 19.2338\n",
      "Epoch 164/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.3250 - mae: 1.4759 - mse: 3.3250 - val_loss: 17.1680 - val_mae: 2.6065 - val_mse: 17.1680\n",
      "Epoch 165/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 3.4436 - mae: 1.5035 - mse: 3.4436 - val_loss: 17.4124 - val_mae: 2.5059 - val_mse: 17.4124\n",
      "Epoch 166/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.2225 - mae: 1.4417 - mse: 3.2225 - val_loss: 17.2817 - val_mae: 2.5472 - val_mse: 17.2817\n",
      "Epoch 167/500\n",
      "649/649 [==============================] - 0s 60us/sample - loss: 3.8248 - mae: 1.5574 - mse: 3.8248 - val_loss: 16.9740 - val_mae: 2.5569 - val_mse: 16.9740\n",
      "Epoch 168/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 3.1441 - mae: 1.3965 - mse: 3.1441 - val_loss: 18.0994 - val_mae: 2.7857 - val_mse: 18.0994\n",
      "Epoch 169/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.7892 - mae: 1.5788 - mse: 3.7892 - val_loss: 14.9779 - val_mae: 2.2777 - val_mse: 14.9779\n",
      "Epoch 170/500\n",
      "649/649 [==============================] - 0s 61us/sample - loss: 3.0882 - mae: 1.4117 - mse: 3.0882 - val_loss: 14.8761 - val_mae: 2.3058 - val_mse: 14.8761\n",
      "Epoch 171/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 3.5832 - mae: 1.5406 - mse: 3.5832 - val_loss: 17.8766 - val_mae: 2.8214 - val_mse: 17.8766\n",
      "Epoch 172/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.3645 - mae: 1.4909 - mse: 3.3645 - val_loss: 17.1460 - val_mae: 2.7418 - val_mse: 17.1460\n",
      "Epoch 173/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.3434 - mae: 1.4710 - mse: 3.3434 - val_loss: 20.1591 - val_mae: 2.9335 - val_mse: 20.1591\n",
      "Epoch 174/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.7187 - mae: 1.5568 - mse: 3.7187 - val_loss: 15.9285 - val_mae: 2.3386 - val_mse: 15.9285\n",
      "Epoch 175/500\n",
      "649/649 [==============================] - 0s 53us/sample - loss: 3.4442 - mae: 1.5076 - mse: 3.4442 - val_loss: 15.1587 - val_mae: 2.2780 - val_mse: 15.1587\n",
      "Epoch 176/500\n",
      "649/649 [==============================] - 0s 60us/sample - loss: 3.3131 - mae: 1.4374 - mse: 3.3131 - val_loss: 17.3188 - val_mae: 2.6726 - val_mse: 17.3188\n",
      "Epoch 177/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.2419 - mae: 1.4394 - mse: 3.2419 - val_loss: 20.8058 - val_mae: 3.2054 - val_mse: 20.8058\n",
      "Epoch 178/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.9103 - mae: 1.6021 - mse: 3.9103 - val_loss: 15.9879 - val_mae: 2.4919 - val_mse: 15.9879\n",
      "Epoch 179/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.7415 - mae: 1.3081 - mse: 2.7415 - val_loss: 15.2897 - val_mae: 2.3386 - val_mse: 15.2897\n",
      "Epoch 180/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.2559 - mae: 1.4538 - mse: 3.2559 - val_loss: 16.6819 - val_mae: 2.6203 - val_mse: 16.6819\n",
      "Epoch 181/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 3.6434 - mae: 1.5344 - mse: 3.6434 - val_loss: 15.1970 - val_mae: 2.3665 - val_mse: 15.1970\n",
      "Epoch 182/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.1742 - mae: 1.4169 - mse: 3.1742 - val_loss: 16.4055 - val_mae: 2.6006 - val_mse: 16.4055\n",
      "Epoch 183/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.3729 - mae: 1.4792 - mse: 3.3729 - val_loss: 17.2656 - val_mae: 2.6709 - val_mse: 17.2656\n",
      "Epoch 184/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.0796 - mae: 1.4177 - mse: 3.0796 - val_loss: 19.9098 - val_mae: 2.9736 - val_mse: 19.9098\n",
      "Epoch 185/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.3606 - mae: 1.4833 - mse: 3.3606 - val_loss: 19.0395 - val_mae: 3.0166 - val_mse: 19.0395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 186/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 3.5573 - mae: 1.5204 - mse: 3.5573 - val_loss: 15.4459 - val_mae: 2.2900 - val_mse: 15.4459\n",
      "Epoch 187/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.1188 - mae: 1.3889 - mse: 3.1188 - val_loss: 16.3575 - val_mae: 2.6068 - val_mse: 16.3575\n",
      "Epoch 188/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.5284 - mae: 1.4944 - mse: 3.5284 - val_loss: 17.6636 - val_mae: 2.6063 - val_mse: 17.6636\n",
      "Epoch 189/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 3.0952 - mae: 1.3935 - mse: 3.0952 - val_loss: 18.7183 - val_mae: 2.8610 - val_mse: 18.7183\n",
      "Epoch 190/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.4758 - mae: 1.4931 - mse: 3.4758 - val_loss: 15.0135 - val_mae: 2.2248 - val_mse: 15.0135\n",
      "Epoch 191/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.0919 - mae: 1.4059 - mse: 3.0919 - val_loss: 17.1763 - val_mae: 2.7068 - val_mse: 17.1763\n",
      "Epoch 192/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.3049 - mae: 1.4353 - mse: 3.3049 - val_loss: 17.6971 - val_mae: 2.6429 - val_mse: 17.6971\n",
      "Epoch 193/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.4239 - mae: 1.4824 - mse: 3.4239 - val_loss: 14.6550 - val_mae: 2.1875 - val_mse: 14.6550\n",
      "Epoch 194/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.9971 - mae: 1.3960 - mse: 2.9971 - val_loss: 15.0959 - val_mae: 2.2359 - val_mse: 15.0959\n",
      "Epoch 195/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.3082 - mae: 1.4582 - mse: 3.3082 - val_loss: 16.5935 - val_mae: 2.6088 - val_mse: 16.5935\n",
      "Epoch 196/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.2471 - mae: 1.4621 - mse: 3.2471 - val_loss: 15.5341 - val_mae: 2.4414 - val_mse: 15.5341\n",
      "Epoch 197/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.1759 - mae: 1.4531 - mse: 3.1759 - val_loss: 16.9031 - val_mae: 2.5895 - val_mse: 16.9031\n",
      "Epoch 198/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.6137 - mae: 1.5503 - mse: 3.6137 - val_loss: 16.4319 - val_mae: 2.5713 - val_mse: 16.4319\n",
      "Epoch 199/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.8639 - mae: 1.3374 - mse: 2.8639 - val_loss: 19.0288 - val_mae: 3.1064 - val_mse: 19.0288\n",
      "Epoch 200/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.0692 - mae: 1.4019 - mse: 3.0692 - val_loss: 20.8637 - val_mae: 3.2711 - val_mse: 20.8637\n",
      "Epoch 201/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.1988 - mae: 1.4351 - mse: 3.1988 - val_loss: 14.5121 - val_mae: 2.1723 - val_mse: 14.5121\n",
      "Epoch 202/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.0318 - mae: 1.3823 - mse: 3.0318 - val_loss: 14.7622 - val_mae: 2.2784 - val_mse: 14.7622\n",
      "Epoch 203/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.4527 - mae: 1.5124 - mse: 3.4527 - val_loss: 15.3422 - val_mae: 2.3683 - val_mse: 15.3422\n",
      "Epoch 204/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.0042 - mae: 1.3754 - mse: 3.0042 - val_loss: 16.9461 - val_mae: 2.5875 - val_mse: 16.9461\n",
      "Epoch 205/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 3.2928 - mae: 1.4808 - mse: 3.2928 - val_loss: 16.9132 - val_mae: 2.6577 - val_mse: 16.9132\n",
      "Epoch 206/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 3.1201 - mae: 1.4062 - mse: 3.1201 - val_loss: 18.2358 - val_mae: 2.8222 - val_mse: 18.2358\n",
      "Epoch 207/500\n",
      "649/649 [==============================] - 0s 53us/sample - loss: 3.2151 - mae: 1.4387 - mse: 3.2151 - val_loss: 14.7484 - val_mae: 2.2215 - val_mse: 14.7484\n",
      "Epoch 208/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.1514 - mae: 1.4030 - mse: 3.1514 - val_loss: 16.7735 - val_mae: 2.6017 - val_mse: 16.7735\n",
      "Epoch 209/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.4319 - mae: 1.5053 - mse: 3.4319 - val_loss: 16.2381 - val_mae: 2.3615 - val_mse: 16.2381\n",
      "Epoch 210/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.2928 - mae: 1.4668 - mse: 3.2928 - val_loss: 15.2063 - val_mae: 2.2820 - val_mse: 15.2063\n",
      "Epoch 211/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.7842 - mae: 1.3260 - mse: 2.7842 - val_loss: 17.6242 - val_mae: 2.8029 - val_mse: 17.6242\n",
      "Epoch 212/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.4346 - mae: 1.2295 - mse: 2.4346 - val_loss: 22.8771 - val_mae: 3.7038 - val_mse: 22.8771\n",
      "Epoch 213/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.5703 - mae: 1.5134 - mse: 3.5703 - val_loss: 16.6981 - val_mae: 2.6568 - val_mse: 16.6981\n",
      "Epoch 214/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.0919 - mae: 1.4342 - mse: 3.0919 - val_loss: 16.0700 - val_mae: 2.4060 - val_mse: 16.0700\n",
      "Epoch 215/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.0996 - mae: 1.4119 - mse: 3.0996 - val_loss: 14.9385 - val_mae: 2.2289 - val_mse: 14.9385\n",
      "Epoch 216/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.9251 - mae: 1.3309 - mse: 2.9251 - val_loss: 15.8872 - val_mae: 2.3814 - val_mse: 15.8872\n",
      "Epoch 217/500\n",
      "649/649 [==============================] - 0s 60us/sample - loss: 3.2243 - mae: 1.4607 - mse: 3.2243 - val_loss: 15.6100 - val_mae: 2.4901 - val_mse: 15.6100\n",
      "Epoch 218/500\n",
      "649/649 [==============================] - 0s 60us/sample - loss: 3.3160 - mae: 1.4915 - mse: 3.3160 - val_loss: 15.4281 - val_mae: 2.2647 - val_mse: 15.4281\n",
      "Epoch 219/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 2.9224 - mae: 1.3942 - mse: 2.9224 - val_loss: 14.6435 - val_mae: 2.2344 - val_mse: 14.6435\n",
      "Epoch 220/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 3.3512 - mae: 1.4729 - mse: 3.3512 - val_loss: 14.5208 - val_mae: 2.2057 - val_mse: 14.5208\n",
      "Epoch 221/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.8233 - mae: 1.3448 - mse: 2.8233 - val_loss: 15.8911 - val_mae: 2.4876 - val_mse: 15.8911\n",
      "Epoch 222/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.1856 - mae: 1.4552 - mse: 3.1856 - val_loss: 18.5006 - val_mae: 2.9583 - val_mse: 18.5006\n",
      "Epoch 223/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.0833 - mae: 1.4004 - mse: 3.0833 - val_loss: 15.6662 - val_mae: 2.3520 - val_mse: 15.6662\n",
      "Epoch 224/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 2.9700 - mae: 1.3506 - mse: 2.9700 - val_loss: 15.7729 - val_mae: 2.4155 - val_mse: 15.7729\n",
      "Epoch 225/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.3844 - mae: 1.5076 - mse: 3.3844 - val_loss: 14.1788 - val_mae: 2.1932 - val_mse: 14.1788\n",
      "Epoch 226/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.9087 - mae: 1.3848 - mse: 2.9087 - val_loss: 14.3692 - val_mae: 2.2396 - val_mse: 14.3692\n",
      "Epoch 227/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.9173 - mae: 1.3629 - mse: 2.9173 - val_loss: 17.0424 - val_mae: 2.6300 - val_mse: 17.0424\n",
      "Epoch 228/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.5024 - mae: 1.5176 - mse: 3.5024 - val_loss: 15.6172 - val_mae: 2.4314 - val_mse: 15.6172\n",
      "Epoch 229/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.8678 - mae: 1.3627 - mse: 2.8678 - val_loss: 15.9307 - val_mae: 2.5988 - val_mse: 15.9307\n",
      "Epoch 230/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.2113 - mae: 1.4582 - mse: 3.2113 - val_loss: 14.5704 - val_mae: 2.1931 - val_mse: 14.5704\n",
      "Epoch 231/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.8334 - mae: 1.3585 - mse: 2.8334 - val_loss: 14.5624 - val_mae: 2.2248 - val_mse: 14.5624\n",
      "Epoch 232/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 2.8874 - mae: 1.3518 - mse: 2.8874 - val_loss: 15.2740 - val_mae: 2.4173 - val_mse: 15.2740\n",
      "Epoch 233/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 3.0425 - mae: 1.3965 - mse: 3.0425 - val_loss: 13.9640 - val_mae: 2.1033 - val_mse: 13.9640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.8760 - mae: 1.3416 - mse: 2.8760 - val_loss: 15.7483 - val_mae: 2.3840 - val_mse: 15.7483\n",
      "Epoch 235/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 2.9494 - mae: 1.3842 - mse: 2.9494 - val_loss: 16.2039 - val_mae: 2.4910 - val_mse: 16.2039\n",
      "Epoch 236/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.0264 - mae: 1.4040 - mse: 3.0264 - val_loss: 13.6339 - val_mae: 2.0774 - val_mse: 13.6339\n",
      "Epoch 237/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.8961 - mae: 1.3496 - mse: 2.8961 - val_loss: 19.0371 - val_mae: 3.0652 - val_mse: 19.0371\n",
      "Epoch 238/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.3824 - mae: 1.2319 - mse: 2.3824 - val_loss: 17.4039 - val_mae: 2.7611 - val_mse: 17.4039\n",
      "Epoch 239/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.3789 - mae: 1.4827 - mse: 3.3789 - val_loss: 17.9403 - val_mae: 2.9413 - val_mse: 17.9403\n",
      "Epoch 240/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.8761 - mae: 1.3547 - mse: 2.8761 - val_loss: 14.8899 - val_mae: 2.3194 - val_mse: 14.8899\n",
      "Epoch 241/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.9669 - mae: 1.3839 - mse: 2.9669 - val_loss: 20.9987 - val_mae: 3.1226 - val_mse: 20.9987\n",
      "Epoch 242/500\n",
      "649/649 [==============================] - 0s 52us/sample - loss: 3.1260 - mae: 1.3944 - mse: 3.1260 - val_loss: 17.2217 - val_mae: 2.5915 - val_mse: 17.2217\n",
      "Epoch 243/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.0959 - mae: 1.4315 - mse: 3.0959 - val_loss: 14.5747 - val_mae: 2.1872 - val_mse: 14.5747\n",
      "Epoch 244/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 2.9700 - mae: 1.3963 - mse: 2.9700 - val_loss: 14.5993 - val_mae: 2.2291 - val_mse: 14.5993\n",
      "Epoch 245/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.5274 - mae: 1.2858 - mse: 2.5274 - val_loss: 14.6614 - val_mae: 2.3057 - val_mse: 14.6614\n",
      "Epoch 246/500\n",
      "649/649 [==============================] - 0s 63us/sample - loss: 2.8172 - mae: 1.3256 - mse: 2.8172 - val_loss: 15.6518 - val_mae: 2.5276 - val_mse: 15.6518\n",
      "Epoch 247/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.2891 - mae: 1.4722 - mse: 3.2891 - val_loss: 14.5289 - val_mae: 2.3189 - val_mse: 14.5289\n",
      "Epoch 248/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.8584 - mae: 1.3489 - mse: 2.8584 - val_loss: 18.3525 - val_mae: 2.9941 - val_mse: 18.3525\n",
      "Epoch 249/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.9432 - mae: 1.3807 - mse: 2.9432 - val_loss: 18.8774 - val_mae: 3.0158 - val_mse: 18.8774\n",
      "Epoch 250/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 3.3254 - mae: 1.4735 - mse: 3.3254 - val_loss: 15.1866 - val_mae: 2.3762 - val_mse: 15.1866\n",
      "Epoch 251/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 2.9055 - mae: 1.3849 - mse: 2.9055 - val_loss: 14.2561 - val_mae: 2.1545 - val_mse: 14.2561\n",
      "Epoch 252/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.0430 - mae: 1.4115 - mse: 3.0430 - val_loss: 19.3658 - val_mae: 3.1442 - val_mse: 19.3658\n",
      "Epoch 253/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.9962 - mae: 1.3700 - mse: 2.9962 - val_loss: 13.9220 - val_mae: 2.0950 - val_mse: 13.9220\n",
      "Epoch 254/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.6588 - mae: 1.2907 - mse: 2.6588 - val_loss: 14.1706 - val_mae: 2.1461 - val_mse: 14.1706\n",
      "Epoch 255/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.0266 - mae: 1.3797 - mse: 3.0266 - val_loss: 15.9614 - val_mae: 2.5165 - val_mse: 15.9614\n",
      "Epoch 256/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.7851 - mae: 1.3362 - mse: 2.7851 - val_loss: 17.1588 - val_mae: 2.6309 - val_mse: 17.1588\n",
      "Epoch 257/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.6303 - mae: 1.2966 - mse: 2.6303 - val_loss: 14.9365 - val_mae: 2.3507 - val_mse: 14.9365\n",
      "Epoch 258/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 3.2179 - mae: 1.4442 - mse: 3.2179 - val_loss: 14.5365 - val_mae: 2.2452 - val_mse: 14.5365\n",
      "Epoch 259/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.9213 - mae: 1.3758 - mse: 2.9213 - val_loss: 14.8543 - val_mae: 2.2291 - val_mse: 14.8543\n",
      "Epoch 260/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.8753 - mae: 1.3701 - mse: 2.8753 - val_loss: 13.5563 - val_mae: 2.0926 - val_mse: 13.5563\n",
      "Epoch 261/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.5168 - mae: 1.2726 - mse: 2.5168 - val_loss: 13.9877 - val_mae: 2.2596 - val_mse: 13.9877\n",
      "Epoch 262/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 3.1904 - mae: 1.4164 - mse: 3.1904 - val_loss: 14.4869 - val_mae: 2.2222 - val_mse: 14.4869\n",
      "Epoch 263/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.8925 - mae: 1.3759 - mse: 2.8925 - val_loss: 15.0902 - val_mae: 2.3251 - val_mse: 15.0902\n",
      "Epoch 264/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 2.8742 - mae: 1.3627 - mse: 2.8742 - val_loss: 14.7001 - val_mae: 2.2966 - val_mse: 14.7001\n",
      "Epoch 265/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.6620 - mae: 1.3236 - mse: 2.6620 - val_loss: 14.1091 - val_mae: 2.1291 - val_mse: 14.1091\n",
      "Epoch 266/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 2.8836 - mae: 1.3692 - mse: 2.8836 - val_loss: 13.9731 - val_mae: 2.1287 - val_mse: 13.9731\n",
      "Epoch 267/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.6759 - mae: 1.2956 - mse: 2.6759 - val_loss: 17.9868 - val_mae: 2.9382 - val_mse: 17.9868\n",
      "Epoch 268/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.9791 - mae: 1.3914 - mse: 2.9790 - val_loss: 17.6701 - val_mae: 2.9245 - val_mse: 17.6701\n",
      "Epoch 269/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 3.1410 - mae: 1.4155 - mse: 3.1410 - val_loss: 15.0035 - val_mae: 2.2854 - val_mse: 15.0035\n",
      "Epoch 270/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 2.7254 - mae: 1.3264 - mse: 2.7254 - val_loss: 17.1383 - val_mae: 2.5934 - val_mse: 17.1383\n",
      "Epoch 271/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.7036 - mae: 1.3146 - mse: 2.7036 - val_loss: 15.6309 - val_mae: 2.4989 - val_mse: 15.6309\n",
      "Epoch 272/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.6188 - mae: 1.2793 - mse: 2.6188 - val_loss: 15.2789 - val_mae: 2.4572 - val_mse: 15.2789\n",
      "Epoch 273/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 3.1502 - mae: 1.4172 - mse: 3.1502 - val_loss: 15.4208 - val_mae: 2.3841 - val_mse: 15.4208\n",
      "Epoch 274/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.6804 - mae: 1.3172 - mse: 2.6804 - val_loss: 14.6987 - val_mae: 2.2456 - val_mse: 14.6987\n",
      "Epoch 275/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.8979 - mae: 1.3491 - mse: 2.8979 - val_loss: 13.5349 - val_mae: 2.0756 - val_mse: 13.5349\n",
      "Epoch 276/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 2.7898 - mae: 1.3363 - mse: 2.7898 - val_loss: 15.3770 - val_mae: 2.3235 - val_mse: 15.3770\n",
      "Epoch 277/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 2.7379 - mae: 1.3188 - mse: 2.7379 - val_loss: 14.4725 - val_mae: 2.2751 - val_mse: 14.4725\n",
      "Epoch 278/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.7868 - mae: 1.3212 - mse: 2.7868 - val_loss: 16.1148 - val_mae: 2.5969 - val_mse: 16.1148\n",
      "Epoch 279/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.6838 - mae: 1.2983 - mse: 2.6838 - val_loss: 13.9715 - val_mae: 2.1935 - val_mse: 13.9715\n",
      "Epoch 280/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.5047 - mae: 1.2556 - mse: 2.5047 - val_loss: 14.2226 - val_mae: 2.1844 - val_mse: 14.2226\n",
      "Epoch 281/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.7089 - mae: 1.3125 - mse: 2.7089 - val_loss: 14.5922 - val_mae: 2.2025 - val_mse: 14.5922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 3.3742 - mae: 1.4721 - mse: 3.3742 - val_loss: 15.4110 - val_mae: 2.3426 - val_mse: 15.4110\n",
      "Epoch 283/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.5363 - mae: 1.2684 - mse: 2.5363 - val_loss: 14.8145 - val_mae: 2.3043 - val_mse: 14.8145\n",
      "Epoch 284/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.7519 - mae: 1.3481 - mse: 2.7519 - val_loss: 17.3658 - val_mae: 2.7637 - val_mse: 17.3658\n",
      "Epoch 285/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.9050 - mae: 1.3694 - mse: 2.9050 - val_loss: 14.1801 - val_mae: 2.1660 - val_mse: 14.1801\n",
      "Epoch 286/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.6661 - mae: 1.3089 - mse: 2.6661 - val_loss: 15.1896 - val_mae: 2.3641 - val_mse: 15.1896\n",
      "Epoch 287/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.5301 - mae: 1.2771 - mse: 2.5301 - val_loss: 16.3945 - val_mae: 2.6687 - val_mse: 16.3945\n",
      "Epoch 288/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.9315 - mae: 1.3640 - mse: 2.9315 - val_loss: 13.7170 - val_mae: 2.0900 - val_mse: 13.7170\n",
      "Epoch 289/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.6581 - mae: 1.3027 - mse: 2.6581 - val_loss: 20.8719 - val_mae: 3.1256 - val_mse: 20.8719\n",
      "Epoch 290/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 2.5557 - mae: 1.2555 - mse: 2.5557 - val_loss: 15.8019 - val_mae: 2.5479 - val_mse: 15.8019\n",
      "Epoch 291/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.9373 - mae: 1.3734 - mse: 2.9373 - val_loss: 14.2887 - val_mae: 2.1842 - val_mse: 14.2887\n",
      "Epoch 292/500\n",
      "649/649 [==============================] - 0s 60us/sample - loss: 2.9940 - mae: 1.3908 - mse: 2.9940 - val_loss: 17.0343 - val_mae: 2.7227 - val_mse: 17.0343\n",
      "Epoch 293/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 2.7129 - mae: 1.3317 - mse: 2.7129 - val_loss: 15.3026 - val_mae: 2.4841 - val_mse: 15.3026\n",
      "Epoch 294/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 2.6808 - mae: 1.2739 - mse: 2.6808 - val_loss: 13.9296 - val_mae: 2.1190 - val_mse: 13.9296\n",
      "Epoch 295/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.3275 - mae: 1.2162 - mse: 2.3275 - val_loss: 19.6326 - val_mae: 3.0834 - val_mse: 19.6326\n",
      "Epoch 296/500\n",
      "649/649 [==============================] - 0s 60us/sample - loss: 3.0409 - mae: 1.3783 - mse: 3.0409 - val_loss: 13.2049 - val_mae: 2.0518 - val_mse: 13.2049\n",
      "Epoch 297/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.6965 - mae: 1.3368 - mse: 2.6965 - val_loss: 14.9230 - val_mae: 2.2405 - val_mse: 14.9230\n",
      "Epoch 298/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.3739 - mae: 1.2198 - mse: 2.3739 - val_loss: 16.3232 - val_mae: 2.6435 - val_mse: 16.3232\n",
      "Epoch 299/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.9232 - mae: 1.3970 - mse: 2.9232 - val_loss: 17.5135 - val_mae: 2.7521 - val_mse: 17.5135\n",
      "Epoch 300/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.4843 - mae: 1.2779 - mse: 2.4843 - val_loss: 16.0667 - val_mae: 2.5146 - val_mse: 16.0667\n",
      "Epoch 301/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 2.7782 - mae: 1.3354 - mse: 2.7782 - val_loss: 14.0370 - val_mae: 2.1589 - val_mse: 14.0370\n",
      "Epoch 302/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.8769 - mae: 1.3648 - mse: 2.8769 - val_loss: 16.3196 - val_mae: 2.4842 - val_mse: 16.3196\n",
      "Epoch 303/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.4366 - mae: 1.2596 - mse: 2.4366 - val_loss: 16.0815 - val_mae: 2.5725 - val_mse: 16.0815\n",
      "Epoch 304/500\n",
      "649/649 [==============================] - 0s 62us/sample - loss: 2.6016 - mae: 1.2836 - mse: 2.6016 - val_loss: 14.2397 - val_mae: 2.2051 - val_mse: 14.2397\n",
      "Epoch 305/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 2.7253 - mae: 1.3397 - mse: 2.7253 - val_loss: 15.7811 - val_mae: 2.4712 - val_mse: 15.7811\n",
      "Epoch 306/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.6444 - mae: 1.3093 - mse: 2.6444 - val_loss: 14.5177 - val_mae: 2.2893 - val_mse: 14.5177\n",
      "Epoch 307/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.6053 - mae: 1.2723 - mse: 2.6053 - val_loss: 14.3877 - val_mae: 2.2232 - val_mse: 14.3877\n",
      "Epoch 308/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.5389 - mae: 1.2734 - mse: 2.5389 - val_loss: 14.0343 - val_mae: 2.2130 - val_mse: 14.0343\n",
      "Epoch 309/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.4819 - mae: 1.2605 - mse: 2.4819 - val_loss: 18.5324 - val_mae: 3.0037 - val_mse: 18.5324\n",
      "Epoch 310/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.8693 - mae: 1.3686 - mse: 2.8693 - val_loss: 15.1206 - val_mae: 2.3265 - val_mse: 15.1206\n",
      "Epoch 311/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 2.2079 - mae: 1.1704 - mse: 2.2079 - val_loss: 17.5880 - val_mae: 2.7892 - val_mse: 17.5880\n",
      "Epoch 312/500\n",
      "649/649 [==============================] - 0s 60us/sample - loss: 2.5888 - mae: 1.2757 - mse: 2.5888 - val_loss: 19.8456 - val_mae: 3.1784 - val_mse: 19.8456\n",
      "Epoch 313/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.7843 - mae: 1.3254 - mse: 2.7843 - val_loss: 16.0938 - val_mae: 2.6036 - val_mse: 16.0938\n",
      "Epoch 314/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.4103 - mae: 1.2248 - mse: 2.4103 - val_loss: 16.8253 - val_mae: 2.7210 - val_mse: 16.8253\n",
      "Epoch 315/500\n",
      "649/649 [==============================] - 0s 62us/sample - loss: 2.6483 - mae: 1.3117 - mse: 2.6483 - val_loss: 16.4183 - val_mae: 2.6452 - val_mse: 16.4183\n",
      "Epoch 316/500\n",
      "649/649 [==============================] - 0s 77us/sample - loss: 2.6314 - mae: 1.2813 - mse: 2.6314 - val_loss: 14.0501 - val_mae: 2.1626 - val_mse: 14.0501\n",
      "Epoch 317/500\n",
      "649/649 [==============================] - 0s 69us/sample - loss: 2.3487 - mae: 1.2542 - mse: 2.3487 - val_loss: 14.0015 - val_mae: 2.1244 - val_mse: 14.0015\n",
      "Epoch 318/500\n",
      "649/649 [==============================] - 0s 67us/sample - loss: 2.7345 - mae: 1.3042 - mse: 2.7345 - val_loss: 15.8582 - val_mae: 2.5428 - val_mse: 15.8582\n",
      "Epoch 319/500\n",
      "649/649 [==============================] - 0s 65us/sample - loss: 2.6662 - mae: 1.3153 - mse: 2.6662 - val_loss: 14.6193 - val_mae: 2.2406 - val_mse: 14.6193\n",
      "Epoch 320/500\n",
      "649/649 [==============================] - 0s 74us/sample - loss: 2.3290 - mae: 1.2165 - mse: 2.3290 - val_loss: 14.8583 - val_mae: 2.3667 - val_mse: 14.8583\n",
      "Epoch 321/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.4218 - mae: 1.2489 - mse: 2.4218 - val_loss: 14.0283 - val_mae: 2.1007 - val_mse: 14.0283\n",
      "Epoch 322/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.9747 - mae: 1.3612 - mse: 2.9747 - val_loss: 14.0869 - val_mae: 2.1421 - val_mse: 14.0869\n",
      "Epoch 323/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.6488 - mae: 1.2938 - mse: 2.6488 - val_loss: 15.5828 - val_mae: 2.4393 - val_mse: 15.5828\n",
      "Epoch 324/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 1.8855 - mae: 1.0793 - mse: 1.8855 - val_loss: 14.1586 - val_mae: 2.1389 - val_mse: 14.1586\n",
      "Epoch 325/500\n",
      "649/649 [==============================] - 0s 58us/sample - loss: 2.8846 - mae: 1.3433 - mse: 2.8846 - val_loss: 15.4953 - val_mae: 2.3911 - val_mse: 15.4953\n",
      "Epoch 326/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.3263 - mae: 1.2388 - mse: 2.3263 - val_loss: 16.8376 - val_mae: 2.5927 - val_mse: 16.8376\n",
      "Epoch 327/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 2.6743 - mae: 1.3134 - mse: 2.6743 - val_loss: 13.7436 - val_mae: 2.1228 - val_mse: 13.7436\n",
      "Epoch 328/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.5410 - mae: 1.2882 - mse: 2.5410 - val_loss: 15.5124 - val_mae: 2.4645 - val_mse: 15.5124\n",
      "Epoch 329/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.2834 - mae: 1.2159 - mse: 2.2834 - val_loss: 15.0226 - val_mae: 2.3464 - val_mse: 15.0226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.5499 - mae: 1.2770 - mse: 2.5499 - val_loss: 17.9816 - val_mae: 2.9185 - val_mse: 17.9816\n",
      "Epoch 331/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 2.7931 - mae: 1.3282 - mse: 2.7931 - val_loss: 14.2990 - val_mae: 2.2273 - val_mse: 14.2990\n",
      "Epoch 332/500\n",
      "649/649 [==============================] - 0s 61us/sample - loss: 2.3665 - mae: 1.2180 - mse: 2.3665 - val_loss: 13.8634 - val_mae: 2.1733 - val_mse: 13.8634\n",
      "Epoch 333/500\n",
      "649/649 [==============================] - 0s 68us/sample - loss: 2.4028 - mae: 1.2551 - mse: 2.4028 - val_loss: 16.7098 - val_mae: 2.6954 - val_mse: 16.7098\n",
      "Epoch 334/500\n",
      "649/649 [==============================] - 0s 82us/sample - loss: 2.4467 - mae: 1.2554 - mse: 2.4467 - val_loss: 15.4069 - val_mae: 2.4386 - val_mse: 15.4069\n",
      "Epoch 335/500\n",
      "649/649 [==============================] - 0s 76us/sample - loss: 2.4497 - mae: 1.2509 - mse: 2.4497 - val_loss: 20.4796 - val_mae: 3.3226 - val_mse: 20.4796\n",
      "Epoch 336/500\n",
      "649/649 [==============================] - 0s 66us/sample - loss: 2.4480 - mae: 1.2332 - mse: 2.4480 - val_loss: 20.5261 - val_mae: 3.2598 - val_mse: 20.5261\n",
      "Epoch 337/500\n",
      "649/649 [==============================] - 0s 65us/sample - loss: 2.4204 - mae: 1.2183 - mse: 2.4204 - val_loss: 14.7756 - val_mae: 2.3111 - val_mse: 14.7756\n",
      "Epoch 338/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.8224 - mae: 1.3550 - mse: 2.8224 - val_loss: 14.5209 - val_mae: 2.1980 - val_mse: 14.5209\n",
      "Epoch 339/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.1332 - mae: 1.1635 - mse: 2.1332 - val_loss: 19.5678 - val_mae: 3.1501 - val_mse: 19.5678\n",
      "Epoch 340/500\n",
      "649/649 [==============================] - 0s 59us/sample - loss: 2.7204 - mae: 1.3209 - mse: 2.7204 - val_loss: 14.6390 - val_mae: 2.3215 - val_mse: 14.6390\n",
      "Epoch 341/500\n",
      "649/649 [==============================] - 0s 60us/sample - loss: 2.4592 - mae: 1.2711 - mse: 2.4592 - val_loss: 14.9015 - val_mae: 2.3831 - val_mse: 14.9015\n",
      "Epoch 342/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.2964 - mae: 1.2007 - mse: 2.2964 - val_loss: 13.9126 - val_mae: 2.1377 - val_mse: 13.9126\n",
      "Epoch 343/500\n",
      "649/649 [==============================] - 0s 57us/sample - loss: 2.4652 - mae: 1.2449 - mse: 2.4652 - val_loss: 15.1205 - val_mae: 2.4259 - val_mse: 15.1205\n",
      "Epoch 344/500\n",
      "649/649 [==============================] - 0s 55us/sample - loss: 2.5330 - mae: 1.2752 - mse: 2.5330 - val_loss: 13.3908 - val_mae: 2.1070 - val_mse: 13.3908\n",
      "Epoch 345/500\n",
      "649/649 [==============================] - 0s 56us/sample - loss: 2.4684 - mae: 1.2468 - mse: 2.4684 - val_loss: 14.5707 - val_mae: 2.2412 - val_mse: 14.5707\n",
      "Epoch 346/500\n",
      "649/649 [==============================] - 0s 54us/sample - loss: 2.3804 - mae: 1.2420 - mse: 2.3804 - val_loss: 14.7014 - val_mae: 2.2748 - val_mse: 14.7014\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 731 samples, validate on 244 samples\n",
      "Epoch 1/500\n",
      "731/731 [==============================] - 1s 808us/sample - loss: 118.4971 - mae: 8.2401 - mse: 118.4971 - val_loss: 163.8529 - val_mae: 8.7742 - val_mse: 163.8529\n",
      "Epoch 2/500\n",
      "731/731 [==============================] - 0s 79us/sample - loss: 65.7770 - mae: 6.0970 - mse: 65.7770 - val_loss: 127.3867 - val_mae: 7.2754 - val_mse: 127.3867\n",
      "Epoch 3/500\n",
      "731/731 [==============================] - 0s 75us/sample - loss: 46.9947 - mae: 5.0237 - mse: 46.9947 - val_loss: 104.9170 - val_mae: 5.8523 - val_mse: 104.9170\n",
      "Epoch 4/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 37.3172 - mae: 4.3762 - mse: 37.3172 - val_loss: 101.1221 - val_mae: 5.8040 - val_mse: 101.1221\n",
      "Epoch 5/500\n",
      "731/731 [==============================] - 0s 51us/sample - loss: 30.7958 - mae: 3.9932 - mse: 30.7958 - val_loss: 89.7222 - val_mae: 5.3924 - val_mse: 89.7222\n",
      "Epoch 6/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 27.3579 - mae: 3.7448 - mse: 27.3579 - val_loss: 80.4407 - val_mae: 5.1197 - val_mse: 80.4407\n",
      "Epoch 7/500\n",
      "731/731 [==============================] - 0s 51us/sample - loss: 23.5495 - mae: 3.5522 - mse: 23.5495 - val_loss: 76.8944 - val_mae: 5.1880 - val_mse: 76.8944\n",
      "Epoch 8/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 20.0622 - mae: 3.2552 - mse: 20.0622 - val_loss: 61.9902 - val_mae: 4.3689 - val_mse: 61.9902\n",
      "Epoch 9/500\n",
      "731/731 [==============================] - 0s 57us/sample - loss: 19.1615 - mae: 3.1656 - mse: 19.1615 - val_loss: 80.5073 - val_mae: 6.0068 - val_mse: 80.5073\n",
      "Epoch 10/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 18.7640 - mae: 3.2028 - mse: 18.7640 - val_loss: 59.3800 - val_mae: 4.6395 - val_mse: 59.3800\n",
      "Epoch 11/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 17.1293 - mae: 3.0778 - mse: 17.1293 - val_loss: 55.9795 - val_mae: 4.4457 - val_mse: 55.9795\n",
      "Epoch 12/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 15.7240 - mae: 2.9892 - mse: 15.7240 - val_loss: 47.5755 - val_mae: 3.8689 - val_mse: 47.5755\n",
      "Epoch 13/500\n",
      "731/731 [==============================] - 0s 83us/sample - loss: 14.1900 - mae: 2.8149 - mse: 14.1900 - val_loss: 44.3484 - val_mae: 3.9158 - val_mse: 44.3484\n",
      "Epoch 14/500\n",
      "731/731 [==============================] - 0s 66us/sample - loss: 14.5302 - mae: 2.8441 - mse: 14.5302 - val_loss: 41.6779 - val_mae: 3.9694 - val_mse: 41.6779\n",
      "Epoch 15/500\n",
      "731/731 [==============================] - 0s 61us/sample - loss: 13.9887 - mae: 2.8371 - mse: 13.9887 - val_loss: 39.0440 - val_mae: 3.5761 - val_mse: 39.0440\n",
      "Epoch 16/500\n",
      "731/731 [==============================] - 0s 68us/sample - loss: 11.7743 - mae: 2.5631 - mse: 11.7743 - val_loss: 38.7500 - val_mae: 3.8583 - val_mse: 38.7500\n",
      "Epoch 17/500\n",
      "731/731 [==============================] - 0s 70us/sample - loss: 11.3612 - mae: 2.5587 - mse: 11.3612 - val_loss: 36.5030 - val_mae: 3.3993 - val_mse: 36.5030\n",
      "Epoch 18/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 11.3471 - mae: 2.5489 - mse: 11.3471 - val_loss: 35.0326 - val_mae: 3.7242 - val_mse: 35.0326\n",
      "Epoch 19/500\n",
      "731/731 [==============================] - 0s 50us/sample - loss: 10.6939 - mae: 2.4929 - mse: 10.6939 - val_loss: 34.2419 - val_mae: 3.4180 - val_mse: 34.2419\n",
      "Epoch 20/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 10.3151 - mae: 2.4620 - mse: 10.3151 - val_loss: 34.6177 - val_mae: 3.9701 - val_mse: 34.6177\n",
      "Epoch 21/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 10.0213 - mae: 2.4326 - mse: 10.0213 - val_loss: 38.0046 - val_mae: 4.0352 - val_mse: 38.0046\n",
      "Epoch 22/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 9.4801 - mae: 2.3580 - mse: 9.4801 - val_loss: 29.6451 - val_mae: 3.3381 - val_mse: 29.6451\n",
      "Epoch 23/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 8.6618 - mae: 2.2644 - mse: 8.6617 - val_loss: 28.5034 - val_mae: 3.0633 - val_mse: 28.5034\n",
      "Epoch 24/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 9.1976 - mae: 2.3244 - mse: 9.1976 - val_loss: 27.5124 - val_mae: 3.2584 - val_mse: 27.5124\n",
      "Epoch 25/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 8.0586 - mae: 2.1881 - mse: 8.0586 - val_loss: 27.1171 - val_mae: 3.0663 - val_mse: 27.1171\n",
      "Epoch 26/500\n",
      "731/731 [==============================] - 0s 71us/sample - loss: 8.5861 - mae: 2.2647 - mse: 8.5861 - val_loss: 26.7163 - val_mae: 3.2049 - val_mse: 26.7163\n",
      "Epoch 27/500\n",
      "731/731 [==============================] - 0s 69us/sample - loss: 7.9451 - mae: 2.1574 - mse: 7.9451 - val_loss: 28.9474 - val_mae: 3.3352 - val_mse: 28.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "731/731 [==============================] - 0s 64us/sample - loss: 7.9884 - mae: 2.2166 - mse: 7.9884 - val_loss: 24.6712 - val_mae: 3.0199 - val_mse: 24.6712\n",
      "Epoch 29/500\n",
      "731/731 [==============================] - 0s 66us/sample - loss: 7.5299 - mae: 2.1167 - mse: 7.5299 - val_loss: 23.9314 - val_mae: 3.0607 - val_mse: 23.9314\n",
      "Epoch 30/500\n",
      "731/731 [==============================] - 0s 75us/sample - loss: 7.8681 - mae: 2.1759 - mse: 7.8681 - val_loss: 25.1292 - val_mae: 3.1095 - val_mse: 25.1292\n",
      "Epoch 31/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 7.0278 - mae: 2.0727 - mse: 7.0278 - val_loss: 22.8863 - val_mae: 3.0057 - val_mse: 22.8863\n",
      "Epoch 32/500\n",
      "731/731 [==============================] - 0s 51us/sample - loss: 7.2346 - mae: 2.1078 - mse: 7.2346 - val_loss: 22.4440 - val_mae: 2.7489 - val_mse: 22.4440\n",
      "Epoch 33/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 6.5970 - mae: 1.9967 - mse: 6.5970 - val_loss: 22.2789 - val_mae: 2.9934 - val_mse: 22.2789\n",
      "Epoch 34/500\n",
      "731/731 [==============================] - 0s 51us/sample - loss: 7.3612 - mae: 2.1465 - mse: 7.3612 - val_loss: 21.3567 - val_mae: 2.6675 - val_mse: 21.3567\n",
      "Epoch 35/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 6.8679 - mae: 2.0812 - mse: 6.8679 - val_loss: 20.2594 - val_mae: 2.5962 - val_mse: 20.2594\n",
      "Epoch 36/500\n",
      "731/731 [==============================] - 0s 51us/sample - loss: 6.0228 - mae: 1.9217 - mse: 6.0228 - val_loss: 20.5771 - val_mae: 2.6078 - val_mse: 20.5771\n",
      "Epoch 37/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 6.8445 - mae: 2.0642 - mse: 6.8445 - val_loss: 20.5977 - val_mae: 2.6356 - val_mse: 20.5977\n",
      "Epoch 38/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 5.9590 - mae: 1.9395 - mse: 5.9590 - val_loss: 19.4427 - val_mae: 2.5259 - val_mse: 19.4427\n",
      "Epoch 39/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 5.8738 - mae: 1.9080 - mse: 5.8738 - val_loss: 21.1392 - val_mae: 2.9210 - val_mse: 21.1392\n",
      "Epoch 40/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 5.8285 - mae: 1.9021 - mse: 5.8285 - val_loss: 23.7191 - val_mae: 3.5586 - val_mse: 23.7190\n",
      "Epoch 41/500\n",
      "731/731 [==============================] - 0s 67us/sample - loss: 6.6600 - mae: 2.0567 - mse: 6.6600 - val_loss: 20.2754 - val_mae: 2.6929 - val_mse: 20.2754\n",
      "Epoch 42/500\n",
      "731/731 [==============================] - 0s 84us/sample - loss: 5.7253 - mae: 1.9068 - mse: 5.7253 - val_loss: 18.1914 - val_mae: 2.4877 - val_mse: 18.1914\n",
      "Epoch 43/500\n",
      "731/731 [==============================] - 0s 73us/sample - loss: 5.6643 - mae: 1.8874 - mse: 5.6643 - val_loss: 18.5337 - val_mae: 2.6785 - val_mse: 18.5337\n",
      "Epoch 44/500\n",
      "731/731 [==============================] - 0s 72us/sample - loss: 5.8086 - mae: 1.9033 - mse: 5.8086 - val_loss: 23.0206 - val_mae: 3.0884 - val_mse: 23.0206\n",
      "Epoch 45/500\n",
      "731/731 [==============================] - 0s 63us/sample - loss: 5.7783 - mae: 1.8886 - mse: 5.7783 - val_loss: 18.5762 - val_mae: 2.4774 - val_mse: 18.5762\n",
      "Epoch 46/500\n",
      "731/731 [==============================] - 0s 61us/sample - loss: 4.9774 - mae: 1.7815 - mse: 4.9774 - val_loss: 21.8961 - val_mae: 3.0430 - val_mse: 21.8961\n",
      "Epoch 47/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 5.3866 - mae: 1.8784 - mse: 5.3866 - val_loss: 25.2611 - val_mae: 3.4504 - val_mse: 25.2611\n",
      "Epoch 48/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 5.6955 - mae: 1.9056 - mse: 5.6955 - val_loss: 17.1670 - val_mae: 2.5241 - val_mse: 17.1670\n",
      "Epoch 49/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 5.2868 - mae: 1.8163 - mse: 5.2868 - val_loss: 22.7669 - val_mae: 3.2098 - val_mse: 22.7669\n",
      "Epoch 50/500\n",
      "731/731 [==============================] - ETA: 0s - loss: 7.5243 - mae: 2.1992 - mse: 7.524 - 0s 52us/sample - loss: 5.2099 - mae: 1.7838 - mse: 5.2099 - val_loss: 20.4714 - val_mae: 2.8760 - val_mse: 20.4714\n",
      "Epoch 51/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 5.0951 - mae: 1.7820 - mse: 5.0951 - val_loss: 19.3405 - val_mae: 2.6999 - val_mse: 19.3405\n",
      "Epoch 52/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 4.6477 - mae: 1.7135 - mse: 4.6477 - val_loss: 19.6230 - val_mae: 3.0694 - val_mse: 19.6230\n",
      "Epoch 53/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 5.3399 - mae: 1.8436 - mse: 5.3399 - val_loss: 16.1609 - val_mae: 2.2823 - val_mse: 16.1609\n",
      "Epoch 54/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 4.8893 - mae: 1.7670 - mse: 4.8893 - val_loss: 16.9862 - val_mae: 2.5826 - val_mse: 16.9862\n",
      "Epoch 55/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 4.8834 - mae: 1.7648 - mse: 4.8834 - val_loss: 16.6526 - val_mae: 2.3252 - val_mse: 16.6526\n",
      "Epoch 56/500\n",
      "731/731 [==============================] - 0s 57us/sample - loss: 4.5697 - mae: 1.6890 - mse: 4.5697 - val_loss: 17.5398 - val_mae: 2.6701 - val_mse: 17.5398\n",
      "Epoch 57/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 5.3300 - mae: 1.8360 - mse: 5.3300 - val_loss: 19.7774 - val_mae: 3.1820 - val_mse: 19.7774\n",
      "Epoch 58/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 4.8676 - mae: 1.7714 - mse: 4.8676 - val_loss: 17.5654 - val_mae: 2.6735 - val_mse: 17.5654\n",
      "Epoch 59/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 4.5826 - mae: 1.7097 - mse: 4.5826 - val_loss: 21.0388 - val_mae: 3.0683 - val_mse: 21.0388\n",
      "Epoch 60/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 4.6661 - mae: 1.7114 - mse: 4.6661 - val_loss: 16.9714 - val_mae: 2.4172 - val_mse: 16.9714\n",
      "Epoch 61/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 4.7667 - mae: 1.7427 - mse: 4.7667 - val_loss: 16.6616 - val_mae: 2.6396 - val_mse: 16.6616\n",
      "Epoch 62/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 4.8224 - mae: 1.7559 - mse: 4.8224 - val_loss: 16.3390 - val_mae: 2.5449 - val_mse: 16.3390\n",
      "Epoch 63/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 4.2358 - mae: 1.6052 - mse: 4.2358 - val_loss: 16.4677 - val_mae: 2.5302 - val_mse: 16.4677\n",
      "Epoch 64/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 4.5784 - mae: 1.6953 - mse: 4.5784 - val_loss: 17.7250 - val_mae: 2.5847 - val_mse: 17.7250\n",
      "Epoch 65/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 3.9978 - mae: 1.5748 - mse: 3.9978 - val_loss: 16.9429 - val_mae: 2.4818 - val_mse: 16.9429\n",
      "Epoch 66/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 4.7647 - mae: 1.7491 - mse: 4.7647 - val_loss: 16.2243 - val_mae: 2.3581 - val_mse: 16.2243\n",
      "Epoch 67/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 4.2179 - mae: 1.6380 - mse: 4.2179 - val_loss: 16.6210 - val_mae: 2.6005 - val_mse: 16.6210\n",
      "Epoch 68/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 4.9366 - mae: 1.8033 - mse: 4.9366 - val_loss: 15.5180 - val_mae: 2.3346 - val_mse: 15.5180\n",
      "Epoch 69/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 3.9377 - mae: 1.5985 - mse: 3.9377 - val_loss: 19.3574 - val_mae: 2.8428 - val_mse: 19.3574\n",
      "Epoch 70/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 4.2209 - mae: 1.6346 - mse: 4.2209 - val_loss: 18.4232 - val_mae: 2.7688 - val_mse: 18.4232\n",
      "Epoch 71/500\n",
      "731/731 [==============================] - 0s 73us/sample - loss: 4.3582 - mae: 1.6752 - mse: 4.3582 - val_loss: 21.2579 - val_mae: 3.1512 - val_mse: 21.2579\n",
      "Epoch 72/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 4.4741 - mae: 1.7263 - mse: 4.4741 - val_loss: 14.4611 - val_mae: 2.2820 - val_mse: 14.4611\n",
      "Epoch 73/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 4.1151 - mae: 1.6225 - mse: 4.1151 - val_loss: 15.8672 - val_mae: 2.5659 - val_mse: 15.8672\n",
      "Epoch 74/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 3.9813 - mae: 1.6167 - mse: 3.9813 - val_loss: 17.1501 - val_mae: 2.6911 - val_mse: 17.1501\n",
      "Epoch 75/500\n",
      "731/731 [==============================] - 0s 57us/sample - loss: 4.2261 - mae: 1.6450 - mse: 4.2261 - val_loss: 14.7601 - val_mae: 2.1365 - val_mse: 14.7601\n",
      "Epoch 76/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 3.9231 - mae: 1.5630 - mse: 3.9231 - val_loss: 18.9383 - val_mae: 2.9931 - val_mse: 18.9383\n",
      "Epoch 77/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 4.3428 - mae: 1.6678 - mse: 4.3428 - val_loss: 15.2774 - val_mae: 2.4991 - val_mse: 15.2773\n",
      "Epoch 78/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 4.0144 - mae: 1.5962 - mse: 4.0144 - val_loss: 14.7415 - val_mae: 2.3313 - val_mse: 14.7415\n",
      "Epoch 79/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 3.8732 - mae: 1.5832 - mse: 3.8732 - val_loss: 16.3498 - val_mae: 2.4288 - val_mse: 16.3498\n",
      "Epoch 80/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 4.3747 - mae: 1.6873 - mse: 4.3747 - val_loss: 15.4262 - val_mae: 2.2551 - val_mse: 15.4262\n",
      "Epoch 81/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 3.6448 - mae: 1.5268 - mse: 3.6448 - val_loss: 14.4206 - val_mae: 2.1868 - val_mse: 14.4206\n",
      "Epoch 82/500\n",
      "731/731 [==============================] - 0s 51us/sample - loss: 4.2427 - mae: 1.6756 - mse: 4.2427 - val_loss: 16.3346 - val_mae: 2.4187 - val_mse: 16.3346\n",
      "Epoch 83/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 3.8905 - mae: 1.5783 - mse: 3.8905 - val_loss: 13.8425 - val_mae: 2.1211 - val_mse: 13.8425\n",
      "Epoch 84/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 3.9687 - mae: 1.5807 - mse: 3.9687 - val_loss: 15.8818 - val_mae: 2.4957 - val_mse: 15.8818\n",
      "Epoch 85/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 3.3466 - mae: 1.4549 - mse: 3.3466 - val_loss: 15.4740 - val_mae: 2.6103 - val_mse: 15.4740\n",
      "Epoch 86/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 4.2729 - mae: 1.6737 - mse: 4.2729 - val_loss: 17.7897 - val_mae: 3.0585 - val_mse: 17.7897\n",
      "Epoch 87/500\n",
      "731/731 [==============================] - 0s 57us/sample - loss: 3.7582 - mae: 1.5663 - mse: 3.7582 - val_loss: 15.0168 - val_mae: 2.2944 - val_mse: 15.0168\n",
      "Epoch 88/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 3.6823 - mae: 1.4875 - mse: 3.6823 - val_loss: 15.5426 - val_mae: 2.3294 - val_mse: 15.5426\n",
      "Epoch 89/500\n",
      "731/731 [==============================] - ETA: 0s - loss: 3.1510 - mae: 1.4708 - mse: 3.151 - 0s 54us/sample - loss: 4.1720 - mae: 1.6428 - mse: 4.1720 - val_loss: 17.1241 - val_mae: 2.6211 - val_mse: 17.1241\n",
      "Epoch 90/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 3.4625 - mae: 1.4898 - mse: 3.4625 - val_loss: 13.3138 - val_mae: 2.0189 - val_mse: 13.3138\n",
      "Epoch 91/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 3.8139 - mae: 1.5809 - mse: 3.8139 - val_loss: 13.5214 - val_mae: 2.0943 - val_mse: 13.5214\n",
      "Epoch 92/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 3.8368 - mae: 1.5723 - mse: 3.8368 - val_loss: 13.4017 - val_mae: 2.0868 - val_mse: 13.4017\n",
      "Epoch 93/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 3.4086 - mae: 1.4679 - mse: 3.4086 - val_loss: 13.8258 - val_mae: 2.2276 - val_mse: 13.8258\n",
      "Epoch 94/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 3.3951 - mae: 1.4798 - mse: 3.3951 - val_loss: 14.6083 - val_mae: 2.2367 - val_mse: 14.6083\n",
      "Epoch 95/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 4.0289 - mae: 1.6361 - mse: 4.0289 - val_loss: 13.4366 - val_mae: 2.1104 - val_mse: 13.4366\n",
      "Epoch 96/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 3.7104 - mae: 1.5391 - mse: 3.7104 - val_loss: 13.7277 - val_mae: 2.0846 - val_mse: 13.7277\n",
      "Epoch 97/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 3.4570 - mae: 1.4862 - mse: 3.4570 - val_loss: 13.5567 - val_mae: 2.1181 - val_mse: 13.5567\n",
      "Epoch 98/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 3.5487 - mae: 1.4957 - mse: 3.5487 - val_loss: 18.4661 - val_mae: 2.8302 - val_mse: 18.4661\n",
      "Epoch 99/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 3.8722 - mae: 1.5828 - mse: 3.8722 - val_loss: 15.4237 - val_mae: 2.3369 - val_mse: 15.4237\n",
      "Epoch 100/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 3.4072 - mae: 1.4852 - mse: 3.4072 - val_loss: 14.1106 - val_mae: 2.3178 - val_mse: 14.1106\n",
      "Epoch 101/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 3.5350 - mae: 1.5140 - mse: 3.5350 - val_loss: 15.8062 - val_mae: 2.4443 - val_mse: 15.8062\n",
      "Epoch 102/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 3.8111 - mae: 1.6031 - mse: 3.8111 - val_loss: 14.2265 - val_mae: 2.2164 - val_mse: 14.2264\n",
      "Epoch 103/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 3.8011 - mae: 1.5685 - mse: 3.8011 - val_loss: 13.8270 - val_mae: 2.3052 - val_mse: 13.8270\n",
      "Epoch 104/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 3.2533 - mae: 1.4522 - mse: 3.2533 - val_loss: 13.2662 - val_mae: 2.0171 - val_mse: 13.2662\n",
      "Epoch 105/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 3.6568 - mae: 1.5472 - mse: 3.6568 - val_loss: 14.7905 - val_mae: 2.4911 - val_mse: 14.7905\n",
      "Epoch 106/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 3.6833 - mae: 1.5338 - mse: 3.6833 - val_loss: 13.8692 - val_mae: 2.2229 - val_mse: 13.8692\n",
      "Epoch 107/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 3.1412 - mae: 1.3941 - mse: 3.1412 - val_loss: 13.1139 - val_mae: 2.0257 - val_mse: 13.1139\n",
      "Epoch 108/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 3.3122 - mae: 1.4769 - mse: 3.3122 - val_loss: 18.7294 - val_mae: 2.9574 - val_mse: 18.7294\n",
      "Epoch 109/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 3.7500 - mae: 1.5813 - mse: 3.7500 - val_loss: 13.3324 - val_mae: 2.1950 - val_mse: 13.3324\n",
      "Epoch 110/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 3.0627 - mae: 1.4132 - mse: 3.0627 - val_loss: 15.9550 - val_mae: 2.5168 - val_mse: 15.9550\n",
      "Epoch 111/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 3.3516 - mae: 1.4688 - mse: 3.3516 - val_loss: 17.7344 - val_mae: 2.7891 - val_mse: 17.7344\n",
      "Epoch 112/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 3.2272 - mae: 1.4402 - mse: 3.2272 - val_loss: 13.3774 - val_mae: 2.0627 - val_mse: 13.3774\n",
      "Epoch 113/500\n",
      "731/731 [==============================] - 0s 57us/sample - loss: 4.0290 - mae: 1.6103 - mse: 4.0290 - val_loss: 13.1427 - val_mae: 1.9844 - val_mse: 13.1427\n",
      "Epoch 114/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 3.3388 - mae: 1.4769 - mse: 3.3388 - val_loss: 12.8872 - val_mae: 1.9474 - val_mse: 12.8872\n",
      "Epoch 115/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 3.3116 - mae: 1.4710 - mse: 3.3116 - val_loss: 13.5747 - val_mae: 2.2249 - val_mse: 13.5747\n",
      "Epoch 116/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 3.3001 - mae: 1.4591 - mse: 3.3001 - val_loss: 13.3203 - val_mae: 2.2255 - val_mse: 13.3203\n",
      "Epoch 117/500\n",
      "731/731 [==============================] - 0s 57us/sample - loss: 3.4091 - mae: 1.5152 - mse: 3.4091 - val_loss: 12.8757 - val_mae: 2.0103 - val_mse: 12.8757\n",
      "Epoch 118/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 3.2236 - mae: 1.4529 - mse: 3.2236 - val_loss: 14.3804 - val_mae: 2.2204 - val_mse: 14.3804\n",
      "Epoch 119/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 3.4257 - mae: 1.4732 - mse: 3.4257 - val_loss: 14.3548 - val_mae: 2.2742 - val_mse: 14.3548\n",
      "Epoch 120/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 3.3181 - mae: 1.4752 - mse: 3.3181 - val_loss: 13.8845 - val_mae: 2.1448 - val_mse: 13.8845\n",
      "Epoch 121/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 3.1112 - mae: 1.4214 - mse: 3.1112 - val_loss: 15.4817 - val_mae: 2.4417 - val_mse: 15.4817\n",
      "Epoch 122/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "731/731 [==============================] - 0s 54us/sample - loss: 3.1670 - mae: 1.4207 - mse: 3.1670 - val_loss: 13.0082 - val_mae: 2.1091 - val_mse: 13.0082\n",
      "Epoch 123/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 3.1039 - mae: 1.4022 - mse: 3.1039 - val_loss: 12.9770 - val_mae: 2.1460 - val_mse: 12.9770\n",
      "Epoch 124/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 3.3198 - mae: 1.4594 - mse: 3.3198 - val_loss: 12.9157 - val_mae: 2.0963 - val_mse: 12.9157\n",
      "Epoch 125/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 3.1263 - mae: 1.4204 - mse: 3.1263 - val_loss: 12.9945 - val_mae: 1.9828 - val_mse: 12.9945\n",
      "Epoch 126/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 3.1854 - mae: 1.4247 - mse: 3.1854 - val_loss: 12.7745 - val_mae: 1.9720 - val_mse: 12.7745\n",
      "Epoch 127/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 3.2562 - mae: 1.4365 - mse: 3.2562 - val_loss: 12.7318 - val_mae: 2.0915 - val_mse: 12.7318\n",
      "Epoch 128/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 2.9313 - mae: 1.3712 - mse: 2.9313 - val_loss: 15.0019 - val_mae: 2.4408 - val_mse: 15.0019\n",
      "Epoch 129/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 3.2335 - mae: 1.4510 - mse: 3.2335 - val_loss: 14.4492 - val_mae: 2.2783 - val_mse: 14.4492\n",
      "Epoch 130/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 3.2887 - mae: 1.4520 - mse: 3.2887 - val_loss: 14.5794 - val_mae: 2.3370 - val_mse: 14.5794\n",
      "Epoch 131/500\n",
      "731/731 [==============================] - 0s 50us/sample - loss: 2.9779 - mae: 1.3841 - mse: 2.9779 - val_loss: 12.2233 - val_mae: 1.8877 - val_mse: 12.2233\n",
      "Epoch 132/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 3.1055 - mae: 1.3898 - mse: 3.1055 - val_loss: 13.4509 - val_mae: 2.1452 - val_mse: 13.4509\n",
      "Epoch 133/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.9350 - mae: 1.3594 - mse: 2.9350 - val_loss: 11.9569 - val_mae: 1.9220 - val_mse: 11.9569\n",
      "Epoch 134/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 3.0961 - mae: 1.4261 - mse: 3.0961 - val_loss: 13.8029 - val_mae: 2.1781 - val_mse: 13.8029\n",
      "Epoch 135/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 2.4920 - mae: 1.2517 - mse: 2.4920 - val_loss: 14.0373 - val_mae: 2.3800 - val_mse: 14.0373\n",
      "Epoch 136/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 3.2044 - mae: 1.4390 - mse: 3.2044 - val_loss: 13.4946 - val_mae: 2.1502 - val_mse: 13.4946\n",
      "Epoch 137/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 2.9365 - mae: 1.3770 - mse: 2.9365 - val_loss: 13.6854 - val_mae: 2.3694 - val_mse: 13.6854\n",
      "Epoch 138/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 3.1821 - mae: 1.4495 - mse: 3.1821 - val_loss: 12.6534 - val_mae: 2.0233 - val_mse: 12.6534\n",
      "Epoch 139/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.9300 - mae: 1.3667 - mse: 2.9300 - val_loss: 16.0340 - val_mae: 2.5977 - val_mse: 16.0340\n",
      "Epoch 140/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.7721 - mae: 1.3330 - mse: 2.7721 - val_loss: 12.7657 - val_mae: 2.0202 - val_mse: 12.7657\n",
      "Epoch 141/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 3.1281 - mae: 1.4129 - mse: 3.1281 - val_loss: 12.7418 - val_mae: 2.0039 - val_mse: 12.7418\n",
      "Epoch 142/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 3.0816 - mae: 1.4059 - mse: 3.0816 - val_loss: 13.1783 - val_mae: 2.0984 - val_mse: 13.1783\n",
      "Epoch 143/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 3.0864 - mae: 1.4165 - mse: 3.0864 - val_loss: 13.3230 - val_mae: 2.1805 - val_mse: 13.3230\n",
      "Epoch 144/500\n",
      "731/731 [==============================] - ETA: 0s - loss: 2.8731 - mae: 1.4257 - mse: 2.873 - 0s 56us/sample - loss: 2.8299 - mae: 1.3640 - mse: 2.8299 - val_loss: 12.5072 - val_mae: 1.9867 - val_mse: 12.5072\n",
      "Epoch 145/500\n",
      "731/731 [==============================] - 0s 57us/sample - loss: 2.6190 - mae: 1.2728 - mse: 2.6190 - val_loss: 20.0466 - val_mae: 3.3210 - val_mse: 20.0466\n",
      "Epoch 146/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 3.2336 - mae: 1.4515 - mse: 3.2336 - val_loss: 13.1199 - val_mae: 2.3022 - val_mse: 13.1199\n",
      "Epoch 147/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 2.8002 - mae: 1.3511 - mse: 2.8002 - val_loss: 14.1601 - val_mae: 2.2752 - val_mse: 14.1601\n",
      "Epoch 148/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 3.0485 - mae: 1.3647 - mse: 3.0485 - val_loss: 13.0808 - val_mae: 2.1287 - val_mse: 13.0808\n",
      "Epoch 149/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 2.7759 - mae: 1.3227 - mse: 2.7759 - val_loss: 12.0984 - val_mae: 1.9180 - val_mse: 12.0984\n",
      "Epoch 150/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 2.7336 - mae: 1.3178 - mse: 2.7336 - val_loss: 14.5889 - val_mae: 2.3842 - val_mse: 14.5889\n",
      "Epoch 151/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 2.9771 - mae: 1.3767 - mse: 2.9771 - val_loss: 12.7884 - val_mae: 2.1566 - val_mse: 12.7884\n",
      "Epoch 152/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 3.0251 - mae: 1.3909 - mse: 3.0251 - val_loss: 12.3355 - val_mae: 2.0296 - val_mse: 12.3355\n",
      "Epoch 153/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 2.7450 - mae: 1.3161 - mse: 2.7450 - val_loss: 12.4305 - val_mae: 1.9179 - val_mse: 12.4305\n",
      "Epoch 154/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 2.8728 - mae: 1.3429 - mse: 2.8728 - val_loss: 13.8907 - val_mae: 2.2631 - val_mse: 13.8907\n",
      "Epoch 155/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 2.8144 - mae: 1.3504 - mse: 2.8144 - val_loss: 13.8175 - val_mae: 2.1998 - val_mse: 13.8175\n",
      "Epoch 156/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.7539 - mae: 1.3338 - mse: 2.7539 - val_loss: 11.7978 - val_mae: 1.8719 - val_mse: 11.7978\n",
      "Epoch 157/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 2.7760 - mae: 1.3249 - mse: 2.7760 - val_loss: 12.4448 - val_mae: 1.9476 - val_mse: 12.4448\n",
      "Epoch 158/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 2.9939 - mae: 1.3898 - mse: 2.9939 - val_loss: 13.7297 - val_mae: 2.1834 - val_mse: 13.7297\n",
      "Epoch 159/500\n",
      "731/731 [==============================] - 0s 57us/sample - loss: 2.9747 - mae: 1.3719 - mse: 2.9747 - val_loss: 13.8592 - val_mae: 2.2060 - val_mse: 13.8592\n",
      "Epoch 160/500\n",
      "731/731 [==============================] - 0s 51us/sample - loss: 2.9695 - mae: 1.3758 - mse: 2.9695 - val_loss: 12.0464 - val_mae: 1.9125 - val_mse: 12.0464\n",
      "Epoch 161/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 2.7151 - mae: 1.3186 - mse: 2.7151 - val_loss: 11.8727 - val_mae: 1.9222 - val_mse: 11.8727\n",
      "Epoch 162/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 2.7348 - mae: 1.3236 - mse: 2.7348 - val_loss: 13.1106 - val_mae: 2.1637 - val_mse: 13.1106\n",
      "Epoch 163/500\n",
      "731/731 [==============================] - 0s 61us/sample - loss: 2.7224 - mae: 1.3162 - mse: 2.7224 - val_loss: 11.9443 - val_mae: 1.8574 - val_mse: 11.9443\n",
      "Epoch 164/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 2.4053 - mae: 1.2215 - mse: 2.4053 - val_loss: 16.8540 - val_mae: 2.9372 - val_mse: 16.8540\n",
      "Epoch 165/500\n",
      "731/731 [==============================] - 0s 51us/sample - loss: 2.9535 - mae: 1.3776 - mse: 2.9535 - val_loss: 14.5882 - val_mae: 2.4866 - val_mse: 14.5882\n",
      "Epoch 166/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 2.9104 - mae: 1.3930 - mse: 2.9104 - val_loss: 12.0573 - val_mae: 1.9263 - val_mse: 12.0573\n",
      "Epoch 167/500\n",
      "731/731 [==============================] - 0s 57us/sample - loss: 2.6356 - mae: 1.2967 - mse: 2.6356 - val_loss: 14.0092 - val_mae: 2.2421 - val_mse: 14.0092\n",
      "Epoch 168/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 3.0569 - mae: 1.3953 - mse: 3.0569 - val_loss: 13.2767 - val_mae: 2.0612 - val_mse: 13.2767\n",
      "Epoch 169/500\n",
      "731/731 [==============================] - 0s 70us/sample - loss: 2.7823 - mae: 1.3290 - mse: 2.7823 - val_loss: 13.7767 - val_mae: 2.2014 - val_mse: 13.7767\n",
      "Epoch 170/500\n",
      "731/731 [==============================] - 0s 64us/sample - loss: 2.7485 - mae: 1.3376 - mse: 2.7485 - val_loss: 12.9020 - val_mae: 2.0254 - val_mse: 12.9020\n",
      "Epoch 171/500\n",
      "731/731 [==============================] - 0s 63us/sample - loss: 2.8746 - mae: 1.3538 - mse: 2.8746 - val_loss: 12.2881 - val_mae: 1.9914 - val_mse: 12.2881\n",
      "Epoch 172/500\n",
      "731/731 [==============================] - 0s 69us/sample - loss: 2.6153 - mae: 1.3158 - mse: 2.6153 - val_loss: 12.0328 - val_mae: 1.9438 - val_mse: 12.0328\n",
      "Epoch 173/500\n",
      "731/731 [==============================] - 0s 60us/sample - loss: 2.6245 - mae: 1.2844 - mse: 2.6245 - val_loss: 11.8414 - val_mae: 1.8429 - val_mse: 11.8414\n",
      "Epoch 174/500\n",
      "731/731 [==============================] - 0s 60us/sample - loss: 2.6410 - mae: 1.2968 - mse: 2.6410 - val_loss: 14.2890 - val_mae: 2.6051 - val_mse: 14.2890\n",
      "Epoch 175/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 2.8340 - mae: 1.3654 - mse: 2.8340 - val_loss: 12.3165 - val_mae: 1.9209 - val_mse: 12.3165\n",
      "Epoch 176/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 2.6868 - mae: 1.3079 - mse: 2.6868 - val_loss: 12.7340 - val_mae: 2.0445 - val_mse: 12.7340\n",
      "Epoch 177/500\n",
      "731/731 [==============================] - 0s 63us/sample - loss: 2.7374 - mae: 1.3215 - mse: 2.7374 - val_loss: 12.0664 - val_mae: 1.9031 - val_mse: 12.0664\n",
      "Epoch 178/500\n",
      "731/731 [==============================] - 0s 60us/sample - loss: 2.6730 - mae: 1.3181 - mse: 2.6730 - val_loss: 12.8409 - val_mae: 2.0564 - val_mse: 12.8409\n",
      "Epoch 179/500\n",
      "731/731 [==============================] - 0s 63us/sample - loss: 2.4509 - mae: 1.2654 - mse: 2.4509 - val_loss: 12.5694 - val_mae: 2.1364 - val_mse: 12.5694\n",
      "Epoch 180/500\n",
      "731/731 [==============================] - 0s 69us/sample - loss: 2.7972 - mae: 1.3432 - mse: 2.7972 - val_loss: 12.4515 - val_mae: 2.1154 - val_mse: 12.4515\n",
      "Epoch 181/500\n",
      "731/731 [==============================] - 0s 61us/sample - loss: 2.5243 - mae: 1.2771 - mse: 2.5243 - val_loss: 12.7502 - val_mae: 2.2437 - val_mse: 12.7502\n",
      "Epoch 182/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 2.8202 - mae: 1.3553 - mse: 2.8202 - val_loss: 11.9779 - val_mae: 1.8203 - val_mse: 11.9779\n",
      "Epoch 183/500\n",
      "731/731 [==============================] - 0s 63us/sample - loss: 2.8680 - mae: 1.3725 - mse: 2.8680 - val_loss: 11.9598 - val_mae: 1.9969 - val_mse: 11.9598\n",
      "Epoch 184/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 2.4396 - mae: 1.2333 - mse: 2.4396 - val_loss: 12.7234 - val_mae: 2.0883 - val_mse: 12.7234\n",
      "Epoch 185/500\n",
      "731/731 [==============================] - 0s 61us/sample - loss: 2.7069 - mae: 1.3203 - mse: 2.7069 - val_loss: 13.9071 - val_mae: 2.3531 - val_mse: 13.9071\n",
      "Epoch 186/500\n",
      "731/731 [==============================] - 0s 59us/sample - loss: 2.6576 - mae: 1.3166 - mse: 2.6576 - val_loss: 12.1431 - val_mae: 2.0130 - val_mse: 12.1431\n",
      "Epoch 187/500\n",
      "731/731 [==============================] - 0s 62us/sample - loss: 2.7598 - mae: 1.3365 - mse: 2.7598 - val_loss: 12.1270 - val_mae: 1.9287 - val_mse: 12.1270\n",
      "Epoch 188/500\n",
      "731/731 [==============================] - 0s 65us/sample - loss: 2.4781 - mae: 1.2263 - mse: 2.4781 - val_loss: 13.0484 - val_mae: 2.2760 - val_mse: 13.0484\n",
      "Epoch 189/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.3253 - mae: 1.2364 - mse: 2.3253 - val_loss: 13.2227 - val_mae: 2.2896 - val_mse: 13.2227\n",
      "Epoch 190/500\n",
      "731/731 [==============================] - 0s 63us/sample - loss: 2.9755 - mae: 1.3838 - mse: 2.9755 - val_loss: 12.4108 - val_mae: 1.9550 - val_mse: 12.4108\n",
      "Epoch 191/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 2.5096 - mae: 1.2617 - mse: 2.5096 - val_loss: 15.7504 - val_mae: 2.5769 - val_mse: 15.7504\n",
      "Epoch 192/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 2.7354 - mae: 1.3448 - mse: 2.7354 - val_loss: 12.5606 - val_mae: 1.9162 - val_mse: 12.5606\n",
      "Epoch 193/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 2.3870 - mae: 1.2282 - mse: 2.3870 - val_loss: 12.9112 - val_mae: 2.0247 - val_mse: 12.9112\n",
      "Epoch 194/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.5989 - mae: 1.2958 - mse: 2.5989 - val_loss: 14.4175 - val_mae: 2.3756 - val_mse: 14.4175\n",
      "Epoch 195/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 2.6277 - mae: 1.3152 - mse: 2.6277 - val_loss: 14.2540 - val_mae: 2.3075 - val_mse: 14.2540\n",
      "Epoch 196/500\n",
      "731/731 [==============================] - 0s 63us/sample - loss: 2.6865 - mae: 1.3017 - mse: 2.6865 - val_loss: 11.7852 - val_mae: 1.8928 - val_mse: 11.7852\n",
      "Epoch 197/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 2.6100 - mae: 1.2838 - mse: 2.6100 - val_loss: 13.5112 - val_mae: 2.2166 - val_mse: 13.5112\n",
      "Epoch 198/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 2.7738 - mae: 1.3476 - mse: 2.7738 - val_loss: 12.5487 - val_mae: 2.1102 - val_mse: 12.5487\n",
      "Epoch 199/500\n",
      "731/731 [==============================] - 0s 57us/sample - loss: 2.5256 - mae: 1.2786 - mse: 2.5256 - val_loss: 12.9500 - val_mae: 1.9985 - val_mse: 12.9500\n",
      "Epoch 200/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.5172 - mae: 1.2822 - mse: 2.5172 - val_loss: 14.7878 - val_mae: 2.3332 - val_mse: 14.7878\n",
      "Epoch 201/500\n",
      "731/731 [==============================] - 0s 63us/sample - loss: 2.8376 - mae: 1.3440 - mse: 2.8376 - val_loss: 11.9241 - val_mae: 1.8570 - val_mse: 11.9241\n",
      "Epoch 202/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 2.5185 - mae: 1.2751 - mse: 2.5185 - val_loss: 11.6843 - val_mae: 1.7844 - val_mse: 11.6843\n",
      "Epoch 203/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 2.6970 - mae: 1.3182 - mse: 2.6970 - val_loss: 14.3011 - val_mae: 2.4479 - val_mse: 14.3011\n",
      "Epoch 204/500\n",
      "731/731 [==============================] - 0s 57us/sample - loss: 2.7041 - mae: 1.3205 - mse: 2.7041 - val_loss: 12.0741 - val_mae: 1.9915 - val_mse: 12.0741\n",
      "Epoch 205/500\n",
      "731/731 [==============================] - 0s 62us/sample - loss: 2.5211 - mae: 1.2687 - mse: 2.5211 - val_loss: 12.6897 - val_mae: 2.2146 - val_mse: 12.6897\n",
      "Epoch 206/500\n",
      "731/731 [==============================] - 0s 57us/sample - loss: 2.6181 - mae: 1.3065 - mse: 2.6181 - val_loss: 12.0311 - val_mae: 1.9039 - val_mse: 12.0311\n",
      "Epoch 207/500\n",
      "731/731 [==============================] - 0s 61us/sample - loss: 2.5353 - mae: 1.2931 - mse: 2.5353 - val_loss: 12.7339 - val_mae: 2.0890 - val_mse: 12.7339\n",
      "Epoch 208/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 2.4290 - mae: 1.2291 - mse: 2.4290 - val_loss: 12.7631 - val_mae: 2.2174 - val_mse: 12.7631\n",
      "Epoch 209/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.4952 - mae: 1.2898 - mse: 2.4952 - val_loss: 13.4529 - val_mae: 2.0923 - val_mse: 13.4529\n",
      "Epoch 210/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 2.4879 - mae: 1.2564 - mse: 2.4879 - val_loss: 13.2622 - val_mae: 2.1244 - val_mse: 13.2622\n",
      "Epoch 211/500\n",
      "731/731 [==============================] - 0s 61us/sample - loss: 2.6696 - mae: 1.3038 - mse: 2.6696 - val_loss: 14.8612 - val_mae: 2.3695 - val_mse: 14.8612\n",
      "Epoch 212/500\n",
      "731/731 [==============================] - 0s 63us/sample - loss: 2.5758 - mae: 1.2906 - mse: 2.5758 - val_loss: 13.9515 - val_mae: 2.2284 - val_mse: 13.9515\n",
      "Epoch 213/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 2.6956 - mae: 1.3220 - mse: 2.6956 - val_loss: 13.7803 - val_mae: 2.1857 - val_mse: 13.7803\n",
      "Epoch 214/500\n",
      "731/731 [==============================] - 0s 74us/sample - loss: 2.4186 - mae: 1.2469 - mse: 2.4186 - val_loss: 13.8260 - val_mae: 2.3853 - val_mse: 13.8260\n",
      "Epoch 215/500\n",
      "731/731 [==============================] - 0s 78us/sample - loss: 2.6669 - mae: 1.3159 - mse: 2.6669 - val_loss: 13.4312 - val_mae: 2.2717 - val_mse: 13.4312\n",
      "Epoch 216/500\n",
      "731/731 [==============================] - 0s 75us/sample - loss: 2.5188 - mae: 1.2820 - mse: 2.5188 - val_loss: 12.3974 - val_mae: 1.9974 - val_mse: 12.3974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/500\n",
      "731/731 [==============================] - 0s 69us/sample - loss: 2.4520 - mae: 1.2199 - mse: 2.4520 - val_loss: 12.2321 - val_mae: 1.8920 - val_mse: 12.2321\n",
      "Epoch 218/500\n",
      "731/731 [==============================] - 0s 72us/sample - loss: 2.6982 - mae: 1.2931 - mse: 2.6982 - val_loss: 12.3679 - val_mae: 1.9112 - val_mse: 12.3679\n",
      "Epoch 219/500\n",
      "731/731 [==============================] - 0s 73us/sample - loss: 2.3727 - mae: 1.2181 - mse: 2.3727 - val_loss: 13.8488 - val_mae: 2.2396 - val_mse: 13.8488\n",
      "Epoch 220/500\n",
      "731/731 [==============================] - 0s 71us/sample - loss: 2.4829 - mae: 1.2788 - mse: 2.4829 - val_loss: 13.1214 - val_mae: 2.1407 - val_mse: 13.1214\n",
      "Epoch 221/500\n",
      "731/731 [==============================] - 0s 63us/sample - loss: 2.2908 - mae: 1.2153 - mse: 2.2908 - val_loss: 13.2176 - val_mae: 2.3080 - val_mse: 13.2176\n",
      "Epoch 222/500\n",
      "731/731 [==============================] - 0s 60us/sample - loss: 2.4740 - mae: 1.2416 - mse: 2.4740 - val_loss: 12.6184 - val_mae: 2.0112 - val_mse: 12.6184\n",
      "Epoch 223/500\n",
      "731/731 [==============================] - 0s 65us/sample - loss: 2.3246 - mae: 1.2346 - mse: 2.3246 - val_loss: 15.2011 - val_mae: 2.4989 - val_mse: 15.2011\n",
      "Epoch 224/500\n",
      "731/731 [==============================] - 0s 61us/sample - loss: 2.6156 - mae: 1.3065 - mse: 2.6156 - val_loss: 14.5599 - val_mae: 2.3229 - val_mse: 14.5599\n",
      "Epoch 225/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.3158 - mae: 1.2273 - mse: 2.3158 - val_loss: 16.6188 - val_mae: 2.8350 - val_mse: 16.6188\n",
      "Epoch 226/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 2.3481 - mae: 1.2211 - mse: 2.3481 - val_loss: 15.9683 - val_mae: 2.5745 - val_mse: 15.9683\n",
      "Epoch 227/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 2.5410 - mae: 1.2724 - mse: 2.5410 - val_loss: 13.3221 - val_mae: 2.1760 - val_mse: 13.3221\n",
      "Epoch 228/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 2.4763 - mae: 1.2446 - mse: 2.4763 - val_loss: 12.1828 - val_mae: 1.8705 - val_mse: 12.1828\n",
      "Epoch 229/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.5839 - mae: 1.2799 - mse: 2.5839 - val_loss: 14.2166 - val_mae: 2.2238 - val_mse: 14.2166\n",
      "Epoch 230/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.3603 - mae: 1.2404 - mse: 2.3603 - val_loss: 12.9445 - val_mae: 2.1036 - val_mse: 12.9445\n",
      "Epoch 231/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.5834 - mae: 1.3008 - mse: 2.5834 - val_loss: 13.9745 - val_mae: 2.2343 - val_mse: 13.9745\n",
      "Epoch 232/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 2.4024 - mae: 1.2414 - mse: 2.4024 - val_loss: 12.2727 - val_mae: 1.8506 - val_mse: 12.2727\n",
      "Epoch 233/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 2.6191 - mae: 1.3082 - mse: 2.6191 - val_loss: 13.7405 - val_mae: 2.1951 - val_mse: 13.7405\n",
      "Epoch 234/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 2.3512 - mae: 1.2322 - mse: 2.3512 - val_loss: 15.1141 - val_mae: 2.5771 - val_mse: 15.1141\n",
      "Epoch 235/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.4791 - mae: 1.2819 - mse: 2.4791 - val_loss: 13.5048 - val_mae: 2.1563 - val_mse: 13.5048\n",
      "Epoch 236/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 2.3798 - mae: 1.2395 - mse: 2.3798 - val_loss: 12.8257 - val_mae: 2.0641 - val_mse: 12.8257\n",
      "Epoch 237/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 2.4455 - mae: 1.2584 - mse: 2.4455 - val_loss: 14.9586 - val_mae: 2.3762 - val_mse: 14.9586\n",
      "Epoch 238/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 2.4976 - mae: 1.2719 - mse: 2.4976 - val_loss: 12.8922 - val_mae: 2.0859 - val_mse: 12.8922\n",
      "Epoch 239/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 2.2120 - mae: 1.1854 - mse: 2.2120 - val_loss: 16.3057 - val_mae: 2.5918 - val_mse: 16.3057\n",
      "Epoch 240/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 2.4790 - mae: 1.2605 - mse: 2.4790 - val_loss: 13.8182 - val_mae: 2.1583 - val_mse: 13.8182\n",
      "Epoch 241/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 2.5688 - mae: 1.2973 - mse: 2.5688 - val_loss: 14.1358 - val_mae: 2.2253 - val_mse: 14.1358\n",
      "Epoch 242/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 2.2192 - mae: 1.1960 - mse: 2.2192 - val_loss: 15.0560 - val_mae: 2.4188 - val_mse: 15.0560\n",
      "Epoch 243/500\n",
      "731/731 [==============================] - 0s 51us/sample - loss: 2.6010 - mae: 1.3000 - mse: 2.6010 - val_loss: 13.4175 - val_mae: 2.0536 - val_mse: 13.4175\n",
      "Epoch 244/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.4703 - mae: 1.2629 - mse: 2.4703 - val_loss: 14.0363 - val_mae: 2.1745 - val_mse: 14.0363\n",
      "Epoch 245/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.2652 - mae: 1.1886 - mse: 2.2652 - val_loss: 12.2989 - val_mae: 1.9462 - val_mse: 12.2989\n",
      "Epoch 246/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 2.4421 - mae: 1.2706 - mse: 2.4421 - val_loss: 13.5584 - val_mae: 2.2722 - val_mse: 13.5584\n",
      "Epoch 247/500\n",
      "731/731 [==============================] - 0s 58us/sample - loss: 2.3411 - mae: 1.2322 - mse: 2.3411 - val_loss: 14.6263 - val_mae: 2.3103 - val_mse: 14.6263\n",
      "Epoch 248/500\n",
      "731/731 [==============================] - 0s 55us/sample - loss: 2.4371 - mae: 1.2570 - mse: 2.4371 - val_loss: 12.6196 - val_mae: 1.9204 - val_mse: 12.6196\n",
      "Epoch 249/500\n",
      "731/731 [==============================] - 0s 56us/sample - loss: 2.2701 - mae: 1.2097 - mse: 2.2701 - val_loss: 12.3184 - val_mae: 1.8386 - val_mse: 12.3184\n",
      "Epoch 250/500\n",
      "731/731 [==============================] - 0s 52us/sample - loss: 2.3005 - mae: 1.2182 - mse: 2.3005 - val_loss: 15.2982 - val_mae: 2.3925 - val_mse: 15.2982\n",
      "Epoch 251/500\n",
      "731/731 [==============================] - 0s 54us/sample - loss: 2.4662 - mae: 1.2713 - mse: 2.4662 - val_loss: 12.4132 - val_mae: 2.0037 - val_mse: 12.4132\n",
      "Epoch 252/500\n",
      "731/731 [==============================] - 0s 53us/sample - loss: 2.4519 - mae: 1.2625 - mse: 2.4519 - val_loss: 13.9720 - val_mae: 2.2519 - val_mse: 13.9720\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 812 samples, validate on 271 samples\n",
      "Epoch 1/500\n",
      "812/812 [==============================] - 0s 579us/sample - loss: 435.1070 - mae: 13.4796 - mse: 435.1070 - val_loss: 56.4039 - val_mae: 5.1762 - val_mse: 56.4039\n",
      "Epoch 2/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 36.6006 - mae: 4.5796 - mse: 36.6006 - val_loss: 58.8748 - val_mae: 5.8451 - val_mse: 58.8748\n",
      "Epoch 3/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 30.4359 - mae: 4.2340 - mse: 30.4359 - val_loss: 51.8128 - val_mae: 5.0015 - val_mse: 51.8128\n",
      "Epoch 4/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 26.9965 - mae: 3.9105 - mse: 26.9965 - val_loss: 39.5896 - val_mae: 3.8306 - val_mse: 39.5896\n",
      "Epoch 5/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 23.4393 - mae: 3.6765 - mse: 23.4394 - val_loss: 44.7572 - val_mae: 4.8166 - val_mse: 44.7572\n",
      "Epoch 6/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 22.4038 - mae: 3.6368 - mse: 22.4038 - val_loss: 33.2385 - val_mae: 3.2928 - val_mse: 33.2385\n",
      "Epoch 7/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 18.5094 - mae: 3.2979 - mse: 18.5094 - val_loss: 37.3932 - val_mae: 3.6557 - val_mse: 37.3932\n",
      "Epoch 8/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 18.6799 - mae: 3.3223 - mse: 18.6799 - val_loss: 30.7482 - val_mae: 3.0793 - val_mse: 30.7482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 16.8552 - mae: 3.1785 - mse: 16.8552 - val_loss: 30.1229 - val_mae: 3.0449 - val_mse: 30.1229\n",
      "Epoch 10/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 17.2024 - mae: 3.2238 - mse: 17.2024 - val_loss: 29.1332 - val_mae: 3.0988 - val_mse: 29.1332\n",
      "Epoch 11/500\n",
      "812/812 [==============================] - 0s 56us/sample - loss: 14.9346 - mae: 3.0339 - mse: 14.9346 - val_loss: 34.7642 - val_mae: 4.0693 - val_mse: 34.7642\n",
      "Epoch 12/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 14.4090 - mae: 2.9331 - mse: 14.4090 - val_loss: 33.4887 - val_mae: 3.4464 - val_mse: 33.4887\n",
      "Epoch 13/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 14.5053 - mae: 3.0030 - mse: 14.5053 - val_loss: 49.2650 - val_mae: 5.7714 - val_mse: 49.2650\n",
      "Epoch 14/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 13.4954 - mae: 2.8381 - mse: 13.4954 - val_loss: 33.8916 - val_mae: 3.5930 - val_mse: 33.8916\n",
      "Epoch 15/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 13.1699 - mae: 2.8567 - mse: 13.1699 - val_loss: 42.0818 - val_mae: 4.4986 - val_mse: 42.0818\n",
      "Epoch 16/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 13.3596 - mae: 2.8661 - mse: 13.3596 - val_loss: 27.4416 - val_mae: 2.9403 - val_mse: 27.4416\n",
      "Epoch 17/500\n",
      "812/812 [==============================] - 0s 56us/sample - loss: 13.9964 - mae: 2.9601 - mse: 13.9964 - val_loss: 26.7636 - val_mae: 3.1256 - val_mse: 26.7636\n",
      "Epoch 18/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 12.2102 - mae: 2.7446 - mse: 12.2102 - val_loss: 38.8857 - val_mae: 4.9092 - val_mse: 38.8857\n",
      "Epoch 19/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 12.2927 - mae: 2.7952 - mse: 12.2927 - val_loss: 27.1382 - val_mae: 3.2931 - val_mse: 27.1382\n",
      "Epoch 20/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 11.5553 - mae: 2.7273 - mse: 11.5553 - val_loss: 29.7780 - val_mae: 3.8219 - val_mse: 29.7780\n",
      "Epoch 21/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 11.7909 - mae: 2.7109 - mse: 11.7909 - val_loss: 35.5814 - val_mae: 4.0321 - val_mse: 35.5814\n",
      "Epoch 22/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 12.1151 - mae: 2.8189 - mse: 12.1151 - val_loss: 28.8610 - val_mae: 3.2410 - val_mse: 28.8610\n",
      "Epoch 23/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 10.5839 - mae: 2.5962 - mse: 10.5839 - val_loss: 24.1466 - val_mae: 2.6689 - val_mse: 24.1466\n",
      "Epoch 24/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 12.6923 - mae: 2.8919 - mse: 12.6923 - val_loss: 25.1503 - val_mae: 2.8215 - val_mse: 25.1503\n",
      "Epoch 25/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 9.3314 - mae: 2.2990 - mse: 9.3314 - val_loss: 23.3940 - val_mae: 2.9590 - val_mse: 23.3940\n",
      "Epoch 26/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 11.7555 - mae: 2.7086 - mse: 11.7555 - val_loss: 23.4867 - val_mae: 3.0176 - val_mse: 23.4867\n",
      "Epoch 27/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 11.6177 - mae: 2.7328 - mse: 11.6177 - val_loss: 27.1930 - val_mae: 3.2363 - val_mse: 27.1930\n",
      "Epoch 28/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 10.1597 - mae: 2.5897 - mse: 10.1597 - val_loss: 28.5494 - val_mae: 3.8473 - val_mse: 28.5494\n",
      "Epoch 29/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 10.0254 - mae: 2.5334 - mse: 10.0254 - val_loss: 30.0167 - val_mae: 4.1193 - val_mse: 30.0167\n",
      "Epoch 30/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 9.2311 - mae: 2.4080 - mse: 9.2311 - val_loss: 22.2308 - val_mae: 2.6190 - val_mse: 22.2308\n",
      "Epoch 31/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 10.5701 - mae: 2.6441 - mse: 10.5701 - val_loss: 22.6956 - val_mae: 2.6372 - val_mse: 22.6956\n",
      "Epoch 32/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 10.0391 - mae: 2.5525 - mse: 10.0391 - val_loss: 35.0524 - val_mae: 4.8502 - val_mse: 35.0524\n",
      "Epoch 33/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 9.5766 - mae: 2.5032 - mse: 9.5766 - val_loss: 19.7291 - val_mae: 2.4437 - val_mse: 19.7291\n",
      "Epoch 34/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 9.4381 - mae: 2.4850 - mse: 9.4381 - val_loss: 19.9580 - val_mae: 2.4019 - val_mse: 19.9580\n",
      "Epoch 35/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 10.2058 - mae: 2.5250 - mse: 10.2058 - val_loss: 19.7057 - val_mae: 2.3937 - val_mse: 19.7057\n",
      "Epoch 36/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 9.0895 - mae: 2.4504 - mse: 9.0895 - val_loss: 38.8326 - val_mae: 4.8296 - val_mse: 38.8326\n",
      "Epoch 37/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 9.7157 - mae: 2.4793 - mse: 9.7157 - val_loss: 23.8453 - val_mae: 2.9522 - val_mse: 23.8453\n",
      "Epoch 38/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 9.3554 - mae: 2.5078 - mse: 9.3554 - val_loss: 27.7496 - val_mae: 3.5166 - val_mse: 27.7496\n",
      "Epoch 39/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 9.2150 - mae: 2.4940 - mse: 9.2150 - val_loss: 19.6982 - val_mae: 2.7468 - val_mse: 19.6982\n",
      "Epoch 40/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 9.8177 - mae: 2.4614 - mse: 9.8177 - val_loss: 24.2897 - val_mae: 3.5412 - val_mse: 24.2897\n",
      "Epoch 41/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 7.5958 - mae: 2.1499 - mse: 7.5958 - val_loss: 22.2344 - val_mae: 3.2265 - val_mse: 22.2344\n",
      "Epoch 42/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 9.3150 - mae: 2.4877 - mse: 9.3150 - val_loss: 27.5846 - val_mae: 4.0854 - val_mse: 27.5846\n",
      "Epoch 43/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 9.4326 - mae: 2.5434 - mse: 9.4326 - val_loss: 24.1398 - val_mae: 3.5859 - val_mse: 24.1398\n",
      "Epoch 44/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 8.0536 - mae: 2.2403 - mse: 8.0536 - val_loss: 19.6066 - val_mae: 2.7604 - val_mse: 19.6066\n",
      "Epoch 45/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 7.9092 - mae: 2.2750 - mse: 7.9092 - val_loss: 18.8123 - val_mae: 2.5839 - val_mse: 18.8123\n",
      "Epoch 46/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 9.8014 - mae: 2.5613 - mse: 9.8014 - val_loss: 18.8438 - val_mae: 2.6676 - val_mse: 18.8438\n",
      "Epoch 47/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 7.9546 - mae: 2.3220 - mse: 7.9546 - val_loss: 20.9872 - val_mae: 2.6435 - val_mse: 20.9872\n",
      "Epoch 48/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 9.2604 - mae: 2.4845 - mse: 9.2604 - val_loss: 20.4660 - val_mae: 2.6656 - val_mse: 20.4660\n",
      "Epoch 49/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 8.7433 - mae: 2.4447 - mse: 8.7433 - val_loss: 19.6012 - val_mae: 2.5105 - val_mse: 19.6013\n",
      "Epoch 50/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 9.0267 - mae: 2.5365 - mse: 9.0267 - val_loss: 18.7689 - val_mae: 2.3851 - val_mse: 18.7689\n",
      "Epoch 51/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 7.2078 - mae: 2.1668 - mse: 7.2078 - val_loss: 19.9814 - val_mae: 2.5654 - val_mse: 19.9814\n",
      "Epoch 52/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 8.8071 - mae: 2.3835 - mse: 8.8071 - val_loss: 17.3614 - val_mae: 2.4353 - val_mse: 17.3614\n",
      "Epoch 53/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 8.2119 - mae: 2.3684 - mse: 8.2119 - val_loss: 18.0468 - val_mae: 2.6606 - val_mse: 18.0468\n",
      "Epoch 54/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 8.5192 - mae: 2.4008 - mse: 8.5192 - val_loss: 16.6367 - val_mae: 2.2427 - val_mse: 16.6367\n",
      "Epoch 55/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 7.1434 - mae: 2.1735 - mse: 7.1434 - val_loss: 22.7664 - val_mae: 3.5995 - val_mse: 22.7664\n",
      "Epoch 56/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 7.3646 - mae: 2.1323 - mse: 7.3646 - val_loss: 16.7928 - val_mae: 2.3498 - val_mse: 16.7928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 8.0228 - mae: 2.3410 - mse: 8.0228 - val_loss: 16.0951 - val_mae: 2.1873 - val_mse: 16.0951\n",
      "Epoch 58/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 8.4793 - mae: 2.3880 - mse: 8.4793 - val_loss: 16.1611 - val_mae: 2.2830 - val_mse: 16.1611\n",
      "Epoch 59/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 6.9983 - mae: 2.0763 - mse: 6.9983 - val_loss: 24.0616 - val_mae: 3.3878 - val_mse: 24.0616\n",
      "Epoch 60/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 7.2834 - mae: 2.2307 - mse: 7.2834 - val_loss: 24.4267 - val_mae: 3.4434 - val_mse: 24.4267\n",
      "Epoch 61/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 7.4153 - mae: 2.2709 - mse: 7.4153 - val_loss: 17.7283 - val_mae: 2.4126 - val_mse: 17.7283\n",
      "Epoch 62/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 7.5842 - mae: 2.2659 - mse: 7.5842 - val_loss: 17.6862 - val_mae: 2.7545 - val_mse: 17.6862\n",
      "Epoch 63/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 7.8233 - mae: 2.3035 - mse: 7.8233 - val_loss: 20.8131 - val_mae: 3.3016 - val_mse: 20.8131\n",
      "Epoch 64/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 7.1412 - mae: 2.2193 - mse: 7.1412 - val_loss: 24.3705 - val_mae: 3.8943 - val_mse: 24.3705\n",
      "Epoch 65/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 7.5120 - mae: 2.3087 - mse: 7.5120 - val_loss: 17.3031 - val_mae: 2.6681 - val_mse: 17.3031\n",
      "Epoch 66/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 7.5379 - mae: 2.2848 - mse: 7.5379 - val_loss: 20.2588 - val_mae: 3.2666 - val_mse: 20.2588\n",
      "Epoch 67/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 6.1428 - mae: 1.9419 - mse: 6.1428 - val_loss: 20.2872 - val_mae: 2.7773 - val_mse: 20.2872\n",
      "Epoch 68/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 8.0286 - mae: 2.3370 - mse: 8.0286 - val_loss: 18.9273 - val_mae: 2.5658 - val_mse: 18.9273\n",
      "Epoch 69/500\n",
      "812/812 [==============================] - 0s 57us/sample - loss: 7.3032 - mae: 2.2684 - mse: 7.3032 - val_loss: 18.0764 - val_mae: 2.5156 - val_mse: 18.0764\n",
      "Epoch 70/500\n",
      "812/812 [==============================] - 0s 46us/sample - loss: 5.5877 - mae: 1.8509 - mse: 5.5877 - val_loss: 17.3597 - val_mae: 2.4321 - val_mse: 17.3597\n",
      "Epoch 71/500\n",
      "812/812 [==============================] - 0s 45us/sample - loss: 7.5632 - mae: 2.2586 - mse: 7.5632 - val_loss: 17.0463 - val_mae: 2.3064 - val_mse: 17.0463\n",
      "Epoch 72/500\n",
      "812/812 [==============================] - 0s 45us/sample - loss: 6.6760 - mae: 2.1429 - mse: 6.6760 - val_loss: 16.6567 - val_mae: 2.3209 - val_mse: 16.6567\n",
      "Epoch 73/500\n",
      "812/812 [==============================] - 0s 46us/sample - loss: 6.5469 - mae: 2.0971 - mse: 6.5469 - val_loss: 15.4765 - val_mae: 2.1497 - val_mse: 15.4765\n",
      "Epoch 74/500\n",
      "812/812 [==============================] - 0s 47us/sample - loss: 7.2243 - mae: 2.1512 - mse: 7.2243 - val_loss: 16.5402 - val_mae: 2.2229 - val_mse: 16.5402\n",
      "Epoch 75/500\n",
      "812/812 [==============================] - 0s 47us/sample - loss: 6.5721 - mae: 2.0859 - mse: 6.5721 - val_loss: 16.7571 - val_mae: 2.3108 - val_mse: 16.7570\n",
      "Epoch 76/500\n",
      "812/812 [==============================] - 0s 46us/sample - loss: 6.5273 - mae: 2.1361 - mse: 6.5273 - val_loss: 16.6949 - val_mae: 2.2955 - val_mse: 16.6949\n",
      "Epoch 77/500\n",
      "812/812 [==============================] - 0s 46us/sample - loss: 6.5391 - mae: 2.1488 - mse: 6.5391 - val_loss: 15.5476 - val_mae: 2.1317 - val_mse: 15.5476\n",
      "Epoch 78/500\n",
      "812/812 [==============================] - 0s 45us/sample - loss: 5.5241 - mae: 1.7919 - mse: 5.5241 - val_loss: 15.5254 - val_mae: 2.4544 - val_mse: 15.5254\n",
      "Epoch 79/500\n",
      "812/812 [==============================] - 0s 46us/sample - loss: 7.4038 - mae: 2.2498 - mse: 7.4038 - val_loss: 17.8812 - val_mae: 2.8445 - val_mse: 17.8812\n",
      "Epoch 80/500\n",
      "812/812 [==============================] - 0s 46us/sample - loss: 6.5919 - mae: 2.1516 - mse: 6.5919 - val_loss: 16.2223 - val_mae: 2.5658 - val_mse: 16.2223\n",
      "Epoch 81/500\n",
      "812/812 [==============================] - 0s 45us/sample - loss: 5.9888 - mae: 1.9920 - mse: 5.9888 - val_loss: 15.9122 - val_mae: 2.4060 - val_mse: 15.9122\n",
      "Epoch 82/500\n",
      "812/812 [==============================] - 0s 45us/sample - loss: 6.4435 - mae: 2.0391 - mse: 6.4435 - val_loss: 14.6703 - val_mae: 2.0383 - val_mse: 14.6703\n",
      "Epoch 83/500\n",
      "812/812 [==============================] - 0s 46us/sample - loss: 6.9230 - mae: 2.1216 - mse: 6.9230 - val_loss: 16.5371 - val_mae: 2.1897 - val_mse: 16.5371\n",
      "Epoch 84/500\n",
      "812/812 [==============================] - 0s 46us/sample - loss: 5.9291 - mae: 2.0353 - mse: 5.9291 - val_loss: 14.6535 - val_mae: 2.0049 - val_mse: 14.6535\n",
      "Epoch 85/500\n",
      "812/812 [==============================] - 0s 47us/sample - loss: 6.0675 - mae: 2.0301 - mse: 6.0675 - val_loss: 18.2484 - val_mae: 2.5805 - val_mse: 18.2484\n",
      "Epoch 86/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 6.8432 - mae: 2.1858 - mse: 6.8432 - val_loss: 16.7790 - val_mae: 2.3390 - val_mse: 16.7790\n",
      "Epoch 87/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 6.4238 - mae: 2.0561 - mse: 6.4238 - val_loss: 14.6543 - val_mae: 2.1153 - val_mse: 14.6543\n",
      "Epoch 88/500\n",
      "812/812 [==============================] - 0s 71us/sample - loss: 5.8606 - mae: 1.9949 - mse: 5.8606 - val_loss: 16.0276 - val_mae: 2.5234 - val_mse: 16.0276\n",
      "Epoch 89/500\n",
      "812/812 [==============================] - 0s 58us/sample - loss: 5.7243 - mae: 1.9736 - mse: 5.7243 - val_loss: 16.1314 - val_mae: 2.2336 - val_mse: 16.1314\n",
      "Epoch 90/500\n",
      "812/812 [==============================] - 0s 57us/sample - loss: 6.7618 - mae: 2.1680 - mse: 6.7618 - val_loss: 16.6137 - val_mae: 2.4265 - val_mse: 16.6137\n",
      "Epoch 91/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 5.2414 - mae: 1.8250 - mse: 5.2414 - val_loss: 21.8405 - val_mae: 3.3129 - val_mse: 21.8405\n",
      "Epoch 92/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 5.9679 - mae: 2.0352 - mse: 5.9679 - val_loss: 19.8800 - val_mae: 2.9845 - val_mse: 19.8800\n",
      "Epoch 93/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 6.4631 - mae: 2.1203 - mse: 6.4631 - val_loss: 23.3763 - val_mae: 3.4821 - val_mse: 23.3763\n",
      "Epoch 94/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 5.6315 - mae: 1.8970 - mse: 5.6315 - val_loss: 19.6632 - val_mae: 2.8503 - val_mse: 19.6632\n",
      "Epoch 95/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 6.7204 - mae: 2.1118 - mse: 6.7204 - val_loss: 14.8476 - val_mae: 2.0015 - val_mse: 14.8476\n",
      "Epoch 96/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 6.0522 - mae: 2.0222 - mse: 6.0522 - val_loss: 19.4752 - val_mae: 2.9540 - val_mse: 19.4752\n",
      "Epoch 97/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 5.1413 - mae: 1.8001 - mse: 5.1413 - val_loss: 21.7417 - val_mae: 3.2983 - val_mse: 21.7417\n",
      "Epoch 98/500\n",
      "812/812 [==============================] - 0s 58us/sample - loss: 6.2037 - mae: 2.0548 - mse: 6.2037 - val_loss: 15.4440 - val_mae: 2.5634 - val_mse: 15.4440\n",
      "Epoch 99/500\n",
      "812/812 [==============================] - 0s 59us/sample - loss: 5.0512 - mae: 1.8198 - mse: 5.0512 - val_loss: 15.0854 - val_mae: 2.0952 - val_mse: 15.0854\n",
      "Epoch 100/500\n",
      "812/812 [==============================] - 0s 56us/sample - loss: 6.5032 - mae: 2.1409 - mse: 6.5032 - val_loss: 14.2441 - val_mae: 2.1305 - val_mse: 14.2441\n",
      "Epoch 101/500\n",
      "812/812 [==============================] - 0s 56us/sample - loss: 4.7764 - mae: 1.7408 - mse: 4.7764 - val_loss: 16.4008 - val_mae: 2.6408 - val_mse: 16.4008\n",
      "Epoch 102/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 6.1628 - mae: 2.0390 - mse: 6.1628 - val_loss: 13.9679 - val_mae: 2.0231 - val_mse: 13.9679\n",
      "Epoch 103/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 5.4804 - mae: 1.9319 - mse: 5.4804 - val_loss: 23.2880 - val_mae: 3.8600 - val_mse: 23.2880\n",
      "Epoch 104/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 5.6062 - mae: 1.9501 - mse: 5.6062 - val_loss: 14.3165 - val_mae: 2.0646 - val_mse: 14.3165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 5.7620 - mae: 2.0246 - mse: 5.7620 - val_loss: 15.5547 - val_mae: 2.5381 - val_mse: 15.5547\n",
      "Epoch 106/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 5.3659 - mae: 1.9083 - mse: 5.3659 - val_loss: 15.1767 - val_mae: 2.4575 - val_mse: 15.1767\n",
      "Epoch 107/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 5.5708 - mae: 1.9302 - mse: 5.5708 - val_loss: 15.3741 - val_mae: 2.5561 - val_mse: 15.3741\n",
      "Epoch 108/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 5.6362 - mae: 1.9823 - mse: 5.6362 - val_loss: 15.6195 - val_mae: 2.5970 - val_mse: 15.6195\n",
      "Epoch 109/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 5.2602 - mae: 1.9088 - mse: 5.2602 - val_loss: 13.8466 - val_mae: 2.1055 - val_mse: 13.8466\n",
      "Epoch 110/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 5.4961 - mae: 1.8789 - mse: 5.4961 - val_loss: 14.0823 - val_mae: 1.9572 - val_mse: 14.0823\n",
      "Epoch 111/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 4.5250 - mae: 1.6298 - mse: 4.5250 - val_loss: 14.2060 - val_mae: 2.2049 - val_mse: 14.2060\n",
      "Epoch 112/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 5.9368 - mae: 1.9580 - mse: 5.9368 - val_loss: 14.0933 - val_mae: 2.1090 - val_mse: 14.0933\n",
      "Epoch 113/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 4.2870 - mae: 1.6424 - mse: 4.2870 - val_loss: 18.7316 - val_mae: 2.7493 - val_mse: 18.7316\n",
      "Epoch 114/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 5.7949 - mae: 1.9979 - mse: 5.7949 - val_loss: 13.8843 - val_mae: 1.8978 - val_mse: 13.8843\n",
      "Epoch 115/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 5.1826 - mae: 1.8460 - mse: 5.1826 - val_loss: 17.4818 - val_mae: 2.4743 - val_mse: 17.4818\n",
      "Epoch 116/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 4.9949 - mae: 1.8258 - mse: 4.9949 - val_loss: 22.0414 - val_mae: 3.4002 - val_mse: 22.0414\n",
      "Epoch 117/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 5.0127 - mae: 1.8135 - mse: 5.0127 - val_loss: 16.6159 - val_mae: 2.7325 - val_mse: 16.6159\n",
      "Epoch 118/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 4.6183 - mae: 1.7088 - mse: 4.6183 - val_loss: 21.1862 - val_mae: 3.5735 - val_mse: 21.1862\n",
      "Epoch 119/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 4.8764 - mae: 1.8029 - mse: 4.8764 - val_loss: 13.6301 - val_mae: 2.0465 - val_mse: 13.6301\n",
      "Epoch 120/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 5.6022 - mae: 1.9411 - mse: 5.6022 - val_loss: 15.4468 - val_mae: 2.5036 - val_mse: 15.4468\n",
      "Epoch 121/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 5.0030 - mae: 1.8722 - mse: 5.0030 - val_loss: 14.4002 - val_mae: 2.2646 - val_mse: 14.4002\n",
      "Epoch 122/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 4.8337 - mae: 1.7613 - mse: 4.8337 - val_loss: 21.7371 - val_mae: 3.2776 - val_mse: 21.7371\n",
      "Epoch 123/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 4.8034 - mae: 1.8206 - mse: 4.8034 - val_loss: 19.3884 - val_mae: 2.8324 - val_mse: 19.3884\n",
      "Epoch 124/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 4.7787 - mae: 1.8017 - mse: 4.7787 - val_loss: 20.0091 - val_mae: 3.0075 - val_mse: 20.0091\n",
      "Epoch 125/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 5.2177 - mae: 1.8150 - mse: 5.2177 - val_loss: 15.1101 - val_mae: 2.0578 - val_mse: 15.1101\n",
      "Epoch 126/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 4.6329 - mae: 1.7888 - mse: 4.6329 - val_loss: 18.1007 - val_mae: 2.6141 - val_mse: 18.1007\n",
      "Epoch 127/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 4.7264 - mae: 1.7920 - mse: 4.7264 - val_loss: 15.0936 - val_mae: 2.1052 - val_mse: 15.0936\n",
      "Epoch 128/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 5.1462 - mae: 1.8482 - mse: 5.1462 - val_loss: 13.1228 - val_mae: 1.8888 - val_mse: 13.1228\n",
      "Epoch 129/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 4.5574 - mae: 1.7423 - mse: 4.5574 - val_loss: 17.2215 - val_mae: 2.5778 - val_mse: 17.2215\n",
      "Epoch 130/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 4.9623 - mae: 1.8358 - mse: 4.9623 - val_loss: 18.8518 - val_mae: 2.8671 - val_mse: 18.8518\n",
      "Epoch 131/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 5.0866 - mae: 1.8679 - mse: 5.0866 - val_loss: 15.6082 - val_mae: 2.1713 - val_mse: 15.6082\n",
      "Epoch 132/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 3.8492 - mae: 1.5449 - mse: 3.8492 - val_loss: 17.8479 - val_mae: 2.6080 - val_mse: 17.8479\n",
      "Epoch 133/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 5.1852 - mae: 1.8447 - mse: 5.1852 - val_loss: 16.8988 - val_mae: 2.3931 - val_mse: 16.8988\n",
      "Epoch 134/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 5.1711 - mae: 1.8563 - mse: 5.1711 - val_loss: 14.6215 - val_mae: 2.4664 - val_mse: 14.6215\n",
      "Epoch 135/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 4.1597 - mae: 1.6340 - mse: 4.1597 - val_loss: 17.4951 - val_mae: 3.0283 - val_mse: 17.4951\n",
      "Epoch 136/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 5.0653 - mae: 1.8666 - mse: 5.0653 - val_loss: 14.0760 - val_mae: 2.2386 - val_mse: 14.0760\n",
      "Epoch 137/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 4.2963 - mae: 1.7008 - mse: 4.2963 - val_loss: 16.0072 - val_mae: 2.7745 - val_mse: 16.0072\n",
      "Epoch 138/500\n",
      "812/812 [==============================] - 0s 55us/sample - loss: 5.0263 - mae: 1.8845 - mse: 5.0263 - val_loss: 15.9495 - val_mae: 2.6047 - val_mse: 15.9495\n",
      "Epoch 139/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 4.2847 - mae: 1.6796 - mse: 4.2847 - val_loss: 19.0781 - val_mae: 3.4196 - val_mse: 19.0781\n",
      "Epoch 140/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 4.6623 - mae: 1.7842 - mse: 4.6623 - val_loss: 15.7302 - val_mae: 2.6645 - val_mse: 15.7302\n",
      "Epoch 141/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 4.3140 - mae: 1.6989 - mse: 4.3140 - val_loss: 13.3306 - val_mae: 2.0349 - val_mse: 13.3306\n",
      "Epoch 142/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 4.9300 - mae: 1.8267 - mse: 4.9300 - val_loss: 13.3355 - val_mae: 2.0727 - val_mse: 13.3355\n",
      "Epoch 143/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 3.4145 - mae: 1.4411 - mse: 3.4145 - val_loss: 14.3531 - val_mae: 2.3320 - val_mse: 14.3531\n",
      "Epoch 144/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 4.9605 - mae: 1.7807 - mse: 4.9605 - val_loss: 13.4469 - val_mae: 1.9749 - val_mse: 13.4469\n",
      "Epoch 145/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 3.8967 - mae: 1.5529 - mse: 3.8967 - val_loss: 24.7063 - val_mae: 3.7122 - val_mse: 24.7063\n",
      "Epoch 146/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 5.2821 - mae: 1.8617 - mse: 5.2821 - val_loss: 13.5023 - val_mae: 2.0659 - val_mse: 13.5023\n",
      "Epoch 147/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 3.9605 - mae: 1.6112 - mse: 3.9605 - val_loss: 16.5622 - val_mae: 2.9181 - val_mse: 16.5622\n",
      "Epoch 148/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 4.7363 - mae: 1.8073 - mse: 4.7363 - val_loss: 13.9400 - val_mae: 2.1369 - val_mse: 13.9400\n",
      "Epoch 149/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 4.0696 - mae: 1.5996 - mse: 4.0696 - val_loss: 17.4270 - val_mae: 3.0529 - val_mse: 17.4270\n",
      "Epoch 150/500\n",
      "812/812 [==============================] - 0s 55us/sample - loss: 4.4289 - mae: 1.7393 - mse: 4.4289 - val_loss: 14.8835 - val_mae: 2.4625 - val_mse: 14.8835\n",
      "Epoch 151/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 3.8773 - mae: 1.5289 - mse: 3.8773 - val_loss: 17.2069 - val_mae: 2.9329 - val_mse: 17.2069\n",
      "Epoch 152/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 4.7293 - mae: 1.8087 - mse: 4.7293 - val_loss: 15.2418 - val_mae: 2.4411 - val_mse: 15.2418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 4.0861 - mae: 1.6665 - mse: 4.0861 - val_loss: 16.0190 - val_mae: 2.7500 - val_mse: 16.0190\n",
      "Epoch 154/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 4.3255 - mae: 1.7206 - mse: 4.3255 - val_loss: 13.9073 - val_mae: 2.1335 - val_mse: 13.9073\n",
      "Epoch 155/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 4.1446 - mae: 1.5990 - mse: 4.1446 - val_loss: 19.2824 - val_mae: 3.0463 - val_mse: 19.2824\n",
      "Epoch 156/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 3.8701 - mae: 1.5780 - mse: 3.8701 - val_loss: 13.8982 - val_mae: 1.9939 - val_mse: 13.8982\n",
      "Epoch 157/500\n",
      "812/812 [==============================] - 0s 52us/sample - loss: 4.3109 - mae: 1.6910 - mse: 4.3109 - val_loss: 14.5120 - val_mae: 2.4461 - val_mse: 14.5120\n",
      "Epoch 158/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 3.9336 - mae: 1.5995 - mse: 3.9336 - val_loss: 13.9248 - val_mae: 1.9322 - val_mse: 13.9248\n",
      "Epoch 159/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 4.2982 - mae: 1.6988 - mse: 4.2982 - val_loss: 19.9543 - val_mae: 2.9737 - val_mse: 19.9543\n",
      "Epoch 160/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 3.9559 - mae: 1.5930 - mse: 3.9559 - val_loss: 16.6498 - val_mae: 2.8992 - val_mse: 16.6498\n",
      "Epoch 161/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 4.4498 - mae: 1.7464 - mse: 4.4498 - val_loss: 14.0661 - val_mae: 2.3052 - val_mse: 14.0661\n",
      "Epoch 162/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 4.4227 - mae: 1.6974 - mse: 4.4227 - val_loss: 16.5371 - val_mae: 2.5398 - val_mse: 16.5371\n",
      "Epoch 163/500\n",
      "812/812 [==============================] - 0s 55us/sample - loss: 4.2663 - mae: 1.6669 - mse: 4.2663 - val_loss: 13.8867 - val_mae: 2.2123 - val_mse: 13.8867\n",
      "Epoch 164/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 3.7200 - mae: 1.5166 - mse: 3.7200 - val_loss: 15.1126 - val_mae: 2.5582 - val_mse: 15.1126\n",
      "Epoch 165/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 4.2058 - mae: 1.6947 - mse: 4.2058 - val_loss: 14.1305 - val_mae: 2.3403 - val_mse: 14.1305\n",
      "Epoch 166/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 4.0793 - mae: 1.6939 - mse: 4.0793 - val_loss: 14.2082 - val_mae: 2.4333 - val_mse: 14.2082\n",
      "Epoch 167/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 4.0899 - mae: 1.6647 - mse: 4.0899 - val_loss: 14.8771 - val_mae: 2.2285 - val_mse: 14.8771\n",
      "Epoch 168/500\n",
      "812/812 [==============================] - 0s 55us/sample - loss: 3.9490 - mae: 1.6136 - mse: 3.9490 - val_loss: 20.4801 - val_mae: 3.1195 - val_mse: 20.4801\n",
      "Epoch 169/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 3.8090 - mae: 1.5862 - mse: 3.8090 - val_loss: 20.3337 - val_mae: 3.1237 - val_mse: 20.3337\n",
      "Epoch 170/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 4.0021 - mae: 1.6149 - mse: 4.0021 - val_loss: 16.0122 - val_mae: 2.3964 - val_mse: 16.0122\n",
      "Epoch 171/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 3.9721 - mae: 1.6355 - mse: 3.9721 - val_loss: 15.6295 - val_mae: 2.2941 - val_mse: 15.6295\n",
      "Epoch 172/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 4.2692 - mae: 1.7135 - mse: 4.2692 - val_loss: 14.9447 - val_mae: 2.0644 - val_mse: 14.9447\n",
      "Epoch 173/500\n",
      "812/812 [==============================] - 0s 51us/sample - loss: 3.7128 - mae: 1.5232 - mse: 3.7128 - val_loss: 15.5136 - val_mae: 2.7827 - val_mse: 15.5136\n",
      "Epoch 174/500\n",
      "812/812 [==============================] - 0s 49us/sample - loss: 4.1675 - mae: 1.6690 - mse: 4.1675 - val_loss: 13.6926 - val_mae: 2.2138 - val_mse: 13.6926\n",
      "Epoch 175/500\n",
      "812/812 [==============================] - 0s 50us/sample - loss: 3.9603 - mae: 1.6493 - mse: 3.9603 - val_loss: 14.8298 - val_mae: 2.3427 - val_mse: 14.8298\n",
      "Epoch 176/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 3.8632 - mae: 1.5965 - mse: 3.8632 - val_loss: 13.6155 - val_mae: 2.2996 - val_mse: 13.6155\n",
      "Epoch 177/500\n",
      "812/812 [==============================] - 0s 54us/sample - loss: 3.8307 - mae: 1.5972 - mse: 3.8307 - val_loss: 14.3527 - val_mae: 2.2582 - val_mse: 14.3527\n",
      "Epoch 178/500\n",
      "812/812 [==============================] - 0s 53us/sample - loss: 3.9145 - mae: 1.6135 - mse: 3.9145 - val_loss: 13.4613 - val_mae: 2.2249 - val_mse: 13.4613\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for f in range(1, 11, 1):\n",
    "    frac = f / 10.0\n",
    "    sample = data_grouped.sample(frac=frac, random_state=12345)\n",
    "    sample_grouped = sample.groupby([\"location\", pd.Grouper(key=\"time\", freq=\"1s\")]).mean().reset_index()\n",
    "    train, validation, test = train_validation_test_split(sample_grouped)\n",
    "\n",
    "    train.sort_values(\"time\", inplace=True)\n",
    "    validation.sort_values(\"time\", inplace=True)\n",
    "    test.sort_values(\"time\", inplace=True)\n",
    "\n",
    "    train_imputed = train.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    train_imputed.fillna(0, inplace=True)\n",
    "    train_imputed.reset_index(inplace=True)\n",
    "\n",
    "    validation_imputed = validation.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    validation_imputed.fillna(0, inplace=True)\n",
    "    validation_imputed.reset_index(inplace=True)\n",
    "\n",
    "    test_imputed = test.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    test_imputed.fillna(0, inplace=True)\n",
    "    test_imputed.reset_index(inplace=True)\n",
    "\n",
    "    train_imputed[\"X\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "    train_imputed[\"Y\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])\n",
    "\n",
    "    validation_imputed[\"X\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "    validation_imputed[\"Y\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])\n",
    "\n",
    "    test_imputed[\"X\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "    test_imputed[\"Y\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])\n",
    "\n",
    "    X_train, y_train = train_imputed[scanners].values, train_imputed[[\"X\", \"Y\"]].values\n",
    "    X_validation, y_validation = validation_imputed[scanners].values, validation_imputed[[\"X\", \"Y\"]].values\n",
    "    X_test, y_test = test_imputed[scanners].values, test_imputed[[\"X\", \"Y\"]].values\n",
    "\n",
    "    model = MLP()\n",
    "    history = model.fit(X_train, y_train, X_validation, y_validation)\n",
    "    train_loss.append(history.history['loss'][-1])\n",
    "    val_loss.append(history.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.1, 1.1, 0.1)\n",
    "plt.plot(x, train_loss, label='Training loss')\n",
    "plt.plot(x, val_loss, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Dataset size\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
