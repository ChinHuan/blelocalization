{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width: 98% !important }<style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 98% !important }<style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "from models import *\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_file = \"../Data/pin.csv\"\n",
    "\n",
    "pin = read_pin(pin_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All beacons: ['0117C55D14E4']\n",
      "Selecting 0117C55D14E4\n"
     ]
    }
   ],
   "source": [
    "filename = \"../Data/rssi4.csv\"\n",
    "B1 = \"0117C55D14E4\"\n",
    "\n",
    "data = read_data(filename, B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[scanners] = minMaxScaling(data[scanners])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped = data.groupby([\"location\", pd.Grouper(key=\"time\", freq=\"1s\")]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Validation Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = train_validation_test_split(data_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C400A2E19293</th>\n",
       "      <th>CD4533FFC0E1</th>\n",
       "      <th>D2B6503554D7</th>\n",
       "      <th>DB8B36A69C56</th>\n",
       "      <th>DD697EA75B68</th>\n",
       "      <th>DF231643E227</th>\n",
       "      <th>E13B805C6CB0</th>\n",
       "      <th>E43355CA8B96</th>\n",
       "      <th>E6D9D20DD197</th>\n",
       "      <th>E8FD0B453DC4</th>\n",
       "      <th>E96AF2C858BA</th>\n",
       "      <th>EC72840D9AD3</th>\n",
       "      <th>F1307ECB3B90</th>\n",
       "      <th>F1EDAF28E08A</th>\n",
       "      <th>F69A86823B96</th>\n",
       "      <th>FB2EE01C18CE</th>\n",
       "      <th>FDAE5980F28C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1_11</th>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>41</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>52</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_12</th>\n",
       "      <td>53</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>64</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>41</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_13</th>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_14</th>\n",
       "      <td>27</td>\n",
       "      <td>64</td>\n",
       "      <td>34</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "      <td>62</td>\n",
       "      <td>39</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_20</th>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_21</th>\n",
       "      <td>44</td>\n",
       "      <td>57</td>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>39</td>\n",
       "      <td>63</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_22</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>38</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>64</td>\n",
       "      <td>67</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>66</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_23</th>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>73</td>\n",
       "      <td>63</td>\n",
       "      <td>34</td>\n",
       "      <td>76</td>\n",
       "      <td>23</td>\n",
       "      <td>64</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_24</th>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>31</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_28</th>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_29</th>\n",
       "      <td>36</td>\n",
       "      <td>61</td>\n",
       "      <td>55</td>\n",
       "      <td>38</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>26</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_30</th>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>72</td>\n",
       "      <td>69</td>\n",
       "      <td>24</td>\n",
       "      <td>75</td>\n",
       "      <td>17</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_31</th>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>57</td>\n",
       "      <td>47</td>\n",
       "      <td>18</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_32</th>\n",
       "      <td>27</td>\n",
       "      <td>52</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>28</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>69</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          C400A2E19293  CD4533FFC0E1  D2B6503554D7  DB8B36A69C56  \\\n",
       "location                                                           \n",
       "V1_11               37            46            38            48   \n",
       "V1_12               53            43            36            56   \n",
       "V1_13               39            55            37            50   \n",
       "V1_14               27            64            34            42   \n",
       "V1_20               61            58            56            53   \n",
       "V1_21               44            57            39            48   \n",
       "V1_22               45            45            38            46   \n",
       "V1_23               40            47            42            37   \n",
       "V1_24               16            37            39            34   \n",
       "V1_28               47            44            48            35   \n",
       "V1_29               36            61            55            38   \n",
       "V1_30               25            49            42            26   \n",
       "V1_31               17            39            32            38   \n",
       "V1_32               27            52            39            35   \n",
       "\n",
       "          DD697EA75B68  DF231643E227  E13B805C6CB0  E43355CA8B96  \\\n",
       "location                                                           \n",
       "V1_11               49            47            41            49   \n",
       "V1_12               53            52            35            37   \n",
       "V1_13               31            44            48            48   \n",
       "V1_14               37            49            62            39   \n",
       "V1_20               56            53            45            44   \n",
       "V1_21               54            48            58            39   \n",
       "V1_22               41            64            67            24   \n",
       "V1_23               26            73            63            34   \n",
       "V1_24               30            47            47            31   \n",
       "V1_28               46            38            43            41   \n",
       "V1_29               48            47            61            38   \n",
       "V1_30               42            72            69            24   \n",
       "V1_31               34            57            47            18   \n",
       "V1_32               36            60            62            28   \n",
       "\n",
       "          E6D9D20DD197  E8FD0B453DC4  E96AF2C858BA  EC72840D9AD3  \\\n",
       "location                                                           \n",
       "V1_11               45            31            38            52   \n",
       "V1_12               64            38            43            65   \n",
       "V1_13               67            11            31            50   \n",
       "V1_14               65             9            64            32   \n",
       "V1_20               47            25            40            51   \n",
       "V1_21               63            18            48            49   \n",
       "V1_22               64            24            66            43   \n",
       "V1_23               76            23            64            43   \n",
       "V1_24               64            15            56            33   \n",
       "V1_28               47            40            35            39   \n",
       "V1_29               57            26            49            42   \n",
       "V1_30               75            17            52            48   \n",
       "V1_31               59             6            67            35   \n",
       "V1_32               72            17            69            43   \n",
       "\n",
       "          F1307ECB3B90  F1EDAF28E08A  F69A86823B96  FB2EE01C18CE  FDAE5980F28C  \n",
       "location                                                                        \n",
       "V1_11               51            19            18            19            43  \n",
       "V1_12               64            41            53            40            44  \n",
       "V1_13               48            50            51            13            41  \n",
       "V1_14               49            40            52            41            46  \n",
       "V1_20               67            11            38            19            41  \n",
       "V1_21               43            41            41            37            39  \n",
       "V1_22               36             7            53            51            32  \n",
       "V1_23               48             7            59            55            31  \n",
       "V1_24               42            16            36            51            17  \n",
       "V1_28               34            47            37            24            45  \n",
       "V1_29               57            27            48            58            43  \n",
       "V1_30               34            15            40            56            43  \n",
       "V1_31               35             7            47            60            34  \n",
       "V1_32               32            11            35            58            52  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(\"location\")[scanners].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(\"time\", inplace=True)\n",
    "validation.sort_values(\"time\", inplace=True)\n",
    "test.sort_values(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "1. Forward fill\n",
    "2. Fill NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imputed = train.set_index(\"location\").groupby(\"location\").ffill()\n",
    "train_imputed.fillna(0, inplace=True)\n",
    "train_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_imputed = validation.set_index(\"location\").groupby(\"location\").ffill()\n",
    "validation_imputed.fillna(0, inplace=True)\n",
    "validation_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imputed = test.set_index(\"location\").groupby(\"location\").ffill()\n",
    "test_imputed.fillna(0, inplace=True)\n",
    "test_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Label Encoding for Each Fingerprint Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_imputed[scanners].values, train_imputed[\"location\"].values\n",
    "X_validation, y_validation = validation_imputed[scanners].values, validation_imputed[\"location\"].values\n",
    "X_test, y_test = test_imputed[scanners].values, test_imputed[\"location\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "\n",
    "y_train = enc.fit_transform(y_train)\n",
    "y_validation = enc.transform(y_validation)\n",
    "y_test = enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/MLP_Classification_GroupBy_FFill_MinMax_Encoder.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(enc, \"../Models/MLP_Classification_GroupBy_FFill_MinMax_Encoder.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 2,062\n",
      "Trainable params: 2,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(size='small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1030 samples, validate on 344 samples\n",
      "Epoch 1/2000\n",
      "1030/1030 [==============================] - 1s 601us/sample - loss: 2.6631 - accuracy: 0.0845 - val_loss: 2.6036 - val_accuracy: 0.1250\n",
      "Epoch 2/2000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 2.5955 - accuracy: 0.1117 - val_loss: 2.5384 - val_accuracy: 0.2151\n",
      "Epoch 3/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 2.5220 - accuracy: 0.1563 - val_loss: 2.4686 - val_accuracy: 0.2442\n",
      "Epoch 4/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 2.4535 - accuracy: 0.2107 - val_loss: 2.3974 - val_accuracy: 0.3169\n",
      "Epoch 5/2000\n",
      "1030/1030 [==============================] - 0s 58us/sample - loss: 2.3705 - accuracy: 0.2583 - val_loss: 2.3179 - val_accuracy: 0.4535\n",
      "Epoch 6/2000\n",
      "1030/1030 [==============================] - 0s 78us/sample - loss: 2.2974 - accuracy: 0.2767 - val_loss: 2.2397 - val_accuracy: 0.5843\n",
      "Epoch 7/2000\n",
      "1030/1030 [==============================] - 0s 69us/sample - loss: 2.2335 - accuracy: 0.3097 - val_loss: 2.1616 - val_accuracy: 0.5523\n",
      "Epoch 8/2000\n",
      "1030/1030 [==============================] - 0s 71us/sample - loss: 2.1565 - accuracy: 0.3175 - val_loss: 2.0856 - val_accuracy: 0.5901\n",
      "Epoch 9/2000\n",
      "1030/1030 [==============================] - 0s 69us/sample - loss: 2.0856 - accuracy: 0.3738 - val_loss: 2.0143 - val_accuracy: 0.5785\n",
      "Epoch 10/2000\n",
      "1030/1030 [==============================] - 0s 59us/sample - loss: 2.0273 - accuracy: 0.3592 - val_loss: 1.9455 - val_accuracy: 0.6541\n",
      "Epoch 11/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.9571 - accuracy: 0.4184 - val_loss: 1.8875 - val_accuracy: 0.5959\n",
      "Epoch 12/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 1.9115 - accuracy: 0.4252 - val_loss: 1.8272 - val_accuracy: 0.6773\n",
      "Epoch 13/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 1.8559 - accuracy: 0.4262 - val_loss: 1.7791 - val_accuracy: 0.7122\n",
      "Epoch 14/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 1.8255 - accuracy: 0.4524 - val_loss: 1.7238 - val_accuracy: 0.6744\n",
      "Epoch 15/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.7727 - accuracy: 0.4485 - val_loss: 1.6692 - val_accuracy: 0.7587\n",
      "Epoch 16/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 1.7215 - accuracy: 0.4864 - val_loss: 1.6185 - val_accuracy: 0.7558\n",
      "Epoch 17/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.6694 - accuracy: 0.4922 - val_loss: 1.5711 - val_accuracy: 0.7907\n",
      "Epoch 18/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.6442 - accuracy: 0.4786 - val_loss: 1.5264 - val_accuracy: 0.7762\n",
      "Epoch 19/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.5842 - accuracy: 0.5291 - val_loss: 1.4795 - val_accuracy: 0.8140\n",
      "Epoch 20/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 1.5732 - accuracy: 0.5214 - val_loss: 1.4422 - val_accuracy: 0.8052\n",
      "Epoch 21/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 1.5323 - accuracy: 0.5466 - val_loss: 1.3995 - val_accuracy: 0.8023\n",
      "Epoch 22/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.4836 - accuracy: 0.5699 - val_loss: 1.3598 - val_accuracy: 0.8401\n",
      "Epoch 23/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 1.4522 - accuracy: 0.5660 - val_loss: 1.3205 - val_accuracy: 0.8285\n",
      "Epoch 24/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 1.4077 - accuracy: 0.5951 - val_loss: 1.2841 - val_accuracy: 0.8140\n",
      "Epoch 25/2000\n",
      "1030/1030 [==============================] - 0s 38us/sample - loss: 1.3794 - accuracy: 0.6000 - val_loss: 1.2448 - val_accuracy: 0.8488\n",
      "Epoch 26/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 1.3547 - accuracy: 0.6301 - val_loss: 1.2086 - val_accuracy: 0.8547\n",
      "Epoch 27/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 1.3288 - accuracy: 0.6194 - val_loss: 1.1797 - val_accuracy: 0.8605\n",
      "Epoch 28/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 1.2861 - accuracy: 0.6466 - val_loss: 1.1479 - val_accuracy: 0.8576\n",
      "Epoch 29/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 1.2706 - accuracy: 0.6437 - val_loss: 1.1164 - val_accuracy: 0.8953\n",
      "Epoch 30/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 1.2270 - accuracy: 0.6602 - val_loss: 1.0877 - val_accuracy: 0.8605\n",
      "Epoch 31/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 1.2235 - accuracy: 0.6495 - val_loss: 1.0546 - val_accuracy: 0.8692\n",
      "Epoch 32/2000\n",
      "1030/1030 [==============================] - 0s 77us/sample - loss: 1.2001 - accuracy: 0.6748 - val_loss: 1.0298 - val_accuracy: 0.8576\n",
      "Epoch 33/2000\n",
      "1030/1030 [==============================] - 0s 73us/sample - loss: 1.1826 - accuracy: 0.6718 - val_loss: 1.0022 - val_accuracy: 0.8663\n",
      "Epoch 34/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.1518 - accuracy: 0.6874 - val_loss: 0.9842 - val_accuracy: 0.8837\n",
      "Epoch 35/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.1237 - accuracy: 0.6854 - val_loss: 0.9518 - val_accuracy: 0.8953\n",
      "Epoch 36/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 1.0992 - accuracy: 0.7126 - val_loss: 0.9413 - val_accuracy: 0.8837\n",
      "Epoch 37/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.0594 - accuracy: 0.7146 - val_loss: 0.9062 - val_accuracy: 0.8866\n",
      "Epoch 38/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 1.0622 - accuracy: 0.7204 - val_loss: 0.8950 - val_accuracy: 0.8924\n",
      "Epoch 39/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 1.0157 - accuracy: 0.7437 - val_loss: 0.8683 - val_accuracy: 0.8924\n",
      "Epoch 40/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 1.0102 - accuracy: 0.7320 - val_loss: 0.8520 - val_accuracy: 0.8866\n",
      "Epoch 41/2000\n",
      "1030/1030 [==============================] - 0s 74us/sample - loss: 0.9952 - accuracy: 0.7427 - val_loss: 0.8304 - val_accuracy: 0.9099\n",
      "Epoch 42/2000\n",
      "1030/1030 [==============================] - 0s 76us/sample - loss: 0.9776 - accuracy: 0.7456 - val_loss: 0.8107 - val_accuracy: 0.9099\n",
      "Epoch 43/2000\n",
      "1030/1030 [==============================] - 0s 68us/sample - loss: 0.9380 - accuracy: 0.7476 - val_loss: 0.7942 - val_accuracy: 0.9099\n",
      "Epoch 44/2000\n",
      "1030/1030 [==============================] - 0s 72us/sample - loss: 0.9161 - accuracy: 0.7553 - val_loss: 0.7802 - val_accuracy: 0.9041\n",
      "Epoch 45/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.9251 - accuracy: 0.7466 - val_loss: 0.7631 - val_accuracy: 0.9186\n",
      "Epoch 46/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.8834 - accuracy: 0.7699 - val_loss: 0.7467 - val_accuracy: 0.9099\n",
      "Epoch 47/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.9031 - accuracy: 0.7709 - val_loss: 0.7313 - val_accuracy: 0.9128\n",
      "Epoch 48/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.8770 - accuracy: 0.7835 - val_loss: 0.7177 - val_accuracy: 0.9186\n",
      "Epoch 49/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.8513 - accuracy: 0.7961 - val_loss: 0.7093 - val_accuracy: 0.9157\n",
      "Epoch 50/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.8328 - accuracy: 0.7961 - val_loss: 0.6961 - val_accuracy: 0.9186\n",
      "Epoch 51/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.8164 - accuracy: 0.7845 - val_loss: 0.6801 - val_accuracy: 0.9070\n",
      "Epoch 52/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.8102 - accuracy: 0.7971 - val_loss: 0.6659 - val_accuracy: 0.9244\n",
      "Epoch 53/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.8235 - accuracy: 0.7767 - val_loss: 0.6616 - val_accuracy: 0.9186\n",
      "Epoch 54/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.7965 - accuracy: 0.7767 - val_loss: 0.6516 - val_accuracy: 0.9215\n",
      "Epoch 55/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.7932 - accuracy: 0.7942 - val_loss: 0.6419 - val_accuracy: 0.9273\n",
      "Epoch 56/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.7794 - accuracy: 0.8117 - val_loss: 0.6256 - val_accuracy: 0.9244\n",
      "Epoch 57/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.7546 - accuracy: 0.8039 - val_loss: 0.6185 - val_accuracy: 0.9360\n",
      "Epoch 58/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.7538 - accuracy: 0.8155 - val_loss: 0.6119 - val_accuracy: 0.9302\n",
      "Epoch 59/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.7530 - accuracy: 0.8146 - val_loss: 0.6029 - val_accuracy: 0.9244\n",
      "Epoch 60/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.7318 - accuracy: 0.8146 - val_loss: 0.5951 - val_accuracy: 0.9273\n",
      "Epoch 61/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.7159 - accuracy: 0.8340 - val_loss: 0.5901 - val_accuracy: 0.9099\n",
      "Epoch 62/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.7209 - accuracy: 0.8058 - val_loss: 0.5811 - val_accuracy: 0.9360\n",
      "Epoch 63/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.6939 - accuracy: 0.8369 - val_loss: 0.5729 - val_accuracy: 0.9331\n",
      "Epoch 64/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.6831 - accuracy: 0.8262 - val_loss: 0.5637 - val_accuracy: 0.9302\n",
      "Epoch 65/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.6869 - accuracy: 0.8311 - val_loss: 0.5600 - val_accuracy: 0.9302\n",
      "Epoch 66/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.6845 - accuracy: 0.8330 - val_loss: 0.5533 - val_accuracy: 0.9215\n",
      "Epoch 67/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.6839 - accuracy: 0.8243 - val_loss: 0.5443 - val_accuracy: 0.9302\n",
      "Epoch 68/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.6561 - accuracy: 0.8359 - val_loss: 0.5410 - val_accuracy: 0.9215\n",
      "Epoch 69/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.6491 - accuracy: 0.8553 - val_loss: 0.5293 - val_accuracy: 0.9302\n",
      "Epoch 70/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.6719 - accuracy: 0.8379 - val_loss: 0.5300 - val_accuracy: 0.9331\n",
      "Epoch 71/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.6370 - accuracy: 0.8398 - val_loss: 0.5211 - val_accuracy: 0.9273\n",
      "Epoch 72/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.6399 - accuracy: 0.8291 - val_loss: 0.5163 - val_accuracy: 0.9390\n",
      "Epoch 73/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.6296 - accuracy: 0.8417 - val_loss: 0.5105 - val_accuracy: 0.9302\n",
      "Epoch 74/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.6378 - accuracy: 0.8379 - val_loss: 0.5070 - val_accuracy: 0.9273\n",
      "Epoch 75/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.6090 - accuracy: 0.8670 - val_loss: 0.5000 - val_accuracy: 0.9331\n",
      "Epoch 76/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.5879 - accuracy: 0.8621 - val_loss: 0.4956 - val_accuracy: 0.9390\n",
      "Epoch 77/2000\n",
      "1030/1030 [==============================] - 0s 57us/sample - loss: 0.6100 - accuracy: 0.8398 - val_loss: 0.4922 - val_accuracy: 0.9360\n",
      "Epoch 78/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.5836 - accuracy: 0.8583 - val_loss: 0.4863 - val_accuracy: 0.9331\n",
      "Epoch 79/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.5876 - accuracy: 0.8563 - val_loss: 0.4835 - val_accuracy: 0.9419\n",
      "Epoch 80/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.5885 - accuracy: 0.8602 - val_loss: 0.4761 - val_accuracy: 0.9273\n",
      "Epoch 81/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.5952 - accuracy: 0.8583 - val_loss: 0.4737 - val_accuracy: 0.9360\n",
      "Epoch 82/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.5730 - accuracy: 0.8524 - val_loss: 0.4782 - val_accuracy: 0.9273\n",
      "Epoch 83/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.5664 - accuracy: 0.8699 - val_loss: 0.4706 - val_accuracy: 0.9360\n",
      "Epoch 84/2000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 0.5564 - accuracy: 0.8709 - val_loss: 0.4612 - val_accuracy: 0.9244\n",
      "Epoch 85/2000\n",
      "1030/1030 [==============================] - 0s 58us/sample - loss: 0.5347 - accuracy: 0.8786 - val_loss: 0.4607 - val_accuracy: 0.9419\n",
      "Epoch 86/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.5393 - accuracy: 0.8728 - val_loss: 0.4577 - val_accuracy: 0.9360\n",
      "Epoch 87/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.5525 - accuracy: 0.8816 - val_loss: 0.4540 - val_accuracy: 0.9390\n",
      "Epoch 88/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.5339 - accuracy: 0.8680 - val_loss: 0.4471 - val_accuracy: 0.9419\n",
      "Epoch 89/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.5233 - accuracy: 0.8767 - val_loss: 0.4454 - val_accuracy: 0.9419\n",
      "Epoch 90/2000\n",
      "1030/1030 [==============================] - 0s 57us/sample - loss: 0.5283 - accuracy: 0.8767 - val_loss: 0.4426 - val_accuracy: 0.9273\n",
      "Epoch 91/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.5307 - accuracy: 0.8728 - val_loss: 0.4448 - val_accuracy: 0.9477\n",
      "Epoch 92/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.5280 - accuracy: 0.8680 - val_loss: 0.4396 - val_accuracy: 0.9302\n",
      "Epoch 93/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.5402 - accuracy: 0.8631 - val_loss: 0.4371 - val_accuracy: 0.9390\n",
      "Epoch 94/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.5257 - accuracy: 0.8718 - val_loss: 0.4324 - val_accuracy: 0.9302\n",
      "Epoch 95/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.5246 - accuracy: 0.8699 - val_loss: 0.4347 - val_accuracy: 0.9360\n",
      "Epoch 96/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.5097 - accuracy: 0.8806 - val_loss: 0.4269 - val_accuracy: 0.9448\n",
      "Epoch 97/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.5101 - accuracy: 0.8864 - val_loss: 0.4250 - val_accuracy: 0.9331\n",
      "Epoch 98/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.4810 - accuracy: 0.8845 - val_loss: 0.4230 - val_accuracy: 0.9419\n",
      "Epoch 99/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.4804 - accuracy: 0.8835 - val_loss: 0.4173 - val_accuracy: 0.9419\n",
      "Epoch 100/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.4870 - accuracy: 0.8854 - val_loss: 0.4190 - val_accuracy: 0.9390\n",
      "Epoch 101/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.4982 - accuracy: 0.8854 - val_loss: 0.4150 - val_accuracy: 0.9390\n",
      "Epoch 102/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.4974 - accuracy: 0.8786 - val_loss: 0.4141 - val_accuracy: 0.9360\n",
      "Epoch 103/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.4811 - accuracy: 0.8825 - val_loss: 0.4090 - val_accuracy: 0.9302\n",
      "Epoch 104/2000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 0.4849 - accuracy: 0.8816 - val_loss: 0.4071 - val_accuracy: 0.9419\n",
      "Epoch 105/2000\n",
      "1030/1030 [==============================] - 0s 56us/sample - loss: 0.4879 - accuracy: 0.8835 - val_loss: 0.4138 - val_accuracy: 0.9419\n",
      "Epoch 106/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.4693 - accuracy: 0.8951 - val_loss: 0.4069 - val_accuracy: 0.9448\n",
      "Epoch 107/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.4897 - accuracy: 0.8806 - val_loss: 0.4049 - val_accuracy: 0.9390\n",
      "Epoch 108/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.4760 - accuracy: 0.8835 - val_loss: 0.4032 - val_accuracy: 0.9331\n",
      "Epoch 109/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.4660 - accuracy: 0.8854 - val_loss: 0.4026 - val_accuracy: 0.9331\n",
      "Epoch 110/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.4714 - accuracy: 0.8893 - val_loss: 0.3981 - val_accuracy: 0.9331\n",
      "Epoch 111/2000\n",
      "1030/1030 [==============================] - 0s 59us/sample - loss: 0.4668 - accuracy: 0.9039 - val_loss: 0.3964 - val_accuracy: 0.9448\n",
      "Epoch 112/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.4700 - accuracy: 0.8903 - val_loss: 0.3965 - val_accuracy: 0.9273\n",
      "Epoch 113/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.4581 - accuracy: 0.8932 - val_loss: 0.3940 - val_accuracy: 0.9331\n",
      "Epoch 114/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.4500 - accuracy: 0.9029 - val_loss: 0.3957 - val_accuracy: 0.9448\n",
      "Epoch 115/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.4685 - accuracy: 0.8903 - val_loss: 0.3947 - val_accuracy: 0.9477\n",
      "Epoch 116/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.4459 - accuracy: 0.9000 - val_loss: 0.3916 - val_accuracy: 0.9302\n",
      "Epoch 117/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.4544 - accuracy: 0.8874 - val_loss: 0.3872 - val_accuracy: 0.9419\n",
      "Epoch 118/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.4281 - accuracy: 0.9058 - val_loss: 0.3818 - val_accuracy: 0.9419\n",
      "Epoch 119/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.4318 - accuracy: 0.9010 - val_loss: 0.3817 - val_accuracy: 0.9360\n",
      "Epoch 120/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.4320 - accuracy: 0.9019 - val_loss: 0.3811 - val_accuracy: 0.9419\n",
      "Epoch 121/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.4498 - accuracy: 0.8942 - val_loss: 0.3835 - val_accuracy: 0.9448\n",
      "Epoch 122/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.4355 - accuracy: 0.9039 - val_loss: 0.3757 - val_accuracy: 0.9477\n",
      "Epoch 123/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.4321 - accuracy: 0.9029 - val_loss: 0.3763 - val_accuracy: 0.9477\n",
      "Epoch 124/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.4339 - accuracy: 0.8971 - val_loss: 0.3740 - val_accuracy: 0.9419\n",
      "Epoch 125/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.4252 - accuracy: 0.9097 - val_loss: 0.3725 - val_accuracy: 0.9360\n",
      "Epoch 126/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.4253 - accuracy: 0.9029 - val_loss: 0.3744 - val_accuracy: 0.9419\n",
      "Epoch 127/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.4175 - accuracy: 0.9097 - val_loss: 0.3749 - val_accuracy: 0.9360\n",
      "Epoch 128/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.4230 - accuracy: 0.9039 - val_loss: 0.3708 - val_accuracy: 0.9477\n",
      "Epoch 129/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.4240 - accuracy: 0.9010 - val_loss: 0.3716 - val_accuracy: 0.9448\n",
      "Epoch 130/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.4128 - accuracy: 0.9019 - val_loss: 0.3690 - val_accuracy: 0.9448\n",
      "Epoch 131/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.4168 - accuracy: 0.9049 - val_loss: 0.3702 - val_accuracy: 0.9419\n",
      "Epoch 132/2000\n",
      "1030/1030 [==============================] - 0s 58us/sample - loss: 0.4212 - accuracy: 0.9107 - val_loss: 0.3707 - val_accuracy: 0.9448\n",
      "Epoch 133/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.3833 - accuracy: 0.9175 - val_loss: 0.3651 - val_accuracy: 0.9390\n",
      "Epoch 134/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.4077 - accuracy: 0.9010 - val_loss: 0.3661 - val_accuracy: 0.9448\n",
      "Epoch 135/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.3806 - accuracy: 0.9175 - val_loss: 0.3654 - val_accuracy: 0.9419\n",
      "Epoch 136/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.4091 - accuracy: 0.9000 - val_loss: 0.3653 - val_accuracy: 0.9448\n",
      "Epoch 137/2000\n",
      "1030/1030 [==============================] - 0s 56us/sample - loss: 0.4087 - accuracy: 0.8942 - val_loss: 0.3622 - val_accuracy: 0.9448\n",
      "Epoch 138/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.3991 - accuracy: 0.9214 - val_loss: 0.3618 - val_accuracy: 0.9419\n",
      "Epoch 139/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.3885 - accuracy: 0.9194 - val_loss: 0.3681 - val_accuracy: 0.9419\n",
      "Epoch 140/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.3919 - accuracy: 0.9097 - val_loss: 0.3621 - val_accuracy: 0.9419\n",
      "Epoch 141/2000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 0.3870 - accuracy: 0.9214 - val_loss: 0.3573 - val_accuracy: 0.9448\n",
      "Epoch 142/2000\n",
      "1030/1030 [==============================] - 0s 57us/sample - loss: 0.3870 - accuracy: 0.9146 - val_loss: 0.3560 - val_accuracy: 0.9448\n",
      "Epoch 143/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.3993 - accuracy: 0.9126 - val_loss: 0.3569 - val_accuracy: 0.9477\n",
      "Epoch 144/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.3963 - accuracy: 0.9155 - val_loss: 0.3530 - val_accuracy: 0.9477\n",
      "Epoch 145/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.3941 - accuracy: 0.9165 - val_loss: 0.3559 - val_accuracy: 0.9448\n",
      "Epoch 146/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.3871 - accuracy: 0.9175 - val_loss: 0.3554 - val_accuracy: 0.9448\n",
      "Epoch 147/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.3885 - accuracy: 0.9078 - val_loss: 0.3571 - val_accuracy: 0.9390\n",
      "Epoch 148/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.3735 - accuracy: 0.9097 - val_loss: 0.3559 - val_accuracy: 0.9360\n",
      "Epoch 149/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.3786 - accuracy: 0.9194 - val_loss: 0.3532 - val_accuracy: 0.9448\n",
      "Epoch 150/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3762 - accuracy: 0.9155 - val_loss: 0.3527 - val_accuracy: 0.9535\n",
      "Epoch 151/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.3785 - accuracy: 0.9165 - val_loss: 0.3477 - val_accuracy: 0.9477\n",
      "Epoch 152/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.3853 - accuracy: 0.9175 - val_loss: 0.3529 - val_accuracy: 0.9419\n",
      "Epoch 153/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.3760 - accuracy: 0.9223 - val_loss: 0.3487 - val_accuracy: 0.9448\n",
      "Epoch 154/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.3785 - accuracy: 0.9165 - val_loss: 0.3483 - val_accuracy: 0.9477\n",
      "Epoch 155/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.3697 - accuracy: 0.9204 - val_loss: 0.3469 - val_accuracy: 0.9419\n",
      "Epoch 156/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.3774 - accuracy: 0.9175 - val_loss: 0.3450 - val_accuracy: 0.9419\n",
      "Epoch 157/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.3699 - accuracy: 0.9146 - val_loss: 0.3466 - val_accuracy: 0.9506\n",
      "Epoch 158/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.3622 - accuracy: 0.9223 - val_loss: 0.3446 - val_accuracy: 0.9448\n",
      "Epoch 159/2000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 0.3631 - accuracy: 0.9175 - val_loss: 0.3464 - val_accuracy: 0.9419\n",
      "Epoch 160/2000\n",
      "1030/1030 [==============================] - 0s 56us/sample - loss: 0.3626 - accuracy: 0.9291 - val_loss: 0.3435 - val_accuracy: 0.9448\n",
      "Epoch 161/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3794 - accuracy: 0.9194 - val_loss: 0.3419 - val_accuracy: 0.9448\n",
      "Epoch 162/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.3538 - accuracy: 0.9136 - val_loss: 0.3431 - val_accuracy: 0.9448\n",
      "Epoch 163/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 62us/sample - loss: 0.3685 - accuracy: 0.9107 - val_loss: 0.3446 - val_accuracy: 0.9448\n",
      "Epoch 164/2000\n",
      "1030/1030 [==============================] - 0s 58us/sample - loss: 0.3646 - accuracy: 0.9184 - val_loss: 0.3412 - val_accuracy: 0.9477\n",
      "Epoch 165/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.3801 - accuracy: 0.9204 - val_loss: 0.3416 - val_accuracy: 0.9506\n",
      "Epoch 166/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.3699 - accuracy: 0.9252 - val_loss: 0.3401 - val_accuracy: 0.9419\n",
      "Epoch 167/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.3512 - accuracy: 0.9175 - val_loss: 0.3395 - val_accuracy: 0.9477\n",
      "Epoch 168/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.3533 - accuracy: 0.9252 - val_loss: 0.3389 - val_accuracy: 0.9477\n",
      "Epoch 169/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.3427 - accuracy: 0.9340 - val_loss: 0.3371 - val_accuracy: 0.9448\n",
      "Epoch 170/2000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 0.3598 - accuracy: 0.9262 - val_loss: 0.3341 - val_accuracy: 0.9448\n",
      "Epoch 171/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.3503 - accuracy: 0.9301 - val_loss: 0.3393 - val_accuracy: 0.9448\n",
      "Epoch 172/2000\n",
      "1030/1030 [==============================] - 0s 56us/sample - loss: 0.3766 - accuracy: 0.9350 - val_loss: 0.3361 - val_accuracy: 0.9448\n",
      "Epoch 173/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.3517 - accuracy: 0.9165 - val_loss: 0.3380 - val_accuracy: 0.9535\n",
      "Epoch 174/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.3483 - accuracy: 0.9262 - val_loss: 0.3340 - val_accuracy: 0.9448\n",
      "Epoch 175/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3567 - accuracy: 0.9320 - val_loss: 0.3334 - val_accuracy: 0.9564\n",
      "Epoch 176/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.3514 - accuracy: 0.9175 - val_loss: 0.3335 - val_accuracy: 0.9506\n",
      "Epoch 177/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.3349 - accuracy: 0.9330 - val_loss: 0.3328 - val_accuracy: 0.9448\n",
      "Epoch 178/2000\n",
      "1030/1030 [==============================] - 0s 57us/sample - loss: 0.3651 - accuracy: 0.9204 - val_loss: 0.3341 - val_accuracy: 0.9506\n",
      "Epoch 179/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.3320 - accuracy: 0.9398 - val_loss: 0.3343 - val_accuracy: 0.9477\n",
      "Epoch 180/2000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 0.3499 - accuracy: 0.9340 - val_loss: 0.3324 - val_accuracy: 0.9477\n",
      "Epoch 181/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.3294 - accuracy: 0.9350 - val_loss: 0.3348 - val_accuracy: 0.9419\n",
      "Epoch 182/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.3274 - accuracy: 0.9340 - val_loss: 0.3316 - val_accuracy: 0.9419\n",
      "Epoch 183/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.3083 - accuracy: 0.9437 - val_loss: 0.3305 - val_accuracy: 0.9506\n",
      "Epoch 184/2000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 0.3244 - accuracy: 0.9379 - val_loss: 0.3314 - val_accuracy: 0.9448\n",
      "Epoch 185/2000\n",
      "1030/1030 [==============================] - 0s 57us/sample - loss: 0.3290 - accuracy: 0.9311 - val_loss: 0.3337 - val_accuracy: 0.9448\n",
      "Epoch 186/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.3316 - accuracy: 0.9408 - val_loss: 0.3329 - val_accuracy: 0.9477\n",
      "Epoch 187/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.3423 - accuracy: 0.9301 - val_loss: 0.3323 - val_accuracy: 0.9506\n",
      "Epoch 188/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.3251 - accuracy: 0.9330 - val_loss: 0.3281 - val_accuracy: 0.9477\n",
      "Epoch 189/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.3333 - accuracy: 0.9359 - val_loss: 0.3268 - val_accuracy: 0.9564\n",
      "Epoch 190/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.3345 - accuracy: 0.9320 - val_loss: 0.3297 - val_accuracy: 0.9477\n",
      "Epoch 191/2000\n",
      "1030/1030 [==============================] - 0s 57us/sample - loss: 0.3520 - accuracy: 0.9136 - val_loss: 0.3322 - val_accuracy: 0.9477\n",
      "Epoch 192/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.3201 - accuracy: 0.9398 - val_loss: 0.3284 - val_accuracy: 0.9506\n",
      "Epoch 193/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.3209 - accuracy: 0.9437 - val_loss: 0.3232 - val_accuracy: 0.9535\n",
      "Epoch 194/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.3317 - accuracy: 0.9282 - val_loss: 0.3270 - val_accuracy: 0.9535\n",
      "Epoch 195/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3150 - accuracy: 0.9350 - val_loss: 0.3193 - val_accuracy: 0.9564\n",
      "Epoch 196/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.3183 - accuracy: 0.9359 - val_loss: 0.3223 - val_accuracy: 0.9564\n",
      "Epoch 197/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.3169 - accuracy: 0.9388 - val_loss: 0.3260 - val_accuracy: 0.9506\n",
      "Epoch 198/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.3164 - accuracy: 0.9427 - val_loss: 0.3264 - val_accuracy: 0.9506\n",
      "Epoch 199/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.3367 - accuracy: 0.9301 - val_loss: 0.3281 - val_accuracy: 0.9477\n",
      "Epoch 200/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.3126 - accuracy: 0.9427 - val_loss: 0.3253 - val_accuracy: 0.9477\n",
      "Epoch 201/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.3250 - accuracy: 0.9350 - val_loss: 0.3227 - val_accuracy: 0.9506\n",
      "Epoch 202/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.3296 - accuracy: 0.9320 - val_loss: 0.3229 - val_accuracy: 0.9477\n",
      "Epoch 203/2000\n",
      "1030/1030 [==============================] - 0s 57us/sample - loss: 0.3203 - accuracy: 0.9311 - val_loss: 0.3257 - val_accuracy: 0.9419\n",
      "Epoch 204/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.3060 - accuracy: 0.9408 - val_loss: 0.3231 - val_accuracy: 0.9506\n",
      "Epoch 205/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.3297 - accuracy: 0.9272 - val_loss: 0.3223 - val_accuracy: 0.9506\n",
      "Epoch 206/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.3148 - accuracy: 0.9369 - val_loss: 0.3180 - val_accuracy: 0.9506\n",
      "Epoch 207/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.3091 - accuracy: 0.9340 - val_loss: 0.3245 - val_accuracy: 0.9448\n",
      "Epoch 208/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.3041 - accuracy: 0.9350 - val_loss: 0.3260 - val_accuracy: 0.9477\n",
      "Epoch 209/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.3022 - accuracy: 0.9408 - val_loss: 0.3217 - val_accuracy: 0.9477\n",
      "Epoch 210/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.3185 - accuracy: 0.9320 - val_loss: 0.3167 - val_accuracy: 0.9564\n",
      "Epoch 211/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.3183 - accuracy: 0.9320 - val_loss: 0.3164 - val_accuracy: 0.9535\n",
      "Epoch 212/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.3105 - accuracy: 0.9437 - val_loss: 0.3199 - val_accuracy: 0.9535\n",
      "Epoch 213/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.3081 - accuracy: 0.9379 - val_loss: 0.3242 - val_accuracy: 0.9564\n",
      "Epoch 214/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.3085 - accuracy: 0.9427 - val_loss: 0.3179 - val_accuracy: 0.9535\n",
      "Epoch 215/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3144 - accuracy: 0.9320 - val_loss: 0.3165 - val_accuracy: 0.9477\n",
      "Epoch 216/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.3151 - accuracy: 0.9359 - val_loss: 0.3149 - val_accuracy: 0.9535\n",
      "Epoch 217/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 51us/sample - loss: 0.3340 - accuracy: 0.9369 - val_loss: 0.3198 - val_accuracy: 0.9506\n",
      "Epoch 218/2000\n",
      "1030/1030 [==============================] - 0s 57us/sample - loss: 0.2875 - accuracy: 0.9485 - val_loss: 0.3179 - val_accuracy: 0.9535\n",
      "Epoch 219/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.3085 - accuracy: 0.9408 - val_loss: 0.3206 - val_accuracy: 0.9506\n",
      "Epoch 220/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.2967 - accuracy: 0.9379 - val_loss: 0.3193 - val_accuracy: 0.9564\n",
      "Epoch 221/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.2887 - accuracy: 0.9505 - val_loss: 0.3188 - val_accuracy: 0.9477\n",
      "Epoch 222/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.3056 - accuracy: 0.9340 - val_loss: 0.3178 - val_accuracy: 0.9477\n",
      "Epoch 223/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2994 - accuracy: 0.9417 - val_loss: 0.3195 - val_accuracy: 0.9448\n",
      "Epoch 224/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3089 - accuracy: 0.9379 - val_loss: 0.3169 - val_accuracy: 0.9477\n",
      "Epoch 225/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.3036 - accuracy: 0.9485 - val_loss: 0.3155 - val_accuracy: 0.9477\n",
      "Epoch 226/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3136 - accuracy: 0.9330 - val_loss: 0.3122 - val_accuracy: 0.9535\n",
      "Epoch 227/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2915 - accuracy: 0.9408 - val_loss: 0.3169 - val_accuracy: 0.9448\n",
      "Epoch 228/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2867 - accuracy: 0.9476 - val_loss: 0.3170 - val_accuracy: 0.9535\n",
      "Epoch 229/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3075 - accuracy: 0.9350 - val_loss: 0.3131 - val_accuracy: 0.9535\n",
      "Epoch 230/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2935 - accuracy: 0.9437 - val_loss: 0.3167 - val_accuracy: 0.9535\n",
      "Epoch 231/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2965 - accuracy: 0.9447 - val_loss: 0.3143 - val_accuracy: 0.9535\n",
      "Epoch 232/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.3027 - accuracy: 0.9398 - val_loss: 0.3144 - val_accuracy: 0.9506\n",
      "Epoch 233/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2861 - accuracy: 0.9437 - val_loss: 0.3138 - val_accuracy: 0.9564\n",
      "Epoch 234/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2786 - accuracy: 0.9408 - val_loss: 0.3133 - val_accuracy: 0.9506\n",
      "Epoch 235/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2860 - accuracy: 0.9408 - val_loss: 0.3124 - val_accuracy: 0.9535\n",
      "Epoch 236/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2850 - accuracy: 0.9476 - val_loss: 0.3108 - val_accuracy: 0.9535\n",
      "Epoch 237/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2926 - accuracy: 0.9350 - val_loss: 0.3090 - val_accuracy: 0.9477\n",
      "Epoch 238/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2740 - accuracy: 0.9456 - val_loss: 0.3118 - val_accuracy: 0.9506\n",
      "Epoch 239/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2913 - accuracy: 0.9408 - val_loss: 0.3089 - val_accuracy: 0.9477\n",
      "Epoch 240/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2925 - accuracy: 0.9398 - val_loss: 0.3082 - val_accuracy: 0.9593\n",
      "Epoch 241/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3006 - accuracy: 0.9291 - val_loss: 0.3143 - val_accuracy: 0.9506\n",
      "Epoch 242/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2759 - accuracy: 0.9495 - val_loss: 0.3129 - val_accuracy: 0.9477\n",
      "Epoch 243/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2825 - accuracy: 0.9505 - val_loss: 0.3146 - val_accuracy: 0.9477\n",
      "Epoch 244/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2942 - accuracy: 0.9408 - val_loss: 0.3145 - val_accuracy: 0.9448\n",
      "Epoch 245/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.2908 - accuracy: 0.9417 - val_loss: 0.3137 - val_accuracy: 0.9506\n",
      "Epoch 246/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.2641 - accuracy: 0.9495 - val_loss: 0.3159 - val_accuracy: 0.9477\n",
      "Epoch 247/2000\n",
      "1030/1030 [==============================] - 0s 62us/sample - loss: 0.2969 - accuracy: 0.9379 - val_loss: 0.3123 - val_accuracy: 0.9477\n",
      "Epoch 248/2000\n",
      "1030/1030 [==============================] - 0s 58us/sample - loss: 0.2880 - accuracy: 0.9379 - val_loss: 0.3106 - val_accuracy: 0.9506\n",
      "Epoch 249/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.2910 - accuracy: 0.9398 - val_loss: 0.3091 - val_accuracy: 0.9506\n",
      "Epoch 250/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2772 - accuracy: 0.9495 - val_loss: 0.3060 - val_accuracy: 0.9535\n",
      "Epoch 251/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2785 - accuracy: 0.9408 - val_loss: 0.3085 - val_accuracy: 0.9535\n",
      "Epoch 252/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2694 - accuracy: 0.9534 - val_loss: 0.3070 - val_accuracy: 0.9593\n",
      "Epoch 253/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2771 - accuracy: 0.9485 - val_loss: 0.3133 - val_accuracy: 0.9506\n",
      "Epoch 254/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2761 - accuracy: 0.9495 - val_loss: 0.3122 - val_accuracy: 0.9448\n",
      "Epoch 255/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2775 - accuracy: 0.9485 - val_loss: 0.3084 - val_accuracy: 0.9506\n",
      "Epoch 256/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2755 - accuracy: 0.9476 - val_loss: 0.3104 - val_accuracy: 0.9535\n",
      "Epoch 257/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2576 - accuracy: 0.9553 - val_loss: 0.3066 - val_accuracy: 0.9506\n",
      "Epoch 258/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2842 - accuracy: 0.9408 - val_loss: 0.3152 - val_accuracy: 0.9419\n",
      "Epoch 259/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.2681 - accuracy: 0.9563 - val_loss: 0.3107 - val_accuracy: 0.9448\n",
      "Epoch 260/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2660 - accuracy: 0.9379 - val_loss: 0.3104 - val_accuracy: 0.9448\n",
      "Epoch 261/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2730 - accuracy: 0.9476 - val_loss: 0.3064 - val_accuracy: 0.9477\n",
      "Epoch 262/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2824 - accuracy: 0.9408 - val_loss: 0.3117 - val_accuracy: 0.9419\n",
      "Epoch 263/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2676 - accuracy: 0.9544 - val_loss: 0.3067 - val_accuracy: 0.9506\n",
      "Epoch 264/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2699 - accuracy: 0.9485 - val_loss: 0.3075 - val_accuracy: 0.9506\n",
      "Epoch 265/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2739 - accuracy: 0.9379 - val_loss: 0.3126 - val_accuracy: 0.9535\n",
      "Epoch 266/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2701 - accuracy: 0.9476 - val_loss: 0.3107 - val_accuracy: 0.9448\n",
      "Epoch 267/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2808 - accuracy: 0.9485 - val_loss: 0.3083 - val_accuracy: 0.9506\n",
      "Epoch 268/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2699 - accuracy: 0.9466 - val_loss: 0.3089 - val_accuracy: 0.9506\n",
      "Epoch 269/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2741 - accuracy: 0.9485 - val_loss: 0.3057 - val_accuracy: 0.9477\n",
      "Epoch 270/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2716 - accuracy: 0.9485 - val_loss: 0.3094 - val_accuracy: 0.9564\n",
      "Epoch 271/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2717 - accuracy: 0.9447 - val_loss: 0.3116 - val_accuracy: 0.9419\n",
      "Epoch 272/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2714 - accuracy: 0.9573 - val_loss: 0.3091 - val_accuracy: 0.9535\n",
      "Epoch 273/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2635 - accuracy: 0.9476 - val_loss: 0.3080 - val_accuracy: 0.9535\n",
      "Epoch 274/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2686 - accuracy: 0.9485 - val_loss: 0.3152 - val_accuracy: 0.9448\n",
      "Epoch 275/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2623 - accuracy: 0.9505 - val_loss: 0.3075 - val_accuracy: 0.9535\n",
      "Epoch 276/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2560 - accuracy: 0.9515 - val_loss: 0.3036 - val_accuracy: 0.9506\n",
      "Epoch 277/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2486 - accuracy: 0.9583 - val_loss: 0.3049 - val_accuracy: 0.9535\n",
      "Epoch 278/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2798 - accuracy: 0.9388 - val_loss: 0.3053 - val_accuracy: 0.9535\n",
      "Epoch 279/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2652 - accuracy: 0.9553 - val_loss: 0.3050 - val_accuracy: 0.9506\n",
      "Epoch 280/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2859 - accuracy: 0.9456 - val_loss: 0.3056 - val_accuracy: 0.9506\n",
      "Epoch 281/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2604 - accuracy: 0.9505 - val_loss: 0.3076 - val_accuracy: 0.9506\n",
      "Epoch 282/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2616 - accuracy: 0.9524 - val_loss: 0.3042 - val_accuracy: 0.9448\n",
      "Epoch 283/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2771 - accuracy: 0.9427 - val_loss: 0.3045 - val_accuracy: 0.9477\n",
      "Epoch 284/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2543 - accuracy: 0.9573 - val_loss: 0.3095 - val_accuracy: 0.9448\n",
      "Epoch 285/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.2728 - accuracy: 0.9485 - val_loss: 0.3030 - val_accuracy: 0.9477\n",
      "Epoch 286/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2589 - accuracy: 0.9379 - val_loss: 0.3032 - val_accuracy: 0.9477\n",
      "Epoch 287/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2627 - accuracy: 0.9417 - val_loss: 0.3103 - val_accuracy: 0.9506\n",
      "Epoch 288/2000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 0.2651 - accuracy: 0.9485 - val_loss: 0.3077 - val_accuracy: 0.9506\n",
      "Epoch 289/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.2670 - accuracy: 0.9592 - val_loss: 0.3036 - val_accuracy: 0.9535\n",
      "Epoch 290/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2512 - accuracy: 0.9524 - val_loss: 0.3051 - val_accuracy: 0.9477\n",
      "Epoch 291/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2639 - accuracy: 0.9427 - val_loss: 0.3042 - val_accuracy: 0.9535\n",
      "Epoch 292/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2725 - accuracy: 0.9515 - val_loss: 0.3024 - val_accuracy: 0.9564\n",
      "Epoch 293/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2486 - accuracy: 0.9583 - val_loss: 0.3055 - val_accuracy: 0.9535\n",
      "Epoch 294/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2728 - accuracy: 0.9437 - val_loss: 0.3080 - val_accuracy: 0.9448\n",
      "Epoch 295/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.2628 - accuracy: 0.9544 - val_loss: 0.3050 - val_accuracy: 0.9564\n",
      "Epoch 296/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.2489 - accuracy: 0.9563 - val_loss: 0.3055 - val_accuracy: 0.9477\n",
      "Epoch 297/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2711 - accuracy: 0.9505 - val_loss: 0.3037 - val_accuracy: 0.9506\n",
      "Epoch 298/2000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 0.2525 - accuracy: 0.9495 - val_loss: 0.3053 - val_accuracy: 0.9535\n",
      "Epoch 299/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.2679 - accuracy: 0.9456 - val_loss: 0.3048 - val_accuracy: 0.9506\n",
      "Epoch 300/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2591 - accuracy: 0.9485 - val_loss: 0.3067 - val_accuracy: 0.9506\n",
      "Epoch 301/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2598 - accuracy: 0.9515 - val_loss: 0.3002 - val_accuracy: 0.9535\n",
      "Epoch 302/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2509 - accuracy: 0.9544 - val_loss: 0.3029 - val_accuracy: 0.9506\n",
      "Epoch 303/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2537 - accuracy: 0.9524 - val_loss: 0.3090 - val_accuracy: 0.9535\n",
      "Epoch 304/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.2487 - accuracy: 0.9485 - val_loss: 0.3023 - val_accuracy: 0.9564\n",
      "Epoch 305/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.2484 - accuracy: 0.9553 - val_loss: 0.3066 - val_accuracy: 0.9477\n",
      "Epoch 306/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.2496 - accuracy: 0.9544 - val_loss: 0.3032 - val_accuracy: 0.9564\n",
      "Epoch 307/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.2535 - accuracy: 0.9495 - val_loss: 0.3021 - val_accuracy: 0.9535\n",
      "Epoch 308/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.2466 - accuracy: 0.9524 - val_loss: 0.3022 - val_accuracy: 0.9448\n",
      "Epoch 309/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2480 - accuracy: 0.9485 - val_loss: 0.3047 - val_accuracy: 0.9506\n",
      "Epoch 310/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2511 - accuracy: 0.9553 - val_loss: 0.3024 - val_accuracy: 0.9535\n",
      "Epoch 311/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2414 - accuracy: 0.9602 - val_loss: 0.3018 - val_accuracy: 0.9564\n",
      "Epoch 312/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2645 - accuracy: 0.9563 - val_loss: 0.2977 - val_accuracy: 0.9593\n",
      "Epoch 313/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2612 - accuracy: 0.9485 - val_loss: 0.3037 - val_accuracy: 0.9506\n",
      "Epoch 314/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.2412 - accuracy: 0.9612 - val_loss: 0.3014 - val_accuracy: 0.9506\n",
      "Epoch 315/2000\n",
      "1030/1030 [==============================] - 0s 61us/sample - loss: 0.2460 - accuracy: 0.9544 - val_loss: 0.3016 - val_accuracy: 0.9477\n",
      "Epoch 316/2000\n",
      "1030/1030 [==============================] - 0s 72us/sample - loss: 0.2684 - accuracy: 0.9437 - val_loss: 0.3003 - val_accuracy: 0.9535\n",
      "Epoch 317/2000\n",
      "1030/1030 [==============================] - 0s 56us/sample - loss: 0.2590 - accuracy: 0.9495 - val_loss: 0.3035 - val_accuracy: 0.9477\n",
      "Epoch 318/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.2332 - accuracy: 0.9641 - val_loss: 0.3043 - val_accuracy: 0.9477\n",
      "Epoch 319/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.2509 - accuracy: 0.9524 - val_loss: 0.3027 - val_accuracy: 0.9506\n",
      "Epoch 320/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.2497 - accuracy: 0.9485 - val_loss: 0.3017 - val_accuracy: 0.9448\n",
      "Epoch 321/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.2406 - accuracy: 0.9553 - val_loss: 0.2995 - val_accuracy: 0.9506\n",
      "Epoch 322/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.2357 - accuracy: 0.9553 - val_loss: 0.3054 - val_accuracy: 0.9477\n",
      "Epoch 323/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2504 - accuracy: 0.9592 - val_loss: 0.3049 - val_accuracy: 0.9535\n",
      "Epoch 324/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.2523 - accuracy: 0.9515 - val_loss: 0.2966 - val_accuracy: 0.9506\n",
      "Epoch 325/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2392 - accuracy: 0.9544 - val_loss: 0.2975 - val_accuracy: 0.9535\n",
      "Epoch 326/2000\n",
      "1030/1030 [==============================] - 0s 57us/sample - loss: 0.2492 - accuracy: 0.9495 - val_loss: 0.2965 - val_accuracy: 0.9477\n",
      "Epoch 327/2000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 0.2373 - accuracy: 0.9544 - val_loss: 0.2997 - val_accuracy: 0.9535\n",
      "Epoch 328/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.2156 - accuracy: 0.9631 - val_loss: 0.3022 - val_accuracy: 0.9506\n",
      "Epoch 329/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.2339 - accuracy: 0.9524 - val_loss: 0.3013 - val_accuracy: 0.9506\n",
      "Epoch 330/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.2439 - accuracy: 0.9621 - val_loss: 0.2993 - val_accuracy: 0.9593\n",
      "Epoch 331/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2447 - accuracy: 0.9476 - val_loss: 0.3000 - val_accuracy: 0.9506\n",
      "Epoch 332/2000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 0.2479 - accuracy: 0.9456 - val_loss: 0.2991 - val_accuracy: 0.9535\n",
      "Epoch 333/2000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 0.2419 - accuracy: 0.9573 - val_loss: 0.3029 - val_accuracy: 0.9448\n",
      "Epoch 334/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.2294 - accuracy: 0.9592 - val_loss: 0.2976 - val_accuracy: 0.9506\n",
      "Epoch 335/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.2593 - accuracy: 0.9456 - val_loss: 0.3026 - val_accuracy: 0.9506\n",
      "Epoch 336/2000\n",
      "1030/1030 [==============================] - 0s 38us/sample - loss: 0.2346 - accuracy: 0.9592 - val_loss: 0.2958 - val_accuracy: 0.9535\n",
      "Epoch 337/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2400 - accuracy: 0.9495 - val_loss: 0.2995 - val_accuracy: 0.9564\n",
      "Epoch 338/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2346 - accuracy: 0.9544 - val_loss: 0.3007 - val_accuracy: 0.9506\n",
      "Epoch 339/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2356 - accuracy: 0.9563 - val_loss: 0.3052 - val_accuracy: 0.9506\n",
      "Epoch 340/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2314 - accuracy: 0.9612 - val_loss: 0.3046 - val_accuracy: 0.9506\n",
      "Epoch 341/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2308 - accuracy: 0.9621 - val_loss: 0.2974 - val_accuracy: 0.9477\n",
      "Epoch 342/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2205 - accuracy: 0.9680 - val_loss: 0.3004 - val_accuracy: 0.9419\n",
      "Epoch 343/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2456 - accuracy: 0.9485 - val_loss: 0.2976 - val_accuracy: 0.9506\n",
      "Epoch 344/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2414 - accuracy: 0.9534 - val_loss: 0.2978 - val_accuracy: 0.9535\n",
      "Epoch 345/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2450 - accuracy: 0.9476 - val_loss: 0.3032 - val_accuracy: 0.9477\n",
      "Epoch 346/2000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 0.2390 - accuracy: 0.9612 - val_loss: 0.3040 - val_accuracy: 0.9535\n",
      "Epoch 347/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2319 - accuracy: 0.9544 - val_loss: 0.3032 - val_accuracy: 0.9419\n",
      "Epoch 348/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2309 - accuracy: 0.9592 - val_loss: 0.3020 - val_accuracy: 0.9477\n",
      "Epoch 349/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2311 - accuracy: 0.9553 - val_loss: 0.3024 - val_accuracy: 0.9477\n",
      "Epoch 350/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2280 - accuracy: 0.9583 - val_loss: 0.2969 - val_accuracy: 0.9506\n",
      "Epoch 351/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2141 - accuracy: 0.9641 - val_loss: 0.2973 - val_accuracy: 0.9535\n",
      "Epoch 352/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2317 - accuracy: 0.9485 - val_loss: 0.2952 - val_accuracy: 0.9564\n",
      "Epoch 353/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2397 - accuracy: 0.9534 - val_loss: 0.2980 - val_accuracy: 0.9506\n",
      "Epoch 354/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2447 - accuracy: 0.9466 - val_loss: 0.2970 - val_accuracy: 0.9506\n",
      "Epoch 355/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2301 - accuracy: 0.9660 - val_loss: 0.2980 - val_accuracy: 0.9506\n",
      "Epoch 356/2000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 0.2266 - accuracy: 0.9602 - val_loss: 0.2986 - val_accuracy: 0.9535\n",
      "Epoch 357/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2210 - accuracy: 0.9563 - val_loss: 0.2957 - val_accuracy: 0.9535\n",
      "Epoch 358/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2219 - accuracy: 0.9612 - val_loss: 0.2949 - val_accuracy: 0.9535\n",
      "Epoch 359/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2088 - accuracy: 0.9641 - val_loss: 0.2970 - val_accuracy: 0.9506\n",
      "Epoch 360/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2373 - accuracy: 0.9524 - val_loss: 0.2954 - val_accuracy: 0.9564\n",
      "Epoch 361/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2342 - accuracy: 0.9553 - val_loss: 0.2920 - val_accuracy: 0.9564\n",
      "Epoch 362/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2378 - accuracy: 0.9553 - val_loss: 0.2969 - val_accuracy: 0.9564\n",
      "Epoch 363/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2231 - accuracy: 0.9573 - val_loss: 0.2944 - val_accuracy: 0.9506\n",
      "Epoch 364/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2268 - accuracy: 0.9515 - val_loss: 0.2931 - val_accuracy: 0.9593\n",
      "Epoch 365/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2243 - accuracy: 0.9563 - val_loss: 0.2988 - val_accuracy: 0.9506\n",
      "Epoch 366/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2166 - accuracy: 0.9621 - val_loss: 0.2987 - val_accuracy: 0.9506\n",
      "Epoch 367/2000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 0.2095 - accuracy: 0.9602 - val_loss: 0.3043 - val_accuracy: 0.9477\n",
      "Epoch 368/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2251 - accuracy: 0.9621 - val_loss: 0.2949 - val_accuracy: 0.9535\n",
      "Epoch 369/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2269 - accuracy: 0.9553 - val_loss: 0.2992 - val_accuracy: 0.9535\n",
      "Epoch 370/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2238 - accuracy: 0.9650 - val_loss: 0.2977 - val_accuracy: 0.9535\n",
      "Epoch 371/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2323 - accuracy: 0.9621 - val_loss: 0.2953 - val_accuracy: 0.9506\n",
      "Epoch 372/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2058 - accuracy: 0.9631 - val_loss: 0.3001 - val_accuracy: 0.9477\n",
      "Epoch 373/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2217 - accuracy: 0.9563 - val_loss: 0.2959 - val_accuracy: 0.9506\n",
      "Epoch 374/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2375 - accuracy: 0.9485 - val_loss: 0.2996 - val_accuracy: 0.9506\n",
      "Epoch 375/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2219 - accuracy: 0.9573 - val_loss: 0.2943 - val_accuracy: 0.9535\n",
      "Epoch 376/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2233 - accuracy: 0.9592 - val_loss: 0.2951 - val_accuracy: 0.9535\n",
      "Epoch 377/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2362 - accuracy: 0.9485 - val_loss: 0.2934 - val_accuracy: 0.9506\n",
      "Epoch 378/2000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 0.2338 - accuracy: 0.9544 - val_loss: 0.2970 - val_accuracy: 0.9477\n",
      "Epoch 379/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 34us/sample - loss: 0.2214 - accuracy: 0.9621 - val_loss: 0.2927 - val_accuracy: 0.9535\n",
      "Epoch 380/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2215 - accuracy: 0.9583 - val_loss: 0.2954 - val_accuracy: 0.9477\n",
      "Epoch 381/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2111 - accuracy: 0.9670 - val_loss: 0.2902 - val_accuracy: 0.9593\n",
      "Epoch 382/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2320 - accuracy: 0.9553 - val_loss: 0.2928 - val_accuracy: 0.9535\n",
      "Epoch 383/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2141 - accuracy: 0.9602 - val_loss: 0.2962 - val_accuracy: 0.9535\n",
      "Epoch 384/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2240 - accuracy: 0.9466 - val_loss: 0.2990 - val_accuracy: 0.9535\n",
      "Epoch 385/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2081 - accuracy: 0.9583 - val_loss: 0.2988 - val_accuracy: 0.9535\n",
      "Epoch 386/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2178 - accuracy: 0.9641 - val_loss: 0.2950 - val_accuracy: 0.9535\n",
      "Epoch 387/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2284 - accuracy: 0.9553 - val_loss: 0.2938 - val_accuracy: 0.9564\n",
      "Epoch 388/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2309 - accuracy: 0.9583 - val_loss: 0.2949 - val_accuracy: 0.9535\n",
      "Epoch 389/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2088 - accuracy: 0.9718 - val_loss: 0.3005 - val_accuracy: 0.9448\n",
      "Epoch 390/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2155 - accuracy: 0.9544 - val_loss: 0.2943 - val_accuracy: 0.9506\n",
      "Epoch 391/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2123 - accuracy: 0.9621 - val_loss: 0.2967 - val_accuracy: 0.9506\n",
      "Epoch 392/2000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 0.2170 - accuracy: 0.9612 - val_loss: 0.2985 - val_accuracy: 0.9477\n",
      "Epoch 393/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2106 - accuracy: 0.9602 - val_loss: 0.2937 - val_accuracy: 0.9564\n",
      "Epoch 394/2000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 0.2081 - accuracy: 0.9592 - val_loss: 0.2986 - val_accuracy: 0.9506\n",
      "Epoch 395/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2152 - accuracy: 0.9573 - val_loss: 0.2983 - val_accuracy: 0.9506\n",
      "Epoch 396/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2199 - accuracy: 0.9631 - val_loss: 0.3017 - val_accuracy: 0.9506\n",
      "Epoch 397/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2375 - accuracy: 0.9505 - val_loss: 0.2946 - val_accuracy: 0.9506\n",
      "Epoch 398/2000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 0.2070 - accuracy: 0.9602 - val_loss: 0.2928 - val_accuracy: 0.9564\n",
      "Epoch 399/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2298 - accuracy: 0.9466 - val_loss: 0.2984 - val_accuracy: 0.9506\n",
      "Epoch 400/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2090 - accuracy: 0.9612 - val_loss: 0.2982 - val_accuracy: 0.9535\n",
      "Epoch 401/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2244 - accuracy: 0.9544 - val_loss: 0.2994 - val_accuracy: 0.9448\n",
      "Epoch 402/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2111 - accuracy: 0.9612 - val_loss: 0.2938 - val_accuracy: 0.9535\n",
      "Epoch 403/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2185 - accuracy: 0.9573 - val_loss: 0.2905 - val_accuracy: 0.9535\n",
      "Epoch 404/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2191 - accuracy: 0.9583 - val_loss: 0.2948 - val_accuracy: 0.9564\n",
      "Epoch 405/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2207 - accuracy: 0.9515 - val_loss: 0.2913 - val_accuracy: 0.9593\n",
      "Epoch 406/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2327 - accuracy: 0.9544 - val_loss: 0.2975 - val_accuracy: 0.9535\n",
      "Epoch 407/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2148 - accuracy: 0.9563 - val_loss: 0.2979 - val_accuracy: 0.9477\n",
      "Epoch 408/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2269 - accuracy: 0.9563 - val_loss: 0.2957 - val_accuracy: 0.9535\n",
      "Epoch 409/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2137 - accuracy: 0.9573 - val_loss: 0.2992 - val_accuracy: 0.9506\n",
      "Epoch 410/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2066 - accuracy: 0.9583 - val_loss: 0.2936 - val_accuracy: 0.9506\n",
      "Epoch 411/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2204 - accuracy: 0.9592 - val_loss: 0.2955 - val_accuracy: 0.9477\n",
      "Epoch 412/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2147 - accuracy: 0.9583 - val_loss: 0.2965 - val_accuracy: 0.9535\n",
      "Epoch 413/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2166 - accuracy: 0.9670 - val_loss: 0.2941 - val_accuracy: 0.9535\n",
      "Epoch 414/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2180 - accuracy: 0.9670 - val_loss: 0.2949 - val_accuracy: 0.9477\n",
      "Epoch 415/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2192 - accuracy: 0.9544 - val_loss: 0.2995 - val_accuracy: 0.9448\n",
      "Epoch 416/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2091 - accuracy: 0.9592 - val_loss: 0.2963 - val_accuracy: 0.9477\n",
      "Epoch 417/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2066 - accuracy: 0.9631 - val_loss: 0.2943 - val_accuracy: 0.9535\n",
      "Epoch 418/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1980 - accuracy: 0.9660 - val_loss: 0.3009 - val_accuracy: 0.9448\n",
      "Epoch 419/2000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 0.1986 - accuracy: 0.9709 - val_loss: 0.2967 - val_accuracy: 0.9477\n",
      "Epoch 420/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2100 - accuracy: 0.9573 - val_loss: 0.2988 - val_accuracy: 0.9506\n",
      "Epoch 421/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2055 - accuracy: 0.9592 - val_loss: 0.3010 - val_accuracy: 0.9535\n",
      "Epoch 422/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1984 - accuracy: 0.9650 - val_loss: 0.3001 - val_accuracy: 0.9448\n",
      "Epoch 423/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2105 - accuracy: 0.9602 - val_loss: 0.2988 - val_accuracy: 0.9477\n",
      "Epoch 424/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1997 - accuracy: 0.9699 - val_loss: 0.2948 - val_accuracy: 0.9535\n",
      "Epoch 425/2000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 0.2137 - accuracy: 0.9573 - val_loss: 0.2931 - val_accuracy: 0.9535\n",
      "Epoch 426/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2100 - accuracy: 0.9573 - val_loss: 0.2931 - val_accuracy: 0.9535\n",
      "Epoch 427/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2203 - accuracy: 0.9573 - val_loss: 0.2889 - val_accuracy: 0.9564\n",
      "Epoch 428/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1978 - accuracy: 0.9612 - val_loss: 0.2948 - val_accuracy: 0.9593\n",
      "Epoch 429/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2134 - accuracy: 0.9602 - val_loss: 0.2937 - val_accuracy: 0.9506\n",
      "Epoch 430/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2098 - accuracy: 0.9553 - val_loss: 0.2902 - val_accuracy: 0.9593\n",
      "Epoch 431/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2106 - accuracy: 0.9573 - val_loss: 0.2898 - val_accuracy: 0.9564\n",
      "Epoch 432/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2198 - accuracy: 0.9485 - val_loss: 0.2961 - val_accuracy: 0.9477\n",
      "Epoch 433/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2089 - accuracy: 0.9544 - val_loss: 0.2947 - val_accuracy: 0.9535\n",
      "Epoch 434/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2130 - accuracy: 0.9553 - val_loss: 0.2953 - val_accuracy: 0.9564\n",
      "Epoch 435/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2106 - accuracy: 0.9660 - val_loss: 0.2969 - val_accuracy: 0.9448\n",
      "Epoch 436/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2040 - accuracy: 0.9680 - val_loss: 0.2954 - val_accuracy: 0.9564\n",
      "Epoch 437/2000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 0.2085 - accuracy: 0.9553 - val_loss: 0.3028 - val_accuracy: 0.9448\n",
      "Epoch 438/2000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 0.2203 - accuracy: 0.9573 - val_loss: 0.2926 - val_accuracy: 0.9535\n",
      "Epoch 439/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2093 - accuracy: 0.9621 - val_loss: 0.2932 - val_accuracy: 0.9535\n",
      "Epoch 440/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2079 - accuracy: 0.9621 - val_loss: 0.2922 - val_accuracy: 0.9535\n",
      "Epoch 441/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2108 - accuracy: 0.9573 - val_loss: 0.2921 - val_accuracy: 0.9564\n",
      "Epoch 442/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1986 - accuracy: 0.9583 - val_loss: 0.2942 - val_accuracy: 0.9535\n",
      "Epoch 443/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2076 - accuracy: 0.9563 - val_loss: 0.2957 - val_accuracy: 0.9477\n",
      "Epoch 444/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2025 - accuracy: 0.9602 - val_loss: 0.2955 - val_accuracy: 0.9448\n",
      "Epoch 445/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2142 - accuracy: 0.9563 - val_loss: 0.2938 - val_accuracy: 0.9535\n",
      "Epoch 446/2000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 0.2058 - accuracy: 0.9612 - val_loss: 0.2978 - val_accuracy: 0.9448\n",
      "Epoch 447/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1995 - accuracy: 0.9660 - val_loss: 0.2986 - val_accuracy: 0.9448\n",
      "Epoch 448/2000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 0.2001 - accuracy: 0.9680 - val_loss: 0.2940 - val_accuracy: 0.9564\n",
      "Epoch 449/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2097 - accuracy: 0.9573 - val_loss: 0.2934 - val_accuracy: 0.9535\n",
      "Epoch 450/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2285 - accuracy: 0.9534 - val_loss: 0.2955 - val_accuracy: 0.9506\n",
      "Epoch 451/2000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 0.2111 - accuracy: 0.9534 - val_loss: 0.2954 - val_accuracy: 0.9564\n",
      "Epoch 452/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2055 - accuracy: 0.9621 - val_loss: 0.2924 - val_accuracy: 0.9535\n",
      "Epoch 453/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1863 - accuracy: 0.9680 - val_loss: 0.2905 - val_accuracy: 0.9622\n",
      "Epoch 454/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2058 - accuracy: 0.9650 - val_loss: 0.2936 - val_accuracy: 0.9564\n",
      "Epoch 455/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1920 - accuracy: 0.9621 - val_loss: 0.2907 - val_accuracy: 0.9564\n",
      "Epoch 456/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2127 - accuracy: 0.9612 - val_loss: 0.2919 - val_accuracy: 0.9564\n",
      "Epoch 457/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1922 - accuracy: 0.9631 - val_loss: 0.2948 - val_accuracy: 0.9535\n",
      "Epoch 458/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2080 - accuracy: 0.9631 - val_loss: 0.2932 - val_accuracy: 0.9535\n",
      "Epoch 459/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1940 - accuracy: 0.9621 - val_loss: 0.2933 - val_accuracy: 0.9535\n",
      "Epoch 460/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1876 - accuracy: 0.9709 - val_loss: 0.2939 - val_accuracy: 0.9564\n",
      "Epoch 461/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1982 - accuracy: 0.9592 - val_loss: 0.2944 - val_accuracy: 0.9506\n",
      "Epoch 462/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2006 - accuracy: 0.9650 - val_loss: 0.2921 - val_accuracy: 0.9564\n",
      "Epoch 463/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2036 - accuracy: 0.9699 - val_loss: 0.2902 - val_accuracy: 0.9564\n",
      "Epoch 464/2000\n",
      "1030/1030 [==============================] - 0s 37us/sample - loss: 0.1908 - accuracy: 0.9631 - val_loss: 0.2947 - val_accuracy: 0.9477\n",
      "Epoch 465/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2190 - accuracy: 0.9505 - val_loss: 0.2938 - val_accuracy: 0.9535\n",
      "Epoch 466/2000\n",
      "1030/1030 [==============================] - 0s 37us/sample - loss: 0.2001 - accuracy: 0.9573 - val_loss: 0.2929 - val_accuracy: 0.9593\n",
      "Epoch 467/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1874 - accuracy: 0.9738 - val_loss: 0.2948 - val_accuracy: 0.9564\n",
      "Epoch 468/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1996 - accuracy: 0.9650 - val_loss: 0.2919 - val_accuracy: 0.9535\n",
      "Epoch 469/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2005 - accuracy: 0.9573 - val_loss: 0.2976 - val_accuracy: 0.9477\n",
      "Epoch 470/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1873 - accuracy: 0.9641 - val_loss: 0.2999 - val_accuracy: 0.9477\n",
      "Epoch 471/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1991 - accuracy: 0.9573 - val_loss: 0.2937 - val_accuracy: 0.9477\n",
      "Epoch 472/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2032 - accuracy: 0.9621 - val_loss: 0.2895 - val_accuracy: 0.9535\n",
      "Epoch 473/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1961 - accuracy: 0.9631 - val_loss: 0.2920 - val_accuracy: 0.9506\n",
      "Epoch 474/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1961 - accuracy: 0.9612 - val_loss: 0.2967 - val_accuracy: 0.9477\n",
      "Epoch 475/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.2066 - accuracy: 0.9534 - val_loss: 0.2944 - val_accuracy: 0.9535\n",
      "Epoch 476/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1921 - accuracy: 0.9660 - val_loss: 0.2968 - val_accuracy: 0.9506\n",
      "Epoch 477/2000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 0.1815 - accuracy: 0.9641 - val_loss: 0.2969 - val_accuracy: 0.9535\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/1 - 0s - loss: 0.1883 - accuracy: 0.9535\n",
      "Validation loss: 0.29685728737088135\n",
      "Accuracy: 0.95348835\n"
     ]
    }
   ],
   "source": [
    "model.model_validation(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/1 - 0s - loss: 0.2907 - accuracy: 0.9331\n",
      "Test loss: 0.25540522433990653\n",
      "Accuracy 0.93313956\n"
     ]
    }
   ],
   "source": [
    "model.model_testing(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 2,062\n",
      "Trainable params: 2,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 103 samples, validate on 34 samples\n",
      "Epoch 1/2000\n",
      "103/103 [==============================] - 0s 3ms/sample - loss: 2.7873 - accuracy: 0.0485 - val_loss: 2.6986 - val_accuracy: 0.0294\n",
      "Epoch 2/2000\n",
      "103/103 [==============================] - 0s 132us/sample - loss: 2.6722 - accuracy: 0.0971 - val_loss: 2.6789 - val_accuracy: 0.0294\n",
      "Epoch 3/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 2.6635 - accuracy: 0.0485 - val_loss: 2.6719 - val_accuracy: 0.0588\n",
      "Epoch 4/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 2.6410 - accuracy: 0.1068 - val_loss: 2.6594 - val_accuracy: 0.0588\n",
      "Epoch 5/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 2.6542 - accuracy: 0.0971 - val_loss: 2.6435 - val_accuracy: 0.1176\n",
      "Epoch 6/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 2.6460 - accuracy: 0.1068 - val_loss: 2.6334 - val_accuracy: 0.1471\n",
      "Epoch 7/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 2.5952 - accuracy: 0.1553 - val_loss: 2.6216 - val_accuracy: 0.1471\n",
      "Epoch 8/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 2.5730 - accuracy: 0.1748 - val_loss: 2.6131 - val_accuracy: 0.1471\n",
      "Epoch 9/2000\n",
      "103/103 [==============================] - 0s 118us/sample - loss: 2.6114 - accuracy: 0.1068 - val_loss: 2.6077 - val_accuracy: 0.1471\n",
      "Epoch 10/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 2.5598 - accuracy: 0.1748 - val_loss: 2.5953 - val_accuracy: 0.1471\n",
      "Epoch 11/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 2.6078 - accuracy: 0.1262 - val_loss: 2.5853 - val_accuracy: 0.1471\n",
      "Epoch 12/2000\n",
      "103/103 [==============================] - 0s 117us/sample - loss: 2.5537 - accuracy: 0.1068 - val_loss: 2.5795 - val_accuracy: 0.1471\n",
      "Epoch 13/2000\n",
      "103/103 [==============================] - 0s 116us/sample - loss: 2.5452 - accuracy: 0.1553 - val_loss: 2.5720 - val_accuracy: 0.1471\n",
      "Epoch 14/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 2.5004 - accuracy: 0.1942 - val_loss: 2.5619 - val_accuracy: 0.1471\n",
      "Epoch 15/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 2.4872 - accuracy: 0.2136 - val_loss: 2.5518 - val_accuracy: 0.1176\n",
      "Epoch 16/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 2.4901 - accuracy: 0.2330 - val_loss: 2.5419 - val_accuracy: 0.1471\n",
      "Epoch 17/2000\n",
      "103/103 [==============================] - 0s 117us/sample - loss: 2.4447 - accuracy: 0.2233 - val_loss: 2.5285 - val_accuracy: 0.1765\n",
      "Epoch 18/2000\n",
      "103/103 [==============================] - 0s 117us/sample - loss: 2.4464 - accuracy: 0.2524 - val_loss: 2.5179 - val_accuracy: 0.1471\n",
      "Epoch 19/2000\n",
      "103/103 [==============================] - 0s 116us/sample - loss: 2.4838 - accuracy: 0.1165 - val_loss: 2.5093 - val_accuracy: 0.1765\n",
      "Epoch 20/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 2.4854 - accuracy: 0.1650 - val_loss: 2.4982 - val_accuracy: 0.1765\n",
      "Epoch 21/2000\n",
      "103/103 [==============================] - 0s 119us/sample - loss: 2.4260 - accuracy: 0.2233 - val_loss: 2.4934 - val_accuracy: 0.2059\n",
      "Epoch 22/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 2.4710 - accuracy: 0.1359 - val_loss: 2.4856 - val_accuracy: 0.1765\n",
      "Epoch 23/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 2.4375 - accuracy: 0.1748 - val_loss: 2.4774 - val_accuracy: 0.1471\n",
      "Epoch 24/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 2.4287 - accuracy: 0.2136 - val_loss: 2.4724 - val_accuracy: 0.1765\n",
      "Epoch 25/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 2.4120 - accuracy: 0.2816 - val_loss: 2.4650 - val_accuracy: 0.1765\n",
      "Epoch 26/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 2.4193 - accuracy: 0.1845 - val_loss: 2.4563 - val_accuracy: 0.1765\n",
      "Epoch 27/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 2.3882 - accuracy: 0.2427 - val_loss: 2.4470 - val_accuracy: 0.2353\n",
      "Epoch 28/2000\n",
      "103/103 [==============================] - 0s 118us/sample - loss: 2.3915 - accuracy: 0.2136 - val_loss: 2.4410 - val_accuracy: 0.1765\n",
      "Epoch 29/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 2.3933 - accuracy: 0.2621 - val_loss: 2.4363 - val_accuracy: 0.1471\n",
      "Epoch 30/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 2.3792 - accuracy: 0.2233 - val_loss: 2.4308 - val_accuracy: 0.1765\n",
      "Epoch 31/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 2.3744 - accuracy: 0.2330 - val_loss: 2.4215 - val_accuracy: 0.1471\n",
      "Epoch 32/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 2.3374 - accuracy: 0.2718 - val_loss: 2.4179 - val_accuracy: 0.1471\n",
      "Epoch 33/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 2.3282 - accuracy: 0.2621 - val_loss: 2.4104 - val_accuracy: 0.1471\n",
      "Epoch 34/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 2.2955 - accuracy: 0.2621 - val_loss: 2.4031 - val_accuracy: 0.1765\n",
      "Epoch 35/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 2.3851 - accuracy: 0.2233 - val_loss: 2.3933 - val_accuracy: 0.1765\n",
      "Epoch 36/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 2.3272 - accuracy: 0.3107 - val_loss: 2.3889 - val_accuracy: 0.1471\n",
      "Epoch 37/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 2.3243 - accuracy: 0.2816 - val_loss: 2.3758 - val_accuracy: 0.1471\n",
      "Epoch 38/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 2.3208 - accuracy: 0.3107 - val_loss: 2.3633 - val_accuracy: 0.1471\n",
      "Epoch 39/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 2.3019 - accuracy: 0.1845 - val_loss: 2.3553 - val_accuracy: 0.1471\n",
      "Epoch 40/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 2.2678 - accuracy: 0.3204 - val_loss: 2.3504 - val_accuracy: 0.1471\n",
      "Epoch 41/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 2.2863 - accuracy: 0.2816 - val_loss: 2.3425 - val_accuracy: 0.1765\n",
      "Epoch 42/2000\n",
      "103/103 [==============================] - 0s 106us/sample - loss: 2.2399 - accuracy: 0.3301 - val_loss: 2.3344 - val_accuracy: 0.2059\n",
      "Epoch 43/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 2.2645 - accuracy: 0.3398 - val_loss: 2.3216 - val_accuracy: 0.2059\n",
      "Epoch 44/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 2.2365 - accuracy: 0.2524 - val_loss: 2.3147 - val_accuracy: 0.1765\n",
      "Epoch 45/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 2.2067 - accuracy: 0.3301 - val_loss: 2.3067 - val_accuracy: 0.1765\n",
      "Epoch 46/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 2.2271 - accuracy: 0.3010 - val_loss: 2.3018 - val_accuracy: 0.2353\n",
      "Epoch 47/2000\n",
      "103/103 [==============================] - 0s 118us/sample - loss: 2.1931 - accuracy: 0.2718 - val_loss: 2.2937 - val_accuracy: 0.2059\n",
      "Epoch 48/2000\n",
      "103/103 [==============================] - 0s 107us/sample - loss: 2.2100 - accuracy: 0.2524 - val_loss: 2.2825 - val_accuracy: 0.1765\n",
      "Epoch 49/2000\n",
      "103/103 [==============================] - 0s 138us/sample - loss: 2.1906 - accuracy: 0.2718 - val_loss: 2.2715 - val_accuracy: 0.1471\n",
      "Epoch 50/2000\n",
      "103/103 [==============================] - 0s 141us/sample - loss: 2.2009 - accuracy: 0.3204 - val_loss: 2.2599 - val_accuracy: 0.1471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/2000\n",
      "103/103 [==============================] - 0s 130us/sample - loss: 2.1717 - accuracy: 0.2913 - val_loss: 2.2491 - val_accuracy: 0.1471\n",
      "Epoch 52/2000\n",
      "103/103 [==============================] - 0s 129us/sample - loss: 2.1808 - accuracy: 0.3301 - val_loss: 2.2417 - val_accuracy: 0.1471\n",
      "Epoch 53/2000\n",
      "103/103 [==============================] - 0s 121us/sample - loss: 2.1261 - accuracy: 0.3592 - val_loss: 2.2340 - val_accuracy: 0.1471\n",
      "Epoch 54/2000\n",
      "103/103 [==============================] - 0s 124us/sample - loss: 2.1080 - accuracy: 0.2913 - val_loss: 2.2242 - val_accuracy: 0.1471\n",
      "Epoch 55/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 2.1922 - accuracy: 0.2330 - val_loss: 2.2215 - val_accuracy: 0.1471\n",
      "Epoch 56/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 2.1547 - accuracy: 0.3204 - val_loss: 2.2158 - val_accuracy: 0.1765\n",
      "Epoch 57/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 2.1172 - accuracy: 0.3301 - val_loss: 2.2069 - val_accuracy: 0.1471\n",
      "Epoch 58/2000\n",
      "103/103 [==============================] - 0s 136us/sample - loss: 2.1012 - accuracy: 0.3689 - val_loss: 2.2004 - val_accuracy: 0.1765\n",
      "Epoch 59/2000\n",
      "103/103 [==============================] - 0s 117us/sample - loss: 2.0993 - accuracy: 0.3981 - val_loss: 2.1917 - val_accuracy: 0.1471\n",
      "Epoch 60/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 2.1309 - accuracy: 0.3204 - val_loss: 2.1817 - val_accuracy: 0.1471\n",
      "Epoch 61/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 2.0995 - accuracy: 0.3204 - val_loss: 2.1756 - val_accuracy: 0.1765\n",
      "Epoch 62/2000\n",
      "103/103 [==============================] - 0s 125us/sample - loss: 2.0985 - accuracy: 0.3204 - val_loss: 2.1652 - val_accuracy: 0.1471\n",
      "Epoch 63/2000\n",
      "103/103 [==============================] - 0s 128us/sample - loss: 2.0822 - accuracy: 0.3592 - val_loss: 2.1604 - val_accuracy: 0.1471\n",
      "Epoch 64/2000\n",
      "103/103 [==============================] - 0s 143us/sample - loss: 2.0595 - accuracy: 0.3883 - val_loss: 2.1607 - val_accuracy: 0.1765\n",
      "Epoch 65/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 2.0662 - accuracy: 0.3204 - val_loss: 2.1535 - val_accuracy: 0.1765\n",
      "Epoch 66/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 2.0103 - accuracy: 0.3786 - val_loss: 2.1408 - val_accuracy: 0.2059\n",
      "Epoch 67/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 2.0432 - accuracy: 0.3495 - val_loss: 2.1358 - val_accuracy: 0.2059\n",
      "Epoch 68/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 2.0121 - accuracy: 0.3689 - val_loss: 2.1323 - val_accuracy: 0.2941\n",
      "Epoch 69/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.9866 - accuracy: 0.3883 - val_loss: 2.1235 - val_accuracy: 0.2647\n",
      "Epoch 70/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.9739 - accuracy: 0.3883 - val_loss: 2.1125 - val_accuracy: 0.2059\n",
      "Epoch 71/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.9675 - accuracy: 0.4272 - val_loss: 2.1085 - val_accuracy: 0.1765\n",
      "Epoch 72/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.9289 - accuracy: 0.4757 - val_loss: 2.1007 - val_accuracy: 0.1765\n",
      "Epoch 73/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.9763 - accuracy: 0.3592 - val_loss: 2.0920 - val_accuracy: 0.1765\n",
      "Epoch 74/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.9409 - accuracy: 0.3981 - val_loss: 2.0841 - val_accuracy: 0.1765\n",
      "Epoch 75/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 2.0657 - accuracy: 0.3398 - val_loss: 2.0775 - val_accuracy: 0.2059\n",
      "Epoch 76/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.9582 - accuracy: 0.4175 - val_loss: 2.0675 - val_accuracy: 0.1765\n",
      "Epoch 77/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.9904 - accuracy: 0.3592 - val_loss: 2.0570 - val_accuracy: 0.2059\n",
      "Epoch 78/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.9120 - accuracy: 0.4175 - val_loss: 2.0503 - val_accuracy: 0.2059\n",
      "Epoch 79/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.9284 - accuracy: 0.3689 - val_loss: 2.0475 - val_accuracy: 0.2059\n",
      "Epoch 80/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.9158 - accuracy: 0.3592 - val_loss: 2.0420 - val_accuracy: 0.2059\n",
      "Epoch 81/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 1.9413 - accuracy: 0.4466 - val_loss: 2.0317 - val_accuracy: 0.2647\n",
      "Epoch 82/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.9010 - accuracy: 0.3592 - val_loss: 2.0224 - val_accuracy: 0.2059\n",
      "Epoch 83/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.9212 - accuracy: 0.4078 - val_loss: 2.0155 - val_accuracy: 0.2353\n",
      "Epoch 84/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.8816 - accuracy: 0.3883 - val_loss: 2.0185 - val_accuracy: 0.2059\n",
      "Epoch 85/2000\n",
      "103/103 [==============================] - 0s 117us/sample - loss: 1.8642 - accuracy: 0.3981 - val_loss: 2.0073 - val_accuracy: 0.2059\n",
      "Epoch 86/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.8530 - accuracy: 0.4563 - val_loss: 2.0030 - val_accuracy: 0.2647\n",
      "Epoch 87/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.9341 - accuracy: 0.4369 - val_loss: 1.9968 - val_accuracy: 0.2059\n",
      "Epoch 88/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.9204 - accuracy: 0.3204 - val_loss: 2.0001 - val_accuracy: 0.2353\n",
      "Epoch 89/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.8363 - accuracy: 0.4175 - val_loss: 1.9980 - val_accuracy: 0.2647\n",
      "Epoch 90/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.8087 - accuracy: 0.4660 - val_loss: 1.9914 - val_accuracy: 0.2941\n",
      "Epoch 91/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.8457 - accuracy: 0.4369 - val_loss: 1.9830 - val_accuracy: 0.2941\n",
      "Epoch 92/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 1.8253 - accuracy: 0.4078 - val_loss: 1.9725 - val_accuracy: 0.2941\n",
      "Epoch 93/2000\n",
      "103/103 [==============================] - 0s 116us/sample - loss: 1.7821 - accuracy: 0.4369 - val_loss: 1.9583 - val_accuracy: 0.2941\n",
      "Epoch 94/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.8379 - accuracy: 0.4272 - val_loss: 1.9535 - val_accuracy: 0.2941\n",
      "Epoch 95/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 1.8219 - accuracy: 0.4369 - val_loss: 1.9525 - val_accuracy: 0.2941\n",
      "Epoch 96/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.7867 - accuracy: 0.4175 - val_loss: 1.9471 - val_accuracy: 0.2647\n",
      "Epoch 97/2000\n",
      "103/103 [==============================] - 0s 119us/sample - loss: 1.7621 - accuracy: 0.3981 - val_loss: 1.9404 - val_accuracy: 0.2941\n",
      "Epoch 98/2000\n",
      "103/103 [==============================] - 0s 153us/sample - loss: 1.7776 - accuracy: 0.4563 - val_loss: 1.9293 - val_accuracy: 0.2647\n",
      "Epoch 99/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.8176 - accuracy: 0.3689 - val_loss: 1.9306 - val_accuracy: 0.2647\n",
      "Epoch 100/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.8437 - accuracy: 0.3883 - val_loss: 1.9217 - val_accuracy: 0.2647\n",
      "Epoch 101/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.7506 - accuracy: 0.5049 - val_loss: 1.9111 - val_accuracy: 0.2647\n",
      "Epoch 102/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.7194 - accuracy: 0.4951 - val_loss: 1.9097 - val_accuracy: 0.2941\n",
      "Epoch 103/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.7625 - accuracy: 0.4369 - val_loss: 1.9044 - val_accuracy: 0.2941\n",
      "Epoch 104/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.7691 - accuracy: 0.4757 - val_loss: 1.9036 - val_accuracy: 0.2941\n",
      "Epoch 105/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.7600 - accuracy: 0.4466 - val_loss: 1.8962 - val_accuracy: 0.2941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/2000\n",
      "103/103 [==============================] - 0s 106us/sample - loss: 1.7010 - accuracy: 0.4951 - val_loss: 1.8894 - val_accuracy: 0.2941\n",
      "Epoch 107/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.7592 - accuracy: 0.3883 - val_loss: 1.8802 - val_accuracy: 0.2647\n",
      "Epoch 108/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.7587 - accuracy: 0.4660 - val_loss: 1.8782 - val_accuracy: 0.2941\n",
      "Epoch 109/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 1.6548 - accuracy: 0.5340 - val_loss: 1.8801 - val_accuracy: 0.2941\n",
      "Epoch 110/2000\n",
      "103/103 [==============================] - 0s 104us/sample - loss: 1.7066 - accuracy: 0.5049 - val_loss: 1.8754 - val_accuracy: 0.2941\n",
      "Epoch 111/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.6926 - accuracy: 0.4175 - val_loss: 1.8602 - val_accuracy: 0.2941\n",
      "Epoch 112/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.7026 - accuracy: 0.4854 - val_loss: 1.8620 - val_accuracy: 0.2941\n",
      "Epoch 113/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.6791 - accuracy: 0.4854 - val_loss: 1.8530 - val_accuracy: 0.2941\n",
      "Epoch 114/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.6785 - accuracy: 0.4466 - val_loss: 1.8428 - val_accuracy: 0.2941\n",
      "Epoch 115/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.6513 - accuracy: 0.5146 - val_loss: 1.8390 - val_accuracy: 0.2941\n",
      "Epoch 116/2000\n",
      "103/103 [==============================] - 0s 117us/sample - loss: 1.6601 - accuracy: 0.3981 - val_loss: 1.8301 - val_accuracy: 0.2941\n",
      "Epoch 117/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.6560 - accuracy: 0.4272 - val_loss: 1.8263 - val_accuracy: 0.2941\n",
      "Epoch 118/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.6198 - accuracy: 0.5049 - val_loss: 1.8193 - val_accuracy: 0.2941\n",
      "Epoch 119/2000\n",
      "103/103 [==============================] - 0s 107us/sample - loss: 1.6578 - accuracy: 0.4466 - val_loss: 1.8224 - val_accuracy: 0.3235\n",
      "Epoch 120/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.6521 - accuracy: 0.4951 - val_loss: 1.8223 - val_accuracy: 0.2941\n",
      "Epoch 121/2000\n",
      "103/103 [==============================] - 0s 107us/sample - loss: 1.6609 - accuracy: 0.4854 - val_loss: 1.8174 - val_accuracy: 0.3235\n",
      "Epoch 122/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 1.6505 - accuracy: 0.4854 - val_loss: 1.8062 - val_accuracy: 0.2941\n",
      "Epoch 123/2000\n",
      "103/103 [==============================] - 0s 106us/sample - loss: 1.6116 - accuracy: 0.5049 - val_loss: 1.8047 - val_accuracy: 0.3235\n",
      "Epoch 124/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.6245 - accuracy: 0.5049 - val_loss: 1.8007 - val_accuracy: 0.3235\n",
      "Epoch 125/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.6073 - accuracy: 0.5340 - val_loss: 1.7935 - val_accuracy: 0.3235\n",
      "Epoch 126/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.6171 - accuracy: 0.4951 - val_loss: 1.7880 - val_accuracy: 0.3235\n",
      "Epoch 127/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.6060 - accuracy: 0.5243 - val_loss: 1.7789 - val_accuracy: 0.3235\n",
      "Epoch 128/2000\n",
      "103/103 [==============================] - 0s 106us/sample - loss: 1.6237 - accuracy: 0.4757 - val_loss: 1.7725 - val_accuracy: 0.3235\n",
      "Epoch 129/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.6006 - accuracy: 0.5146 - val_loss: 1.7660 - val_accuracy: 0.3235\n",
      "Epoch 130/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.5683 - accuracy: 0.5049 - val_loss: 1.7634 - val_accuracy: 0.3235\n",
      "Epoch 131/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.4905 - accuracy: 0.6117 - val_loss: 1.7505 - val_accuracy: 0.3235\n",
      "Epoch 132/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.5353 - accuracy: 0.5728 - val_loss: 1.7531 - val_accuracy: 0.3235\n",
      "Epoch 133/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.5795 - accuracy: 0.5243 - val_loss: 1.7517 - val_accuracy: 0.3235\n",
      "Epoch 134/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.5560 - accuracy: 0.5728 - val_loss: 1.7488 - val_accuracy: 0.3235\n",
      "Epoch 135/2000\n",
      "103/103 [==============================] - 0s 106us/sample - loss: 1.6070 - accuracy: 0.4078 - val_loss: 1.7377 - val_accuracy: 0.3235\n",
      "Epoch 136/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.6093 - accuracy: 0.4272 - val_loss: 1.7355 - val_accuracy: 0.3235\n",
      "Epoch 137/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 1.5347 - accuracy: 0.5146 - val_loss: 1.7310 - val_accuracy: 0.2647\n",
      "Epoch 138/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 1.5684 - accuracy: 0.5728 - val_loss: 1.7267 - val_accuracy: 0.2647\n",
      "Epoch 139/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.5309 - accuracy: 0.5825 - val_loss: 1.7250 - val_accuracy: 0.2647\n",
      "Epoch 140/2000\n",
      "103/103 [==============================] - 0s 106us/sample - loss: 1.5473 - accuracy: 0.5534 - val_loss: 1.7192 - val_accuracy: 0.2647\n",
      "Epoch 141/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.5859 - accuracy: 0.5146 - val_loss: 1.7173 - val_accuracy: 0.2647\n",
      "Epoch 142/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.4853 - accuracy: 0.6214 - val_loss: 1.7205 - val_accuracy: 0.2647\n",
      "Epoch 143/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.5358 - accuracy: 0.5437 - val_loss: 1.7139 - val_accuracy: 0.3235\n",
      "Epoch 144/2000\n",
      "103/103 [==============================] - 0s 106us/sample - loss: 1.5609 - accuracy: 0.4854 - val_loss: 1.7107 - val_accuracy: 0.3235\n",
      "Epoch 145/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.5036 - accuracy: 0.6019 - val_loss: 1.7075 - val_accuracy: 0.3235\n",
      "Epoch 146/2000\n",
      "103/103 [==============================] - 0s 116us/sample - loss: 1.4613 - accuracy: 0.6214 - val_loss: 1.7082 - val_accuracy: 0.3235\n",
      "Epoch 147/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.4635 - accuracy: 0.6019 - val_loss: 1.6985 - val_accuracy: 0.3235\n",
      "Epoch 148/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.5025 - accuracy: 0.5146 - val_loss: 1.7024 - val_accuracy: 0.3235\n",
      "Epoch 149/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.4390 - accuracy: 0.5631 - val_loss: 1.6982 - val_accuracy: 0.3235\n",
      "Epoch 150/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.4260 - accuracy: 0.5631 - val_loss: 1.6894 - val_accuracy: 0.3235\n",
      "Epoch 151/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.4812 - accuracy: 0.5534 - val_loss: 1.6829 - val_accuracy: 0.3235\n",
      "Epoch 152/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.4106 - accuracy: 0.5922 - val_loss: 1.6767 - val_accuracy: 0.3529\n",
      "Epoch 153/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.4120 - accuracy: 0.5825 - val_loss: 1.6773 - val_accuracy: 0.3529\n",
      "Epoch 154/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 1.4637 - accuracy: 0.5146 - val_loss: 1.6679 - val_accuracy: 0.3529\n",
      "Epoch 155/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.3738 - accuracy: 0.6505 - val_loss: 1.6675 - val_accuracy: 0.3824\n",
      "Epoch 156/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.4224 - accuracy: 0.6214 - val_loss: 1.6600 - val_accuracy: 0.4118\n",
      "Epoch 157/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.3741 - accuracy: 0.6699 - val_loss: 1.6620 - val_accuracy: 0.4118\n",
      "Epoch 158/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.4557 - accuracy: 0.5437 - val_loss: 1.6574 - val_accuracy: 0.3529\n",
      "Epoch 159/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.3789 - accuracy: 0.5825 - val_loss: 1.6597 - val_accuracy: 0.3529\n",
      "Epoch 160/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 107us/sample - loss: 1.3877 - accuracy: 0.6019 - val_loss: 1.6592 - val_accuracy: 0.3529\n",
      "Epoch 161/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.3834 - accuracy: 0.6602 - val_loss: 1.6531 - val_accuracy: 0.4118\n",
      "Epoch 162/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.4158 - accuracy: 0.6117 - val_loss: 1.6413 - val_accuracy: 0.4118\n",
      "Epoch 163/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.5008 - accuracy: 0.5243 - val_loss: 1.6343 - val_accuracy: 0.4118\n",
      "Epoch 164/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.4037 - accuracy: 0.5728 - val_loss: 1.6301 - val_accuracy: 0.4118\n",
      "Epoch 165/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.3631 - accuracy: 0.6214 - val_loss: 1.6287 - val_accuracy: 0.4412\n",
      "Epoch 166/2000\n",
      "103/103 [==============================] - 0s 107us/sample - loss: 1.3883 - accuracy: 0.5728 - val_loss: 1.6347 - val_accuracy: 0.4412\n",
      "Epoch 167/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.4468 - accuracy: 0.6019 - val_loss: 1.6424 - val_accuracy: 0.4412\n",
      "Epoch 168/2000\n",
      "103/103 [==============================] - 0s 106us/sample - loss: 1.3767 - accuracy: 0.6117 - val_loss: 1.6421 - val_accuracy: 0.4118\n",
      "Epoch 169/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.4391 - accuracy: 0.5243 - val_loss: 1.6432 - val_accuracy: 0.4118\n",
      "Epoch 170/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 1.3764 - accuracy: 0.6214 - val_loss: 1.6355 - val_accuracy: 0.4118\n",
      "Epoch 171/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.2890 - accuracy: 0.6311 - val_loss: 1.6274 - val_accuracy: 0.4118\n",
      "Epoch 172/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.3349 - accuracy: 0.6214 - val_loss: 1.6310 - val_accuracy: 0.4118\n",
      "Epoch 173/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.4006 - accuracy: 0.6019 - val_loss: 1.6206 - val_accuracy: 0.4118\n",
      "Epoch 174/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.3251 - accuracy: 0.5922 - val_loss: 1.6148 - val_accuracy: 0.4118\n",
      "Epoch 175/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.3901 - accuracy: 0.5631 - val_loss: 1.6065 - val_accuracy: 0.4118\n",
      "Epoch 176/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.3585 - accuracy: 0.6311 - val_loss: 1.5996 - val_accuracy: 0.4118\n",
      "Epoch 177/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.2965 - accuracy: 0.6796 - val_loss: 1.5966 - val_accuracy: 0.4412\n",
      "Epoch 178/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.3032 - accuracy: 0.6117 - val_loss: 1.5878 - val_accuracy: 0.4412\n",
      "Epoch 179/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.2893 - accuracy: 0.6019 - val_loss: 1.5784 - val_accuracy: 0.4412\n",
      "Epoch 180/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.3000 - accuracy: 0.5534 - val_loss: 1.5795 - val_accuracy: 0.4118\n",
      "Epoch 181/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.3026 - accuracy: 0.6796 - val_loss: 1.5842 - val_accuracy: 0.4706\n",
      "Epoch 182/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.2625 - accuracy: 0.7184 - val_loss: 1.5739 - val_accuracy: 0.4706\n",
      "Epoch 183/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.3489 - accuracy: 0.5728 - val_loss: 1.5609 - val_accuracy: 0.4706\n",
      "Epoch 184/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.2600 - accuracy: 0.6796 - val_loss: 1.5658 - val_accuracy: 0.4412\n",
      "Epoch 185/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 1.2826 - accuracy: 0.6117 - val_loss: 1.5578 - val_accuracy: 0.4118\n",
      "Epoch 186/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 1.1989 - accuracy: 0.7087 - val_loss: 1.5553 - val_accuracy: 0.4118\n",
      "Epoch 187/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.2941 - accuracy: 0.6990 - val_loss: 1.5476 - val_accuracy: 0.4412\n",
      "Epoch 188/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.2652 - accuracy: 0.6796 - val_loss: 1.5508 - val_accuracy: 0.4412\n",
      "Epoch 189/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.2544 - accuracy: 0.6699 - val_loss: 1.5426 - val_accuracy: 0.5294\n",
      "Epoch 190/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.2149 - accuracy: 0.7573 - val_loss: 1.5481 - val_accuracy: 0.4412\n",
      "Epoch 191/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.2262 - accuracy: 0.6505 - val_loss: 1.5387 - val_accuracy: 0.4412\n",
      "Epoch 192/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.1741 - accuracy: 0.6990 - val_loss: 1.5274 - val_accuracy: 0.5294\n",
      "Epoch 193/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.2198 - accuracy: 0.6796 - val_loss: 1.5261 - val_accuracy: 0.4706\n",
      "Epoch 194/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.2827 - accuracy: 0.6311 - val_loss: 1.5250 - val_accuracy: 0.5000\n",
      "Epoch 195/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.2715 - accuracy: 0.6408 - val_loss: 1.5253 - val_accuracy: 0.5000\n",
      "Epoch 196/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.2522 - accuracy: 0.6117 - val_loss: 1.5235 - val_accuracy: 0.5294\n",
      "Epoch 197/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.2154 - accuracy: 0.6602 - val_loss: 1.5159 - val_accuracy: 0.5882\n",
      "Epoch 198/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.3320 - accuracy: 0.5922 - val_loss: 1.5138 - val_accuracy: 0.5882\n",
      "Epoch 199/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.2129 - accuracy: 0.7184 - val_loss: 1.5151 - val_accuracy: 0.5882\n",
      "Epoch 200/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.2709 - accuracy: 0.6505 - val_loss: 1.5159 - val_accuracy: 0.5294\n",
      "Epoch 201/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.2615 - accuracy: 0.6990 - val_loss: 1.5116 - val_accuracy: 0.5294\n",
      "Epoch 202/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.1999 - accuracy: 0.7476 - val_loss: 1.5060 - val_accuracy: 0.5588\n",
      "Epoch 203/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.1343 - accuracy: 0.7282 - val_loss: 1.5054 - val_accuracy: 0.5588\n",
      "Epoch 204/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.1723 - accuracy: 0.7476 - val_loss: 1.5010 - val_accuracy: 0.5294\n",
      "Epoch 205/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.2043 - accuracy: 0.7379 - val_loss: 1.4936 - val_accuracy: 0.5294\n",
      "Epoch 206/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.1381 - accuracy: 0.7184 - val_loss: 1.4940 - val_accuracy: 0.5294\n",
      "Epoch 207/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.2196 - accuracy: 0.6990 - val_loss: 1.4844 - val_accuracy: 0.5588\n",
      "Epoch 208/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 1.1918 - accuracy: 0.7573 - val_loss: 1.4831 - val_accuracy: 0.5294\n",
      "Epoch 209/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.1504 - accuracy: 0.7670 - val_loss: 1.4798 - val_accuracy: 0.5294\n",
      "Epoch 210/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.1885 - accuracy: 0.6214 - val_loss: 1.4875 - val_accuracy: 0.5294\n",
      "Epoch 211/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.1832 - accuracy: 0.6893 - val_loss: 1.4809 - val_accuracy: 0.5294\n",
      "Epoch 212/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 1.1599 - accuracy: 0.7670 - val_loss: 1.4811 - val_accuracy: 0.5000\n",
      "Epoch 213/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.1681 - accuracy: 0.6796 - val_loss: 1.4782 - val_accuracy: 0.5000\n",
      "Epoch 214/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.1684 - accuracy: 0.7087 - val_loss: 1.4674 - val_accuracy: 0.5294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.2112 - accuracy: 0.6019 - val_loss: 1.4721 - val_accuracy: 0.5000\n",
      "Epoch 216/2000\n",
      "103/103 [==============================] - 0s 116us/sample - loss: 1.1563 - accuracy: 0.7573 - val_loss: 1.4683 - val_accuracy: 0.5000\n",
      "Epoch 217/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.2063 - accuracy: 0.6796 - val_loss: 1.4701 - val_accuracy: 0.5588\n",
      "Epoch 218/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.0533 - accuracy: 0.7670 - val_loss: 1.4669 - val_accuracy: 0.5294\n",
      "Epoch 219/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.0843 - accuracy: 0.8058 - val_loss: 1.4645 - val_accuracy: 0.5000\n",
      "Epoch 220/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.1655 - accuracy: 0.6796 - val_loss: 1.4659 - val_accuracy: 0.5294\n",
      "Epoch 221/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 1.0836 - accuracy: 0.7379 - val_loss: 1.4592 - val_accuracy: 0.5294\n",
      "Epoch 222/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 1.1387 - accuracy: 0.6796 - val_loss: 1.4566 - val_accuracy: 0.5000\n",
      "Epoch 223/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.0783 - accuracy: 0.7476 - val_loss: 1.4513 - val_accuracy: 0.5000\n",
      "Epoch 224/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.0565 - accuracy: 0.7282 - val_loss: 1.4503 - val_accuracy: 0.5000\n",
      "Epoch 225/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.0922 - accuracy: 0.6214 - val_loss: 1.4486 - val_accuracy: 0.5000\n",
      "Epoch 226/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.1444 - accuracy: 0.6893 - val_loss: 1.4447 - val_accuracy: 0.5000\n",
      "Epoch 227/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.0883 - accuracy: 0.7282 - val_loss: 1.4401 - val_accuracy: 0.5294\n",
      "Epoch 228/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.0721 - accuracy: 0.8252 - val_loss: 1.4288 - val_accuracy: 0.5588\n",
      "Epoch 229/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.0964 - accuracy: 0.6990 - val_loss: 1.4242 - val_accuracy: 0.5882\n",
      "Epoch 230/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.1134 - accuracy: 0.7087 - val_loss: 1.4253 - val_accuracy: 0.5588\n",
      "Epoch 231/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.0648 - accuracy: 0.7087 - val_loss: 1.4151 - val_accuracy: 0.5588\n",
      "Epoch 232/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.0921 - accuracy: 0.6505 - val_loss: 1.4146 - val_accuracy: 0.5882\n",
      "Epoch 233/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.0923 - accuracy: 0.7184 - val_loss: 1.4168 - val_accuracy: 0.6176\n",
      "Epoch 234/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.0516 - accuracy: 0.7767 - val_loss: 1.4100 - val_accuracy: 0.5882\n",
      "Epoch 235/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.0795 - accuracy: 0.7476 - val_loss: 1.4081 - val_accuracy: 0.6176\n",
      "Epoch 236/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.0789 - accuracy: 0.7476 - val_loss: 1.3987 - val_accuracy: 0.5882\n",
      "Epoch 237/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.1082 - accuracy: 0.7184 - val_loss: 1.3942 - val_accuracy: 0.5882\n",
      "Epoch 238/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.0206 - accuracy: 0.7767 - val_loss: 1.4037 - val_accuracy: 0.6176\n",
      "Epoch 239/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.0196 - accuracy: 0.7670 - val_loss: 1.4050 - val_accuracy: 0.6176\n",
      "Epoch 240/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 1.0919 - accuracy: 0.6990 - val_loss: 1.3986 - val_accuracy: 0.5882\n",
      "Epoch 241/2000\n",
      "103/103 [==============================] - 0s 105us/sample - loss: 1.1294 - accuracy: 0.7379 - val_loss: 1.4033 - val_accuracy: 0.6176\n",
      "Epoch 242/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 1.0804 - accuracy: 0.7573 - val_loss: 1.3964 - val_accuracy: 0.6176\n",
      "Epoch 243/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 1.1181 - accuracy: 0.6796 - val_loss: 1.4012 - val_accuracy: 0.5882\n",
      "Epoch 244/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.9777 - accuracy: 0.7767 - val_loss: 1.3884 - val_accuracy: 0.5882\n",
      "Epoch 245/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 1.0528 - accuracy: 0.7573 - val_loss: 1.3871 - val_accuracy: 0.5882\n",
      "Epoch 246/2000\n",
      "103/103 [==============================] - 0s 121us/sample - loss: 0.9740 - accuracy: 0.7864 - val_loss: 1.3783 - val_accuracy: 0.5882\n",
      "Epoch 247/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 1.0314 - accuracy: 0.6990 - val_loss: 1.3721 - val_accuracy: 0.6176\n",
      "Epoch 248/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.9509 - accuracy: 0.7573 - val_loss: 1.3627 - val_accuracy: 0.6176\n",
      "Epoch 249/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 1.0175 - accuracy: 0.7670 - val_loss: 1.3607 - val_accuracy: 0.5882\n",
      "Epoch 250/2000\n",
      "103/103 [==============================] - 0s 107us/sample - loss: 1.1251 - accuracy: 0.6408 - val_loss: 1.3665 - val_accuracy: 0.5882\n",
      "Epoch 251/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 1.1109 - accuracy: 0.7087 - val_loss: 1.3726 - val_accuracy: 0.5882\n",
      "Epoch 252/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 1.0291 - accuracy: 0.7767 - val_loss: 1.3741 - val_accuracy: 0.5294\n",
      "Epoch 253/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 1.0735 - accuracy: 0.7573 - val_loss: 1.3686 - val_accuracy: 0.5294\n",
      "Epoch 254/2000\n",
      "103/103 [==============================] - 0s 127us/sample - loss: 0.9590 - accuracy: 0.8350 - val_loss: 1.3657 - val_accuracy: 0.5588\n",
      "Epoch 255/2000\n",
      "103/103 [==============================] - 0s 155us/sample - loss: 1.0530 - accuracy: 0.7379 - val_loss: 1.3615 - val_accuracy: 0.5882\n",
      "Epoch 256/2000\n",
      "103/103 [==============================] - 0s 137us/sample - loss: 0.9331 - accuracy: 0.8058 - val_loss: 1.3541 - val_accuracy: 0.5588\n",
      "Epoch 257/2000\n",
      "103/103 [==============================] - 0s 131us/sample - loss: 1.0577 - accuracy: 0.7476 - val_loss: 1.3513 - val_accuracy: 0.5294\n",
      "Epoch 258/2000\n",
      "103/103 [==============================] - 0s 141us/sample - loss: 0.9952 - accuracy: 0.7476 - val_loss: 1.3392 - val_accuracy: 0.6176\n",
      "Epoch 259/2000\n",
      "103/103 [==============================] - 0s 140us/sample - loss: 1.0080 - accuracy: 0.7379 - val_loss: 1.3355 - val_accuracy: 0.5294\n",
      "Epoch 260/2000\n",
      "103/103 [==============================] - 0s 141us/sample - loss: 0.9336 - accuracy: 0.7670 - val_loss: 1.3333 - val_accuracy: 0.5588\n",
      "Epoch 261/2000\n",
      "103/103 [==============================] - 0s 147us/sample - loss: 0.8902 - accuracy: 0.8350 - val_loss: 1.3296 - val_accuracy: 0.6176\n",
      "Epoch 262/2000\n",
      "103/103 [==============================] - 0s 149us/sample - loss: 0.9703 - accuracy: 0.7767 - val_loss: 1.3353 - val_accuracy: 0.6176\n",
      "Epoch 263/2000\n",
      "103/103 [==============================] - 0s 149us/sample - loss: 1.0077 - accuracy: 0.6893 - val_loss: 1.3297 - val_accuracy: 0.6176\n",
      "Epoch 264/2000\n",
      "103/103 [==============================] - 0s 152us/sample - loss: 0.9494 - accuracy: 0.7670 - val_loss: 1.3377 - val_accuracy: 0.6471\n",
      "Epoch 265/2000\n",
      "103/103 [==============================] - 0s 152us/sample - loss: 0.9611 - accuracy: 0.7864 - val_loss: 1.3428 - val_accuracy: 0.5882\n",
      "Epoch 266/2000\n",
      "103/103 [==============================] - 0s 148us/sample - loss: 0.9626 - accuracy: 0.8155 - val_loss: 1.3331 - val_accuracy: 0.5882\n",
      "Epoch 267/2000\n",
      "103/103 [==============================] - 0s 152us/sample - loss: 0.9264 - accuracy: 0.7961 - val_loss: 1.3183 - val_accuracy: 0.6176\n",
      "Epoch 268/2000\n",
      "103/103 [==============================] - 0s 142us/sample - loss: 0.9552 - accuracy: 0.7961 - val_loss: 1.3218 - val_accuracy: 0.6176\n",
      "Epoch 269/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 141us/sample - loss: 1.0269 - accuracy: 0.7087 - val_loss: 1.3238 - val_accuracy: 0.5882\n",
      "Epoch 270/2000\n",
      "103/103 [==============================] - 0s 143us/sample - loss: 0.9760 - accuracy: 0.7184 - val_loss: 1.3199 - val_accuracy: 0.6471\n",
      "Epoch 271/2000\n",
      "103/103 [==============================] - 0s 130us/sample - loss: 0.9485 - accuracy: 0.7184 - val_loss: 1.3230 - val_accuracy: 0.5882\n",
      "Epoch 272/2000\n",
      "103/103 [==============================] - 0s 138us/sample - loss: 0.9351 - accuracy: 0.7087 - val_loss: 1.3286 - val_accuracy: 0.5882\n",
      "Epoch 273/2000\n",
      "103/103 [==============================] - 0s 135us/sample - loss: 0.9329 - accuracy: 0.7573 - val_loss: 1.3348 - val_accuracy: 0.5882\n",
      "Epoch 274/2000\n",
      "103/103 [==============================] - 0s 144us/sample - loss: 0.9655 - accuracy: 0.8155 - val_loss: 1.3351 - val_accuracy: 0.5882\n",
      "Epoch 275/2000\n",
      "103/103 [==============================] - 0s 150us/sample - loss: 0.8931 - accuracy: 0.8155 - val_loss: 1.3354 - val_accuracy: 0.5882\n",
      "Epoch 276/2000\n",
      "103/103 [==============================] - 0s 151us/sample - loss: 0.9794 - accuracy: 0.7864 - val_loss: 1.3248 - val_accuracy: 0.5882\n",
      "Epoch 277/2000\n",
      "103/103 [==============================] - 0s 141us/sample - loss: 0.9076 - accuracy: 0.7767 - val_loss: 1.3142 - val_accuracy: 0.6176\n",
      "Epoch 278/2000\n",
      "103/103 [==============================] - 0s 154us/sample - loss: 0.8677 - accuracy: 0.8350 - val_loss: 1.3067 - val_accuracy: 0.5882\n",
      "Epoch 279/2000\n",
      "103/103 [==============================] - 0s 148us/sample - loss: 0.9445 - accuracy: 0.7670 - val_loss: 1.3021 - val_accuracy: 0.6176\n",
      "Epoch 280/2000\n",
      "103/103 [==============================] - 0s 145us/sample - loss: 0.9140 - accuracy: 0.7573 - val_loss: 1.2954 - val_accuracy: 0.6176\n",
      "Epoch 281/2000\n",
      "103/103 [==============================] - 0s 149us/sample - loss: 0.9501 - accuracy: 0.7379 - val_loss: 1.2982 - val_accuracy: 0.6176\n",
      "Epoch 282/2000\n",
      "103/103 [==============================] - 0s 149us/sample - loss: 0.9922 - accuracy: 0.7670 - val_loss: 1.2883 - val_accuracy: 0.6176\n",
      "Epoch 283/2000\n",
      "103/103 [==============================] - 0s 138us/sample - loss: 0.9498 - accuracy: 0.7184 - val_loss: 1.2978 - val_accuracy: 0.6471\n",
      "Epoch 284/2000\n",
      "103/103 [==============================] - 0s 139us/sample - loss: 0.8961 - accuracy: 0.8447 - val_loss: 1.2884 - val_accuracy: 0.6176\n",
      "Epoch 285/2000\n",
      "103/103 [==============================] - 0s 124us/sample - loss: 0.8893 - accuracy: 0.7767 - val_loss: 1.2987 - val_accuracy: 0.6176\n",
      "Epoch 286/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.9321 - accuracy: 0.7476 - val_loss: 1.3026 - val_accuracy: 0.5882\n",
      "Epoch 287/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.9660 - accuracy: 0.7573 - val_loss: 1.3019 - val_accuracy: 0.6176\n",
      "Epoch 288/2000\n",
      "103/103 [==============================] - 0s 107us/sample - loss: 0.8170 - accuracy: 0.8155 - val_loss: 1.3091 - val_accuracy: 0.6176\n",
      "Epoch 289/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.9389 - accuracy: 0.7767 - val_loss: 1.3084 - val_accuracy: 0.5882\n",
      "Epoch 290/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.8633 - accuracy: 0.8350 - val_loss: 1.3108 - val_accuracy: 0.5882\n",
      "Epoch 291/2000\n",
      "103/103 [==============================] - 0s 104us/sample - loss: 0.9413 - accuracy: 0.7573 - val_loss: 1.2947 - val_accuracy: 0.6176\n",
      "Epoch 292/2000\n",
      "103/103 [==============================] - 0s 104us/sample - loss: 0.9053 - accuracy: 0.7670 - val_loss: 1.2988 - val_accuracy: 0.6176\n",
      "Epoch 293/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.8547 - accuracy: 0.7961 - val_loss: 1.3004 - val_accuracy: 0.5882\n",
      "Epoch 294/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.8911 - accuracy: 0.7767 - val_loss: 1.3055 - val_accuracy: 0.5882\n",
      "Epoch 295/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.8196 - accuracy: 0.9320 - val_loss: 1.2849 - val_accuracy: 0.6176\n",
      "Epoch 296/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.8597 - accuracy: 0.8252 - val_loss: 1.2935 - val_accuracy: 0.6471\n",
      "Epoch 297/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.9271 - accuracy: 0.7961 - val_loss: 1.2916 - val_accuracy: 0.6176\n",
      "Epoch 298/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.9156 - accuracy: 0.7476 - val_loss: 1.2879 - val_accuracy: 0.6176\n",
      "Epoch 299/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.8770 - accuracy: 0.7767 - val_loss: 1.2827 - val_accuracy: 0.6176\n",
      "Epoch 300/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.8551 - accuracy: 0.8252 - val_loss: 1.2780 - val_accuracy: 0.6176\n",
      "Epoch 301/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.8511 - accuracy: 0.7573 - val_loss: 1.2807 - val_accuracy: 0.6176\n",
      "Epoch 302/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.8094 - accuracy: 0.8641 - val_loss: 1.2679 - val_accuracy: 0.6176\n",
      "Epoch 303/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.9437 - accuracy: 0.8058 - val_loss: 1.2546 - val_accuracy: 0.6176\n",
      "Epoch 304/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 0.8285 - accuracy: 0.8447 - val_loss: 1.2553 - val_accuracy: 0.6176\n",
      "Epoch 305/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.8974 - accuracy: 0.7670 - val_loss: 1.2480 - val_accuracy: 0.6176\n",
      "Epoch 306/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.7974 - accuracy: 0.9029 - val_loss: 1.2484 - val_accuracy: 0.6176\n",
      "Epoch 307/2000\n",
      "103/103 [==============================] - 0s 117us/sample - loss: 0.8814 - accuracy: 0.7767 - val_loss: 1.2505 - val_accuracy: 0.6176\n",
      "Epoch 308/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.8388 - accuracy: 0.8058 - val_loss: 1.2507 - val_accuracy: 0.6176\n",
      "Epoch 309/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.8305 - accuracy: 0.8155 - val_loss: 1.2527 - val_accuracy: 0.6176\n",
      "Epoch 310/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.8137 - accuracy: 0.8058 - val_loss: 1.2618 - val_accuracy: 0.6176\n",
      "Epoch 311/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.8560 - accuracy: 0.8447 - val_loss: 1.2508 - val_accuracy: 0.6471\n",
      "Epoch 312/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.8306 - accuracy: 0.7961 - val_loss: 1.2476 - val_accuracy: 0.6176\n",
      "Epoch 313/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.8106 - accuracy: 0.8641 - val_loss: 1.2490 - val_accuracy: 0.6471\n",
      "Epoch 314/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.8260 - accuracy: 0.8058 - val_loss: 1.2522 - val_accuracy: 0.5882\n",
      "Epoch 315/2000\n",
      "103/103 [==============================] - 0s 107us/sample - loss: 0.8365 - accuracy: 0.8641 - val_loss: 1.2549 - val_accuracy: 0.5882\n",
      "Epoch 316/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.8127 - accuracy: 0.7864 - val_loss: 1.2498 - val_accuracy: 0.5882\n",
      "Epoch 317/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.8822 - accuracy: 0.7573 - val_loss: 1.2558 - val_accuracy: 0.5882\n",
      "Epoch 318/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.8173 - accuracy: 0.8447 - val_loss: 1.2552 - val_accuracy: 0.5882\n",
      "Epoch 319/2000\n",
      "103/103 [==============================] - 0s 106us/sample - loss: 0.8172 - accuracy: 0.8155 - val_loss: 1.2498 - val_accuracy: 0.5588\n",
      "Epoch 320/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.8142 - accuracy: 0.8058 - val_loss: 1.2403 - val_accuracy: 0.6176\n",
      "Epoch 321/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.8269 - accuracy: 0.8252 - val_loss: 1.2421 - val_accuracy: 0.5882\n",
      "Epoch 322/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.8537 - accuracy: 0.7767 - val_loss: 1.2406 - val_accuracy: 0.5882\n",
      "Epoch 323/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.7758 - accuracy: 0.8155 - val_loss: 1.2399 - val_accuracy: 0.5882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.8689 - accuracy: 0.7864 - val_loss: 1.2305 - val_accuracy: 0.6176\n",
      "Epoch 325/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.7981 - accuracy: 0.7767 - val_loss: 1.2250 - val_accuracy: 0.5882\n",
      "Epoch 326/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 0.8509 - accuracy: 0.7670 - val_loss: 1.2214 - val_accuracy: 0.5882\n",
      "Epoch 327/2000\n",
      "103/103 [==============================] - 0s 104us/sample - loss: 0.7905 - accuracy: 0.8544 - val_loss: 1.2292 - val_accuracy: 0.6176\n",
      "Epoch 328/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.8065 - accuracy: 0.8447 - val_loss: 1.2307 - val_accuracy: 0.6176\n",
      "Epoch 329/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.7623 - accuracy: 0.8544 - val_loss: 1.2316 - val_accuracy: 0.6176\n",
      "Epoch 330/2000\n",
      "103/103 [==============================] - 0s 106us/sample - loss: 0.8734 - accuracy: 0.8155 - val_loss: 1.2284 - val_accuracy: 0.6176\n",
      "Epoch 331/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.7750 - accuracy: 0.8058 - val_loss: 1.2206 - val_accuracy: 0.5882\n",
      "Epoch 332/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.7120 - accuracy: 0.8447 - val_loss: 1.2142 - val_accuracy: 0.6471\n",
      "Epoch 333/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.7481 - accuracy: 0.8155 - val_loss: 1.2131 - val_accuracy: 0.6176\n",
      "Epoch 334/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.7746 - accuracy: 0.7961 - val_loss: 1.2037 - val_accuracy: 0.6471\n",
      "Epoch 335/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.7682 - accuracy: 0.8738 - val_loss: 1.2069 - val_accuracy: 0.6471\n",
      "Epoch 336/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.7894 - accuracy: 0.8447 - val_loss: 1.2184 - val_accuracy: 0.5882\n",
      "Epoch 337/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.8225 - accuracy: 0.8350 - val_loss: 1.2235 - val_accuracy: 0.5882\n",
      "Epoch 338/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.8271 - accuracy: 0.8447 - val_loss: 1.2186 - val_accuracy: 0.5588\n",
      "Epoch 339/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.7300 - accuracy: 0.8058 - val_loss: 1.2121 - val_accuracy: 0.6176\n",
      "Epoch 340/2000\n",
      "103/103 [==============================] - 0s 107us/sample - loss: 0.7638 - accuracy: 0.8447 - val_loss: 1.2073 - val_accuracy: 0.6176\n",
      "Epoch 341/2000\n",
      "103/103 [==============================] - 0s 105us/sample - loss: 0.7607 - accuracy: 0.8738 - val_loss: 1.2126 - val_accuracy: 0.6471\n",
      "Epoch 342/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.7133 - accuracy: 0.8738 - val_loss: 1.2198 - val_accuracy: 0.5588\n",
      "Epoch 343/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.7622 - accuracy: 0.8447 - val_loss: 1.2103 - val_accuracy: 0.5882\n",
      "Epoch 344/2000\n",
      "103/103 [==============================] - 0s 116us/sample - loss: 0.7989 - accuracy: 0.7864 - val_loss: 1.2154 - val_accuracy: 0.5588\n",
      "Epoch 345/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 0.7076 - accuracy: 0.8835 - val_loss: 1.2002 - val_accuracy: 0.5882\n",
      "Epoch 346/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.7564 - accuracy: 0.8350 - val_loss: 1.1878 - val_accuracy: 0.6176\n",
      "Epoch 347/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.7190 - accuracy: 0.8835 - val_loss: 1.1819 - val_accuracy: 0.6471\n",
      "Epoch 348/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.7354 - accuracy: 0.8350 - val_loss: 1.1810 - val_accuracy: 0.6176\n",
      "Epoch 349/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.7196 - accuracy: 0.8544 - val_loss: 1.1856 - val_accuracy: 0.6176\n",
      "Epoch 350/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.7377 - accuracy: 0.8544 - val_loss: 1.1732 - val_accuracy: 0.6176\n",
      "Epoch 351/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.7734 - accuracy: 0.8252 - val_loss: 1.1777 - val_accuracy: 0.6176\n",
      "Epoch 352/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.7822 - accuracy: 0.8058 - val_loss: 1.1831 - val_accuracy: 0.6176\n",
      "Epoch 353/2000\n",
      "103/103 [==============================] - 0s 117us/sample - loss: 0.7495 - accuracy: 0.8932 - val_loss: 1.1900 - val_accuracy: 0.6176\n",
      "Epoch 354/2000\n",
      "103/103 [==============================] - 0s 116us/sample - loss: 0.7488 - accuracy: 0.8058 - val_loss: 1.1962 - val_accuracy: 0.5882\n",
      "Epoch 355/2000\n",
      "103/103 [==============================] - 0s 121us/sample - loss: 0.7070 - accuracy: 0.8350 - val_loss: 1.2053 - val_accuracy: 0.5882\n",
      "Epoch 356/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.7584 - accuracy: 0.8447 - val_loss: 1.1930 - val_accuracy: 0.5882\n",
      "Epoch 357/2000\n",
      "103/103 [==============================] - 0s 106us/sample - loss: 0.7221 - accuracy: 0.8738 - val_loss: 1.1959 - val_accuracy: 0.5882\n",
      "Epoch 358/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.7122 - accuracy: 0.8932 - val_loss: 1.1983 - val_accuracy: 0.5882\n",
      "Epoch 359/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 0.7527 - accuracy: 0.8058 - val_loss: 1.1909 - val_accuracy: 0.5588\n",
      "Epoch 360/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.7824 - accuracy: 0.8544 - val_loss: 1.1800 - val_accuracy: 0.5588\n",
      "Epoch 361/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.7307 - accuracy: 0.8544 - val_loss: 1.1839 - val_accuracy: 0.6176\n",
      "Epoch 362/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 0.7792 - accuracy: 0.7767 - val_loss: 1.1826 - val_accuracy: 0.6176\n",
      "Epoch 363/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.7326 - accuracy: 0.8155 - val_loss: 1.1792 - val_accuracy: 0.5882\n",
      "Epoch 364/2000\n",
      "103/103 [==============================] - 0s 104us/sample - loss: 0.6572 - accuracy: 0.8932 - val_loss: 1.1749 - val_accuracy: 0.6471\n",
      "Epoch 365/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.6932 - accuracy: 0.9126 - val_loss: 1.1804 - val_accuracy: 0.5294\n",
      "Epoch 366/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.7239 - accuracy: 0.8641 - val_loss: 1.1768 - val_accuracy: 0.5882\n",
      "Epoch 367/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.6759 - accuracy: 0.9029 - val_loss: 1.1720 - val_accuracy: 0.5882\n",
      "Epoch 368/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.7946 - accuracy: 0.7864 - val_loss: 1.1774 - val_accuracy: 0.5294\n",
      "Epoch 369/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.7263 - accuracy: 0.8155 - val_loss: 1.1605 - val_accuracy: 0.5882\n",
      "Epoch 370/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.6929 - accuracy: 0.8544 - val_loss: 1.1673 - val_accuracy: 0.5588\n",
      "Epoch 371/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.7525 - accuracy: 0.8447 - val_loss: 1.1600 - val_accuracy: 0.6176\n",
      "Epoch 372/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.7131 - accuracy: 0.8447 - val_loss: 1.1624 - val_accuracy: 0.5882\n",
      "Epoch 373/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.6965 - accuracy: 0.8932 - val_loss: 1.1480 - val_accuracy: 0.6176\n",
      "Epoch 374/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.7742 - accuracy: 0.8350 - val_loss: 1.1484 - val_accuracy: 0.6176\n",
      "Epoch 375/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.6836 - accuracy: 0.8932 - val_loss: 1.1430 - val_accuracy: 0.6176\n",
      "Epoch 376/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.6616 - accuracy: 0.9223 - val_loss: 1.1491 - val_accuracy: 0.6176\n",
      "Epoch 377/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 0.6518 - accuracy: 0.8641 - val_loss: 1.1498 - val_accuracy: 0.5882\n",
      "Epoch 378/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 109us/sample - loss: 0.6789 - accuracy: 0.8641 - val_loss: 1.1577 - val_accuracy: 0.5882\n",
      "Epoch 379/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.6275 - accuracy: 0.9029 - val_loss: 1.1488 - val_accuracy: 0.6176\n",
      "Epoch 380/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.6943 - accuracy: 0.8252 - val_loss: 1.1499 - val_accuracy: 0.6176\n",
      "Epoch 381/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.6637 - accuracy: 0.8738 - val_loss: 1.1545 - val_accuracy: 0.6176\n",
      "Epoch 382/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.6979 - accuracy: 0.8350 - val_loss: 1.1567 - val_accuracy: 0.6176\n",
      "Epoch 383/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 0.7389 - accuracy: 0.8350 - val_loss: 1.1475 - val_accuracy: 0.5882\n",
      "Epoch 384/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 0.6397 - accuracy: 0.8641 - val_loss: 1.1587 - val_accuracy: 0.5882\n",
      "Epoch 385/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.6867 - accuracy: 0.8350 - val_loss: 1.1582 - val_accuracy: 0.6176\n",
      "Epoch 386/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.6440 - accuracy: 0.8738 - val_loss: 1.1564 - val_accuracy: 0.6176\n",
      "Epoch 387/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.6230 - accuracy: 0.8932 - val_loss: 1.1569 - val_accuracy: 0.6176\n",
      "Epoch 388/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.7342 - accuracy: 0.8350 - val_loss: 1.1418 - val_accuracy: 0.6176\n",
      "Epoch 389/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.6711 - accuracy: 0.8835 - val_loss: 1.1507 - val_accuracy: 0.5588\n",
      "Epoch 390/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.6743 - accuracy: 0.8641 - val_loss: 1.1384 - val_accuracy: 0.5882\n",
      "Epoch 391/2000\n",
      "103/103 [==============================] - 0s 107us/sample - loss: 0.6503 - accuracy: 0.8932 - val_loss: 1.1375 - val_accuracy: 0.5882\n",
      "Epoch 392/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.6360 - accuracy: 0.8544 - val_loss: 1.1493 - val_accuracy: 0.5588\n",
      "Epoch 393/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.6653 - accuracy: 0.8544 - val_loss: 1.1435 - val_accuracy: 0.5588\n",
      "Epoch 394/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.6136 - accuracy: 0.9126 - val_loss: 1.1429 - val_accuracy: 0.5588\n",
      "Epoch 395/2000\n",
      "103/103 [==============================] - 0s 107us/sample - loss: 0.6599 - accuracy: 0.8155 - val_loss: 1.1334 - val_accuracy: 0.5294\n",
      "Epoch 396/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.6031 - accuracy: 0.9223 - val_loss: 1.1315 - val_accuracy: 0.5882\n",
      "Epoch 397/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.6514 - accuracy: 0.8835 - val_loss: 1.1311 - val_accuracy: 0.5588\n",
      "Epoch 398/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.6737 - accuracy: 0.9126 - val_loss: 1.1150 - val_accuracy: 0.5882\n",
      "Epoch 399/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.7009 - accuracy: 0.8058 - val_loss: 1.1157 - val_accuracy: 0.6176\n",
      "Epoch 400/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.6591 - accuracy: 0.8641 - val_loss: 1.1270 - val_accuracy: 0.6176\n",
      "Epoch 401/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.7180 - accuracy: 0.8252 - val_loss: 1.1190 - val_accuracy: 0.5882\n",
      "Epoch 402/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.6188 - accuracy: 0.8932 - val_loss: 1.1178 - val_accuracy: 0.6176\n",
      "Epoch 403/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 0.6282 - accuracy: 0.8447 - val_loss: 1.1253 - val_accuracy: 0.5882\n",
      "Epoch 404/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 0.5458 - accuracy: 0.9126 - val_loss: 1.1056 - val_accuracy: 0.6176\n",
      "Epoch 405/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 0.6196 - accuracy: 0.9223 - val_loss: 1.1186 - val_accuracy: 0.6176\n",
      "Epoch 406/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 0.6543 - accuracy: 0.8738 - val_loss: 1.1328 - val_accuracy: 0.5882\n",
      "Epoch 407/2000\n",
      "103/103 [==============================] - 0s 117us/sample - loss: 0.5490 - accuracy: 0.9029 - val_loss: 1.1398 - val_accuracy: 0.5882\n",
      "Epoch 408/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.5872 - accuracy: 0.9320 - val_loss: 1.1307 - val_accuracy: 0.5882\n",
      "Epoch 409/2000\n",
      "103/103 [==============================] - 0s 107us/sample - loss: 0.6480 - accuracy: 0.8835 - val_loss: 1.1293 - val_accuracy: 0.5588\n",
      "Epoch 410/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.6379 - accuracy: 0.8544 - val_loss: 1.1329 - val_accuracy: 0.5294\n",
      "Epoch 411/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.6000 - accuracy: 0.8932 - val_loss: 1.1356 - val_accuracy: 0.5588\n",
      "Epoch 412/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.5858 - accuracy: 0.9029 - val_loss: 1.1158 - val_accuracy: 0.6765\n",
      "Epoch 413/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.6033 - accuracy: 0.8738 - val_loss: 1.1116 - val_accuracy: 0.6471\n",
      "Epoch 414/2000\n",
      "103/103 [==============================] - 0s 107us/sample - loss: 0.6485 - accuracy: 0.8835 - val_loss: 1.1189 - val_accuracy: 0.6471\n",
      "Epoch 415/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.6006 - accuracy: 0.8932 - val_loss: 1.1020 - val_accuracy: 0.6765\n",
      "Epoch 416/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.6478 - accuracy: 0.8835 - val_loss: 1.1094 - val_accuracy: 0.5882\n",
      "Epoch 417/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.5849 - accuracy: 0.9223 - val_loss: 1.1107 - val_accuracy: 0.6471\n",
      "Epoch 418/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.6078 - accuracy: 0.8738 - val_loss: 1.1152 - val_accuracy: 0.6176\n",
      "Epoch 419/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.5796 - accuracy: 0.9029 - val_loss: 1.1053 - val_accuracy: 0.6471\n",
      "Epoch 420/2000\n",
      "103/103 [==============================] - 0s 117us/sample - loss: 0.6834 - accuracy: 0.8544 - val_loss: 1.1074 - val_accuracy: 0.6176\n",
      "Epoch 421/2000\n",
      "103/103 [==============================] - 0s 162us/sample - loss: 0.6362 - accuracy: 0.8350 - val_loss: 1.1192 - val_accuracy: 0.6176\n",
      "Epoch 422/2000\n",
      "103/103 [==============================] - 0s 142us/sample - loss: 0.6669 - accuracy: 0.8641 - val_loss: 1.1115 - val_accuracy: 0.6471\n",
      "Epoch 423/2000\n",
      "103/103 [==============================] - 0s 147us/sample - loss: 0.5407 - accuracy: 0.9029 - val_loss: 1.1059 - val_accuracy: 0.6471\n",
      "Epoch 424/2000\n",
      "103/103 [==============================] - 0s 126us/sample - loss: 0.6306 - accuracy: 0.8738 - val_loss: 1.1068 - val_accuracy: 0.6471\n",
      "Epoch 425/2000\n",
      "103/103 [==============================] - 0s 129us/sample - loss: 0.5697 - accuracy: 0.8932 - val_loss: 1.1106 - val_accuracy: 0.6176\n",
      "Epoch 426/2000\n",
      "103/103 [==============================] - 0s 142us/sample - loss: 0.6336 - accuracy: 0.9029 - val_loss: 1.1087 - val_accuracy: 0.6471\n",
      "Epoch 427/2000\n",
      "103/103 [==============================] - 0s 149us/sample - loss: 0.5328 - accuracy: 0.9223 - val_loss: 1.1011 - val_accuracy: 0.6176\n",
      "Epoch 428/2000\n",
      "103/103 [==============================] - 0s 152us/sample - loss: 0.5570 - accuracy: 0.9320 - val_loss: 1.0983 - val_accuracy: 0.6176\n",
      "Epoch 429/2000\n",
      "103/103 [==============================] - 0s 142us/sample - loss: 0.5918 - accuracy: 0.8738 - val_loss: 1.1069 - val_accuracy: 0.6471\n",
      "Epoch 430/2000\n",
      "103/103 [==============================] - 0s 146us/sample - loss: 0.6044 - accuracy: 0.8641 - val_loss: 1.1171 - val_accuracy: 0.6176\n",
      "Epoch 431/2000\n",
      "103/103 [==============================] - 0s 147us/sample - loss: 0.5729 - accuracy: 0.8932 - val_loss: 1.1126 - val_accuracy: 0.6176\n",
      "Epoch 432/2000\n",
      "103/103 [==============================] - 0s 152us/sample - loss: 0.5972 - accuracy: 0.8835 - val_loss: 1.1213 - val_accuracy: 0.6176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/2000\n",
      "103/103 [==============================] - 0s 141us/sample - loss: 0.6003 - accuracy: 0.8835 - val_loss: 1.1156 - val_accuracy: 0.6176\n",
      "Epoch 434/2000\n",
      "103/103 [==============================] - 0s 163us/sample - loss: 0.6213 - accuracy: 0.8738 - val_loss: 1.1009 - val_accuracy: 0.6176\n",
      "Epoch 435/2000\n",
      "103/103 [==============================] - 0s 148us/sample - loss: 0.5774 - accuracy: 0.9029 - val_loss: 1.0979 - val_accuracy: 0.6471\n",
      "Epoch 436/2000\n",
      "103/103 [==============================] - 0s 152us/sample - loss: 0.5557 - accuracy: 0.9126 - val_loss: 1.1081 - val_accuracy: 0.6176\n",
      "Epoch 437/2000\n",
      "103/103 [==============================] - 0s 146us/sample - loss: 0.5809 - accuracy: 0.8835 - val_loss: 1.0969 - val_accuracy: 0.6471\n",
      "Epoch 438/2000\n",
      "103/103 [==============================] - 0s 143us/sample - loss: 0.5310 - accuracy: 0.9223 - val_loss: 1.0965 - val_accuracy: 0.6471\n",
      "Epoch 439/2000\n",
      "103/103 [==============================] - 0s 133us/sample - loss: 0.5982 - accuracy: 0.8350 - val_loss: 1.1076 - val_accuracy: 0.6176\n",
      "Epoch 440/2000\n",
      "103/103 [==============================] - 0s 139us/sample - loss: 0.5145 - accuracy: 0.9515 - val_loss: 1.1053 - val_accuracy: 0.6176\n",
      "Epoch 441/2000\n",
      "103/103 [==============================] - 0s 138us/sample - loss: 0.5500 - accuracy: 0.9223 - val_loss: 1.1110 - val_accuracy: 0.5882\n",
      "Epoch 442/2000\n",
      "103/103 [==============================] - 0s 140us/sample - loss: 0.6195 - accuracy: 0.8738 - val_loss: 1.1157 - val_accuracy: 0.5882\n",
      "Epoch 443/2000\n",
      "103/103 [==============================] - 0s 140us/sample - loss: 0.5190 - accuracy: 0.9126 - val_loss: 1.0984 - val_accuracy: 0.6176\n",
      "Epoch 444/2000\n",
      "103/103 [==============================] - 0s 151us/sample - loss: 0.5593 - accuracy: 0.9223 - val_loss: 1.1055 - val_accuracy: 0.6176\n",
      "Epoch 445/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 0.5724 - accuracy: 0.9029 - val_loss: 1.1003 - val_accuracy: 0.6176\n",
      "Epoch 446/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.5420 - accuracy: 0.9223 - val_loss: 1.1031 - val_accuracy: 0.5882\n",
      "Epoch 447/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.5515 - accuracy: 0.8932 - val_loss: 1.1036 - val_accuracy: 0.5882\n",
      "Epoch 448/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.6024 - accuracy: 0.8544 - val_loss: 1.1076 - val_accuracy: 0.5882\n",
      "Epoch 449/2000\n",
      "103/103 [==============================] - 0s 116us/sample - loss: 0.5721 - accuracy: 0.8641 - val_loss: 1.1077 - val_accuracy: 0.5588\n",
      "Epoch 450/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.6162 - accuracy: 0.8641 - val_loss: 1.1058 - val_accuracy: 0.5882\n",
      "Epoch 451/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.5612 - accuracy: 0.9029 - val_loss: 1.1087 - val_accuracy: 0.6176\n",
      "Epoch 452/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.5463 - accuracy: 0.9029 - val_loss: 1.1030 - val_accuracy: 0.5882\n",
      "Epoch 453/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.5666 - accuracy: 0.9029 - val_loss: 1.0987 - val_accuracy: 0.6176\n",
      "Epoch 454/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 0.5365 - accuracy: 0.9029 - val_loss: 1.0944 - val_accuracy: 0.6176\n",
      "Epoch 455/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.6179 - accuracy: 0.8544 - val_loss: 1.0850 - val_accuracy: 0.6765\n",
      "Epoch 456/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.5153 - accuracy: 0.9126 - val_loss: 1.0786 - val_accuracy: 0.6471\n",
      "Epoch 457/2000\n",
      "103/103 [==============================] - 0s 117us/sample - loss: 0.5701 - accuracy: 0.9029 - val_loss: 1.0778 - val_accuracy: 0.6471\n",
      "Epoch 458/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.5473 - accuracy: 0.8835 - val_loss: 1.0812 - val_accuracy: 0.6176\n",
      "Epoch 459/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.5325 - accuracy: 0.9126 - val_loss: 1.0843 - val_accuracy: 0.6471\n",
      "Epoch 460/2000\n",
      "103/103 [==============================] - 0s 120us/sample - loss: 0.5302 - accuracy: 0.9029 - val_loss: 1.0859 - val_accuracy: 0.6471\n",
      "Epoch 461/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.4824 - accuracy: 0.9612 - val_loss: 1.0990 - val_accuracy: 0.6176\n",
      "Epoch 462/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.5526 - accuracy: 0.9126 - val_loss: 1.0891 - val_accuracy: 0.6176\n",
      "Epoch 463/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.5795 - accuracy: 0.8835 - val_loss: 1.0937 - val_accuracy: 0.6176\n",
      "Epoch 464/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.5367 - accuracy: 0.9223 - val_loss: 1.0902 - val_accuracy: 0.5882\n",
      "Epoch 465/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.5954 - accuracy: 0.8447 - val_loss: 1.0853 - val_accuracy: 0.6176\n",
      "Epoch 466/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.5527 - accuracy: 0.8738 - val_loss: 1.0771 - val_accuracy: 0.6471\n",
      "Epoch 467/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 0.6369 - accuracy: 0.8641 - val_loss: 1.0731 - val_accuracy: 0.6176\n",
      "Epoch 468/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.5338 - accuracy: 0.8835 - val_loss: 1.0659 - val_accuracy: 0.5882\n",
      "Epoch 469/2000\n",
      "103/103 [==============================] - 0s 107us/sample - loss: 0.4974 - accuracy: 0.9417 - val_loss: 1.0778 - val_accuracy: 0.5882\n",
      "Epoch 470/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 0.5089 - accuracy: 0.9126 - val_loss: 1.0846 - val_accuracy: 0.5882\n",
      "Epoch 471/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.5557 - accuracy: 0.8932 - val_loss: 1.0732 - val_accuracy: 0.6176\n",
      "Epoch 472/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.5416 - accuracy: 0.8932 - val_loss: 1.0662 - val_accuracy: 0.5882\n",
      "Epoch 473/2000\n",
      "103/103 [==============================] - 0s 116us/sample - loss: 0.5147 - accuracy: 0.9223 - val_loss: 1.0733 - val_accuracy: 0.5882\n",
      "Epoch 474/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.5424 - accuracy: 0.8932 - val_loss: 1.0633 - val_accuracy: 0.6176\n",
      "Epoch 475/2000\n",
      "103/103 [==============================] - 0s 107us/sample - loss: 0.5519 - accuracy: 0.8835 - val_loss: 1.0687 - val_accuracy: 0.6176\n",
      "Epoch 476/2000\n",
      "103/103 [==============================] - 0s 118us/sample - loss: 0.5031 - accuracy: 0.9320 - val_loss: 1.0518 - val_accuracy: 0.6471\n",
      "Epoch 477/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.5767 - accuracy: 0.9029 - val_loss: 1.0441 - val_accuracy: 0.6471\n",
      "Epoch 478/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.4989 - accuracy: 0.9126 - val_loss: 1.0372 - val_accuracy: 0.6765\n",
      "Epoch 479/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.4995 - accuracy: 0.9223 - val_loss: 1.0548 - val_accuracy: 0.6471\n",
      "Epoch 480/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.4984 - accuracy: 0.8932 - val_loss: 1.0683 - val_accuracy: 0.6471\n",
      "Epoch 481/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.4992 - accuracy: 0.9223 - val_loss: 1.0714 - val_accuracy: 0.6176\n",
      "Epoch 482/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.4625 - accuracy: 0.9320 - val_loss: 1.0863 - val_accuracy: 0.6176\n",
      "Epoch 483/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.5603 - accuracy: 0.9029 - val_loss: 1.0751 - val_accuracy: 0.5882\n",
      "Epoch 484/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 0.4862 - accuracy: 0.9223 - val_loss: 1.0664 - val_accuracy: 0.6471\n",
      "Epoch 485/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.5044 - accuracy: 0.9126 - val_loss: 1.0744 - val_accuracy: 0.5882\n",
      "Epoch 486/2000\n",
      "103/103 [==============================] - 0s 117us/sample - loss: 0.5052 - accuracy: 0.9223 - val_loss: 1.0756 - val_accuracy: 0.6176\n",
      "Epoch 487/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 111us/sample - loss: 0.5386 - accuracy: 0.9029 - val_loss: 1.0777 - val_accuracy: 0.5882\n",
      "Epoch 488/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 0.5290 - accuracy: 0.9223 - val_loss: 1.0751 - val_accuracy: 0.6176\n",
      "Epoch 489/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.5280 - accuracy: 0.9029 - val_loss: 1.0685 - val_accuracy: 0.6176\n",
      "Epoch 490/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.4754 - accuracy: 0.9029 - val_loss: 1.0753 - val_accuracy: 0.6176\n",
      "Epoch 491/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 0.4989 - accuracy: 0.9126 - val_loss: 1.0773 - val_accuracy: 0.6471\n",
      "Epoch 492/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.5285 - accuracy: 0.9126 - val_loss: 1.0772 - val_accuracy: 0.6176\n",
      "Epoch 493/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.4674 - accuracy: 0.9320 - val_loss: 1.0795 - val_accuracy: 0.6471\n",
      "Epoch 494/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.5311 - accuracy: 0.9126 - val_loss: 1.0757 - val_accuracy: 0.6176\n",
      "Epoch 495/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.4675 - accuracy: 0.9417 - val_loss: 1.0866 - val_accuracy: 0.5882\n",
      "Epoch 496/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.4420 - accuracy: 0.9709 - val_loss: 1.0749 - val_accuracy: 0.6176\n",
      "Epoch 497/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.4709 - accuracy: 0.9223 - val_loss: 1.0764 - val_accuracy: 0.6176\n",
      "Epoch 498/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.5117 - accuracy: 0.8932 - val_loss: 1.0689 - val_accuracy: 0.6176\n",
      "Epoch 499/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.5387 - accuracy: 0.8641 - val_loss: 1.0705 - val_accuracy: 0.6176\n",
      "Epoch 500/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.4704 - accuracy: 0.9417 - val_loss: 1.0762 - val_accuracy: 0.6471\n",
      "Epoch 501/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.4951 - accuracy: 0.9320 - val_loss: 1.0863 - val_accuracy: 0.6176\n",
      "Epoch 502/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.5277 - accuracy: 0.9320 - val_loss: 1.0790 - val_accuracy: 0.6176\n",
      "Epoch 503/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.4392 - accuracy: 0.9709 - val_loss: 1.0692 - val_accuracy: 0.5882\n",
      "Epoch 504/2000\n",
      "103/103 [==============================] - 0s 105us/sample - loss: 0.5285 - accuracy: 0.9029 - val_loss: 1.0811 - val_accuracy: 0.5882\n",
      "Epoch 505/2000\n",
      "103/103 [==============================] - 0s 106us/sample - loss: 0.4540 - accuracy: 0.9126 - val_loss: 1.0764 - val_accuracy: 0.6176\n",
      "Epoch 506/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.4608 - accuracy: 0.9126 - val_loss: 1.0866 - val_accuracy: 0.5882\n",
      "Epoch 507/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.5214 - accuracy: 0.8932 - val_loss: 1.0875 - val_accuracy: 0.5882\n",
      "Epoch 508/2000\n",
      "103/103 [==============================] - 0s 114us/sample - loss: 0.4530 - accuracy: 0.9417 - val_loss: 1.0948 - val_accuracy: 0.5882\n",
      "Epoch 509/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.5034 - accuracy: 0.9223 - val_loss: 1.1040 - val_accuracy: 0.5882\n",
      "Epoch 510/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.4465 - accuracy: 0.9709 - val_loss: 1.0892 - val_accuracy: 0.6176\n",
      "Epoch 511/2000\n",
      "103/103 [==============================] - 0s 113us/sample - loss: 0.5264 - accuracy: 0.9029 - val_loss: 1.0932 - val_accuracy: 0.5882\n",
      "Epoch 512/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.4569 - accuracy: 0.9417 - val_loss: 1.0818 - val_accuracy: 0.6176\n",
      "Epoch 513/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.4704 - accuracy: 0.9223 - val_loss: 1.0731 - val_accuracy: 0.6176\n",
      "Epoch 514/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.4727 - accuracy: 0.9417 - val_loss: 1.0744 - val_accuracy: 0.6471\n",
      "Epoch 515/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.4567 - accuracy: 0.9223 - val_loss: 1.0732 - val_accuracy: 0.6176\n",
      "Epoch 516/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.4189 - accuracy: 0.9515 - val_loss: 1.0679 - val_accuracy: 0.6176\n",
      "Epoch 517/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.4853 - accuracy: 0.9223 - val_loss: 1.0716 - val_accuracy: 0.5882\n",
      "Epoch 518/2000\n",
      "103/103 [==============================] - 0s 108us/sample - loss: 0.4593 - accuracy: 0.9612 - val_loss: 1.0672 - val_accuracy: 0.6176\n",
      "Epoch 519/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.4924 - accuracy: 0.9126 - val_loss: 1.0774 - val_accuracy: 0.5882\n",
      "Epoch 520/2000\n",
      "103/103 [==============================] - 0s 115us/sample - loss: 0.4496 - accuracy: 0.9126 - val_loss: 1.0684 - val_accuracy: 0.6176\n",
      "Epoch 521/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.4718 - accuracy: 0.9223 - val_loss: 1.0767 - val_accuracy: 0.5882\n",
      "Epoch 522/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.4229 - accuracy: 0.9515 - val_loss: 1.0851 - val_accuracy: 0.6176\n",
      "Epoch 523/2000\n",
      "103/103 [==============================] - 0s 112us/sample - loss: 0.5372 - accuracy: 0.8835 - val_loss: 1.0763 - val_accuracy: 0.6176\n",
      "Epoch 524/2000\n",
      "103/103 [==============================] - 0s 116us/sample - loss: 0.4376 - accuracy: 0.9417 - val_loss: 1.0506 - val_accuracy: 0.6471\n",
      "Epoch 525/2000\n",
      "103/103 [==============================] - 0s 111us/sample - loss: 0.4160 - accuracy: 0.9612 - val_loss: 1.0537 - val_accuracy: 0.6471\n",
      "Epoch 526/2000\n",
      "103/103 [==============================] - 0s 116us/sample - loss: 0.5376 - accuracy: 0.9126 - val_loss: 1.0613 - val_accuracy: 0.5882\n",
      "Epoch 527/2000\n",
      "103/103 [==============================] - 0s 109us/sample - loss: 0.4561 - accuracy: 0.9320 - val_loss: 1.0612 - val_accuracy: 0.6471\n",
      "Epoch 528/2000\n",
      "103/103 [==============================] - 0s 110us/sample - loss: 0.5187 - accuracy: 0.8641 - val_loss: 1.0546 - val_accuracy: 0.6471\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 2,062\n",
      "Trainable params: 2,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 206 samples, validate on 69 samples\n",
      "Epoch 1/2000\n",
      "206/206 [==============================] - 0s 2ms/sample - loss: 2.6521 - accuracy: 0.1165 - val_loss: 2.6165 - val_accuracy: 0.0870\n",
      "Epoch 2/2000\n",
      "206/206 [==============================] - 0s 80us/sample - loss: 2.6255 - accuracy: 0.1117 - val_loss: 2.5982 - val_accuracy: 0.1304\n",
      "Epoch 3/2000\n",
      "206/206 [==============================] - 0s 75us/sample - loss: 2.6149 - accuracy: 0.1262 - val_loss: 2.5844 - val_accuracy: 0.2029\n",
      "Epoch 4/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 2.6109 - accuracy: 0.1214 - val_loss: 2.5753 - val_accuracy: 0.2464\n",
      "Epoch 5/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 2.5631 - accuracy: 0.1845 - val_loss: 2.5604 - val_accuracy: 0.2899\n",
      "Epoch 6/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 2.5532 - accuracy: 0.1845 - val_loss: 2.5488 - val_accuracy: 0.3478\n",
      "Epoch 7/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 2.5639 - accuracy: 0.1505 - val_loss: 2.5330 - val_accuracy: 0.3478\n",
      "Epoch 8/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 66us/sample - loss: 2.5288 - accuracy: 0.2330 - val_loss: 2.5175 - val_accuracy: 0.3188\n",
      "Epoch 9/2000\n",
      "206/206 [==============================] - 0s 87us/sample - loss: 2.5287 - accuracy: 0.1942 - val_loss: 2.5049 - val_accuracy: 0.3043\n",
      "Epoch 10/2000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 2.4816 - accuracy: 0.2476 - val_loss: 2.4897 - val_accuracy: 0.3333\n",
      "Epoch 11/2000\n",
      "206/206 [==============================] - 0s 85us/sample - loss: 2.4812 - accuracy: 0.2864 - val_loss: 2.4770 - val_accuracy: 0.3768\n",
      "Epoch 12/2000\n",
      "206/206 [==============================] - 0s 87us/sample - loss: 2.4943 - accuracy: 0.2670 - val_loss: 2.4631 - val_accuracy: 0.3333\n",
      "Epoch 13/2000\n",
      "206/206 [==============================] - 0s 81us/sample - loss: 2.4506 - accuracy: 0.3155 - val_loss: 2.4493 - val_accuracy: 0.3623\n",
      "Epoch 14/2000\n",
      "206/206 [==============================] - 0s 78us/sample - loss: 2.4219 - accuracy: 0.3204 - val_loss: 2.4351 - val_accuracy: 0.3478\n",
      "Epoch 15/2000\n",
      "206/206 [==============================] - 0s 90us/sample - loss: 2.4164 - accuracy: 0.3204 - val_loss: 2.4225 - val_accuracy: 0.3768\n",
      "Epoch 16/2000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 2.3646 - accuracy: 0.3592 - val_loss: 2.4030 - val_accuracy: 0.3913\n",
      "Epoch 17/2000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 2.3618 - accuracy: 0.3350 - val_loss: 2.3865 - val_accuracy: 0.4203\n",
      "Epoch 18/2000\n",
      "206/206 [==============================] - 0s 88us/sample - loss: 2.3743 - accuracy: 0.2670 - val_loss: 2.3698 - val_accuracy: 0.4058\n",
      "Epoch 19/2000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 2.3757 - accuracy: 0.3204 - val_loss: 2.3554 - val_accuracy: 0.3913\n",
      "Epoch 20/2000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 2.3490 - accuracy: 0.3544 - val_loss: 2.3388 - val_accuracy: 0.3768\n",
      "Epoch 21/2000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 2.3066 - accuracy: 0.3544 - val_loss: 2.3264 - val_accuracy: 0.3768\n",
      "Epoch 22/2000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 2.3099 - accuracy: 0.3398 - val_loss: 2.3121 - val_accuracy: 0.3768\n",
      "Epoch 23/2000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 2.3153 - accuracy: 0.3058 - val_loss: 2.2965 - val_accuracy: 0.3768\n",
      "Epoch 24/2000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 2.2678 - accuracy: 0.3495 - val_loss: 2.2804 - val_accuracy: 0.3913\n",
      "Epoch 25/2000\n",
      "206/206 [==============================] - 0s 85us/sample - loss: 2.2550 - accuracy: 0.3447 - val_loss: 2.2660 - val_accuracy: 0.3478\n",
      "Epoch 26/2000\n",
      "206/206 [==============================] - 0s 83us/sample - loss: 2.2748 - accuracy: 0.3398 - val_loss: 2.2541 - val_accuracy: 0.3623\n",
      "Epoch 27/2000\n",
      "206/206 [==============================] - 0s 85us/sample - loss: 2.2128 - accuracy: 0.3786 - val_loss: 2.2383 - val_accuracy: 0.3478\n",
      "Epoch 28/2000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 2.2091 - accuracy: 0.3398 - val_loss: 2.2202 - val_accuracy: 0.3478\n",
      "Epoch 29/2000\n",
      "206/206 [==============================] - 0s 79us/sample - loss: 2.1910 - accuracy: 0.3883 - val_loss: 2.2039 - val_accuracy: 0.3623\n",
      "Epoch 30/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 2.1498 - accuracy: 0.4175 - val_loss: 2.1885 - val_accuracy: 0.3478\n",
      "Epoch 31/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 2.1593 - accuracy: 0.3883 - val_loss: 2.1687 - val_accuracy: 0.3478\n",
      "Epoch 32/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 2.1622 - accuracy: 0.3883 - val_loss: 2.1561 - val_accuracy: 0.3768\n",
      "Epoch 33/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 2.1110 - accuracy: 0.3932 - val_loss: 2.1407 - val_accuracy: 0.3478\n",
      "Epoch 34/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 2.0990 - accuracy: 0.3786 - val_loss: 2.1251 - val_accuracy: 0.3768\n",
      "Epoch 35/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 2.1037 - accuracy: 0.3689 - val_loss: 2.1074 - val_accuracy: 0.4058\n",
      "Epoch 36/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 2.0497 - accuracy: 0.4029 - val_loss: 2.0890 - val_accuracy: 0.4058\n",
      "Epoch 37/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 2.0240 - accuracy: 0.4320 - val_loss: 2.0713 - val_accuracy: 0.4058\n",
      "Epoch 38/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 2.0055 - accuracy: 0.4320 - val_loss: 2.0566 - val_accuracy: 0.4203\n",
      "Epoch 39/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 2.0011 - accuracy: 0.3786 - val_loss: 2.0411 - val_accuracy: 0.4638\n",
      "Epoch 40/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 2.0301 - accuracy: 0.4320 - val_loss: 2.0275 - val_accuracy: 0.4638\n",
      "Epoch 41/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 1.9814 - accuracy: 0.4320 - val_loss: 2.0150 - val_accuracy: 0.4493\n",
      "Epoch 42/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.9797 - accuracy: 0.4466 - val_loss: 1.9996 - val_accuracy: 0.4783\n",
      "Epoch 43/2000\n",
      "206/206 [==============================] - 0s 76us/sample - loss: 1.9131 - accuracy: 0.4563 - val_loss: 1.9845 - val_accuracy: 0.5217\n",
      "Epoch 44/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 1.9580 - accuracy: 0.4223 - val_loss: 1.9728 - val_accuracy: 0.4783\n",
      "Epoch 45/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.8906 - accuracy: 0.4660 - val_loss: 1.9604 - val_accuracy: 0.5072\n",
      "Epoch 46/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 1.8614 - accuracy: 0.4903 - val_loss: 1.9456 - val_accuracy: 0.4348\n",
      "Epoch 47/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.8926 - accuracy: 0.4563 - val_loss: 1.9307 - val_accuracy: 0.5072\n",
      "Epoch 48/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.8588 - accuracy: 0.5000 - val_loss: 1.9195 - val_accuracy: 0.5362\n",
      "Epoch 49/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.8971 - accuracy: 0.4175 - val_loss: 1.9069 - val_accuracy: 0.5362\n",
      "Epoch 50/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 1.7912 - accuracy: 0.5340 - val_loss: 1.8886 - val_accuracy: 0.5217\n",
      "Epoch 51/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.8150 - accuracy: 0.4951 - val_loss: 1.8747 - val_accuracy: 0.5217\n",
      "Epoch 52/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.7772 - accuracy: 0.4806 - val_loss: 1.8597 - val_accuracy: 0.5217\n",
      "Epoch 53/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 1.8053 - accuracy: 0.5049 - val_loss: 1.8522 - val_accuracy: 0.5362\n",
      "Epoch 54/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 1.8134 - accuracy: 0.4806 - val_loss: 1.8355 - val_accuracy: 0.5362\n",
      "Epoch 55/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.7446 - accuracy: 0.4854 - val_loss: 1.8181 - val_accuracy: 0.5652\n",
      "Epoch 56/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.7807 - accuracy: 0.4515 - val_loss: 1.8073 - val_accuracy: 0.5797\n",
      "Epoch 57/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 1.7668 - accuracy: 0.5194 - val_loss: 1.7989 - val_accuracy: 0.5217\n",
      "Epoch 58/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.7694 - accuracy: 0.4854 - val_loss: 1.7881 - val_accuracy: 0.5797\n",
      "Epoch 59/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.7400 - accuracy: 0.4660 - val_loss: 1.7725 - val_accuracy: 0.5797\n",
      "Epoch 60/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.6870 - accuracy: 0.5437 - val_loss: 1.7542 - val_accuracy: 0.6232\n",
      "Epoch 61/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.7597 - accuracy: 0.4369 - val_loss: 1.7504 - val_accuracy: 0.6087\n",
      "Epoch 62/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.7010 - accuracy: 0.5097 - val_loss: 1.7435 - val_accuracy: 0.5942\n",
      "Epoch 63/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 67us/sample - loss: 1.6679 - accuracy: 0.4660 - val_loss: 1.7331 - val_accuracy: 0.6087\n",
      "Epoch 64/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.6752 - accuracy: 0.5291 - val_loss: 1.7170 - val_accuracy: 0.6377\n",
      "Epoch 65/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.6454 - accuracy: 0.5194 - val_loss: 1.7050 - val_accuracy: 0.6522\n",
      "Epoch 66/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.6664 - accuracy: 0.5631 - val_loss: 1.6955 - val_accuracy: 0.6232\n",
      "Epoch 67/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.6350 - accuracy: 0.5485 - val_loss: 1.6859 - val_accuracy: 0.6377\n",
      "Epoch 68/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.6281 - accuracy: 0.5291 - val_loss: 1.6768 - val_accuracy: 0.6232\n",
      "Epoch 69/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.6483 - accuracy: 0.5049 - val_loss: 1.6663 - val_accuracy: 0.6232\n",
      "Epoch 70/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 1.6369 - accuracy: 0.4757 - val_loss: 1.6619 - val_accuracy: 0.6087\n",
      "Epoch 71/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.6106 - accuracy: 0.5388 - val_loss: 1.6517 - val_accuracy: 0.6087\n",
      "Epoch 72/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 1.6007 - accuracy: 0.5340 - val_loss: 1.6399 - val_accuracy: 0.6232\n",
      "Epoch 73/2000\n",
      "206/206 [==============================] - 0s 72us/sample - loss: 1.5631 - accuracy: 0.5825 - val_loss: 1.6309 - val_accuracy: 0.6232\n",
      "Epoch 74/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.5505 - accuracy: 0.5777 - val_loss: 1.6190 - val_accuracy: 0.6522\n",
      "Epoch 75/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 1.5576 - accuracy: 0.5922 - val_loss: 1.6168 - val_accuracy: 0.6087\n",
      "Epoch 76/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.5183 - accuracy: 0.6019 - val_loss: 1.6018 - val_accuracy: 0.6377\n",
      "Epoch 77/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.5411 - accuracy: 0.5534 - val_loss: 1.5919 - val_accuracy: 0.6232\n",
      "Epoch 78/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 1.5417 - accuracy: 0.5243 - val_loss: 1.5798 - val_accuracy: 0.6667\n",
      "Epoch 79/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.5357 - accuracy: 0.5680 - val_loss: 1.5786 - val_accuracy: 0.6232\n",
      "Epoch 80/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 1.4831 - accuracy: 0.5874 - val_loss: 1.5663 - val_accuracy: 0.6667\n",
      "Epoch 81/2000\n",
      "206/206 [==============================] - 0s 77us/sample - loss: 1.5160 - accuracy: 0.5583 - val_loss: 1.5592 - val_accuracy: 0.6232\n",
      "Epoch 82/2000\n",
      "206/206 [==============================] - 0s 89us/sample - loss: 1.4897 - accuracy: 0.5971 - val_loss: 1.5498 - val_accuracy: 0.6522\n",
      "Epoch 83/2000\n",
      "206/206 [==============================] - 0s 88us/sample - loss: 1.4649 - accuracy: 0.5971 - val_loss: 1.5357 - val_accuracy: 0.6667\n",
      "Epoch 84/2000\n",
      "206/206 [==============================] - 0s 89us/sample - loss: 1.4528 - accuracy: 0.5922 - val_loss: 1.5262 - val_accuracy: 0.6667\n",
      "Epoch 85/2000\n",
      "206/206 [==============================] - 0s 85us/sample - loss: 1.4750 - accuracy: 0.5728 - val_loss: 1.5233 - val_accuracy: 0.6522\n",
      "Epoch 86/2000\n",
      "206/206 [==============================] - 0s 84us/sample - loss: 1.4181 - accuracy: 0.6068 - val_loss: 1.5104 - val_accuracy: 0.6957\n",
      "Epoch 87/2000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 1.4447 - accuracy: 0.5922 - val_loss: 1.4988 - val_accuracy: 0.6667\n",
      "Epoch 88/2000\n",
      "206/206 [==============================] - 0s 90us/sample - loss: 1.4485 - accuracy: 0.5680 - val_loss: 1.4955 - val_accuracy: 0.6957\n",
      "Epoch 89/2000\n",
      "206/206 [==============================] - 0s 93us/sample - loss: 1.4119 - accuracy: 0.6408 - val_loss: 1.4874 - val_accuracy: 0.6667\n",
      "Epoch 90/2000\n",
      "206/206 [==============================] - 0s 89us/sample - loss: 1.4507 - accuracy: 0.5631 - val_loss: 1.4806 - val_accuracy: 0.6812\n",
      "Epoch 91/2000\n",
      "206/206 [==============================] - 0s 89us/sample - loss: 1.4140 - accuracy: 0.6117 - val_loss: 1.4727 - val_accuracy: 0.6812\n",
      "Epoch 92/2000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 1.3556 - accuracy: 0.6505 - val_loss: 1.4623 - val_accuracy: 0.6667\n",
      "Epoch 93/2000\n",
      "206/206 [==============================] - 0s 84us/sample - loss: 1.3939 - accuracy: 0.5825 - val_loss: 1.4558 - val_accuracy: 0.6667\n",
      "Epoch 94/2000\n",
      "206/206 [==============================] - 0s 84us/sample - loss: 1.3748 - accuracy: 0.6359 - val_loss: 1.4526 - val_accuracy: 0.6667\n",
      "Epoch 95/2000\n",
      "206/206 [==============================] - 0s 85us/sample - loss: 1.3596 - accuracy: 0.5874 - val_loss: 1.4389 - val_accuracy: 0.6667\n",
      "Epoch 96/2000\n",
      "206/206 [==============================] - 0s 89us/sample - loss: 1.3392 - accuracy: 0.5874 - val_loss: 1.4245 - val_accuracy: 0.6667\n",
      "Epoch 97/2000\n",
      "206/206 [==============================] - 0s 85us/sample - loss: 1.3830 - accuracy: 0.6068 - val_loss: 1.4195 - val_accuracy: 0.6667\n",
      "Epoch 98/2000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 1.3269 - accuracy: 0.6650 - val_loss: 1.4119 - val_accuracy: 0.6667\n",
      "Epoch 99/2000\n",
      "206/206 [==============================] - 0s 87us/sample - loss: 1.3042 - accuracy: 0.6602 - val_loss: 1.4025 - val_accuracy: 0.6667\n",
      "Epoch 100/2000\n",
      "206/206 [==============================] - 0s 90us/sample - loss: 1.2510 - accuracy: 0.6408 - val_loss: 1.3786 - val_accuracy: 0.6957\n",
      "Epoch 101/2000\n",
      "206/206 [==============================] - 0s 85us/sample - loss: 1.3242 - accuracy: 0.6359 - val_loss: 1.3788 - val_accuracy: 0.6957\n",
      "Epoch 102/2000\n",
      "206/206 [==============================] - 0s 85us/sample - loss: 1.2610 - accuracy: 0.6845 - val_loss: 1.3724 - val_accuracy: 0.7101\n",
      "Epoch 103/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 1.3313 - accuracy: 0.6214 - val_loss: 1.3715 - val_accuracy: 0.6957\n",
      "Epoch 104/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.3202 - accuracy: 0.6505 - val_loss: 1.3732 - val_accuracy: 0.7101\n",
      "Epoch 105/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.3393 - accuracy: 0.6068 - val_loss: 1.3644 - val_accuracy: 0.7101\n",
      "Epoch 106/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.2963 - accuracy: 0.6553 - val_loss: 1.3492 - val_accuracy: 0.7391\n",
      "Epoch 107/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.2254 - accuracy: 0.6748 - val_loss: 1.3439 - val_accuracy: 0.7391\n",
      "Epoch 108/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.2671 - accuracy: 0.6699 - val_loss: 1.3302 - val_accuracy: 0.7536\n",
      "Epoch 109/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.2558 - accuracy: 0.6796 - val_loss: 1.3232 - val_accuracy: 0.7536\n",
      "Epoch 110/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.2312 - accuracy: 0.7039 - val_loss: 1.3214 - val_accuracy: 0.7391\n",
      "Epoch 111/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.2580 - accuracy: 0.6748 - val_loss: 1.3154 - val_accuracy: 0.7391\n",
      "Epoch 112/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.2043 - accuracy: 0.6408 - val_loss: 1.3097 - val_accuracy: 0.7391\n",
      "Epoch 113/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.2190 - accuracy: 0.6845 - val_loss: 1.3046 - val_accuracy: 0.7246\n",
      "Epoch 114/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.1722 - accuracy: 0.7039 - val_loss: 1.3000 - val_accuracy: 0.7391\n",
      "Epoch 115/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.2200 - accuracy: 0.6456 - val_loss: 1.2907 - val_accuracy: 0.7681\n",
      "Epoch 116/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.1599 - accuracy: 0.7087 - val_loss: 1.2852 - val_accuracy: 0.7536\n",
      "Epoch 117/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.2042 - accuracy: 0.6699 - val_loss: 1.2784 - val_accuracy: 0.7391\n",
      "Epoch 118/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 70us/sample - loss: 1.1557 - accuracy: 0.6893 - val_loss: 1.2691 - val_accuracy: 0.7681\n",
      "Epoch 119/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.1673 - accuracy: 0.6796 - val_loss: 1.2643 - val_accuracy: 0.7391\n",
      "Epoch 120/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.1548 - accuracy: 0.7524 - val_loss: 1.2539 - val_accuracy: 0.7391\n",
      "Epoch 121/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.1049 - accuracy: 0.7087 - val_loss: 1.2498 - val_accuracy: 0.7391\n",
      "Epoch 122/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.1257 - accuracy: 0.7184 - val_loss: 1.2468 - val_accuracy: 0.7391\n",
      "Epoch 123/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.1554 - accuracy: 0.6942 - val_loss: 1.2335 - val_accuracy: 0.7681\n",
      "Epoch 124/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.1487 - accuracy: 0.6942 - val_loss: 1.2330 - val_accuracy: 0.7101\n",
      "Epoch 125/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 1.1380 - accuracy: 0.6650 - val_loss: 1.2234 - val_accuracy: 0.7536\n",
      "Epoch 126/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.0836 - accuracy: 0.7621 - val_loss: 1.2113 - val_accuracy: 0.7536\n",
      "Epoch 127/2000\n",
      "206/206 [==============================] - 0s 72us/sample - loss: 1.1976 - accuracy: 0.6699 - val_loss: 1.2131 - val_accuracy: 0.7826\n",
      "Epoch 128/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 1.0807 - accuracy: 0.7184 - val_loss: 1.2015 - val_accuracy: 0.7681\n",
      "Epoch 129/2000\n",
      "206/206 [==============================] - 0s 73us/sample - loss: 1.1267 - accuracy: 0.6650 - val_loss: 1.1944 - val_accuracy: 0.7681\n",
      "Epoch 130/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 1.0915 - accuracy: 0.6942 - val_loss: 1.1902 - val_accuracy: 0.7681\n",
      "Epoch 131/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 1.0674 - accuracy: 0.7330 - val_loss: 1.1806 - val_accuracy: 0.7826\n",
      "Epoch 132/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.1184 - accuracy: 0.6990 - val_loss: 1.1836 - val_accuracy: 0.7536\n",
      "Epoch 133/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.0737 - accuracy: 0.7233 - val_loss: 1.1802 - val_accuracy: 0.7971\n",
      "Epoch 134/2000\n",
      "206/206 [==============================] - 0s 72us/sample - loss: 1.0159 - accuracy: 0.7718 - val_loss: 1.1707 - val_accuracy: 0.7536\n",
      "Epoch 135/2000\n",
      "206/206 [==============================] - 0s 72us/sample - loss: 1.0602 - accuracy: 0.7233 - val_loss: 1.1683 - val_accuracy: 0.7681\n",
      "Epoch 136/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 1.0230 - accuracy: 0.7913 - val_loss: 1.1610 - val_accuracy: 0.7536\n",
      "Epoch 137/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 1.0384 - accuracy: 0.7767 - val_loss: 1.1586 - val_accuracy: 0.7826\n",
      "Epoch 138/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 1.0522 - accuracy: 0.7184 - val_loss: 1.1489 - val_accuracy: 0.7681\n",
      "Epoch 139/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.0115 - accuracy: 0.7524 - val_loss: 1.1426 - val_accuracy: 0.7681\n",
      "Epoch 140/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.0254 - accuracy: 0.7330 - val_loss: 1.1311 - val_accuracy: 0.7826\n",
      "Epoch 141/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 1.0233 - accuracy: 0.7136 - val_loss: 1.1266 - val_accuracy: 0.7826\n",
      "Epoch 142/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 1.0016 - accuracy: 0.7524 - val_loss: 1.1305 - val_accuracy: 0.7826\n",
      "Epoch 143/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 0.9997 - accuracy: 0.7913 - val_loss: 1.1303 - val_accuracy: 0.7681\n",
      "Epoch 144/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 1.0111 - accuracy: 0.7379 - val_loss: 1.1162 - val_accuracy: 0.7536\n",
      "Epoch 145/2000\n",
      "206/206 [==============================] - 0s 79us/sample - loss: 1.0065 - accuracy: 0.7427 - val_loss: 1.1077 - val_accuracy: 0.7681\n",
      "Epoch 146/2000\n",
      "206/206 [==============================] - 0s 77us/sample - loss: 0.9949 - accuracy: 0.7573 - val_loss: 1.1090 - val_accuracy: 0.7536\n",
      "Epoch 147/2000\n",
      "206/206 [==============================] - 0s 73us/sample - loss: 1.0225 - accuracy: 0.7087 - val_loss: 1.1034 - val_accuracy: 0.7826\n",
      "Epoch 148/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.9898 - accuracy: 0.7476 - val_loss: 1.0986 - val_accuracy: 0.7681\n",
      "Epoch 149/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.9628 - accuracy: 0.7816 - val_loss: 1.0925 - val_accuracy: 0.7826\n",
      "Epoch 150/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.9858 - accuracy: 0.7670 - val_loss: 1.0916 - val_accuracy: 0.7681\n",
      "Epoch 151/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.9877 - accuracy: 0.7330 - val_loss: 1.0824 - val_accuracy: 0.7826\n",
      "Epoch 152/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.9666 - accuracy: 0.7379 - val_loss: 1.0821 - val_accuracy: 0.7826\n",
      "Epoch 153/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.9889 - accuracy: 0.7573 - val_loss: 1.0768 - val_accuracy: 0.7826\n",
      "Epoch 154/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.9487 - accuracy: 0.7913 - val_loss: 1.0742 - val_accuracy: 0.7826\n",
      "Epoch 155/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.9433 - accuracy: 0.7767 - val_loss: 1.0696 - val_accuracy: 0.7826\n",
      "Epoch 156/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.9187 - accuracy: 0.8010 - val_loss: 1.0623 - val_accuracy: 0.7681\n",
      "Epoch 157/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 0.9571 - accuracy: 0.7718 - val_loss: 1.0692 - val_accuracy: 0.7681\n",
      "Epoch 158/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.8833 - accuracy: 0.8204 - val_loss: 1.0581 - val_accuracy: 0.7826\n",
      "Epoch 159/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.9505 - accuracy: 0.7379 - val_loss: 1.0553 - val_accuracy: 0.7681\n",
      "Epoch 160/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.9645 - accuracy: 0.7573 - val_loss: 1.0477 - val_accuracy: 0.7826\n",
      "Epoch 161/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.9260 - accuracy: 0.7670 - val_loss: 1.0487 - val_accuracy: 0.7826\n",
      "Epoch 162/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 0.9626 - accuracy: 0.7621 - val_loss: 1.0397 - val_accuracy: 0.7681\n",
      "Epoch 163/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.9493 - accuracy: 0.7379 - val_loss: 1.0349 - val_accuracy: 0.7826\n",
      "Epoch 164/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.9229 - accuracy: 0.7913 - val_loss: 1.0329 - val_accuracy: 0.7681\n",
      "Epoch 165/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.8862 - accuracy: 0.7913 - val_loss: 1.0228 - val_accuracy: 0.7826\n",
      "Epoch 166/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.8717 - accuracy: 0.7961 - val_loss: 1.0174 - val_accuracy: 0.7826\n",
      "Epoch 167/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.9012 - accuracy: 0.7573 - val_loss: 1.0269 - val_accuracy: 0.7971\n",
      "Epoch 168/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.8786 - accuracy: 0.8107 - val_loss: 1.0152 - val_accuracy: 0.8116\n",
      "Epoch 169/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.8847 - accuracy: 0.7573 - val_loss: 1.0103 - val_accuracy: 0.7681\n",
      "Epoch 170/2000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 0.8913 - accuracy: 0.7913 - val_loss: 1.0055 - val_accuracy: 0.7971\n",
      "Epoch 171/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.8884 - accuracy: 0.7816 - val_loss: 0.9916 - val_accuracy: 0.7826\n",
      "Epoch 172/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.8710 - accuracy: 0.7864 - val_loss: 0.9955 - val_accuracy: 0.7826\n",
      "Epoch 173/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 67us/sample - loss: 0.8410 - accuracy: 0.7913 - val_loss: 0.9949 - val_accuracy: 0.7826\n",
      "Epoch 174/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.8331 - accuracy: 0.8010 - val_loss: 0.9892 - val_accuracy: 0.7826\n",
      "Epoch 175/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.8181 - accuracy: 0.8398 - val_loss: 0.9856 - val_accuracy: 0.7826\n",
      "Epoch 176/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.8154 - accuracy: 0.8252 - val_loss: 0.9818 - val_accuracy: 0.7681\n",
      "Epoch 177/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.8364 - accuracy: 0.8447 - val_loss: 0.9737 - val_accuracy: 0.7826\n",
      "Epoch 178/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.7984 - accuracy: 0.8398 - val_loss: 0.9705 - val_accuracy: 0.7681\n",
      "Epoch 179/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.8480 - accuracy: 0.7913 - val_loss: 0.9676 - val_accuracy: 0.7681\n",
      "Epoch 180/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.7885 - accuracy: 0.8301 - val_loss: 0.9579 - val_accuracy: 0.7681\n",
      "Epoch 181/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.8197 - accuracy: 0.7816 - val_loss: 0.9579 - val_accuracy: 0.7681\n",
      "Epoch 182/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.8457 - accuracy: 0.8107 - val_loss: 0.9603 - val_accuracy: 0.7826\n",
      "Epoch 183/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 0.7754 - accuracy: 0.8252 - val_loss: 0.9542 - val_accuracy: 0.7826\n",
      "Epoch 184/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.7886 - accuracy: 0.8350 - val_loss: 0.9536 - val_accuracy: 0.7826\n",
      "Epoch 185/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.8192 - accuracy: 0.7961 - val_loss: 0.9435 - val_accuracy: 0.7971\n",
      "Epoch 186/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.8381 - accuracy: 0.7621 - val_loss: 0.9445 - val_accuracy: 0.7826\n",
      "Epoch 187/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.7974 - accuracy: 0.8544 - val_loss: 0.9353 - val_accuracy: 0.7971\n",
      "Epoch 188/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.8070 - accuracy: 0.8350 - val_loss: 0.9368 - val_accuracy: 0.7826\n",
      "Epoch 189/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.7759 - accuracy: 0.8252 - val_loss: 0.9366 - val_accuracy: 0.7826\n",
      "Epoch 190/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.7966 - accuracy: 0.8350 - val_loss: 0.9342 - val_accuracy: 0.7826\n",
      "Epoch 191/2000\n",
      "206/206 [==============================] - 0s 83us/sample - loss: 0.7867 - accuracy: 0.8301 - val_loss: 0.9211 - val_accuracy: 0.7826\n",
      "Epoch 192/2000\n",
      "206/206 [==============================] - 0s 87us/sample - loss: 0.7846 - accuracy: 0.7864 - val_loss: 0.9280 - val_accuracy: 0.7826\n",
      "Epoch 193/2000\n",
      "206/206 [==============================] - 0s 75us/sample - loss: 0.7659 - accuracy: 0.8641 - val_loss: 0.9317 - val_accuracy: 0.7826\n",
      "Epoch 194/2000\n",
      "206/206 [==============================] - 0s 73us/sample - loss: 0.8261 - accuracy: 0.7767 - val_loss: 0.9287 - val_accuracy: 0.7681\n",
      "Epoch 195/2000\n",
      "206/206 [==============================] - 0s 75us/sample - loss: 0.7628 - accuracy: 0.8107 - val_loss: 0.9264 - val_accuracy: 0.7681\n",
      "Epoch 196/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.7954 - accuracy: 0.8252 - val_loss: 0.9220 - val_accuracy: 0.7826\n",
      "Epoch 197/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.7321 - accuracy: 0.8447 - val_loss: 0.9221 - val_accuracy: 0.7681\n",
      "Epoch 198/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.7481 - accuracy: 0.8058 - val_loss: 0.9135 - val_accuracy: 0.7826\n",
      "Epoch 199/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.7731 - accuracy: 0.8252 - val_loss: 0.9070 - val_accuracy: 0.7826\n",
      "Epoch 200/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 0.7397 - accuracy: 0.8204 - val_loss: 0.9013 - val_accuracy: 0.7826\n",
      "Epoch 201/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.7594 - accuracy: 0.8350 - val_loss: 0.9002 - val_accuracy: 0.7826\n",
      "Epoch 202/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.7364 - accuracy: 0.8641 - val_loss: 0.8966 - val_accuracy: 0.7681\n",
      "Epoch 203/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.7481 - accuracy: 0.8544 - val_loss: 0.8965 - val_accuracy: 0.7681\n",
      "Epoch 204/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.7600 - accuracy: 0.8204 - val_loss: 0.8949 - val_accuracy: 0.7826\n",
      "Epoch 205/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.7030 - accuracy: 0.8592 - val_loss: 0.8998 - val_accuracy: 0.7826\n",
      "Epoch 206/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.7201 - accuracy: 0.8447 - val_loss: 0.8914 - val_accuracy: 0.7681\n",
      "Epoch 207/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.7126 - accuracy: 0.8544 - val_loss: 0.8902 - val_accuracy: 0.7826\n",
      "Epoch 208/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.6958 - accuracy: 0.8641 - val_loss: 0.8791 - val_accuracy: 0.7826\n",
      "Epoch 209/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.7165 - accuracy: 0.8204 - val_loss: 0.8802 - val_accuracy: 0.7826\n",
      "Epoch 210/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.6989 - accuracy: 0.8641 - val_loss: 0.8782 - val_accuracy: 0.7826\n",
      "Epoch 211/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.6859 - accuracy: 0.8689 - val_loss: 0.8615 - val_accuracy: 0.7971\n",
      "Epoch 212/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.7307 - accuracy: 0.8107 - val_loss: 0.8707 - val_accuracy: 0.7971\n",
      "Epoch 213/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.7421 - accuracy: 0.8398 - val_loss: 0.8651 - val_accuracy: 0.7826\n",
      "Epoch 214/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.6915 - accuracy: 0.8301 - val_loss: 0.8577 - val_accuracy: 0.7971\n",
      "Epoch 215/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.7318 - accuracy: 0.8155 - val_loss: 0.8667 - val_accuracy: 0.7826\n",
      "Epoch 216/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.6482 - accuracy: 0.8689 - val_loss: 0.8523 - val_accuracy: 0.7826\n",
      "Epoch 217/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.6522 - accuracy: 0.8689 - val_loss: 0.8558 - val_accuracy: 0.7826\n",
      "Epoch 218/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.6669 - accuracy: 0.8738 - val_loss: 0.8582 - val_accuracy: 0.7826\n",
      "Epoch 219/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.6750 - accuracy: 0.8641 - val_loss: 0.8496 - val_accuracy: 0.7826\n",
      "Epoch 220/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.6221 - accuracy: 0.8883 - val_loss: 0.8460 - val_accuracy: 0.7826\n",
      "Epoch 221/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.6808 - accuracy: 0.8689 - val_loss: 0.8416 - val_accuracy: 0.7826\n",
      "Epoch 222/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.6702 - accuracy: 0.8738 - val_loss: 0.8493 - val_accuracy: 0.7826\n",
      "Epoch 223/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.6646 - accuracy: 0.8447 - val_loss: 0.8551 - val_accuracy: 0.7826\n",
      "Epoch 224/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.7025 - accuracy: 0.8058 - val_loss: 0.8473 - val_accuracy: 0.7826\n",
      "Epoch 225/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.6854 - accuracy: 0.8350 - val_loss: 0.8490 - val_accuracy: 0.7826\n",
      "Epoch 226/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.6385 - accuracy: 0.8544 - val_loss: 0.8368 - val_accuracy: 0.7826\n",
      "Epoch 227/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.6801 - accuracy: 0.8204 - val_loss: 0.8394 - val_accuracy: 0.7826\n",
      "Epoch 228/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 67us/sample - loss: 0.6815 - accuracy: 0.8883 - val_loss: 0.8396 - val_accuracy: 0.7681\n",
      "Epoch 229/2000\n",
      "206/206 [==============================] - 0s 78us/sample - loss: 0.6298 - accuracy: 0.8738 - val_loss: 0.8369 - val_accuracy: 0.7826\n",
      "Epoch 230/2000\n",
      "206/206 [==============================] - 0s 113us/sample - loss: 0.6370 - accuracy: 0.8932 - val_loss: 0.8367 - val_accuracy: 0.7826\n",
      "Epoch 231/2000\n",
      "206/206 [==============================] - 0s 82us/sample - loss: 0.6417 - accuracy: 0.8641 - val_loss: 0.8315 - val_accuracy: 0.7971\n",
      "Epoch 232/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.6274 - accuracy: 0.8447 - val_loss: 0.8276 - val_accuracy: 0.7826\n",
      "Epoch 233/2000\n",
      "206/206 [==============================] - 0s 85us/sample - loss: 0.6429 - accuracy: 0.8835 - val_loss: 0.8223 - val_accuracy: 0.7826\n",
      "Epoch 234/2000\n",
      "206/206 [==============================] - 0s 73us/sample - loss: 0.6747 - accuracy: 0.8350 - val_loss: 0.8198 - val_accuracy: 0.7681\n",
      "Epoch 235/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.6652 - accuracy: 0.8350 - val_loss: 0.8179 - val_accuracy: 0.7681\n",
      "Epoch 236/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.6152 - accuracy: 0.8883 - val_loss: 0.8206 - val_accuracy: 0.7826\n",
      "Epoch 237/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.6601 - accuracy: 0.8544 - val_loss: 0.8133 - val_accuracy: 0.7826\n",
      "Epoch 238/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.5892 - accuracy: 0.8689 - val_loss: 0.8115 - val_accuracy: 0.7826\n",
      "Epoch 239/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.6438 - accuracy: 0.8350 - val_loss: 0.8124 - val_accuracy: 0.7826\n",
      "Epoch 240/2000\n",
      "206/206 [==============================] - 0s 79us/sample - loss: 0.6118 - accuracy: 0.8738 - val_loss: 0.8126 - val_accuracy: 0.7826\n",
      "Epoch 241/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.6149 - accuracy: 0.8544 - val_loss: 0.8076 - val_accuracy: 0.7826\n",
      "Epoch 242/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.6527 - accuracy: 0.8641 - val_loss: 0.8049 - val_accuracy: 0.7826\n",
      "Epoch 243/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.6070 - accuracy: 0.8786 - val_loss: 0.8026 - val_accuracy: 0.7826\n",
      "Epoch 244/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 0.5879 - accuracy: 0.8738 - val_loss: 0.7969 - val_accuracy: 0.7681\n",
      "Epoch 245/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.5991 - accuracy: 0.8786 - val_loss: 0.7907 - val_accuracy: 0.7681\n",
      "Epoch 246/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5709 - accuracy: 0.8786 - val_loss: 0.7953 - val_accuracy: 0.7826\n",
      "Epoch 247/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5892 - accuracy: 0.9078 - val_loss: 0.7919 - val_accuracy: 0.7826\n",
      "Epoch 248/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5756 - accuracy: 0.8835 - val_loss: 0.7853 - val_accuracy: 0.7826\n",
      "Epoch 249/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.5951 - accuracy: 0.8592 - val_loss: 0.7821 - val_accuracy: 0.7681\n",
      "Epoch 250/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5945 - accuracy: 0.8738 - val_loss: 0.7813 - val_accuracy: 0.7681\n",
      "Epoch 251/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5834 - accuracy: 0.8932 - val_loss: 0.7950 - val_accuracy: 0.7826\n",
      "Epoch 252/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.6091 - accuracy: 0.8786 - val_loss: 0.7998 - val_accuracy: 0.7971\n",
      "Epoch 253/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.5878 - accuracy: 0.8641 - val_loss: 0.7856 - val_accuracy: 0.7826\n",
      "Epoch 254/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.6261 - accuracy: 0.8689 - val_loss: 0.7859 - val_accuracy: 0.7826\n",
      "Epoch 255/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5650 - accuracy: 0.8932 - val_loss: 0.7892 - val_accuracy: 0.7826\n",
      "Epoch 256/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.5779 - accuracy: 0.8932 - val_loss: 0.7817 - val_accuracy: 0.7826\n",
      "Epoch 257/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5440 - accuracy: 0.8835 - val_loss: 0.7852 - val_accuracy: 0.7826\n",
      "Epoch 258/2000\n",
      "206/206 [==============================] - 0s 72us/sample - loss: 0.5747 - accuracy: 0.8835 - val_loss: 0.7805 - val_accuracy: 0.7681\n",
      "Epoch 259/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5593 - accuracy: 0.8738 - val_loss: 0.7832 - val_accuracy: 0.7826\n",
      "Epoch 260/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.5581 - accuracy: 0.8738 - val_loss: 0.7833 - val_accuracy: 0.7826\n",
      "Epoch 261/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.5730 - accuracy: 0.8592 - val_loss: 0.7866 - val_accuracy: 0.7971\n",
      "Epoch 262/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.5767 - accuracy: 0.8689 - val_loss: 0.7797 - val_accuracy: 0.7971\n",
      "Epoch 263/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.6303 - accuracy: 0.8495 - val_loss: 0.7698 - val_accuracy: 0.7681\n",
      "Epoch 264/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.5811 - accuracy: 0.9126 - val_loss: 0.7694 - val_accuracy: 0.7681\n",
      "Epoch 265/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5585 - accuracy: 0.8738 - val_loss: 0.7702 - val_accuracy: 0.7826\n",
      "Epoch 266/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5540 - accuracy: 0.9175 - val_loss: 0.7676 - val_accuracy: 0.7826\n",
      "Epoch 267/2000\n",
      "206/206 [==============================] - 0s 76us/sample - loss: 0.5406 - accuracy: 0.8786 - val_loss: 0.7735 - val_accuracy: 0.7826\n",
      "Epoch 268/2000\n",
      "206/206 [==============================] - 0s 78us/sample - loss: 0.5159 - accuracy: 0.8932 - val_loss: 0.7702 - val_accuracy: 0.7826\n",
      "Epoch 269/2000\n",
      "206/206 [==============================] - 0s 74us/sample - loss: 0.5590 - accuracy: 0.8738 - val_loss: 0.7728 - val_accuracy: 0.7826\n",
      "Epoch 270/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5718 - accuracy: 0.8641 - val_loss: 0.7671 - val_accuracy: 0.7826\n",
      "Epoch 271/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.5644 - accuracy: 0.8932 - val_loss: 0.7693 - val_accuracy: 0.7826\n",
      "Epoch 272/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5468 - accuracy: 0.8835 - val_loss: 0.7666 - val_accuracy: 0.7826\n",
      "Epoch 273/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5693 - accuracy: 0.8495 - val_loss: 0.7658 - val_accuracy: 0.7826\n",
      "Epoch 274/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5776 - accuracy: 0.8592 - val_loss: 0.7640 - val_accuracy: 0.7826\n",
      "Epoch 275/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5652 - accuracy: 0.8932 - val_loss: 0.7615 - val_accuracy: 0.7826\n",
      "Epoch 276/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.5066 - accuracy: 0.8883 - val_loss: 0.7527 - val_accuracy: 0.7681\n",
      "Epoch 277/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5515 - accuracy: 0.8932 - val_loss: 0.7475 - val_accuracy: 0.7826\n",
      "Epoch 278/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5361 - accuracy: 0.8932 - val_loss: 0.7551 - val_accuracy: 0.7971\n",
      "Epoch 279/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 0.5343 - accuracy: 0.8883 - val_loss: 0.7536 - val_accuracy: 0.8116\n",
      "Epoch 280/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.5582 - accuracy: 0.8592 - val_loss: 0.7563 - val_accuracy: 0.7971\n",
      "Epoch 281/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.5586 - accuracy: 0.8835 - val_loss: 0.7537 - val_accuracy: 0.7971\n",
      "Epoch 282/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.5363 - accuracy: 0.8981 - val_loss: 0.7499 - val_accuracy: 0.7971\n",
      "Epoch 283/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 68us/sample - loss: 0.5320 - accuracy: 0.8883 - val_loss: 0.7483 - val_accuracy: 0.7971\n",
      "Epoch 284/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.5536 - accuracy: 0.8689 - val_loss: 0.7410 - val_accuracy: 0.8116\n",
      "Epoch 285/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 0.5127 - accuracy: 0.9175 - val_loss: 0.7501 - val_accuracy: 0.7971\n",
      "Epoch 286/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 0.4962 - accuracy: 0.8932 - val_loss: 0.7470 - val_accuracy: 0.7826\n",
      "Epoch 287/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.5086 - accuracy: 0.9126 - val_loss: 0.7478 - val_accuracy: 0.7971\n",
      "Epoch 288/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4770 - accuracy: 0.9175 - val_loss: 0.7459 - val_accuracy: 0.8116\n",
      "Epoch 289/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.5029 - accuracy: 0.8883 - val_loss: 0.7364 - val_accuracy: 0.7971\n",
      "Epoch 290/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.4955 - accuracy: 0.9126 - val_loss: 0.7323 - val_accuracy: 0.7826\n",
      "Epoch 291/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.5425 - accuracy: 0.9078 - val_loss: 0.7278 - val_accuracy: 0.7826\n",
      "Epoch 292/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.5084 - accuracy: 0.8883 - val_loss: 0.7264 - val_accuracy: 0.7681\n",
      "Epoch 293/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4852 - accuracy: 0.9078 - val_loss: 0.7275 - val_accuracy: 0.7681\n",
      "Epoch 294/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.4964 - accuracy: 0.8835 - val_loss: 0.7247 - val_accuracy: 0.7681\n",
      "Epoch 295/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.4982 - accuracy: 0.8883 - val_loss: 0.7289 - val_accuracy: 0.7826\n",
      "Epoch 296/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.4689 - accuracy: 0.9029 - val_loss: 0.7246 - val_accuracy: 0.7971\n",
      "Epoch 297/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.5020 - accuracy: 0.8786 - val_loss: 0.7268 - val_accuracy: 0.7971\n",
      "Epoch 298/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.5164 - accuracy: 0.8786 - val_loss: 0.7307 - val_accuracy: 0.7826\n",
      "Epoch 299/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4965 - accuracy: 0.8981 - val_loss: 0.7278 - val_accuracy: 0.7826\n",
      "Epoch 300/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.4941 - accuracy: 0.9029 - val_loss: 0.7276 - val_accuracy: 0.7826\n",
      "Epoch 301/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4724 - accuracy: 0.9272 - val_loss: 0.7257 - val_accuracy: 0.7971\n",
      "Epoch 302/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.5020 - accuracy: 0.8932 - val_loss: 0.7187 - val_accuracy: 0.7971\n",
      "Epoch 303/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 0.5097 - accuracy: 0.8883 - val_loss: 0.7145 - val_accuracy: 0.7971\n",
      "Epoch 304/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.4631 - accuracy: 0.9078 - val_loss: 0.7237 - val_accuracy: 0.7971\n",
      "Epoch 305/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.5220 - accuracy: 0.8835 - val_loss: 0.7207 - val_accuracy: 0.7971\n",
      "Epoch 306/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.5226 - accuracy: 0.8932 - val_loss: 0.7229 - val_accuracy: 0.7971\n",
      "Epoch 307/2000\n",
      "206/206 [==============================] - 0s 113us/sample - loss: 0.5250 - accuracy: 0.8835 - val_loss: 0.7184 - val_accuracy: 0.7971\n",
      "Epoch 308/2000\n",
      "206/206 [==============================] - 0s 85us/sample - loss: 0.5186 - accuracy: 0.8544 - val_loss: 0.7189 - val_accuracy: 0.7971\n",
      "Epoch 309/2000\n",
      "206/206 [==============================] - 0s 80us/sample - loss: 0.4486 - accuracy: 0.9272 - val_loss: 0.7138 - val_accuracy: 0.7971\n",
      "Epoch 310/2000\n",
      "206/206 [==============================] - 0s 77us/sample - loss: 0.4678 - accuracy: 0.8786 - val_loss: 0.7185 - val_accuracy: 0.7971\n",
      "Epoch 311/2000\n",
      "206/206 [==============================] - 0s 77us/sample - loss: 0.4808 - accuracy: 0.9369 - val_loss: 0.7126 - val_accuracy: 0.7826\n",
      "Epoch 312/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4248 - accuracy: 0.9175 - val_loss: 0.7184 - val_accuracy: 0.7971\n",
      "Epoch 313/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4852 - accuracy: 0.8786 - val_loss: 0.7077 - val_accuracy: 0.7971\n",
      "Epoch 314/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.5162 - accuracy: 0.8738 - val_loss: 0.7144 - val_accuracy: 0.7971\n",
      "Epoch 315/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4630 - accuracy: 0.9175 - val_loss: 0.7112 - val_accuracy: 0.8116\n",
      "Epoch 316/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.4696 - accuracy: 0.8981 - val_loss: 0.7061 - val_accuracy: 0.8116\n",
      "Epoch 317/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4860 - accuracy: 0.9029 - val_loss: 0.7039 - val_accuracy: 0.7971\n",
      "Epoch 318/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.4695 - accuracy: 0.8981 - val_loss: 0.7035 - val_accuracy: 0.7971\n",
      "Epoch 319/2000\n",
      "206/206 [==============================] - 0s 81us/sample - loss: 0.4451 - accuracy: 0.9320 - val_loss: 0.6975 - val_accuracy: 0.7826\n",
      "Epoch 320/2000\n",
      "206/206 [==============================] - 0s 72us/sample - loss: 0.4573 - accuracy: 0.9126 - val_loss: 0.7007 - val_accuracy: 0.8116\n",
      "Epoch 321/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.4736 - accuracy: 0.9029 - val_loss: 0.6991 - val_accuracy: 0.7971\n",
      "Epoch 322/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4714 - accuracy: 0.8981 - val_loss: 0.7003 - val_accuracy: 0.7971\n",
      "Epoch 323/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.4685 - accuracy: 0.9029 - val_loss: 0.6990 - val_accuracy: 0.7826\n",
      "Epoch 324/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3939 - accuracy: 0.9272 - val_loss: 0.7017 - val_accuracy: 0.7971\n",
      "Epoch 325/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.4741 - accuracy: 0.8835 - val_loss: 0.6957 - val_accuracy: 0.7826\n",
      "Epoch 326/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4711 - accuracy: 0.8932 - val_loss: 0.6938 - val_accuracy: 0.7971\n",
      "Epoch 327/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4806 - accuracy: 0.9078 - val_loss: 0.7000 - val_accuracy: 0.7971\n",
      "Epoch 328/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.5017 - accuracy: 0.8835 - val_loss: 0.6948 - val_accuracy: 0.7826\n",
      "Epoch 329/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4807 - accuracy: 0.9175 - val_loss: 0.6852 - val_accuracy: 0.7826\n",
      "Epoch 330/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4280 - accuracy: 0.9417 - val_loss: 0.7004 - val_accuracy: 0.7971\n",
      "Epoch 331/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4558 - accuracy: 0.9078 - val_loss: 0.6999 - val_accuracy: 0.7971\n",
      "Epoch 332/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4280 - accuracy: 0.9272 - val_loss: 0.6905 - val_accuracy: 0.7826\n",
      "Epoch 333/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.5064 - accuracy: 0.8544 - val_loss: 0.7109 - val_accuracy: 0.8116\n",
      "Epoch 334/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4406 - accuracy: 0.9078 - val_loss: 0.7056 - val_accuracy: 0.8116\n",
      "Epoch 335/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4290 - accuracy: 0.9175 - val_loss: 0.7021 - val_accuracy: 0.7971\n",
      "Epoch 336/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4707 - accuracy: 0.8981 - val_loss: 0.6904 - val_accuracy: 0.7826\n",
      "Epoch 337/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4552 - accuracy: 0.8981 - val_loss: 0.6936 - val_accuracy: 0.7971\n",
      "Epoch 338/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 67us/sample - loss: 0.5021 - accuracy: 0.8835 - val_loss: 0.6942 - val_accuracy: 0.7971\n",
      "Epoch 339/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4353 - accuracy: 0.9272 - val_loss: 0.6904 - val_accuracy: 0.7826\n",
      "Epoch 340/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.4752 - accuracy: 0.8883 - val_loss: 0.6961 - val_accuracy: 0.7971\n",
      "Epoch 341/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.4046 - accuracy: 0.9369 - val_loss: 0.6974 - val_accuracy: 0.7971\n",
      "Epoch 342/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4027 - accuracy: 0.9272 - val_loss: 0.6971 - val_accuracy: 0.7971\n",
      "Epoch 343/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.4505 - accuracy: 0.9272 - val_loss: 0.7024 - val_accuracy: 0.8261\n",
      "Epoch 344/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4442 - accuracy: 0.9223 - val_loss: 0.6830 - val_accuracy: 0.7826\n",
      "Epoch 345/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4262 - accuracy: 0.9272 - val_loss: 0.6848 - val_accuracy: 0.7826\n",
      "Epoch 346/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.4469 - accuracy: 0.8883 - val_loss: 0.6949 - val_accuracy: 0.7971\n",
      "Epoch 347/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.3815 - accuracy: 0.9369 - val_loss: 0.6971 - val_accuracy: 0.7971\n",
      "Epoch 348/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4417 - accuracy: 0.9175 - val_loss: 0.6889 - val_accuracy: 0.7826\n",
      "Epoch 349/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4662 - accuracy: 0.9078 - val_loss: 0.6895 - val_accuracy: 0.7971\n",
      "Epoch 350/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4516 - accuracy: 0.9029 - val_loss: 0.6935 - val_accuracy: 0.8116\n",
      "Epoch 351/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4277 - accuracy: 0.8981 - val_loss: 0.6880 - val_accuracy: 0.7971\n",
      "Epoch 352/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4276 - accuracy: 0.9078 - val_loss: 0.6864 - val_accuracy: 0.7826\n",
      "Epoch 353/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.4076 - accuracy: 0.9126 - val_loss: 0.6900 - val_accuracy: 0.7971\n",
      "Epoch 354/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4049 - accuracy: 0.9320 - val_loss: 0.6937 - val_accuracy: 0.8116\n",
      "Epoch 355/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4412 - accuracy: 0.8883 - val_loss: 0.6815 - val_accuracy: 0.8116\n",
      "Epoch 356/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4412 - accuracy: 0.9029 - val_loss: 0.6741 - val_accuracy: 0.7826\n",
      "Epoch 357/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.4198 - accuracy: 0.9223 - val_loss: 0.6893 - val_accuracy: 0.7971\n",
      "Epoch 358/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4095 - accuracy: 0.9320 - val_loss: 0.6927 - val_accuracy: 0.7971\n",
      "Epoch 359/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4594 - accuracy: 0.8932 - val_loss: 0.6841 - val_accuracy: 0.7971\n",
      "Epoch 360/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3976 - accuracy: 0.9320 - val_loss: 0.6987 - val_accuracy: 0.8261\n",
      "Epoch 361/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4222 - accuracy: 0.9466 - val_loss: 0.6860 - val_accuracy: 0.7971\n",
      "Epoch 362/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4203 - accuracy: 0.9126 - val_loss: 0.6787 - val_accuracy: 0.7826\n",
      "Epoch 363/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.4332 - accuracy: 0.9369 - val_loss: 0.6843 - val_accuracy: 0.7826\n",
      "Epoch 364/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4236 - accuracy: 0.9126 - val_loss: 0.6681 - val_accuracy: 0.7971\n",
      "Epoch 365/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4070 - accuracy: 0.9126 - val_loss: 0.6754 - val_accuracy: 0.7826\n",
      "Epoch 366/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3990 - accuracy: 0.9417 - val_loss: 0.6710 - val_accuracy: 0.7971\n",
      "Epoch 367/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.4371 - accuracy: 0.9126 - val_loss: 0.6760 - val_accuracy: 0.7826\n",
      "Epoch 368/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.4241 - accuracy: 0.9223 - val_loss: 0.6839 - val_accuracy: 0.7826\n",
      "Epoch 369/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4092 - accuracy: 0.9272 - val_loss: 0.6805 - val_accuracy: 0.7971\n",
      "Epoch 370/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.4173 - accuracy: 0.9223 - val_loss: 0.6781 - val_accuracy: 0.7826\n",
      "Epoch 371/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4181 - accuracy: 0.9272 - val_loss: 0.6814 - val_accuracy: 0.8116\n",
      "Epoch 372/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3728 - accuracy: 0.9417 - val_loss: 0.6742 - val_accuracy: 0.8116\n",
      "Epoch 373/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.4139 - accuracy: 0.9126 - val_loss: 0.6722 - val_accuracy: 0.7971\n",
      "Epoch 374/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3775 - accuracy: 0.9272 - val_loss: 0.6786 - val_accuracy: 0.8116\n",
      "Epoch 375/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3849 - accuracy: 0.9175 - val_loss: 0.6724 - val_accuracy: 0.8116\n",
      "Epoch 376/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.4245 - accuracy: 0.9078 - val_loss: 0.6635 - val_accuracy: 0.7971\n",
      "Epoch 377/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.3945 - accuracy: 0.9320 - val_loss: 0.6691 - val_accuracy: 0.7971\n",
      "Epoch 378/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3980 - accuracy: 0.9175 - val_loss: 0.6690 - val_accuracy: 0.7971\n",
      "Epoch 379/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4195 - accuracy: 0.9175 - val_loss: 0.6734 - val_accuracy: 0.7971\n",
      "Epoch 380/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.4106 - accuracy: 0.9126 - val_loss: 0.6745 - val_accuracy: 0.7971\n",
      "Epoch 381/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3759 - accuracy: 0.9466 - val_loss: 0.6714 - val_accuracy: 0.7826\n",
      "Epoch 382/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4052 - accuracy: 0.9272 - val_loss: 0.6789 - val_accuracy: 0.7971\n",
      "Epoch 383/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3978 - accuracy: 0.9223 - val_loss: 0.6762 - val_accuracy: 0.7826\n",
      "Epoch 384/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4374 - accuracy: 0.9126 - val_loss: 0.6703 - val_accuracy: 0.7826\n",
      "Epoch 385/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3962 - accuracy: 0.9223 - val_loss: 0.6752 - val_accuracy: 0.7971\n",
      "Epoch 386/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3943 - accuracy: 0.9369 - val_loss: 0.6667 - val_accuracy: 0.7971\n",
      "Epoch 387/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3528 - accuracy: 0.9466 - val_loss: 0.6681 - val_accuracy: 0.7826\n",
      "Epoch 388/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3931 - accuracy: 0.9223 - val_loss: 0.6738 - val_accuracy: 0.7971\n",
      "Epoch 389/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3944 - accuracy: 0.9223 - val_loss: 0.6639 - val_accuracy: 0.7826\n",
      "Epoch 390/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3800 - accuracy: 0.9223 - val_loss: 0.6632 - val_accuracy: 0.7826\n",
      "Epoch 391/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3906 - accuracy: 0.9369 - val_loss: 0.6728 - val_accuracy: 0.7971\n",
      "Epoch 392/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3819 - accuracy: 0.9369 - val_loss: 0.6653 - val_accuracy: 0.7971\n",
      "Epoch 393/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3781 - accuracy: 0.9417 - val_loss: 0.6632 - val_accuracy: 0.7971\n",
      "Epoch 394/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4066 - accuracy: 0.9078 - val_loss: 0.6567 - val_accuracy: 0.7971\n",
      "Epoch 395/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3944 - accuracy: 0.9417 - val_loss: 0.6696 - val_accuracy: 0.7826\n",
      "Epoch 396/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3743 - accuracy: 0.9175 - val_loss: 0.6665 - val_accuracy: 0.7826\n",
      "Epoch 397/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.4331 - accuracy: 0.9175 - val_loss: 0.6798 - val_accuracy: 0.7826\n",
      "Epoch 398/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3884 - accuracy: 0.9175 - val_loss: 0.6759 - val_accuracy: 0.7826\n",
      "Epoch 399/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3633 - accuracy: 0.9223 - val_loss: 0.6661 - val_accuracy: 0.8116\n",
      "Epoch 400/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3632 - accuracy: 0.9223 - val_loss: 0.6634 - val_accuracy: 0.7826\n",
      "Epoch 401/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3863 - accuracy: 0.9466 - val_loss: 0.6741 - val_accuracy: 0.7971\n",
      "Epoch 402/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3769 - accuracy: 0.9369 - val_loss: 0.6625 - val_accuracy: 0.7971\n",
      "Epoch 403/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3559 - accuracy: 0.9369 - val_loss: 0.6625 - val_accuracy: 0.7971\n",
      "Epoch 404/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3909 - accuracy: 0.9175 - val_loss: 0.6695 - val_accuracy: 0.7971\n",
      "Epoch 405/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3550 - accuracy: 0.9320 - val_loss: 0.6665 - val_accuracy: 0.7971\n",
      "Epoch 406/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.4014 - accuracy: 0.9126 - val_loss: 0.6565 - val_accuracy: 0.8116\n",
      "Epoch 407/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.4262 - accuracy: 0.9029 - val_loss: 0.6490 - val_accuracy: 0.7971\n",
      "Epoch 408/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.3197 - accuracy: 0.9709 - val_loss: 0.6456 - val_accuracy: 0.7971\n",
      "Epoch 409/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3856 - accuracy: 0.9223 - val_loss: 0.6545 - val_accuracy: 0.8116\n",
      "Epoch 410/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3339 - accuracy: 0.9369 - val_loss: 0.6571 - val_accuracy: 0.8116\n",
      "Epoch 411/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3417 - accuracy: 0.9563 - val_loss: 0.6564 - val_accuracy: 0.8116\n",
      "Epoch 412/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3974 - accuracy: 0.9272 - val_loss: 0.6536 - val_accuracy: 0.8116\n",
      "Epoch 413/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3489 - accuracy: 0.9320 - val_loss: 0.6554 - val_accuracy: 0.7826\n",
      "Epoch 414/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3611 - accuracy: 0.9466 - val_loss: 0.6611 - val_accuracy: 0.8116\n",
      "Epoch 415/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3853 - accuracy: 0.9417 - val_loss: 0.6569 - val_accuracy: 0.7971\n",
      "Epoch 416/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3524 - accuracy: 0.9369 - val_loss: 0.6473 - val_accuracy: 0.8116\n",
      "Epoch 417/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3638 - accuracy: 0.9126 - val_loss: 0.6672 - val_accuracy: 0.7826\n",
      "Epoch 418/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3413 - accuracy: 0.9515 - val_loss: 0.6596 - val_accuracy: 0.8116\n",
      "Epoch 419/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3638 - accuracy: 0.9369 - val_loss: 0.6644 - val_accuracy: 0.8261\n",
      "Epoch 420/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3640 - accuracy: 0.9175 - val_loss: 0.6559 - val_accuracy: 0.8261\n",
      "Epoch 421/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3308 - accuracy: 0.9369 - val_loss: 0.6613 - val_accuracy: 0.8116\n",
      "Epoch 422/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 0.3707 - accuracy: 0.9223 - val_loss: 0.6583 - val_accuracy: 0.7826\n",
      "Epoch 423/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3463 - accuracy: 0.9466 - val_loss: 0.6607 - val_accuracy: 0.8116\n",
      "Epoch 424/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3608 - accuracy: 0.9369 - val_loss: 0.6648 - val_accuracy: 0.8116\n",
      "Epoch 425/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3722 - accuracy: 0.9272 - val_loss: 0.6624 - val_accuracy: 0.8261\n",
      "Epoch 426/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3295 - accuracy: 0.9466 - val_loss: 0.6563 - val_accuracy: 0.8116\n",
      "Epoch 427/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3668 - accuracy: 0.9417 - val_loss: 0.6526 - val_accuracy: 0.8116\n",
      "Epoch 428/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.3503 - accuracy: 0.9320 - val_loss: 0.6454 - val_accuracy: 0.8116\n",
      "Epoch 429/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3606 - accuracy: 0.9078 - val_loss: 0.6456 - val_accuracy: 0.8116\n",
      "Epoch 430/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.3769 - accuracy: 0.9029 - val_loss: 0.6454 - val_accuracy: 0.8116\n",
      "Epoch 431/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3757 - accuracy: 0.9369 - val_loss: 0.6523 - val_accuracy: 0.8116\n",
      "Epoch 432/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3871 - accuracy: 0.9272 - val_loss: 0.6532 - val_accuracy: 0.8261\n",
      "Epoch 433/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3872 - accuracy: 0.9029 - val_loss: 0.6602 - val_accuracy: 0.8261\n",
      "Epoch 434/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3677 - accuracy: 0.9320 - val_loss: 0.6604 - val_accuracy: 0.8261\n",
      "Epoch 435/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3249 - accuracy: 0.9612 - val_loss: 0.6467 - val_accuracy: 0.7971\n",
      "Epoch 436/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3457 - accuracy: 0.9466 - val_loss: 0.6483 - val_accuracy: 0.7971\n",
      "Epoch 437/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3241 - accuracy: 0.9320 - val_loss: 0.6598 - val_accuracy: 0.7971\n",
      "Epoch 438/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3554 - accuracy: 0.9078 - val_loss: 0.6521 - val_accuracy: 0.7971\n",
      "Epoch 439/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.3379 - accuracy: 0.9417 - val_loss: 0.6533 - val_accuracy: 0.7971\n",
      "Epoch 440/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3872 - accuracy: 0.8932 - val_loss: 0.6599 - val_accuracy: 0.7971\n",
      "Epoch 441/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3240 - accuracy: 0.9612 - val_loss: 0.6612 - val_accuracy: 0.7971\n",
      "Epoch 442/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3654 - accuracy: 0.9223 - val_loss: 0.6630 - val_accuracy: 0.7971\n",
      "Epoch 443/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3907 - accuracy: 0.9223 - val_loss: 0.6560 - val_accuracy: 0.8116\n",
      "Epoch 444/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3801 - accuracy: 0.9369 - val_loss: 0.6617 - val_accuracy: 0.8116\n",
      "Epoch 445/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.3373 - accuracy: 0.9369 - val_loss: 0.6499 - val_accuracy: 0.7971\n",
      "Epoch 446/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3480 - accuracy: 0.9466 - val_loss: 0.6518 - val_accuracy: 0.8116\n",
      "Epoch 447/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3295 - accuracy: 0.9466 - val_loss: 0.6553 - val_accuracy: 0.8116\n",
      "Epoch 448/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3543 - accuracy: 0.9320 - val_loss: 0.6554 - val_accuracy: 0.8116\n",
      "Epoch 449/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3584 - accuracy: 0.9466 - val_loss: 0.6606 - val_accuracy: 0.7971\n",
      "Epoch 450/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3217 - accuracy: 0.9417 - val_loss: 0.6511 - val_accuracy: 0.8116\n",
      "Epoch 451/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3663 - accuracy: 0.9417 - val_loss: 0.6530 - val_accuracy: 0.7971\n",
      "Epoch 452/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3673 - accuracy: 0.9126 - val_loss: 0.6497 - val_accuracy: 0.8116\n",
      "Epoch 453/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3482 - accuracy: 0.9369 - val_loss: 0.6563 - val_accuracy: 0.8116\n",
      "Epoch 454/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3462 - accuracy: 0.9320 - val_loss: 0.6434 - val_accuracy: 0.8116\n",
      "Epoch 455/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3442 - accuracy: 0.9563 - val_loss: 0.6475 - val_accuracy: 0.8116\n",
      "Epoch 456/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3332 - accuracy: 0.9515 - val_loss: 0.6524 - val_accuracy: 0.8116\n",
      "Epoch 457/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3562 - accuracy: 0.9029 - val_loss: 0.6530 - val_accuracy: 0.8116\n",
      "Epoch 458/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3335 - accuracy: 0.9515 - val_loss: 0.6591 - val_accuracy: 0.8116\n",
      "Epoch 459/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3205 - accuracy: 0.9466 - val_loss: 0.6547 - val_accuracy: 0.7971\n",
      "Epoch 460/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3729 - accuracy: 0.9369 - val_loss: 0.6644 - val_accuracy: 0.7971\n",
      "Epoch 461/2000\n",
      "206/206 [==============================] - 0s 82us/sample - loss: 0.3760 - accuracy: 0.9175 - val_loss: 0.6648 - val_accuracy: 0.7971\n",
      "Epoch 462/2000\n",
      "206/206 [==============================] - 0s 80us/sample - loss: 0.3503 - accuracy: 0.9320 - val_loss: 0.6594 - val_accuracy: 0.7971\n",
      "Epoch 463/2000\n",
      "206/206 [==============================] - 0s 83us/sample - loss: 0.3674 - accuracy: 0.9126 - val_loss: 0.6682 - val_accuracy: 0.7971\n",
      "Epoch 464/2000\n",
      "206/206 [==============================] - 0s 83us/sample - loss: 0.3402 - accuracy: 0.9320 - val_loss: 0.6658 - val_accuracy: 0.7826\n",
      "Epoch 465/2000\n",
      "206/206 [==============================] - 0s 87us/sample - loss: 0.3566 - accuracy: 0.9175 - val_loss: 0.6621 - val_accuracy: 0.7826\n",
      "Epoch 466/2000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 0.3482 - accuracy: 0.9466 - val_loss: 0.6502 - val_accuracy: 0.7971\n",
      "Epoch 467/2000\n",
      "206/206 [==============================] - 0s 91us/sample - loss: 0.3428 - accuracy: 0.9369 - val_loss: 0.6534 - val_accuracy: 0.7971\n",
      "Epoch 468/2000\n",
      "206/206 [==============================] - 0s 94us/sample - loss: 0.3279 - accuracy: 0.9563 - val_loss: 0.6489 - val_accuracy: 0.7971\n",
      "Epoch 469/2000\n",
      "206/206 [==============================] - 0s 84us/sample - loss: 0.3178 - accuracy: 0.9417 - val_loss: 0.6557 - val_accuracy: 0.7971\n",
      "Epoch 470/2000\n",
      "206/206 [==============================] - 0s 85us/sample - loss: 0.3298 - accuracy: 0.9369 - val_loss: 0.6586 - val_accuracy: 0.8116\n",
      "Epoch 471/2000\n",
      "206/206 [==============================] - 0s 88us/sample - loss: 0.3518 - accuracy: 0.9272 - val_loss: 0.6493 - val_accuracy: 0.8116\n",
      "Epoch 472/2000\n",
      "206/206 [==============================] - 0s 84us/sample - loss: 0.3049 - accuracy: 0.9515 - val_loss: 0.6537 - val_accuracy: 0.7971\n",
      "Epoch 473/2000\n",
      "206/206 [==============================] - 0s 87us/sample - loss: 0.3183 - accuracy: 0.9466 - val_loss: 0.6475 - val_accuracy: 0.8116\n",
      "Epoch 474/2000\n",
      "206/206 [==============================] - 0s 90us/sample - loss: 0.3384 - accuracy: 0.9320 - val_loss: 0.6435 - val_accuracy: 0.8116\n",
      "Epoch 475/2000\n",
      "206/206 [==============================] - 0s 92us/sample - loss: 0.3591 - accuracy: 0.9078 - val_loss: 0.6508 - val_accuracy: 0.7971\n",
      "Epoch 476/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3196 - accuracy: 0.9417 - val_loss: 0.6481 - val_accuracy: 0.7971\n",
      "Epoch 477/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3296 - accuracy: 0.9417 - val_loss: 0.6574 - val_accuracy: 0.7971\n",
      "Epoch 478/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.2990 - accuracy: 0.9466 - val_loss: 0.6523 - val_accuracy: 0.7971\n",
      "Epoch 479/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.3325 - accuracy: 0.9272 - val_loss: 0.6488 - val_accuracy: 0.7971\n",
      "Epoch 480/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3221 - accuracy: 0.9417 - val_loss: 0.6442 - val_accuracy: 0.7971\n",
      "Epoch 481/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3024 - accuracy: 0.9660 - val_loss: 0.6437 - val_accuracy: 0.7971\n",
      "Epoch 482/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3336 - accuracy: 0.9563 - val_loss: 0.6450 - val_accuracy: 0.7971\n",
      "Epoch 483/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3726 - accuracy: 0.9175 - val_loss: 0.6377 - val_accuracy: 0.7971\n",
      "Epoch 484/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3220 - accuracy: 0.9515 - val_loss: 0.6428 - val_accuracy: 0.7826\n",
      "Epoch 485/2000\n",
      "206/206 [==============================] - 0s 71us/sample - loss: 0.3018 - accuracy: 0.9709 - val_loss: 0.6603 - val_accuracy: 0.7971\n",
      "Epoch 486/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.2795 - accuracy: 0.9660 - val_loss: 0.6465 - val_accuracy: 0.7971\n",
      "Epoch 487/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3614 - accuracy: 0.9078 - val_loss: 0.6475 - val_accuracy: 0.7971\n",
      "Epoch 488/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3307 - accuracy: 0.9515 - val_loss: 0.6565 - val_accuracy: 0.7971\n",
      "Epoch 489/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3441 - accuracy: 0.9272 - val_loss: 0.6630 - val_accuracy: 0.7971\n",
      "Epoch 490/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.2782 - accuracy: 0.9515 - val_loss: 0.6475 - val_accuracy: 0.7971\n",
      "Epoch 491/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3234 - accuracy: 0.9417 - val_loss: 0.6511 - val_accuracy: 0.7971\n",
      "Epoch 492/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3041 - accuracy: 0.9612 - val_loss: 0.6499 - val_accuracy: 0.7971\n",
      "Epoch 493/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3199 - accuracy: 0.9466 - val_loss: 0.6474 - val_accuracy: 0.7971\n",
      "Epoch 494/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3299 - accuracy: 0.9272 - val_loss: 0.6566 - val_accuracy: 0.7971\n",
      "Epoch 495/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.2923 - accuracy: 0.9563 - val_loss: 0.6601 - val_accuracy: 0.7971\n",
      "Epoch 496/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.3145 - accuracy: 0.9515 - val_loss: 0.6568 - val_accuracy: 0.7971\n",
      "Epoch 497/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3052 - accuracy: 0.9563 - val_loss: 0.6524 - val_accuracy: 0.7971\n",
      "Epoch 498/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3441 - accuracy: 0.9272 - val_loss: 0.6507 - val_accuracy: 0.7971\n",
      "Epoch 499/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3033 - accuracy: 0.9417 - val_loss: 0.6447 - val_accuracy: 0.7971\n",
      "Epoch 500/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3185 - accuracy: 0.9417 - val_loss: 0.6564 - val_accuracy: 0.7971\n",
      "Epoch 501/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3283 - accuracy: 0.9320 - val_loss: 0.6663 - val_accuracy: 0.7971\n",
      "Epoch 502/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.3093 - accuracy: 0.9466 - val_loss: 0.6599 - val_accuracy: 0.7971\n",
      "Epoch 503/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3041 - accuracy: 0.9515 - val_loss: 0.6596 - val_accuracy: 0.7971\n",
      "Epoch 504/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3346 - accuracy: 0.9369 - val_loss: 0.6567 - val_accuracy: 0.7971\n",
      "Epoch 505/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3372 - accuracy: 0.9515 - val_loss: 0.6595 - val_accuracy: 0.7971\n",
      "Epoch 506/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3285 - accuracy: 0.9320 - val_loss: 0.6553 - val_accuracy: 0.7971\n",
      "Epoch 507/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3076 - accuracy: 0.9417 - val_loss: 0.6577 - val_accuracy: 0.8116\n",
      "Epoch 508/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3044 - accuracy: 0.9563 - val_loss: 0.6644 - val_accuracy: 0.7971\n",
      "Epoch 509/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.3114 - accuracy: 0.9612 - val_loss: 0.6603 - val_accuracy: 0.7971\n",
      "Epoch 510/2000\n",
      "206/206 [==============================] - 0s 72us/sample - loss: 0.3345 - accuracy: 0.9369 - val_loss: 0.6629 - val_accuracy: 0.7971\n",
      "Epoch 511/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3481 - accuracy: 0.9320 - val_loss: 0.6655 - val_accuracy: 0.8116\n",
      "Epoch 512/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3267 - accuracy: 0.9417 - val_loss: 0.6587 - val_accuracy: 0.7971\n",
      "Epoch 513/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.3152 - accuracy: 0.9417 - val_loss: 0.6647 - val_accuracy: 0.7971\n",
      "Epoch 514/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3029 - accuracy: 0.9563 - val_loss: 0.6667 - val_accuracy: 0.7826\n",
      "Epoch 515/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3268 - accuracy: 0.9369 - val_loss: 0.6670 - val_accuracy: 0.7826\n",
      "Epoch 516/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.2906 - accuracy: 0.9466 - val_loss: 0.6601 - val_accuracy: 0.7971\n",
      "Epoch 517/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.2943 - accuracy: 0.9612 - val_loss: 0.6551 - val_accuracy: 0.7971\n",
      "Epoch 518/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3088 - accuracy: 0.9417 - val_loss: 0.6485 - val_accuracy: 0.7971\n",
      "Epoch 519/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.2964 - accuracy: 0.9612 - val_loss: 0.6598 - val_accuracy: 0.7971\n",
      "Epoch 520/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3039 - accuracy: 0.9612 - val_loss: 0.6502 - val_accuracy: 0.7971\n",
      "Epoch 521/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.3596 - accuracy: 0.9272 - val_loss: 0.6495 - val_accuracy: 0.7971\n",
      "Epoch 522/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3258 - accuracy: 0.9417 - val_loss: 0.6552 - val_accuracy: 0.7971\n",
      "Epoch 523/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.3125 - accuracy: 0.9515 - val_loss: 0.6515 - val_accuracy: 0.7971\n",
      "Epoch 524/2000\n",
      "206/206 [==============================] - 0s 65us/sample - loss: 0.3313 - accuracy: 0.9320 - val_loss: 0.6496 - val_accuracy: 0.7971\n",
      "Epoch 525/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.2949 - accuracy: 0.9563 - val_loss: 0.6486 - val_accuracy: 0.7971\n",
      "Epoch 526/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3220 - accuracy: 0.9320 - val_loss: 0.6637 - val_accuracy: 0.7971\n",
      "Epoch 527/2000\n",
      "206/206 [==============================] - 0s 70us/sample - loss: 0.2918 - accuracy: 0.9563 - val_loss: 0.6561 - val_accuracy: 0.7681\n",
      "Epoch 528/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.2947 - accuracy: 0.9466 - val_loss: 0.6501 - val_accuracy: 0.7971\n",
      "Epoch 529/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3108 - accuracy: 0.9369 - val_loss: 0.6584 - val_accuracy: 0.7971\n",
      "Epoch 530/2000\n",
      "206/206 [==============================] - 0s 69us/sample - loss: 0.3149 - accuracy: 0.9320 - val_loss: 0.6540 - val_accuracy: 0.7971\n",
      "Epoch 531/2000\n",
      "206/206 [==============================] - 0s 68us/sample - loss: 0.2830 - accuracy: 0.9515 - val_loss: 0.6551 - val_accuracy: 0.7971\n",
      "Epoch 532/2000\n",
      "206/206 [==============================] - 0s 66us/sample - loss: 0.3093 - accuracy: 0.9466 - val_loss: 0.6618 - val_accuracy: 0.7971\n",
      "Epoch 533/2000\n",
      "206/206 [==============================] - 0s 67us/sample - loss: 0.3390 - accuracy: 0.9417 - val_loss: 0.6540 - val_accuracy: 0.7971\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 2,062\n",
      "Trainable params: 2,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 309 samples, validate on 103 samples\n",
      "Epoch 1/2000\n",
      "309/309 [==============================] - 0s 1ms/sample - loss: 2.6858 - accuracy: 0.0647 - val_loss: 2.6589 - val_accuracy: 0.0583\n",
      "Epoch 2/2000\n",
      "309/309 [==============================] - 0s 56us/sample - loss: 2.6314 - accuracy: 0.0841 - val_loss: 2.6334 - val_accuracy: 0.0388\n",
      "Epoch 3/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 2.6369 - accuracy: 0.0939 - val_loss: 2.6115 - val_accuracy: 0.0388\n",
      "Epoch 4/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 2.5603 - accuracy: 0.1294 - val_loss: 2.5918 - val_accuracy: 0.0388\n",
      "Epoch 5/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 2.5528 - accuracy: 0.1392 - val_loss: 2.5740 - val_accuracy: 0.0291\n",
      "Epoch 6/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 2.5275 - accuracy: 0.1618 - val_loss: 2.5587 - val_accuracy: 0.0680\n",
      "Epoch 7/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 2.5237 - accuracy: 0.1650 - val_loss: 2.5400 - val_accuracy: 0.0777\n",
      "Epoch 8/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 2.4490 - accuracy: 0.2265 - val_loss: 2.5213 - val_accuracy: 0.0971\n",
      "Epoch 9/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 2.4675 - accuracy: 0.1942 - val_loss: 2.5037 - val_accuracy: 0.0874\n",
      "Epoch 10/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 2.4393 - accuracy: 0.2362 - val_loss: 2.4868 - val_accuracy: 0.0874\n",
      "Epoch 11/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 2.4343 - accuracy: 0.2233 - val_loss: 2.4696 - val_accuracy: 0.1359\n",
      "Epoch 12/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 2.3833 - accuracy: 0.2362 - val_loss: 2.4478 - val_accuracy: 0.1165\n",
      "Epoch 13/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 2.3619 - accuracy: 0.2751 - val_loss: 2.4311 - val_accuracy: 0.1456\n",
      "Epoch 14/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 2.3233 - accuracy: 0.2686 - val_loss: 2.4146 - val_accuracy: 0.1748\n",
      "Epoch 15/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 2.3215 - accuracy: 0.2654 - val_loss: 2.3967 - val_accuracy: 0.1748\n",
      "Epoch 16/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 2.3010 - accuracy: 0.3172 - val_loss: 2.3759 - val_accuracy: 0.1650\n",
      "Epoch 17/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 2.2504 - accuracy: 0.3042 - val_loss: 2.3537 - val_accuracy: 0.1748\n",
      "Epoch 18/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 2.2468 - accuracy: 0.2977 - val_loss: 2.3330 - val_accuracy: 0.1748\n",
      "Epoch 19/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 2.2358 - accuracy: 0.3107 - val_loss: 2.3121 - val_accuracy: 0.1942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 2.1684 - accuracy: 0.3625 - val_loss: 2.2892 - val_accuracy: 0.2039\n",
      "Epoch 21/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 2.1624 - accuracy: 0.3528 - val_loss: 2.2668 - val_accuracy: 0.2039\n",
      "Epoch 22/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 2.1561 - accuracy: 0.3560 - val_loss: 2.2442 - val_accuracy: 0.2233\n",
      "Epoch 23/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 2.1068 - accuracy: 0.3754 - val_loss: 2.2225 - val_accuracy: 0.2233\n",
      "Epoch 24/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 2.0878 - accuracy: 0.3689 - val_loss: 2.2007 - val_accuracy: 0.2136\n",
      "Epoch 25/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 2.0719 - accuracy: 0.3916 - val_loss: 2.1808 - val_accuracy: 0.2524\n",
      "Epoch 26/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 2.0737 - accuracy: 0.3560 - val_loss: 2.1593 - val_accuracy: 0.2427\n",
      "Epoch 27/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 2.0133 - accuracy: 0.3786 - val_loss: 2.1364 - val_accuracy: 0.2718\n",
      "Epoch 28/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.9959 - accuracy: 0.3883 - val_loss: 2.1174 - val_accuracy: 0.2718\n",
      "Epoch 29/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 2.0039 - accuracy: 0.3625 - val_loss: 2.0980 - val_accuracy: 0.2816\n",
      "Epoch 30/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.9715 - accuracy: 0.4110 - val_loss: 2.0769 - val_accuracy: 0.2913\n",
      "Epoch 31/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 1.9534 - accuracy: 0.4078 - val_loss: 2.0562 - val_accuracy: 0.3301\n",
      "Epoch 32/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.9428 - accuracy: 0.4142 - val_loss: 2.0408 - val_accuracy: 0.3301\n",
      "Epoch 33/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 1.9014 - accuracy: 0.4466 - val_loss: 2.0184 - val_accuracy: 0.3592\n",
      "Epoch 34/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 1.8946 - accuracy: 0.4498 - val_loss: 1.9955 - val_accuracy: 0.3786\n",
      "Epoch 35/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.8413 - accuracy: 0.4563 - val_loss: 1.9737 - val_accuracy: 0.3786\n",
      "Epoch 36/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 1.8298 - accuracy: 0.4337 - val_loss: 1.9588 - val_accuracy: 0.3592\n",
      "Epoch 37/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.8321 - accuracy: 0.4207 - val_loss: 1.9398 - val_accuracy: 0.3981\n",
      "Epoch 38/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.8298 - accuracy: 0.4790 - val_loss: 1.9186 - val_accuracy: 0.4175\n",
      "Epoch 39/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.8001 - accuracy: 0.4466 - val_loss: 1.9005 - val_accuracy: 0.4175\n",
      "Epoch 40/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.7522 - accuracy: 0.4757 - val_loss: 1.8832 - val_accuracy: 0.4078\n",
      "Epoch 41/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 1.7794 - accuracy: 0.4595 - val_loss: 1.8659 - val_accuracy: 0.4078\n",
      "Epoch 42/2000\n",
      "309/309 [==============================] - 0s 61us/sample - loss: 1.7314 - accuracy: 0.5113 - val_loss: 1.8440 - val_accuracy: 0.4369\n",
      "Epoch 43/2000\n",
      "309/309 [==============================] - 0s 51us/sample - loss: 1.6949 - accuracy: 0.5016 - val_loss: 1.8250 - val_accuracy: 0.4563\n",
      "Epoch 44/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 1.6800 - accuracy: 0.5663 - val_loss: 1.8089 - val_accuracy: 0.4660\n",
      "Epoch 45/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 1.6963 - accuracy: 0.4984 - val_loss: 1.7960 - val_accuracy: 0.4757\n",
      "Epoch 46/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.6752 - accuracy: 0.4887 - val_loss: 1.7788 - val_accuracy: 0.4660\n",
      "Epoch 47/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.6234 - accuracy: 0.5566 - val_loss: 1.7626 - val_accuracy: 0.4951\n",
      "Epoch 48/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.6574 - accuracy: 0.5049 - val_loss: 1.7493 - val_accuracy: 0.4757\n",
      "Epoch 49/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.6121 - accuracy: 0.5696 - val_loss: 1.7307 - val_accuracy: 0.5049\n",
      "Epoch 50/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 1.5994 - accuracy: 0.5728 - val_loss: 1.7136 - val_accuracy: 0.5049\n",
      "Epoch 51/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 1.5658 - accuracy: 0.5761 - val_loss: 1.6977 - val_accuracy: 0.5049\n",
      "Epoch 52/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 1.5616 - accuracy: 0.5405 - val_loss: 1.6853 - val_accuracy: 0.5146\n",
      "Epoch 53/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 1.5415 - accuracy: 0.5761 - val_loss: 1.6616 - val_accuracy: 0.5340\n",
      "Epoch 54/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.5537 - accuracy: 0.5599 - val_loss: 1.6535 - val_accuracy: 0.5243\n",
      "Epoch 55/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.5622 - accuracy: 0.5858 - val_loss: 1.6366 - val_accuracy: 0.5146\n",
      "Epoch 56/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 1.5187 - accuracy: 0.5825 - val_loss: 1.6238 - val_accuracy: 0.5437\n",
      "Epoch 57/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.4695 - accuracy: 0.5858 - val_loss: 1.6087 - val_accuracy: 0.5437\n",
      "Epoch 58/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.5101 - accuracy: 0.5728 - val_loss: 1.5985 - val_accuracy: 0.5534\n",
      "Epoch 59/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 1.4789 - accuracy: 0.5761 - val_loss: 1.5853 - val_accuracy: 0.5437\n",
      "Epoch 60/2000\n",
      "309/309 [==============================] - 0s 56us/sample - loss: 1.4219 - accuracy: 0.6311 - val_loss: 1.5668 - val_accuracy: 0.5631\n",
      "Epoch 61/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.4586 - accuracy: 0.5987 - val_loss: 1.5568 - val_accuracy: 0.5340\n",
      "Epoch 62/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.4623 - accuracy: 0.5922 - val_loss: 1.5435 - val_accuracy: 0.5631\n",
      "Epoch 63/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 1.4020 - accuracy: 0.6505 - val_loss: 1.5268 - val_accuracy: 0.5631\n",
      "Epoch 64/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 1.3950 - accuracy: 0.6343 - val_loss: 1.5133 - val_accuracy: 0.5631\n",
      "Epoch 65/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.3622 - accuracy: 0.6375 - val_loss: 1.5003 - val_accuracy: 0.5728\n",
      "Epoch 66/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 1.3515 - accuracy: 0.6408 - val_loss: 1.4810 - val_accuracy: 0.5922\n",
      "Epoch 67/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 1.3553 - accuracy: 0.6440 - val_loss: 1.4693 - val_accuracy: 0.6019\n",
      "Epoch 68/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 1.3635 - accuracy: 0.6537 - val_loss: 1.4592 - val_accuracy: 0.5922\n",
      "Epoch 69/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.3484 - accuracy: 0.6246 - val_loss: 1.4496 - val_accuracy: 0.5825\n",
      "Epoch 70/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.3262 - accuracy: 0.6570 - val_loss: 1.4422 - val_accuracy: 0.5825\n",
      "Epoch 71/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.3055 - accuracy: 0.6602 - val_loss: 1.4250 - val_accuracy: 0.5922\n",
      "Epoch 72/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.2991 - accuracy: 0.6634 - val_loss: 1.4145 - val_accuracy: 0.6019\n",
      "Epoch 73/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 1.2567 - accuracy: 0.6796 - val_loss: 1.4068 - val_accuracy: 0.5825\n",
      "Epoch 74/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 1.2669 - accuracy: 0.6731 - val_loss: 1.3925 - val_accuracy: 0.6019\n",
      "Epoch 75/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 54us/sample - loss: 1.2295 - accuracy: 0.7087 - val_loss: 1.3776 - val_accuracy: 0.6117\n",
      "Epoch 76/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.2516 - accuracy: 0.6472 - val_loss: 1.3670 - val_accuracy: 0.6214\n",
      "Epoch 77/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.2309 - accuracy: 0.6796 - val_loss: 1.3535 - val_accuracy: 0.6311\n",
      "Epoch 78/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.2183 - accuracy: 0.6828 - val_loss: 1.3429 - val_accuracy: 0.6214\n",
      "Epoch 79/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.1977 - accuracy: 0.7087 - val_loss: 1.3353 - val_accuracy: 0.6214\n",
      "Epoch 80/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.1884 - accuracy: 0.7120 - val_loss: 1.3244 - val_accuracy: 0.6311\n",
      "Epoch 81/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.1843 - accuracy: 0.6764 - val_loss: 1.3151 - val_accuracy: 0.6019\n",
      "Epoch 82/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.2090 - accuracy: 0.7152 - val_loss: 1.3037 - val_accuracy: 0.6796\n",
      "Epoch 83/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.2277 - accuracy: 0.6570 - val_loss: 1.2964 - val_accuracy: 0.6311\n",
      "Epoch 84/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 1.1636 - accuracy: 0.7184 - val_loss: 1.2888 - val_accuracy: 0.6505\n",
      "Epoch 85/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 1.1343 - accuracy: 0.6926 - val_loss: 1.2800 - val_accuracy: 0.6505\n",
      "Epoch 86/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.1440 - accuracy: 0.6990 - val_loss: 1.2680 - val_accuracy: 0.6699\n",
      "Epoch 87/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 1.1585 - accuracy: 0.6861 - val_loss: 1.2555 - val_accuracy: 0.6893\n",
      "Epoch 88/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.0957 - accuracy: 0.7476 - val_loss: 1.2457 - val_accuracy: 0.6893\n",
      "Epoch 89/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 1.1150 - accuracy: 0.7087 - val_loss: 1.2345 - val_accuracy: 0.6893\n",
      "Epoch 90/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 1.0978 - accuracy: 0.7605 - val_loss: 1.2220 - val_accuracy: 0.6893\n",
      "Epoch 91/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.1054 - accuracy: 0.7346 - val_loss: 1.2147 - val_accuracy: 0.6893\n",
      "Epoch 92/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 1.1178 - accuracy: 0.7023 - val_loss: 1.2112 - val_accuracy: 0.6796\n",
      "Epoch 93/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.0865 - accuracy: 0.7346 - val_loss: 1.2050 - val_accuracy: 0.6796\n",
      "Epoch 94/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.0575 - accuracy: 0.7832 - val_loss: 1.1896 - val_accuracy: 0.6796\n",
      "Epoch 95/2000\n",
      "309/309 [==============================] - 0s 77us/sample - loss: 1.0609 - accuracy: 0.7379 - val_loss: 1.1778 - val_accuracy: 0.6699\n",
      "Epoch 96/2000\n",
      "309/309 [==============================] - 0s 71us/sample - loss: 1.0290 - accuracy: 0.7540 - val_loss: 1.1643 - val_accuracy: 0.6990\n",
      "Epoch 97/2000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 1.0537 - accuracy: 0.7605 - val_loss: 1.1620 - val_accuracy: 0.6699\n",
      "Epoch 98/2000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 1.0326 - accuracy: 0.7573 - val_loss: 1.1515 - val_accuracy: 0.6699\n",
      "Epoch 99/2000\n",
      "309/309 [==============================] - 0s 73us/sample - loss: 1.0160 - accuracy: 0.7702 - val_loss: 1.1398 - val_accuracy: 0.6796\n",
      "Epoch 100/2000\n",
      "309/309 [==============================] - 0s 70us/sample - loss: 1.0434 - accuracy: 0.7443 - val_loss: 1.1404 - val_accuracy: 0.7087\n",
      "Epoch 101/2000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 1.0759 - accuracy: 0.7152 - val_loss: 1.1355 - val_accuracy: 0.6893\n",
      "Epoch 102/2000\n",
      "309/309 [==============================] - 0s 72us/sample - loss: 1.0032 - accuracy: 0.7411 - val_loss: 1.1298 - val_accuracy: 0.6893\n",
      "Epoch 103/2000\n",
      "309/309 [==============================] - 0s 60us/sample - loss: 1.0009 - accuracy: 0.7702 - val_loss: 1.1252 - val_accuracy: 0.6796\n",
      "Epoch 104/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 1.0012 - accuracy: 0.7411 - val_loss: 1.1107 - val_accuracy: 0.6796\n",
      "Epoch 105/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.9461 - accuracy: 0.7638 - val_loss: 1.1054 - val_accuracy: 0.6796\n",
      "Epoch 106/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.9745 - accuracy: 0.7476 - val_loss: 1.1013 - val_accuracy: 0.6990\n",
      "Epoch 107/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.9442 - accuracy: 0.8026 - val_loss: 1.0899 - val_accuracy: 0.6893\n",
      "Epoch 108/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.9816 - accuracy: 0.7443 - val_loss: 1.0876 - val_accuracy: 0.6796\n",
      "Epoch 109/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.8866 - accuracy: 0.8155 - val_loss: 1.0823 - val_accuracy: 0.6796\n",
      "Epoch 110/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.9217 - accuracy: 0.8026 - val_loss: 1.0717 - val_accuracy: 0.6699\n",
      "Epoch 111/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.9562 - accuracy: 0.7735 - val_loss: 1.0624 - val_accuracy: 0.6893\n",
      "Epoch 112/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.9259 - accuracy: 0.7832 - val_loss: 1.0573 - val_accuracy: 0.6893\n",
      "Epoch 113/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.9146 - accuracy: 0.7638 - val_loss: 1.0458 - val_accuracy: 0.6990\n",
      "Epoch 114/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.9176 - accuracy: 0.7832 - val_loss: 1.0449 - val_accuracy: 0.6893\n",
      "Epoch 115/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.8836 - accuracy: 0.7961 - val_loss: 1.0326 - val_accuracy: 0.7087\n",
      "Epoch 116/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.8718 - accuracy: 0.8220 - val_loss: 1.0340 - val_accuracy: 0.6990\n",
      "Epoch 117/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.8984 - accuracy: 0.8058 - val_loss: 1.0267 - val_accuracy: 0.6990\n",
      "Epoch 118/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.8910 - accuracy: 0.7638 - val_loss: 1.0216 - val_accuracy: 0.7087\n",
      "Epoch 119/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.8403 - accuracy: 0.8026 - val_loss: 1.0096 - val_accuracy: 0.7184\n",
      "Epoch 120/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.8713 - accuracy: 0.7767 - val_loss: 0.9998 - val_accuracy: 0.7087\n",
      "Epoch 121/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.8115 - accuracy: 0.8350 - val_loss: 0.9898 - val_accuracy: 0.7184\n",
      "Epoch 122/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.8742 - accuracy: 0.7767 - val_loss: 0.9853 - val_accuracy: 0.7282\n",
      "Epoch 123/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.8341 - accuracy: 0.8220 - val_loss: 0.9882 - val_accuracy: 0.7087\n",
      "Epoch 124/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.7940 - accuracy: 0.8220 - val_loss: 0.9821 - val_accuracy: 0.7184\n",
      "Epoch 125/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.8079 - accuracy: 0.8252 - val_loss: 0.9797 - val_accuracy: 0.6796\n",
      "Epoch 126/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.8527 - accuracy: 0.7702 - val_loss: 0.9737 - val_accuracy: 0.6990\n",
      "Epoch 127/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.8270 - accuracy: 0.7929 - val_loss: 0.9634 - val_accuracy: 0.7282\n",
      "Epoch 128/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.8532 - accuracy: 0.7832 - val_loss: 0.9596 - val_accuracy: 0.7282\n",
      "Epoch 129/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.8129 - accuracy: 0.8252 - val_loss: 0.9511 - val_accuracy: 0.7282\n",
      "Epoch 130/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 53us/sample - loss: 0.7936 - accuracy: 0.8479 - val_loss: 0.9467 - val_accuracy: 0.7184\n",
      "Epoch 131/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.8387 - accuracy: 0.7799 - val_loss: 0.9503 - val_accuracy: 0.7087\n",
      "Epoch 132/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.7742 - accuracy: 0.8220 - val_loss: 0.9389 - val_accuracy: 0.7282\n",
      "Epoch 133/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.7917 - accuracy: 0.8414 - val_loss: 0.9357 - val_accuracy: 0.7282\n",
      "Epoch 134/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.8101 - accuracy: 0.8155 - val_loss: 0.9372 - val_accuracy: 0.7087\n",
      "Epoch 135/2000\n",
      "309/309 [==============================] - 0s 60us/sample - loss: 0.7666 - accuracy: 0.8285 - val_loss: 0.9335 - val_accuracy: 0.7087\n",
      "Epoch 136/2000\n",
      "309/309 [==============================] - 0s 77us/sample - loss: 0.7758 - accuracy: 0.8058 - val_loss: 0.9227 - val_accuracy: 0.7184\n",
      "Epoch 137/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.7803 - accuracy: 0.8252 - val_loss: 0.9219 - val_accuracy: 0.7184\n",
      "Epoch 138/2000\n",
      "309/309 [==============================] - 0s 73us/sample - loss: 0.7622 - accuracy: 0.8155 - val_loss: 0.9131 - val_accuracy: 0.7282\n",
      "Epoch 139/2000\n",
      "309/309 [==============================] - 0s 70us/sample - loss: 0.7674 - accuracy: 0.8220 - val_loss: 0.8997 - val_accuracy: 0.7282\n",
      "Epoch 140/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.7330 - accuracy: 0.8414 - val_loss: 0.9011 - val_accuracy: 0.7282\n",
      "Epoch 141/2000\n",
      "309/309 [==============================] - 0s 73us/sample - loss: 0.7446 - accuracy: 0.8026 - val_loss: 0.8974 - val_accuracy: 0.7282\n",
      "Epoch 142/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.7323 - accuracy: 0.8382 - val_loss: 0.8929 - val_accuracy: 0.7184\n",
      "Epoch 143/2000\n",
      "309/309 [==============================] - 0s 68us/sample - loss: 0.7028 - accuracy: 0.8544 - val_loss: 0.8792 - val_accuracy: 0.7282\n",
      "Epoch 144/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.7438 - accuracy: 0.8447 - val_loss: 0.8823 - val_accuracy: 0.7184\n",
      "Epoch 145/2000\n",
      "309/309 [==============================] - 0s 74us/sample - loss: 0.7315 - accuracy: 0.8479 - val_loss: 0.8821 - val_accuracy: 0.7282\n",
      "Epoch 146/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.6952 - accuracy: 0.8835 - val_loss: 0.8788 - val_accuracy: 0.7282\n",
      "Epoch 147/2000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 0.7063 - accuracy: 0.8511 - val_loss: 0.8745 - val_accuracy: 0.7282\n",
      "Epoch 148/2000\n",
      "309/309 [==============================] - 0s 73us/sample - loss: 0.7291 - accuracy: 0.8350 - val_loss: 0.8743 - val_accuracy: 0.7282\n",
      "Epoch 149/2000\n",
      "309/309 [==============================] - 0s 70us/sample - loss: 0.7051 - accuracy: 0.8803 - val_loss: 0.8703 - val_accuracy: 0.7282\n",
      "Epoch 150/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.6475 - accuracy: 0.8706 - val_loss: 0.8664 - val_accuracy: 0.7282\n",
      "Epoch 151/2000\n",
      "309/309 [==============================] - 0s 73us/sample - loss: 0.6883 - accuracy: 0.8350 - val_loss: 0.8659 - val_accuracy: 0.7282\n",
      "Epoch 152/2000\n",
      "309/309 [==============================] - 0s 69us/sample - loss: 0.6907 - accuracy: 0.8350 - val_loss: 0.8555 - val_accuracy: 0.7282\n",
      "Epoch 153/2000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 0.6972 - accuracy: 0.8188 - val_loss: 0.8568 - val_accuracy: 0.7282\n",
      "Epoch 154/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.6456 - accuracy: 0.8997 - val_loss: 0.8425 - val_accuracy: 0.7379\n",
      "Epoch 155/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.6634 - accuracy: 0.8544 - val_loss: 0.8424 - val_accuracy: 0.7476\n",
      "Epoch 156/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.6582 - accuracy: 0.8414 - val_loss: 0.8341 - val_accuracy: 0.7379\n",
      "Epoch 157/2000\n",
      "309/309 [==============================] - 0s 60us/sample - loss: 0.6811 - accuracy: 0.8382 - val_loss: 0.8346 - val_accuracy: 0.7379\n",
      "Epoch 158/2000\n",
      "309/309 [==============================] - 0s 71us/sample - loss: 0.6554 - accuracy: 0.8867 - val_loss: 0.8421 - val_accuracy: 0.7282\n",
      "Epoch 159/2000\n",
      "309/309 [==============================] - 0s 65us/sample - loss: 0.6251 - accuracy: 0.9126 - val_loss: 0.8335 - val_accuracy: 0.7379\n",
      "Epoch 160/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.6681 - accuracy: 0.8382 - val_loss: 0.8279 - val_accuracy: 0.7379\n",
      "Epoch 161/2000\n",
      "309/309 [==============================] - 0s 73us/sample - loss: 0.6836 - accuracy: 0.8350 - val_loss: 0.8224 - val_accuracy: 0.7379\n",
      "Epoch 162/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.6509 - accuracy: 0.8803 - val_loss: 0.8252 - val_accuracy: 0.7282\n",
      "Epoch 163/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.6152 - accuracy: 0.8511 - val_loss: 0.8194 - val_accuracy: 0.7476\n",
      "Epoch 164/2000\n",
      "309/309 [==============================] - 0s 76us/sample - loss: 0.6328 - accuracy: 0.8964 - val_loss: 0.8217 - val_accuracy: 0.7282\n",
      "Epoch 165/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.6401 - accuracy: 0.8608 - val_loss: 0.8157 - val_accuracy: 0.7379\n",
      "Epoch 166/2000\n",
      "309/309 [==============================] - 0s 63us/sample - loss: 0.6433 - accuracy: 0.8382 - val_loss: 0.8187 - val_accuracy: 0.7476\n",
      "Epoch 167/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.6240 - accuracy: 0.8608 - val_loss: 0.8071 - val_accuracy: 0.7379\n",
      "Epoch 168/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.6164 - accuracy: 0.8803 - val_loss: 0.8099 - val_accuracy: 0.7282\n",
      "Epoch 169/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.6139 - accuracy: 0.8673 - val_loss: 0.8071 - val_accuracy: 0.7379\n",
      "Epoch 170/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.6114 - accuracy: 0.8738 - val_loss: 0.7982 - val_accuracy: 0.7282\n",
      "Epoch 171/2000\n",
      "309/309 [==============================] - 0s 56us/sample - loss: 0.5748 - accuracy: 0.8997 - val_loss: 0.7975 - val_accuracy: 0.7379\n",
      "Epoch 172/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.5758 - accuracy: 0.8900 - val_loss: 0.8004 - val_accuracy: 0.7379\n",
      "Epoch 173/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.6057 - accuracy: 0.8770 - val_loss: 0.7960 - val_accuracy: 0.7282\n",
      "Epoch 174/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.6137 - accuracy: 0.8738 - val_loss: 0.7952 - val_accuracy: 0.7379\n",
      "Epoch 175/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.5917 - accuracy: 0.8964 - val_loss: 0.8010 - val_accuracy: 0.7379\n",
      "Epoch 176/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.6136 - accuracy: 0.8706 - val_loss: 0.7944 - val_accuracy: 0.7379\n",
      "Epoch 177/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.5930 - accuracy: 0.8803 - val_loss: 0.7941 - val_accuracy: 0.7379\n",
      "Epoch 178/2000\n",
      "309/309 [==============================] - 0s 72us/sample - loss: 0.5941 - accuracy: 0.8835 - val_loss: 0.7872 - val_accuracy: 0.7282\n",
      "Epoch 179/2000\n",
      "309/309 [==============================] - 0s 61us/sample - loss: 0.5692 - accuracy: 0.8997 - val_loss: 0.7863 - val_accuracy: 0.7379\n",
      "Epoch 180/2000\n",
      "309/309 [==============================] - 0s 61us/sample - loss: 0.5816 - accuracy: 0.8576 - val_loss: 0.7838 - val_accuracy: 0.7282\n",
      "Epoch 181/2000\n",
      "309/309 [==============================] - 0s 63us/sample - loss: 0.5537 - accuracy: 0.9029 - val_loss: 0.7720 - val_accuracy: 0.7476\n",
      "Epoch 182/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.5735 - accuracy: 0.8900 - val_loss: 0.7747 - val_accuracy: 0.7476\n",
      "Epoch 183/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.5876 - accuracy: 0.8770 - val_loss: 0.7742 - val_accuracy: 0.7282\n",
      "Epoch 184/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.5331 - accuracy: 0.9126 - val_loss: 0.7662 - val_accuracy: 0.7573\n",
      "Epoch 185/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 54us/sample - loss: 0.5778 - accuracy: 0.8706 - val_loss: 0.7787 - val_accuracy: 0.7282\n",
      "Epoch 186/2000\n",
      "309/309 [==============================] - 0s 56us/sample - loss: 0.5601 - accuracy: 0.9061 - val_loss: 0.7713 - val_accuracy: 0.7476\n",
      "Epoch 187/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.5652 - accuracy: 0.8803 - val_loss: 0.7645 - val_accuracy: 0.7864\n",
      "Epoch 188/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.5591 - accuracy: 0.8835 - val_loss: 0.7699 - val_accuracy: 0.7379\n",
      "Epoch 189/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.5595 - accuracy: 0.8803 - val_loss: 0.7677 - val_accuracy: 0.7573\n",
      "Epoch 190/2000\n",
      "309/309 [==============================] - 0s 61us/sample - loss: 0.5618 - accuracy: 0.9126 - val_loss: 0.7699 - val_accuracy: 0.7379\n",
      "Epoch 191/2000\n",
      "309/309 [==============================] - 0s 63us/sample - loss: 0.5608 - accuracy: 0.8803 - val_loss: 0.7676 - val_accuracy: 0.7282\n",
      "Epoch 192/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.5285 - accuracy: 0.9094 - val_loss: 0.7717 - val_accuracy: 0.7282\n",
      "Epoch 193/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.5050 - accuracy: 0.8964 - val_loss: 0.7678 - val_accuracy: 0.7379\n",
      "Epoch 194/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.5403 - accuracy: 0.8835 - val_loss: 0.7625 - val_accuracy: 0.7670\n",
      "Epoch 195/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.5311 - accuracy: 0.8997 - val_loss: 0.7611 - val_accuracy: 0.7379\n",
      "Epoch 196/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.5068 - accuracy: 0.8900 - val_loss: 0.7498 - val_accuracy: 0.7282\n",
      "Epoch 197/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.5324 - accuracy: 0.8997 - val_loss: 0.7527 - val_accuracy: 0.7379\n",
      "Epoch 198/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.4966 - accuracy: 0.9029 - val_loss: 0.7509 - val_accuracy: 0.7573\n",
      "Epoch 199/2000\n",
      "309/309 [==============================] - 0s 58us/sample - loss: 0.5342 - accuracy: 0.8673 - val_loss: 0.7491 - val_accuracy: 0.7670\n",
      "Epoch 200/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.5164 - accuracy: 0.8997 - val_loss: 0.7468 - val_accuracy: 0.7379\n",
      "Epoch 201/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.4889 - accuracy: 0.9061 - val_loss: 0.7406 - val_accuracy: 0.7573\n",
      "Epoch 202/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.5198 - accuracy: 0.8932 - val_loss: 0.7386 - val_accuracy: 0.7767\n",
      "Epoch 203/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.4859 - accuracy: 0.9029 - val_loss: 0.7271 - val_accuracy: 0.7961\n",
      "Epoch 204/2000\n",
      "309/309 [==============================] - 0s 58us/sample - loss: 0.4791 - accuracy: 0.9191 - val_loss: 0.7406 - val_accuracy: 0.7573\n",
      "Epoch 205/2000\n",
      "309/309 [==============================] - 0s 71us/sample - loss: 0.5078 - accuracy: 0.9159 - val_loss: 0.7375 - val_accuracy: 0.7670\n",
      "Epoch 206/2000\n",
      "309/309 [==============================] - 0s 69us/sample - loss: 0.5317 - accuracy: 0.8867 - val_loss: 0.7413 - val_accuracy: 0.7573\n",
      "Epoch 207/2000\n",
      "309/309 [==============================] - 0s 74us/sample - loss: 0.4944 - accuracy: 0.9288 - val_loss: 0.7428 - val_accuracy: 0.7573\n",
      "Epoch 208/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.5031 - accuracy: 0.8997 - val_loss: 0.7313 - val_accuracy: 0.7670\n",
      "Epoch 209/2000\n",
      "309/309 [==============================] - 0s 65us/sample - loss: 0.4909 - accuracy: 0.9094 - val_loss: 0.7206 - val_accuracy: 0.7670\n",
      "Epoch 210/2000\n",
      "309/309 [==============================] - 0s 74us/sample - loss: 0.4548 - accuracy: 0.9223 - val_loss: 0.7253 - val_accuracy: 0.7573\n",
      "Epoch 211/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.4615 - accuracy: 0.9288 - val_loss: 0.7320 - val_accuracy: 0.7476\n",
      "Epoch 212/2000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 0.4701 - accuracy: 0.9159 - val_loss: 0.7324 - val_accuracy: 0.7573\n",
      "Epoch 213/2000\n",
      "309/309 [==============================] - 0s 72us/sample - loss: 0.4914 - accuracy: 0.9159 - val_loss: 0.7334 - val_accuracy: 0.7767\n",
      "Epoch 214/2000\n",
      "309/309 [==============================] - 0s 71us/sample - loss: 0.4819 - accuracy: 0.9159 - val_loss: 0.7232 - val_accuracy: 0.7864\n",
      "Epoch 215/2000\n",
      "309/309 [==============================] - 0s 63us/sample - loss: 0.5065 - accuracy: 0.8803 - val_loss: 0.7236 - val_accuracy: 0.7961\n",
      "Epoch 216/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.4725 - accuracy: 0.8997 - val_loss: 0.7181 - val_accuracy: 0.7961\n",
      "Epoch 217/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.4905 - accuracy: 0.8964 - val_loss: 0.7265 - val_accuracy: 0.7670\n",
      "Epoch 218/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.4707 - accuracy: 0.9061 - val_loss: 0.7177 - val_accuracy: 0.7767\n",
      "Epoch 219/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.4528 - accuracy: 0.9094 - val_loss: 0.7178 - val_accuracy: 0.7573\n",
      "Epoch 220/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.4695 - accuracy: 0.9029 - val_loss: 0.7168 - val_accuracy: 0.7670\n",
      "Epoch 221/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.4545 - accuracy: 0.8932 - val_loss: 0.7148 - val_accuracy: 0.7670\n",
      "Epoch 222/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.4528 - accuracy: 0.9061 - val_loss: 0.7182 - val_accuracy: 0.7767\n",
      "Epoch 223/2000\n",
      "309/309 [==============================] - 0s 56us/sample - loss: 0.5082 - accuracy: 0.8803 - val_loss: 0.7290 - val_accuracy: 0.7476\n",
      "Epoch 224/2000\n",
      "309/309 [==============================] - 0s 64us/sample - loss: 0.4955 - accuracy: 0.9126 - val_loss: 0.7253 - val_accuracy: 0.7379\n",
      "Epoch 225/2000\n",
      "309/309 [==============================] - 0s 74us/sample - loss: 0.4943 - accuracy: 0.8932 - val_loss: 0.7221 - val_accuracy: 0.7379\n",
      "Epoch 226/2000\n",
      "309/309 [==============================] - 0s 85us/sample - loss: 0.4516 - accuracy: 0.9029 - val_loss: 0.7223 - val_accuracy: 0.7864\n",
      "Epoch 227/2000\n",
      "309/309 [==============================] - 0s 65us/sample - loss: 0.4725 - accuracy: 0.9061 - val_loss: 0.7191 - val_accuracy: 0.7767\n",
      "Epoch 228/2000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 0.4597 - accuracy: 0.9191 - val_loss: 0.7163 - val_accuracy: 0.7670\n",
      "Epoch 229/2000\n",
      "309/309 [==============================] - 0s 74us/sample - loss: 0.4458 - accuracy: 0.9256 - val_loss: 0.7161 - val_accuracy: 0.7864\n",
      "Epoch 230/2000\n",
      "309/309 [==============================] - 0s 70us/sample - loss: 0.4683 - accuracy: 0.9223 - val_loss: 0.7200 - val_accuracy: 0.7573\n",
      "Epoch 231/2000\n",
      "309/309 [==============================] - 0s 68us/sample - loss: 0.4449 - accuracy: 0.9029 - val_loss: 0.7131 - val_accuracy: 0.7476\n",
      "Epoch 232/2000\n",
      "309/309 [==============================] - 0s 73us/sample - loss: 0.4561 - accuracy: 0.9126 - val_loss: 0.7176 - val_accuracy: 0.7282\n",
      "Epoch 233/2000\n",
      "309/309 [==============================] - 0s 74us/sample - loss: 0.4367 - accuracy: 0.9288 - val_loss: 0.7097 - val_accuracy: 0.7573\n",
      "Epoch 234/2000\n",
      "309/309 [==============================] - 0s 70us/sample - loss: 0.4530 - accuracy: 0.9191 - val_loss: 0.7175 - val_accuracy: 0.7379\n",
      "Epoch 235/2000\n",
      "309/309 [==============================] - 0s 65us/sample - loss: 0.4203 - accuracy: 0.9223 - val_loss: 0.7070 - val_accuracy: 0.7573\n",
      "Epoch 236/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.4367 - accuracy: 0.9288 - val_loss: 0.6973 - val_accuracy: 0.7573\n",
      "Epoch 237/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.4576 - accuracy: 0.8997 - val_loss: 0.7087 - val_accuracy: 0.7573\n",
      "Epoch 238/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.4471 - accuracy: 0.9159 - val_loss: 0.7083 - val_accuracy: 0.7573\n",
      "Epoch 239/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.4564 - accuracy: 0.9191 - val_loss: 0.7042 - val_accuracy: 0.7573\n",
      "Epoch 240/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 54us/sample - loss: 0.4377 - accuracy: 0.9288 - val_loss: 0.7061 - val_accuracy: 0.7864\n",
      "Epoch 241/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.4196 - accuracy: 0.9223 - val_loss: 0.7083 - val_accuracy: 0.7573\n",
      "Epoch 242/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.4439 - accuracy: 0.9094 - val_loss: 0.7033 - val_accuracy: 0.7670\n",
      "Epoch 243/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.4226 - accuracy: 0.9094 - val_loss: 0.6891 - val_accuracy: 0.7864\n",
      "Epoch 244/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.4373 - accuracy: 0.9223 - val_loss: 0.7026 - val_accuracy: 0.7767\n",
      "Epoch 245/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3938 - accuracy: 0.9515 - val_loss: 0.7126 - val_accuracy: 0.7573\n",
      "Epoch 246/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.4144 - accuracy: 0.9256 - val_loss: 0.7082 - val_accuracy: 0.7573\n",
      "Epoch 247/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3961 - accuracy: 0.9482 - val_loss: 0.7089 - val_accuracy: 0.7379\n",
      "Epoch 248/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.4299 - accuracy: 0.9061 - val_loss: 0.7064 - val_accuracy: 0.7670\n",
      "Epoch 249/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.4121 - accuracy: 0.9353 - val_loss: 0.7077 - val_accuracy: 0.7573\n",
      "Epoch 250/2000\n",
      "309/309 [==============================] - 0s 57us/sample - loss: 0.4312 - accuracy: 0.9061 - val_loss: 0.6982 - val_accuracy: 0.7670\n",
      "Epoch 251/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3999 - accuracy: 0.9223 - val_loss: 0.7017 - val_accuracy: 0.7670\n",
      "Epoch 252/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.4050 - accuracy: 0.9320 - val_loss: 0.6941 - val_accuracy: 0.7864\n",
      "Epoch 253/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.4154 - accuracy: 0.9256 - val_loss: 0.7001 - val_accuracy: 0.7573\n",
      "Epoch 254/2000\n",
      "309/309 [==============================] - 0s 61us/sample - loss: 0.4012 - accuracy: 0.9288 - val_loss: 0.6980 - val_accuracy: 0.7864\n",
      "Epoch 255/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.4064 - accuracy: 0.9223 - val_loss: 0.6988 - val_accuracy: 0.7670\n",
      "Epoch 256/2000\n",
      "309/309 [==============================] - 0s 58us/sample - loss: 0.4523 - accuracy: 0.9223 - val_loss: 0.6891 - val_accuracy: 0.7767\n",
      "Epoch 257/2000\n",
      "309/309 [==============================] - 0s 70us/sample - loss: 0.4017 - accuracy: 0.9061 - val_loss: 0.6972 - val_accuracy: 0.7670\n",
      "Epoch 258/2000\n",
      "309/309 [==============================] - 0s 71us/sample - loss: 0.4091 - accuracy: 0.8997 - val_loss: 0.6837 - val_accuracy: 0.7767\n",
      "Epoch 259/2000\n",
      "309/309 [==============================] - 0s 73us/sample - loss: 0.3963 - accuracy: 0.9191 - val_loss: 0.6861 - val_accuracy: 0.7961\n",
      "Epoch 260/2000\n",
      "309/309 [==============================] - 0s 70us/sample - loss: 0.3703 - accuracy: 0.9417 - val_loss: 0.6841 - val_accuracy: 0.7961\n",
      "Epoch 261/2000\n",
      "309/309 [==============================] - 0s 68us/sample - loss: 0.3786 - accuracy: 0.9353 - val_loss: 0.6811 - val_accuracy: 0.7864\n",
      "Epoch 262/2000\n",
      "309/309 [==============================] - 0s 74us/sample - loss: 0.3901 - accuracy: 0.9223 - val_loss: 0.6872 - val_accuracy: 0.7864\n",
      "Epoch 263/2000\n",
      "309/309 [==============================] - 0s 68us/sample - loss: 0.3861 - accuracy: 0.9320 - val_loss: 0.6780 - val_accuracy: 0.7961\n",
      "Epoch 264/2000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 0.4141 - accuracy: 0.9159 - val_loss: 0.6804 - val_accuracy: 0.7767\n",
      "Epoch 265/2000\n",
      "309/309 [==============================] - 0s 74us/sample - loss: 0.3840 - accuracy: 0.9450 - val_loss: 0.6840 - val_accuracy: 0.7864\n",
      "Epoch 266/2000\n",
      "309/309 [==============================] - 0s 71us/sample - loss: 0.3924 - accuracy: 0.9288 - val_loss: 0.6747 - val_accuracy: 0.8058\n",
      "Epoch 267/2000\n",
      "309/309 [==============================] - 0s 69us/sample - loss: 0.3937 - accuracy: 0.9450 - val_loss: 0.6770 - val_accuracy: 0.7961\n",
      "Epoch 268/2000\n",
      "309/309 [==============================] - 0s 71us/sample - loss: 0.3932 - accuracy: 0.9223 - val_loss: 0.6864 - val_accuracy: 0.7767\n",
      "Epoch 269/2000\n",
      "309/309 [==============================] - 0s 69us/sample - loss: 0.3901 - accuracy: 0.9288 - val_loss: 0.6904 - val_accuracy: 0.7961\n",
      "Epoch 270/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.3980 - accuracy: 0.9482 - val_loss: 0.6909 - val_accuracy: 0.7767\n",
      "Epoch 271/2000\n",
      "309/309 [==============================] - 0s 82us/sample - loss: 0.3722 - accuracy: 0.9450 - val_loss: 0.6801 - val_accuracy: 0.7961\n",
      "Epoch 272/2000\n",
      "309/309 [==============================] - 0s 58us/sample - loss: 0.3693 - accuracy: 0.9417 - val_loss: 0.6775 - val_accuracy: 0.8058\n",
      "Epoch 273/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3550 - accuracy: 0.9547 - val_loss: 0.6770 - val_accuracy: 0.7864\n",
      "Epoch 274/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3608 - accuracy: 0.9320 - val_loss: 0.6749 - val_accuracy: 0.7961\n",
      "Epoch 275/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.3818 - accuracy: 0.9288 - val_loss: 0.6773 - val_accuracy: 0.7961\n",
      "Epoch 276/2000\n",
      "309/309 [==============================] - 0s 74us/sample - loss: 0.4000 - accuracy: 0.9159 - val_loss: 0.6783 - val_accuracy: 0.7961\n",
      "Epoch 277/2000\n",
      "309/309 [==============================] - 0s 69us/sample - loss: 0.3668 - accuracy: 0.9482 - val_loss: 0.6819 - val_accuracy: 0.7864\n",
      "Epoch 278/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.3814 - accuracy: 0.9320 - val_loss: 0.6870 - val_accuracy: 0.7864\n",
      "Epoch 279/2000\n",
      "309/309 [==============================] - 0s 73us/sample - loss: 0.3805 - accuracy: 0.9288 - val_loss: 0.6818 - val_accuracy: 0.7864\n",
      "Epoch 280/2000\n",
      "309/309 [==============================] - 0s 68us/sample - loss: 0.3638 - accuracy: 0.9385 - val_loss: 0.6758 - val_accuracy: 0.7864\n",
      "Epoch 281/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.3725 - accuracy: 0.9159 - val_loss: 0.6744 - val_accuracy: 0.7864\n",
      "Epoch 282/2000\n",
      "309/309 [==============================] - 0s 75us/sample - loss: 0.3950 - accuracy: 0.9191 - val_loss: 0.6829 - val_accuracy: 0.7864\n",
      "Epoch 283/2000\n",
      "309/309 [==============================] - 0s 69us/sample - loss: 0.3840 - accuracy: 0.9223 - val_loss: 0.6863 - val_accuracy: 0.7864\n",
      "Epoch 284/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.3843 - accuracy: 0.9417 - val_loss: 0.6833 - val_accuracy: 0.7864\n",
      "Epoch 285/2000\n",
      "309/309 [==============================] - 0s 75us/sample - loss: 0.3750 - accuracy: 0.9385 - val_loss: 0.6910 - val_accuracy: 0.7864\n",
      "Epoch 286/2000\n",
      "309/309 [==============================] - 0s 68us/sample - loss: 0.3621 - accuracy: 0.9385 - val_loss: 0.6786 - val_accuracy: 0.7864\n",
      "Epoch 287/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.3830 - accuracy: 0.9094 - val_loss: 0.6773 - val_accuracy: 0.7767\n",
      "Epoch 288/2000\n",
      "309/309 [==============================] - 0s 68us/sample - loss: 0.3709 - accuracy: 0.9450 - val_loss: 0.6837 - val_accuracy: 0.7767\n",
      "Epoch 289/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3785 - accuracy: 0.9288 - val_loss: 0.6894 - val_accuracy: 0.7864\n",
      "Epoch 290/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3708 - accuracy: 0.9223 - val_loss: 0.6843 - val_accuracy: 0.7767\n",
      "Epoch 291/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3549 - accuracy: 0.9515 - val_loss: 0.6853 - val_accuracy: 0.7864\n",
      "Epoch 292/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.3674 - accuracy: 0.9191 - val_loss: 0.6838 - val_accuracy: 0.7864\n",
      "Epoch 293/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3868 - accuracy: 0.9320 - val_loss: 0.6901 - val_accuracy: 0.7767\n",
      "Epoch 294/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3993 - accuracy: 0.9126 - val_loss: 0.6800 - val_accuracy: 0.7961\n",
      "Epoch 295/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3574 - accuracy: 0.9547 - val_loss: 0.6877 - val_accuracy: 0.7767\n",
      "Epoch 296/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3540 - accuracy: 0.9288 - val_loss: 0.6770 - val_accuracy: 0.7767\n",
      "Epoch 297/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3300 - accuracy: 0.9515 - val_loss: 0.6713 - val_accuracy: 0.7864\n",
      "Epoch 298/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3452 - accuracy: 0.9450 - val_loss: 0.6754 - val_accuracy: 0.7670\n",
      "Epoch 299/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.3585 - accuracy: 0.9353 - val_loss: 0.6842 - val_accuracy: 0.7767\n",
      "Epoch 300/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.3450 - accuracy: 0.9482 - val_loss: 0.6789 - val_accuracy: 0.7670\n",
      "Epoch 301/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3420 - accuracy: 0.9417 - val_loss: 0.6687 - val_accuracy: 0.7961\n",
      "Epoch 302/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3589 - accuracy: 0.9417 - val_loss: 0.6806 - val_accuracy: 0.7767\n",
      "Epoch 303/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3299 - accuracy: 0.9579 - val_loss: 0.6725 - val_accuracy: 0.7961\n",
      "Epoch 304/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.3411 - accuracy: 0.9515 - val_loss: 0.6742 - val_accuracy: 0.7864\n",
      "Epoch 305/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3261 - accuracy: 0.9417 - val_loss: 0.6645 - val_accuracy: 0.7961\n",
      "Epoch 306/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.3310 - accuracy: 0.9515 - val_loss: 0.6694 - val_accuracy: 0.7864\n",
      "Epoch 307/2000\n",
      "309/309 [==============================] - 0s 58us/sample - loss: 0.3641 - accuracy: 0.9288 - val_loss: 0.6801 - val_accuracy: 0.7961\n",
      "Epoch 308/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3222 - accuracy: 0.9482 - val_loss: 0.6850 - val_accuracy: 0.8058\n",
      "Epoch 309/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3240 - accuracy: 0.9612 - val_loss: 0.6760 - val_accuracy: 0.7864\n",
      "Epoch 310/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.3573 - accuracy: 0.9320 - val_loss: 0.6812 - val_accuracy: 0.7864\n",
      "Epoch 311/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.3505 - accuracy: 0.9385 - val_loss: 0.6704 - val_accuracy: 0.8058\n",
      "Epoch 312/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.3596 - accuracy: 0.9417 - val_loss: 0.6775 - val_accuracy: 0.7961\n",
      "Epoch 313/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3057 - accuracy: 0.9709 - val_loss: 0.6859 - val_accuracy: 0.7864\n",
      "Epoch 314/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.3193 - accuracy: 0.9515 - val_loss: 0.6732 - val_accuracy: 0.8058\n",
      "Epoch 315/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3345 - accuracy: 0.9482 - val_loss: 0.6800 - val_accuracy: 0.8058\n",
      "Epoch 316/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.3380 - accuracy: 0.9450 - val_loss: 0.6748 - val_accuracy: 0.7864\n",
      "Epoch 317/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3294 - accuracy: 0.9644 - val_loss: 0.6817 - val_accuracy: 0.7864\n",
      "Epoch 318/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3363 - accuracy: 0.9450 - val_loss: 0.6799 - val_accuracy: 0.7864\n",
      "Epoch 319/2000\n",
      "309/309 [==============================] - 0s 57us/sample - loss: 0.3554 - accuracy: 0.9482 - val_loss: 0.6697 - val_accuracy: 0.8155\n",
      "Epoch 320/2000\n",
      "309/309 [==============================] - 0s 56us/sample - loss: 0.3123 - accuracy: 0.9579 - val_loss: 0.6675 - val_accuracy: 0.8058\n",
      "Epoch 321/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3283 - accuracy: 0.9385 - val_loss: 0.6759 - val_accuracy: 0.7961\n",
      "Epoch 322/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.3247 - accuracy: 0.9385 - val_loss: 0.6686 - val_accuracy: 0.7961\n",
      "Epoch 323/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.3208 - accuracy: 0.9417 - val_loss: 0.6578 - val_accuracy: 0.7961\n",
      "Epoch 324/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.3103 - accuracy: 0.9547 - val_loss: 0.6689 - val_accuracy: 0.7864\n",
      "Epoch 325/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3305 - accuracy: 0.9417 - val_loss: 0.6744 - val_accuracy: 0.7961\n",
      "Epoch 326/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3497 - accuracy: 0.9288 - val_loss: 0.6765 - val_accuracy: 0.7961\n",
      "Epoch 327/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3325 - accuracy: 0.9385 - val_loss: 0.6763 - val_accuracy: 0.7961\n",
      "Epoch 328/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3508 - accuracy: 0.9450 - val_loss: 0.6753 - val_accuracy: 0.7864\n",
      "Epoch 329/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3316 - accuracy: 0.9547 - val_loss: 0.6709 - val_accuracy: 0.7864\n",
      "Epoch 330/2000\n",
      "309/309 [==============================] - 0s 73us/sample - loss: 0.3453 - accuracy: 0.9223 - val_loss: 0.6791 - val_accuracy: 0.7864\n",
      "Epoch 331/2000\n",
      "309/309 [==============================] - 0s 71us/sample - loss: 0.3230 - accuracy: 0.9676 - val_loss: 0.6843 - val_accuracy: 0.7864\n",
      "Epoch 332/2000\n",
      "309/309 [==============================] - 0s 72us/sample - loss: 0.3324 - accuracy: 0.9482 - val_loss: 0.6725 - val_accuracy: 0.7864\n",
      "Epoch 333/2000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 0.3154 - accuracy: 0.9515 - val_loss: 0.6807 - val_accuracy: 0.7767\n",
      "Epoch 334/2000\n",
      "309/309 [==============================] - 0s 69us/sample - loss: 0.3169 - accuracy: 0.9482 - val_loss: 0.6839 - val_accuracy: 0.7864\n",
      "Epoch 335/2000\n",
      "309/309 [==============================] - 0s 70us/sample - loss: 0.3033 - accuracy: 0.9515 - val_loss: 0.6684 - val_accuracy: 0.7864\n",
      "Epoch 336/2000\n",
      "309/309 [==============================] - 0s 65us/sample - loss: 0.3428 - accuracy: 0.9385 - val_loss: 0.6602 - val_accuracy: 0.7864\n",
      "Epoch 337/2000\n",
      "309/309 [==============================] - 0s 65us/sample - loss: 0.3093 - accuracy: 0.9612 - val_loss: 0.6629 - val_accuracy: 0.7767\n",
      "Epoch 338/2000\n",
      "309/309 [==============================] - 0s 77us/sample - loss: 0.3045 - accuracy: 0.9676 - val_loss: 0.6718 - val_accuracy: 0.7670\n",
      "Epoch 339/2000\n",
      "309/309 [==============================] - 0s 68us/sample - loss: 0.3245 - accuracy: 0.9385 - val_loss: 0.6577 - val_accuracy: 0.7961\n",
      "Epoch 340/2000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 0.3468 - accuracy: 0.9482 - val_loss: 0.6528 - val_accuracy: 0.7961\n",
      "Epoch 341/2000\n",
      "309/309 [==============================] - 0s 74us/sample - loss: 0.2922 - accuracy: 0.9579 - val_loss: 0.6645 - val_accuracy: 0.7864\n",
      "Epoch 342/2000\n",
      "309/309 [==============================] - 0s 68us/sample - loss: 0.3155 - accuracy: 0.9450 - val_loss: 0.6687 - val_accuracy: 0.7864\n",
      "Epoch 343/2000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 0.2999 - accuracy: 0.9515 - val_loss: 0.6682 - val_accuracy: 0.7961\n",
      "Epoch 344/2000\n",
      "309/309 [==============================] - 0s 72us/sample - loss: 0.3143 - accuracy: 0.9417 - val_loss: 0.6698 - val_accuracy: 0.7767\n",
      "Epoch 345/2000\n",
      "309/309 [==============================] - 0s 69us/sample - loss: 0.3069 - accuracy: 0.9547 - val_loss: 0.6682 - val_accuracy: 0.7767\n",
      "Epoch 346/2000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 0.3045 - accuracy: 0.9515 - val_loss: 0.6803 - val_accuracy: 0.7864\n",
      "Epoch 347/2000\n",
      "309/309 [==============================] - 0s 63us/sample - loss: 0.2968 - accuracy: 0.9709 - val_loss: 0.6726 - val_accuracy: 0.7864\n",
      "Epoch 348/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.3285 - accuracy: 0.9385 - val_loss: 0.6736 - val_accuracy: 0.7864\n",
      "Epoch 349/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.2963 - accuracy: 0.9515 - val_loss: 0.6638 - val_accuracy: 0.7864\n",
      "Epoch 350/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 65us/sample - loss: 0.2972 - accuracy: 0.9612 - val_loss: 0.6799 - val_accuracy: 0.7864\n",
      "Epoch 351/2000\n",
      "309/309 [==============================] - 0s 69us/sample - loss: 0.3063 - accuracy: 0.9579 - val_loss: 0.6643 - val_accuracy: 0.7961\n",
      "Epoch 352/2000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 0.2893 - accuracy: 0.9547 - val_loss: 0.6753 - val_accuracy: 0.7864\n",
      "Epoch 353/2000\n",
      "309/309 [==============================] - 0s 72us/sample - loss: 0.3014 - accuracy: 0.9547 - val_loss: 0.6596 - val_accuracy: 0.7961\n",
      "Epoch 354/2000\n",
      "309/309 [==============================] - 0s 69us/sample - loss: 0.2930 - accuracy: 0.9676 - val_loss: 0.6732 - val_accuracy: 0.7767\n",
      "Epoch 355/2000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 0.3134 - accuracy: 0.9482 - val_loss: 0.6733 - val_accuracy: 0.7767\n",
      "Epoch 356/2000\n",
      "309/309 [==============================] - 0s 74us/sample - loss: 0.2988 - accuracy: 0.9482 - val_loss: 0.6551 - val_accuracy: 0.7864\n",
      "Epoch 357/2000\n",
      "309/309 [==============================] - 0s 71us/sample - loss: 0.3232 - accuracy: 0.9417 - val_loss: 0.6686 - val_accuracy: 0.7864\n",
      "Epoch 358/2000\n",
      "309/309 [==============================] - 0s 65us/sample - loss: 0.2966 - accuracy: 0.9547 - val_loss: 0.6629 - val_accuracy: 0.7864\n",
      "Epoch 359/2000\n",
      "309/309 [==============================] - 0s 72us/sample - loss: 0.3000 - accuracy: 0.9482 - val_loss: 0.6750 - val_accuracy: 0.7864\n",
      "Epoch 360/2000\n",
      "309/309 [==============================] - 0s 70us/sample - loss: 0.3093 - accuracy: 0.9385 - val_loss: 0.6761 - val_accuracy: 0.7961\n",
      "Epoch 361/2000\n",
      "309/309 [==============================] - 0s 69us/sample - loss: 0.2909 - accuracy: 0.9579 - val_loss: 0.6727 - val_accuracy: 0.7864\n",
      "Epoch 362/2000\n",
      "309/309 [==============================] - 0s 76us/sample - loss: 0.3261 - accuracy: 0.9482 - val_loss: 0.6656 - val_accuracy: 0.7864\n",
      "Epoch 363/2000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 0.3096 - accuracy: 0.9515 - val_loss: 0.6653 - val_accuracy: 0.7864\n",
      "Epoch 364/2000\n",
      "309/309 [==============================] - 0s 68us/sample - loss: 0.3197 - accuracy: 0.9191 - val_loss: 0.6657 - val_accuracy: 0.7864\n",
      "Epoch 365/2000\n",
      "309/309 [==============================] - 0s 73us/sample - loss: 0.2865 - accuracy: 0.9515 - val_loss: 0.6717 - val_accuracy: 0.7864\n",
      "Epoch 366/2000\n",
      "309/309 [==============================] - 0s 68us/sample - loss: 0.2832 - accuracy: 0.9579 - val_loss: 0.6667 - val_accuracy: 0.7961\n",
      "Epoch 367/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.2937 - accuracy: 0.9644 - val_loss: 0.6639 - val_accuracy: 0.7767\n",
      "Epoch 368/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.3069 - accuracy: 0.9385 - val_loss: 0.6652 - val_accuracy: 0.7767\n",
      "Epoch 369/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.2730 - accuracy: 0.9547 - val_loss: 0.6701 - val_accuracy: 0.7864\n",
      "Epoch 370/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.2700 - accuracy: 0.9709 - val_loss: 0.6672 - val_accuracy: 0.7961\n",
      "Epoch 371/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.2863 - accuracy: 0.9482 - val_loss: 0.6708 - val_accuracy: 0.7864\n",
      "Epoch 372/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3017 - accuracy: 0.9482 - val_loss: 0.6676 - val_accuracy: 0.7961\n",
      "Epoch 373/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.2919 - accuracy: 0.9547 - val_loss: 0.6680 - val_accuracy: 0.7864\n",
      "Epoch 374/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.2769 - accuracy: 0.9547 - val_loss: 0.6635 - val_accuracy: 0.7864\n",
      "Epoch 375/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.2790 - accuracy: 0.9612 - val_loss: 0.6734 - val_accuracy: 0.7864\n",
      "Epoch 376/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3309 - accuracy: 0.9417 - val_loss: 0.6612 - val_accuracy: 0.7961\n",
      "Epoch 377/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.2775 - accuracy: 0.9547 - val_loss: 0.6656 - val_accuracy: 0.7864\n",
      "Epoch 378/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.2836 - accuracy: 0.9547 - val_loss: 0.6729 - val_accuracy: 0.7767\n",
      "Epoch 379/2000\n",
      "309/309 [==============================] - 0s 54us/sample - loss: 0.2775 - accuracy: 0.9709 - val_loss: 0.6662 - val_accuracy: 0.7864\n",
      "Epoch 380/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.2967 - accuracy: 0.9450 - val_loss: 0.6710 - val_accuracy: 0.7864\n",
      "Epoch 381/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3156 - accuracy: 0.9353 - val_loss: 0.6687 - val_accuracy: 0.7767\n",
      "Epoch 382/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.2747 - accuracy: 0.9644 - val_loss: 0.6628 - val_accuracy: 0.7864\n",
      "Epoch 383/2000\n",
      "309/309 [==============================] - 0s 55us/sample - loss: 0.2816 - accuracy: 0.9676 - val_loss: 0.6704 - val_accuracy: 0.7864\n",
      "Epoch 384/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.2899 - accuracy: 0.9482 - val_loss: 0.6717 - val_accuracy: 0.7864\n",
      "Epoch 385/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.3211 - accuracy: 0.9320 - val_loss: 0.6598 - val_accuracy: 0.7961\n",
      "Epoch 386/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.2780 - accuracy: 0.9676 - val_loss: 0.6575 - val_accuracy: 0.7961\n",
      "Epoch 387/2000\n",
      "309/309 [==============================] - 0s 52us/sample - loss: 0.2703 - accuracy: 0.9612 - val_loss: 0.6714 - val_accuracy: 0.7961\n",
      "Epoch 388/2000\n",
      "309/309 [==============================] - 0s 57us/sample - loss: 0.2662 - accuracy: 0.9612 - val_loss: 0.6718 - val_accuracy: 0.7961\n",
      "Epoch 389/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.2840 - accuracy: 0.9644 - val_loss: 0.6666 - val_accuracy: 0.7961\n",
      "Epoch 390/2000\n",
      "309/309 [==============================] - 0s 53us/sample - loss: 0.2824 - accuracy: 0.9612 - val_loss: 0.6780 - val_accuracy: 0.7864\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 2,062\n",
      "Trainable params: 2,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 412 samples, validate on 137 samples\n",
      "Epoch 1/2000\n",
      "412/412 [==============================] - 0s 801us/sample - loss: 2.6279 - accuracy: 0.0801 - val_loss: 2.6037 - val_accuracy: 0.0876\n",
      "Epoch 2/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.5860 - accuracy: 0.1481 - val_loss: 2.5746 - val_accuracy: 0.1387\n",
      "Epoch 3/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.5560 - accuracy: 0.1772 - val_loss: 2.5468 - val_accuracy: 0.1387\n",
      "Epoch 4/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.5087 - accuracy: 0.1966 - val_loss: 2.5195 - val_accuracy: 0.1387\n",
      "Epoch 5/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 2.5090 - accuracy: 0.2184 - val_loss: 2.4923 - val_accuracy: 0.1898\n",
      "Epoch 6/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.4549 - accuracy: 0.2379 - val_loss: 2.4618 - val_accuracy: 0.2190\n",
      "Epoch 7/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.4330 - accuracy: 0.2282 - val_loss: 2.4282 - val_accuracy: 0.2263\n",
      "Epoch 8/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 2.4046 - accuracy: 0.2670 - val_loss: 2.3946 - val_accuracy: 0.2628\n",
      "Epoch 9/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 2.3653 - accuracy: 0.2767 - val_loss: 2.3612 - val_accuracy: 0.2847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 2.3504 - accuracy: 0.2864 - val_loss: 2.3278 - val_accuracy: 0.3212\n",
      "Epoch 11/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.2821 - accuracy: 0.3519 - val_loss: 2.2933 - val_accuracy: 0.3139\n",
      "Epoch 12/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.2842 - accuracy: 0.3034 - val_loss: 2.2621 - val_accuracy: 0.3358\n",
      "Epoch 13/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.2507 - accuracy: 0.3325 - val_loss: 2.2288 - val_accuracy: 0.3577\n",
      "Epoch 14/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 2.2237 - accuracy: 0.3155 - val_loss: 2.1983 - val_accuracy: 0.3723\n",
      "Epoch 15/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.1770 - accuracy: 0.3665 - val_loss: 2.1646 - val_accuracy: 0.3504\n",
      "Epoch 16/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.1647 - accuracy: 0.3398 - val_loss: 2.1366 - val_accuracy: 0.3942\n",
      "Epoch 17/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.1022 - accuracy: 0.3981 - val_loss: 2.1008 - val_accuracy: 0.3796\n",
      "Epoch 18/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.0958 - accuracy: 0.3617 - val_loss: 2.0711 - val_accuracy: 0.3723\n",
      "Epoch 19/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.0514 - accuracy: 0.4320 - val_loss: 2.0450 - val_accuracy: 0.3723\n",
      "Epoch 20/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.0530 - accuracy: 0.3956 - val_loss: 2.0144 - val_accuracy: 0.4234\n",
      "Epoch 21/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 2.0079 - accuracy: 0.4005 - val_loss: 1.9884 - val_accuracy: 0.4307\n",
      "Epoch 22/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 2.0046 - accuracy: 0.3956 - val_loss: 1.9589 - val_accuracy: 0.4672\n",
      "Epoch 23/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.9814 - accuracy: 0.4150 - val_loss: 1.9384 - val_accuracy: 0.4891\n",
      "Epoch 24/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.9440 - accuracy: 0.4053 - val_loss: 1.9100 - val_accuracy: 0.4818\n",
      "Epoch 25/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.8828 - accuracy: 0.4684 - val_loss: 1.8811 - val_accuracy: 0.5036\n",
      "Epoch 26/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.8902 - accuracy: 0.4660 - val_loss: 1.8558 - val_accuracy: 0.5109\n",
      "Epoch 27/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 1.8894 - accuracy: 0.4490 - val_loss: 1.8336 - val_accuracy: 0.5401\n",
      "Epoch 28/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.8463 - accuracy: 0.4393 - val_loss: 1.8125 - val_accuracy: 0.5255\n",
      "Epoch 29/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.8028 - accuracy: 0.4709 - val_loss: 1.7876 - val_accuracy: 0.5839\n",
      "Epoch 30/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.7784 - accuracy: 0.5024 - val_loss: 1.7639 - val_accuracy: 0.5547\n",
      "Epoch 31/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.7609 - accuracy: 0.5000 - val_loss: 1.7460 - val_accuracy: 0.5547\n",
      "Epoch 32/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.7618 - accuracy: 0.4636 - val_loss: 1.7256 - val_accuracy: 0.5474\n",
      "Epoch 33/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.7141 - accuracy: 0.4976 - val_loss: 1.7039 - val_accuracy: 0.5985\n",
      "Epoch 34/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.7181 - accuracy: 0.4587 - val_loss: 1.6809 - val_accuracy: 0.5985\n",
      "Epoch 35/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 1.6764 - accuracy: 0.5170 - val_loss: 1.6547 - val_accuracy: 0.6350\n",
      "Epoch 36/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.6577 - accuracy: 0.5340 - val_loss: 1.6378 - val_accuracy: 0.6350\n",
      "Epoch 37/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.6369 - accuracy: 0.5267 - val_loss: 1.6187 - val_accuracy: 0.6350\n",
      "Epoch 38/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.6189 - accuracy: 0.5437 - val_loss: 1.5978 - val_accuracy: 0.6496\n",
      "Epoch 39/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.6131 - accuracy: 0.5413 - val_loss: 1.5786 - val_accuracy: 0.6569\n",
      "Epoch 40/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.5789 - accuracy: 0.5655 - val_loss: 1.5643 - val_accuracy: 0.6642\n",
      "Epoch 41/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.5924 - accuracy: 0.5655 - val_loss: 1.5434 - val_accuracy: 0.7007\n",
      "Epoch 42/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.5563 - accuracy: 0.5655 - val_loss: 1.5291 - val_accuracy: 0.6861\n",
      "Epoch 43/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 1.5526 - accuracy: 0.5680 - val_loss: 1.5093 - val_accuracy: 0.7007\n",
      "Epoch 44/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.5450 - accuracy: 0.5291 - val_loss: 1.4946 - val_accuracy: 0.6934\n",
      "Epoch 45/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 1.4903 - accuracy: 0.5922 - val_loss: 1.4786 - val_accuracy: 0.6861\n",
      "Epoch 46/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 1.4615 - accuracy: 0.6019 - val_loss: 1.4629 - val_accuracy: 0.6788\n",
      "Epoch 47/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.4574 - accuracy: 0.6019 - val_loss: 1.4445 - val_accuracy: 0.7226\n",
      "Epoch 48/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.4624 - accuracy: 0.5825 - val_loss: 1.4224 - val_accuracy: 0.7080\n",
      "Epoch 49/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.4078 - accuracy: 0.6383 - val_loss: 1.4065 - val_accuracy: 0.7299\n",
      "Epoch 50/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 1.4128 - accuracy: 0.6286 - val_loss: 1.3908 - val_accuracy: 0.7372\n",
      "Epoch 51/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 1.3649 - accuracy: 0.6432 - val_loss: 1.3822 - val_accuracy: 0.6861\n",
      "Epoch 52/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.3856 - accuracy: 0.6286 - val_loss: 1.3649 - val_accuracy: 0.7299\n",
      "Epoch 53/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.3660 - accuracy: 0.6286 - val_loss: 1.3478 - val_accuracy: 0.7445\n",
      "Epoch 54/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 1.3533 - accuracy: 0.6068 - val_loss: 1.3356 - val_accuracy: 0.7299\n",
      "Epoch 55/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.3229 - accuracy: 0.6675 - val_loss: 1.3171 - val_accuracy: 0.7299\n",
      "Epoch 56/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 1.3139 - accuracy: 0.6626 - val_loss: 1.2993 - val_accuracy: 0.7591\n",
      "Epoch 57/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.2969 - accuracy: 0.6748 - val_loss: 1.2866 - val_accuracy: 0.7445\n",
      "Epoch 58/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.2644 - accuracy: 0.6772 - val_loss: 1.2738 - val_accuracy: 0.7299\n",
      "Epoch 59/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 1.2608 - accuracy: 0.6481 - val_loss: 1.2596 - val_accuracy: 0.7299\n",
      "Epoch 60/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.2346 - accuracy: 0.6723 - val_loss: 1.2441 - val_accuracy: 0.7591\n",
      "Epoch 61/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.2195 - accuracy: 0.6990 - val_loss: 1.2314 - val_accuracy: 0.7372\n",
      "Epoch 62/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.2210 - accuracy: 0.7015 - val_loss: 1.2183 - val_accuracy: 0.7445\n",
      "Epoch 63/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.2263 - accuracy: 0.6845 - val_loss: 1.2095 - val_accuracy: 0.7591\n",
      "Epoch 64/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.1710 - accuracy: 0.7184 - val_loss: 1.1965 - val_accuracy: 0.7518\n",
      "Epoch 65/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 46us/sample - loss: 1.1690 - accuracy: 0.7233 - val_loss: 1.1844 - val_accuracy: 0.7518\n",
      "Epoch 66/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.1818 - accuracy: 0.7063 - val_loss: 1.1721 - val_accuracy: 0.7518\n",
      "Epoch 67/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.1742 - accuracy: 0.6893 - val_loss: 1.1564 - val_accuracy: 0.7664\n",
      "Epoch 68/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.1622 - accuracy: 0.6626 - val_loss: 1.1484 - val_accuracy: 0.7737\n",
      "Epoch 69/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.1253 - accuracy: 0.6966 - val_loss: 1.1318 - val_accuracy: 0.7737\n",
      "Epoch 70/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.1172 - accuracy: 0.7136 - val_loss: 1.1231 - val_accuracy: 0.7883\n",
      "Epoch 71/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 1.1332 - accuracy: 0.7039 - val_loss: 1.1140 - val_accuracy: 0.7810\n",
      "Epoch 72/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 1.0851 - accuracy: 0.7573 - val_loss: 1.1030 - val_accuracy: 0.7737\n",
      "Epoch 73/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.0634 - accuracy: 0.7476 - val_loss: 1.0897 - val_accuracy: 0.7810\n",
      "Epoch 74/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 1.0889 - accuracy: 0.6990 - val_loss: 1.0808 - val_accuracy: 0.7883\n",
      "Epoch 75/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.0497 - accuracy: 0.7476 - val_loss: 1.0746 - val_accuracy: 0.7737\n",
      "Epoch 76/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 1.0555 - accuracy: 0.7282 - val_loss: 1.0646 - val_accuracy: 0.7810\n",
      "Epoch 77/2000\n",
      "412/412 [==============================] - 0s 50us/sample - loss: 1.0494 - accuracy: 0.7646 - val_loss: 1.0534 - val_accuracy: 0.7737\n",
      "Epoch 78/2000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 1.0614 - accuracy: 0.7282 - val_loss: 1.0440 - val_accuracy: 0.7956\n",
      "Epoch 79/2000\n",
      "412/412 [==============================] - 0s 57us/sample - loss: 1.0305 - accuracy: 0.7427 - val_loss: 1.0362 - val_accuracy: 0.7883\n",
      "Epoch 80/2000\n",
      "412/412 [==============================] - 0s 70us/sample - loss: 0.9854 - accuracy: 0.7767 - val_loss: 1.0201 - val_accuracy: 0.8102\n",
      "Epoch 81/2000\n",
      "412/412 [==============================] - 0s 79us/sample - loss: 1.0177 - accuracy: 0.7549 - val_loss: 1.0137 - val_accuracy: 0.7956\n",
      "Epoch 82/2000\n",
      "412/412 [==============================] - 0s 67us/sample - loss: 0.9710 - accuracy: 0.7670 - val_loss: 1.0009 - val_accuracy: 0.7956\n",
      "Epoch 83/2000\n",
      "412/412 [==============================] - 0s 62us/sample - loss: 0.9683 - accuracy: 0.7718 - val_loss: 0.9888 - val_accuracy: 0.8102\n",
      "Epoch 84/2000\n",
      "412/412 [==============================] - 0s 65us/sample - loss: 0.9470 - accuracy: 0.7549 - val_loss: 0.9803 - val_accuracy: 0.8029\n",
      "Epoch 85/2000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 0.9611 - accuracy: 0.7961 - val_loss: 0.9738 - val_accuracy: 0.8029\n",
      "Epoch 86/2000\n",
      "412/412 [==============================] - 0s 62us/sample - loss: 0.9766 - accuracy: 0.7694 - val_loss: 0.9706 - val_accuracy: 0.8102\n",
      "Epoch 87/2000\n",
      "412/412 [==============================] - 0s 57us/sample - loss: 0.9425 - accuracy: 0.7718 - val_loss: 0.9604 - val_accuracy: 0.8029\n",
      "Epoch 88/2000\n",
      "412/412 [==============================] - 0s 66us/sample - loss: 0.9190 - accuracy: 0.7816 - val_loss: 0.9533 - val_accuracy: 0.8029\n",
      "Epoch 89/2000\n",
      "412/412 [==============================] - 0s 65us/sample - loss: 0.9234 - accuracy: 0.7864 - val_loss: 0.9492 - val_accuracy: 0.7956\n",
      "Epoch 90/2000\n",
      "412/412 [==============================] - 0s 58us/sample - loss: 0.9186 - accuracy: 0.7791 - val_loss: 0.9403 - val_accuracy: 0.8102\n",
      "Epoch 91/2000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 0.9257 - accuracy: 0.7864 - val_loss: 0.9327 - val_accuracy: 0.8029\n",
      "Epoch 92/2000\n",
      "412/412 [==============================] - 0s 59us/sample - loss: 0.8706 - accuracy: 0.8155 - val_loss: 0.9261 - val_accuracy: 0.8102\n",
      "Epoch 93/2000\n",
      "412/412 [==============================] - 0s 65us/sample - loss: 0.8792 - accuracy: 0.7840 - val_loss: 0.9186 - val_accuracy: 0.8029\n",
      "Epoch 94/2000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 0.8913 - accuracy: 0.7985 - val_loss: 0.9073 - val_accuracy: 0.7956\n",
      "Epoch 95/2000\n",
      "412/412 [==============================] - 0s 66us/sample - loss: 0.8743 - accuracy: 0.7961 - val_loss: 0.9009 - val_accuracy: 0.7883\n",
      "Epoch 96/2000\n",
      "412/412 [==============================] - 0s 58us/sample - loss: 0.8555 - accuracy: 0.8107 - val_loss: 0.8916 - val_accuracy: 0.8029\n",
      "Epoch 97/2000\n",
      "412/412 [==============================] - 0s 66us/sample - loss: 0.8480 - accuracy: 0.8034 - val_loss: 0.8835 - val_accuracy: 0.8102\n",
      "Epoch 98/2000\n",
      "412/412 [==============================] - 0s 66us/sample - loss: 0.8611 - accuracy: 0.7913 - val_loss: 0.8807 - val_accuracy: 0.8102\n",
      "Epoch 99/2000\n",
      "412/412 [==============================] - 0s 60us/sample - loss: 0.8571 - accuracy: 0.8204 - val_loss: 0.8719 - val_accuracy: 0.8029\n",
      "Epoch 100/2000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 0.8275 - accuracy: 0.8228 - val_loss: 0.8683 - val_accuracy: 0.8175\n",
      "Epoch 101/2000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 0.8018 - accuracy: 0.8447 - val_loss: 0.8591 - val_accuracy: 0.8102\n",
      "Epoch 102/2000\n",
      "412/412 [==============================] - 0s 65us/sample - loss: 0.8175 - accuracy: 0.8083 - val_loss: 0.8488 - val_accuracy: 0.8175\n",
      "Epoch 103/2000\n",
      "412/412 [==============================] - 0s 60us/sample - loss: 0.8050 - accuracy: 0.8204 - val_loss: 0.8456 - val_accuracy: 0.8029\n",
      "Epoch 104/2000\n",
      "412/412 [==============================] - 0s 61us/sample - loss: 0.8101 - accuracy: 0.7913 - val_loss: 0.8406 - val_accuracy: 0.8102\n",
      "Epoch 105/2000\n",
      "412/412 [==============================] - 0s 59us/sample - loss: 0.8076 - accuracy: 0.8155 - val_loss: 0.8405 - val_accuracy: 0.8175\n",
      "Epoch 106/2000\n",
      "412/412 [==============================] - 0s 62us/sample - loss: 0.7584 - accuracy: 0.8277 - val_loss: 0.8245 - val_accuracy: 0.8175\n",
      "Epoch 107/2000\n",
      "412/412 [==============================] - 0s 62us/sample - loss: 0.7597 - accuracy: 0.8350 - val_loss: 0.8260 - val_accuracy: 0.8248\n",
      "Epoch 108/2000\n",
      "412/412 [==============================] - 0s 58us/sample - loss: 0.7829 - accuracy: 0.8131 - val_loss: 0.8177 - val_accuracy: 0.8175\n",
      "Epoch 109/2000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 0.7934 - accuracy: 0.8131 - val_loss: 0.8109 - val_accuracy: 0.8175\n",
      "Epoch 110/2000\n",
      "412/412 [==============================] - 0s 57us/sample - loss: 0.7599 - accuracy: 0.8325 - val_loss: 0.8060 - val_accuracy: 0.8175\n",
      "Epoch 111/2000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 0.7639 - accuracy: 0.8495 - val_loss: 0.7972 - val_accuracy: 0.8102\n",
      "Epoch 112/2000\n",
      "412/412 [==============================] - 0s 61us/sample - loss: 0.7644 - accuracy: 0.8350 - val_loss: 0.7965 - val_accuracy: 0.8102\n",
      "Epoch 113/2000\n",
      "412/412 [==============================] - 0s 67us/sample - loss: 0.7371 - accuracy: 0.8277 - val_loss: 0.7907 - val_accuracy: 0.8102\n",
      "Epoch 114/2000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 0.7143 - accuracy: 0.8471 - val_loss: 0.7843 - val_accuracy: 0.8102\n",
      "Epoch 115/2000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 0.7255 - accuracy: 0.8374 - val_loss: 0.7827 - val_accuracy: 0.8248\n",
      "Epoch 116/2000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 0.7084 - accuracy: 0.8447 - val_loss: 0.7743 - val_accuracy: 0.8248\n",
      "Epoch 117/2000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 0.7197 - accuracy: 0.8277 - val_loss: 0.7696 - val_accuracy: 0.8175\n",
      "Epoch 118/2000\n",
      "412/412 [==============================] - 0s 57us/sample - loss: 0.7214 - accuracy: 0.8301 - val_loss: 0.7650 - val_accuracy: 0.8102\n",
      "Epoch 119/2000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 0.7179 - accuracy: 0.8252 - val_loss: 0.7662 - val_accuracy: 0.8175\n",
      "Epoch 120/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 61us/sample - loss: 0.6991 - accuracy: 0.8447 - val_loss: 0.7606 - val_accuracy: 0.8102\n",
      "Epoch 121/2000\n",
      "412/412 [==============================] - 0s 49us/sample - loss: 0.6592 - accuracy: 0.8617 - val_loss: 0.7565 - val_accuracy: 0.8029\n",
      "Epoch 122/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.6848 - accuracy: 0.8592 - val_loss: 0.7503 - val_accuracy: 0.8029\n",
      "Epoch 123/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.6895 - accuracy: 0.8277 - val_loss: 0.7458 - val_accuracy: 0.8029\n",
      "Epoch 124/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.6817 - accuracy: 0.8422 - val_loss: 0.7425 - val_accuracy: 0.8102\n",
      "Epoch 125/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.6435 - accuracy: 0.8592 - val_loss: 0.7352 - val_accuracy: 0.8102\n",
      "Epoch 126/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.6789 - accuracy: 0.8617 - val_loss: 0.7327 - val_accuracy: 0.8102\n",
      "Epoch 127/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.6716 - accuracy: 0.8447 - val_loss: 0.7329 - val_accuracy: 0.8175\n",
      "Epoch 128/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.6609 - accuracy: 0.8592 - val_loss: 0.7316 - val_accuracy: 0.8102\n",
      "Epoch 129/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.6703 - accuracy: 0.8544 - val_loss: 0.7231 - val_accuracy: 0.8029\n",
      "Epoch 130/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.6568 - accuracy: 0.8519 - val_loss: 0.7235 - val_accuracy: 0.8102\n",
      "Epoch 131/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.6178 - accuracy: 0.8689 - val_loss: 0.7179 - val_accuracy: 0.8029\n",
      "Epoch 132/2000\n",
      "412/412 [==============================] - 0s 49us/sample - loss: 0.6678 - accuracy: 0.8544 - val_loss: 0.7124 - val_accuracy: 0.8102\n",
      "Epoch 133/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 0.6397 - accuracy: 0.8495 - val_loss: 0.7070 - val_accuracy: 0.8175\n",
      "Epoch 134/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5954 - accuracy: 0.8932 - val_loss: 0.6995 - val_accuracy: 0.8102\n",
      "Epoch 135/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.6175 - accuracy: 0.8811 - val_loss: 0.6967 - val_accuracy: 0.8248\n",
      "Epoch 136/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.6421 - accuracy: 0.8738 - val_loss: 0.6957 - val_accuracy: 0.8102\n",
      "Epoch 137/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.5875 - accuracy: 0.8786 - val_loss: 0.6977 - val_accuracy: 0.8175\n",
      "Epoch 138/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.6432 - accuracy: 0.8447 - val_loss: 0.6899 - val_accuracy: 0.8175\n",
      "Epoch 139/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.6252 - accuracy: 0.8592 - val_loss: 0.6875 - val_accuracy: 0.8175\n",
      "Epoch 140/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.5923 - accuracy: 0.8859 - val_loss: 0.6842 - val_accuracy: 0.8175\n",
      "Epoch 141/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5785 - accuracy: 0.8811 - val_loss: 0.6819 - val_accuracy: 0.8175\n",
      "Epoch 142/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.6028 - accuracy: 0.8786 - val_loss: 0.6749 - val_accuracy: 0.8175\n",
      "Epoch 143/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5947 - accuracy: 0.8568 - val_loss: 0.6760 - val_accuracy: 0.8175\n",
      "Epoch 144/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5977 - accuracy: 0.8762 - val_loss: 0.6675 - val_accuracy: 0.8321\n",
      "Epoch 145/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.5749 - accuracy: 0.8811 - val_loss: 0.6677 - val_accuracy: 0.8248\n",
      "Epoch 146/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.5857 - accuracy: 0.8786 - val_loss: 0.6666 - val_accuracy: 0.8248\n",
      "Epoch 147/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.5786 - accuracy: 0.8956 - val_loss: 0.6626 - val_accuracy: 0.8175\n",
      "Epoch 148/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5650 - accuracy: 0.8835 - val_loss: 0.6562 - val_accuracy: 0.8175\n",
      "Epoch 149/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.5369 - accuracy: 0.8908 - val_loss: 0.6533 - val_accuracy: 0.8248\n",
      "Epoch 150/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5549 - accuracy: 0.8908 - val_loss: 0.6539 - val_accuracy: 0.8248\n",
      "Epoch 151/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5570 - accuracy: 0.8883 - val_loss: 0.6548 - val_accuracy: 0.8321\n",
      "Epoch 152/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5515 - accuracy: 0.8762 - val_loss: 0.6463 - val_accuracy: 0.8175\n",
      "Epoch 153/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5698 - accuracy: 0.8495 - val_loss: 0.6420 - val_accuracy: 0.8248\n",
      "Epoch 154/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5561 - accuracy: 0.8883 - val_loss: 0.6429 - val_accuracy: 0.8175\n",
      "Epoch 155/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5407 - accuracy: 0.9029 - val_loss: 0.6424 - val_accuracy: 0.8321\n",
      "Epoch 156/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5204 - accuracy: 0.9005 - val_loss: 0.6359 - val_accuracy: 0.8248\n",
      "Epoch 157/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 0.5260 - accuracy: 0.8859 - val_loss: 0.6499 - val_accuracy: 0.8321\n",
      "Epoch 158/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5321 - accuracy: 0.8738 - val_loss: 0.6441 - val_accuracy: 0.8248\n",
      "Epoch 159/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5288 - accuracy: 0.9005 - val_loss: 0.6391 - val_accuracy: 0.8321\n",
      "Epoch 160/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 0.5229 - accuracy: 0.9005 - val_loss: 0.6296 - val_accuracy: 0.8248\n",
      "Epoch 161/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5611 - accuracy: 0.8714 - val_loss: 0.6356 - val_accuracy: 0.8467\n",
      "Epoch 162/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5426 - accuracy: 0.8908 - val_loss: 0.6277 - val_accuracy: 0.8321\n",
      "Epoch 163/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5422 - accuracy: 0.8835 - val_loss: 0.6228 - val_accuracy: 0.8394\n",
      "Epoch 164/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5235 - accuracy: 0.9005 - val_loss: 0.6209 - val_accuracy: 0.8248\n",
      "Epoch 165/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5262 - accuracy: 0.8811 - val_loss: 0.6206 - val_accuracy: 0.8175\n",
      "Epoch 166/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5216 - accuracy: 0.8786 - val_loss: 0.6201 - val_accuracy: 0.8394\n",
      "Epoch 167/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.5084 - accuracy: 0.8981 - val_loss: 0.6128 - val_accuracy: 0.8321\n",
      "Epoch 168/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4972 - accuracy: 0.9102 - val_loss: 0.6130 - val_accuracy: 0.8394\n",
      "Epoch 169/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5140 - accuracy: 0.8932 - val_loss: 0.6148 - val_accuracy: 0.8321\n",
      "Epoch 170/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4885 - accuracy: 0.8956 - val_loss: 0.6116 - val_accuracy: 0.8394\n",
      "Epoch 171/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.5047 - accuracy: 0.8908 - val_loss: 0.6119 - val_accuracy: 0.8467\n",
      "Epoch 172/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4907 - accuracy: 0.8956 - val_loss: 0.6148 - val_accuracy: 0.8394\n",
      "Epoch 173/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4848 - accuracy: 0.9053 - val_loss: 0.6160 - val_accuracy: 0.8248\n",
      "Epoch 174/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.5254 - accuracy: 0.8762 - val_loss: 0.6085 - val_accuracy: 0.8394\n",
      "Epoch 175/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 45us/sample - loss: 0.4671 - accuracy: 0.9199 - val_loss: 0.6064 - val_accuracy: 0.8394\n",
      "Epoch 176/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4963 - accuracy: 0.8932 - val_loss: 0.6010 - val_accuracy: 0.8175\n",
      "Epoch 177/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4927 - accuracy: 0.8981 - val_loss: 0.6027 - val_accuracy: 0.8467\n",
      "Epoch 178/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4737 - accuracy: 0.8932 - val_loss: 0.5962 - val_accuracy: 0.8686\n",
      "Epoch 179/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4876 - accuracy: 0.9102 - val_loss: 0.5946 - val_accuracy: 0.8613\n",
      "Epoch 180/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4754 - accuracy: 0.8981 - val_loss: 0.5884 - val_accuracy: 0.8321\n",
      "Epoch 181/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4732 - accuracy: 0.9053 - val_loss: 0.5969 - val_accuracy: 0.8613\n",
      "Epoch 182/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4607 - accuracy: 0.9175 - val_loss: 0.5903 - val_accuracy: 0.8394\n",
      "Epoch 183/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 0.4626 - accuracy: 0.9029 - val_loss: 0.5870 - val_accuracy: 0.8321\n",
      "Epoch 184/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4832 - accuracy: 0.9005 - val_loss: 0.5829 - val_accuracy: 0.8394\n",
      "Epoch 185/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4437 - accuracy: 0.9175 - val_loss: 0.5831 - val_accuracy: 0.8467\n",
      "Epoch 186/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4440 - accuracy: 0.9223 - val_loss: 0.5880 - val_accuracy: 0.8540\n",
      "Epoch 187/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4653 - accuracy: 0.8835 - val_loss: 0.5772 - val_accuracy: 0.8321\n",
      "Epoch 188/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4593 - accuracy: 0.8956 - val_loss: 0.5784 - val_accuracy: 0.8540\n",
      "Epoch 189/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 0.4640 - accuracy: 0.9029 - val_loss: 0.5796 - val_accuracy: 0.8467\n",
      "Epoch 190/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4761 - accuracy: 0.9053 - val_loss: 0.5767 - val_accuracy: 0.8467\n",
      "Epoch 191/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4850 - accuracy: 0.8908 - val_loss: 0.5789 - val_accuracy: 0.8467\n",
      "Epoch 192/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4867 - accuracy: 0.8981 - val_loss: 0.5859 - val_accuracy: 0.8540\n",
      "Epoch 193/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4436 - accuracy: 0.9005 - val_loss: 0.5815 - val_accuracy: 0.8467\n",
      "Epoch 194/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4481 - accuracy: 0.8981 - val_loss: 0.5733 - val_accuracy: 0.8394\n",
      "Epoch 195/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 0.4345 - accuracy: 0.9223 - val_loss: 0.5745 - val_accuracy: 0.8321\n",
      "Epoch 196/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4526 - accuracy: 0.9150 - val_loss: 0.5680 - val_accuracy: 0.8394\n",
      "Epoch 197/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4241 - accuracy: 0.9150 - val_loss: 0.5716 - val_accuracy: 0.8540\n",
      "Epoch 198/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4472 - accuracy: 0.9029 - val_loss: 0.5661 - val_accuracy: 0.8540\n",
      "Epoch 199/2000\n",
      "412/412 [==============================] - 0s 49us/sample - loss: 0.4365 - accuracy: 0.9199 - val_loss: 0.5727 - val_accuracy: 0.8686\n",
      "Epoch 200/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4237 - accuracy: 0.9199 - val_loss: 0.5751 - val_accuracy: 0.8467\n",
      "Epoch 201/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4294 - accuracy: 0.9053 - val_loss: 0.5639 - val_accuracy: 0.8540\n",
      "Epoch 202/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4269 - accuracy: 0.9248 - val_loss: 0.5637 - val_accuracy: 0.8613\n",
      "Epoch 203/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 0.4024 - accuracy: 0.9272 - val_loss: 0.5631 - val_accuracy: 0.8613\n",
      "Epoch 204/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4417 - accuracy: 0.9029 - val_loss: 0.5657 - val_accuracy: 0.8467\n",
      "Epoch 205/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4181 - accuracy: 0.9248 - val_loss: 0.5580 - val_accuracy: 0.8394\n",
      "Epoch 206/2000\n",
      "412/412 [==============================] - 0s 49us/sample - loss: 0.4457 - accuracy: 0.9126 - val_loss: 0.5597 - val_accuracy: 0.8540\n",
      "Epoch 207/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4082 - accuracy: 0.9175 - val_loss: 0.5626 - val_accuracy: 0.8467\n",
      "Epoch 208/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4243 - accuracy: 0.9150 - val_loss: 0.5650 - val_accuracy: 0.8540\n",
      "Epoch 209/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4131 - accuracy: 0.9199 - val_loss: 0.5634 - val_accuracy: 0.8540\n",
      "Epoch 210/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3923 - accuracy: 0.9296 - val_loss: 0.5541 - val_accuracy: 0.8467\n",
      "Epoch 211/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4223 - accuracy: 0.9102 - val_loss: 0.5497 - val_accuracy: 0.8686\n",
      "Epoch 212/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4405 - accuracy: 0.9029 - val_loss: 0.5450 - val_accuracy: 0.8686\n",
      "Epoch 213/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.4193 - accuracy: 0.9078 - val_loss: 0.5536 - val_accuracy: 0.8613\n",
      "Epoch 214/2000\n",
      "412/412 [==============================] - 0s 50us/sample - loss: 0.4027 - accuracy: 0.9296 - val_loss: 0.5518 - val_accuracy: 0.8686\n",
      "Epoch 215/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.4106 - accuracy: 0.9199 - val_loss: 0.5548 - val_accuracy: 0.8613\n",
      "Epoch 216/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.3902 - accuracy: 0.9248 - val_loss: 0.5591 - val_accuracy: 0.8467\n",
      "Epoch 217/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4051 - accuracy: 0.9199 - val_loss: 0.5616 - val_accuracy: 0.8540\n",
      "Epoch 218/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3856 - accuracy: 0.9296 - val_loss: 0.5498 - val_accuracy: 0.8540\n",
      "Epoch 219/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4058 - accuracy: 0.9272 - val_loss: 0.5452 - val_accuracy: 0.8613\n",
      "Epoch 220/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4206 - accuracy: 0.9248 - val_loss: 0.5419 - val_accuracy: 0.8613\n",
      "Epoch 221/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 0.4225 - accuracy: 0.9150 - val_loss: 0.5506 - val_accuracy: 0.8613\n",
      "Epoch 222/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.4048 - accuracy: 0.9175 - val_loss: 0.5483 - val_accuracy: 0.8686\n",
      "Epoch 223/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.4345 - accuracy: 0.8908 - val_loss: 0.5471 - val_accuracy: 0.8686\n",
      "Epoch 224/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4035 - accuracy: 0.9053 - val_loss: 0.5413 - val_accuracy: 0.8540\n",
      "Epoch 225/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4058 - accuracy: 0.9248 - val_loss: 0.5339 - val_accuracy: 0.8613\n",
      "Epoch 226/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3876 - accuracy: 0.9272 - val_loss: 0.5329 - val_accuracy: 0.8613\n",
      "Epoch 227/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3939 - accuracy: 0.9248 - val_loss: 0.5400 - val_accuracy: 0.8613\n",
      "Epoch 228/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3919 - accuracy: 0.9126 - val_loss: 0.5434 - val_accuracy: 0.8540\n",
      "Epoch 229/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3819 - accuracy: 0.9199 - val_loss: 0.5329 - val_accuracy: 0.8540\n",
      "Epoch 230/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 47us/sample - loss: 0.4273 - accuracy: 0.9223 - val_loss: 0.5427 - val_accuracy: 0.8540\n",
      "Epoch 231/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3936 - accuracy: 0.9223 - val_loss: 0.5364 - val_accuracy: 0.8613\n",
      "Epoch 232/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3821 - accuracy: 0.9442 - val_loss: 0.5388 - val_accuracy: 0.8686\n",
      "Epoch 233/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3716 - accuracy: 0.9369 - val_loss: 0.5277 - val_accuracy: 0.8540\n",
      "Epoch 234/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3890 - accuracy: 0.9248 - val_loss: 0.5287 - val_accuracy: 0.8686\n",
      "Epoch 235/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3872 - accuracy: 0.9126 - val_loss: 0.5305 - val_accuracy: 0.8686\n",
      "Epoch 236/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.4140 - accuracy: 0.9053 - val_loss: 0.5291 - val_accuracy: 0.8613\n",
      "Epoch 237/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3668 - accuracy: 0.9320 - val_loss: 0.5335 - val_accuracy: 0.8613\n",
      "Epoch 238/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3958 - accuracy: 0.9248 - val_loss: 0.5325 - val_accuracy: 0.8613\n",
      "Epoch 239/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.3893 - accuracy: 0.9175 - val_loss: 0.5278 - val_accuracy: 0.8613\n",
      "Epoch 240/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3872 - accuracy: 0.9320 - val_loss: 0.5391 - val_accuracy: 0.8686\n",
      "Epoch 241/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3733 - accuracy: 0.9417 - val_loss: 0.5410 - val_accuracy: 0.8540\n",
      "Epoch 242/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3667 - accuracy: 0.9393 - val_loss: 0.5346 - val_accuracy: 0.8613\n",
      "Epoch 243/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3681 - accuracy: 0.9345 - val_loss: 0.5380 - val_accuracy: 0.8540\n",
      "Epoch 244/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3880 - accuracy: 0.9223 - val_loss: 0.5282 - val_accuracy: 0.8613\n",
      "Epoch 245/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 0.4015 - accuracy: 0.9053 - val_loss: 0.5274 - val_accuracy: 0.8540\n",
      "Epoch 246/2000\n",
      "412/412 [==============================] - 0s 44us/sample - loss: 0.3701 - accuracy: 0.9296 - val_loss: 0.5263 - val_accuracy: 0.8540\n",
      "Epoch 247/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3513 - accuracy: 0.9466 - val_loss: 0.5276 - val_accuracy: 0.8613\n",
      "Epoch 248/2000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 0.3524 - accuracy: 0.9296 - val_loss: 0.5348 - val_accuracy: 0.8759\n",
      "Epoch 249/2000\n",
      "412/412 [==============================] - 0s 58us/sample - loss: 0.3687 - accuracy: 0.9223 - val_loss: 0.5314 - val_accuracy: 0.8613\n",
      "Epoch 250/2000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 0.3412 - accuracy: 0.9539 - val_loss: 0.5251 - val_accuracy: 0.8613\n",
      "Epoch 251/2000\n",
      "412/412 [==============================] - 0s 58us/sample - loss: 0.3923 - accuracy: 0.9199 - val_loss: 0.5259 - val_accuracy: 0.8613\n",
      "Epoch 252/2000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 0.3634 - accuracy: 0.9417 - val_loss: 0.5312 - val_accuracy: 0.8540\n",
      "Epoch 253/2000\n",
      "412/412 [==============================] - 0s 57us/sample - loss: 0.3744 - accuracy: 0.9126 - val_loss: 0.5318 - val_accuracy: 0.8613\n",
      "Epoch 254/2000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 0.3848 - accuracy: 0.9175 - val_loss: 0.5268 - val_accuracy: 0.8540\n",
      "Epoch 255/2000\n",
      "412/412 [==============================] - 0s 58us/sample - loss: 0.3539 - accuracy: 0.9417 - val_loss: 0.5211 - val_accuracy: 0.8540\n",
      "Epoch 256/2000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 0.3693 - accuracy: 0.9320 - val_loss: 0.5251 - val_accuracy: 0.8613\n",
      "Epoch 257/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3503 - accuracy: 0.9248 - val_loss: 0.5233 - val_accuracy: 0.8540\n",
      "Epoch 258/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3558 - accuracy: 0.9126 - val_loss: 0.5269 - val_accuracy: 0.8613\n",
      "Epoch 259/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3654 - accuracy: 0.9272 - val_loss: 0.5197 - val_accuracy: 0.8686\n",
      "Epoch 260/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3505 - accuracy: 0.9393 - val_loss: 0.5198 - val_accuracy: 0.8686\n",
      "Epoch 261/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.3732 - accuracy: 0.9199 - val_loss: 0.5220 - val_accuracy: 0.8686\n",
      "Epoch 262/2000\n",
      "412/412 [==============================] - 0s 50us/sample - loss: 0.3470 - accuracy: 0.9272 - val_loss: 0.5319 - val_accuracy: 0.8467\n",
      "Epoch 263/2000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 0.3616 - accuracy: 0.9369 - val_loss: 0.5199 - val_accuracy: 0.8686\n",
      "Epoch 264/2000\n",
      "412/412 [==============================] - 0s 65us/sample - loss: 0.3416 - accuracy: 0.9442 - val_loss: 0.5245 - val_accuracy: 0.8540\n",
      "Epoch 265/2000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 0.3595 - accuracy: 0.9248 - val_loss: 0.5212 - val_accuracy: 0.8613\n",
      "Epoch 266/2000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 0.3617 - accuracy: 0.9296 - val_loss: 0.5150 - val_accuracy: 0.8832\n",
      "Epoch 267/2000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 0.3639 - accuracy: 0.9296 - val_loss: 0.5206 - val_accuracy: 0.8759\n",
      "Epoch 268/2000\n",
      "412/412 [==============================] - 0s 62us/sample - loss: 0.3210 - accuracy: 0.9539 - val_loss: 0.5137 - val_accuracy: 0.8686\n",
      "Epoch 269/2000\n",
      "412/412 [==============================] - 0s 59us/sample - loss: 0.3153 - accuracy: 0.9612 - val_loss: 0.5211 - val_accuracy: 0.8613\n",
      "Epoch 270/2000\n",
      "412/412 [==============================] - 0s 62us/sample - loss: 0.3230 - accuracy: 0.9393 - val_loss: 0.5047 - val_accuracy: 0.8759\n",
      "Epoch 271/2000\n",
      "412/412 [==============================] - 0s 60us/sample - loss: 0.3525 - accuracy: 0.9345 - val_loss: 0.5161 - val_accuracy: 0.8613\n",
      "Epoch 272/2000\n",
      "412/412 [==============================] - 0s 61us/sample - loss: 0.3374 - accuracy: 0.9320 - val_loss: 0.5153 - val_accuracy: 0.8613\n",
      "Epoch 273/2000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 0.3501 - accuracy: 0.9369 - val_loss: 0.5174 - val_accuracy: 0.8613\n",
      "Epoch 274/2000\n",
      "412/412 [==============================] - 0s 59us/sample - loss: 0.3734 - accuracy: 0.9272 - val_loss: 0.5225 - val_accuracy: 0.8613\n",
      "Epoch 275/2000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 0.3306 - accuracy: 0.9490 - val_loss: 0.5202 - val_accuracy: 0.8540\n",
      "Epoch 276/2000\n",
      "412/412 [==============================] - 0s 59us/sample - loss: 0.3355 - accuracy: 0.9417 - val_loss: 0.5112 - val_accuracy: 0.8540\n",
      "Epoch 277/2000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 0.3515 - accuracy: 0.9272 - val_loss: 0.5217 - val_accuracy: 0.8613\n",
      "Epoch 278/2000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 0.3343 - accuracy: 0.9345 - val_loss: 0.5183 - val_accuracy: 0.8686\n",
      "Epoch 279/2000\n",
      "412/412 [==============================] - 0s 65us/sample - loss: 0.3352 - accuracy: 0.9417 - val_loss: 0.5080 - val_accuracy: 0.8686\n",
      "Epoch 280/2000\n",
      "412/412 [==============================] - 0s 54us/sample - loss: 0.3378 - accuracy: 0.9296 - val_loss: 0.5115 - val_accuracy: 0.8759\n",
      "Epoch 281/2000\n",
      "412/412 [==============================] - 0s 49us/sample - loss: 0.3142 - accuracy: 0.9490 - val_loss: 0.5178 - val_accuracy: 0.8686\n",
      "Epoch 282/2000\n",
      "412/412 [==============================] - 0s 57us/sample - loss: 0.3265 - accuracy: 0.9466 - val_loss: 0.5150 - val_accuracy: 0.8467\n",
      "Epoch 283/2000\n",
      "412/412 [==============================] - 0s 60us/sample - loss: 0.3585 - accuracy: 0.9369 - val_loss: 0.5207 - val_accuracy: 0.8540\n",
      "Epoch 284/2000\n",
      "412/412 [==============================] - 0s 61us/sample - loss: 0.3293 - accuracy: 0.9369 - val_loss: 0.5126 - val_accuracy: 0.8540\n",
      "Epoch 285/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 65us/sample - loss: 0.3037 - accuracy: 0.9612 - val_loss: 0.5354 - val_accuracy: 0.8467\n",
      "Epoch 286/2000\n",
      "412/412 [==============================] - 0s 60us/sample - loss: 0.3569 - accuracy: 0.9223 - val_loss: 0.5168 - val_accuracy: 0.8540\n",
      "Epoch 287/2000\n",
      "412/412 [==============================] - 0s 65us/sample - loss: 0.3075 - accuracy: 0.9733 - val_loss: 0.5202 - val_accuracy: 0.8613\n",
      "Epoch 288/2000\n",
      "412/412 [==============================] - 0s 59us/sample - loss: 0.3249 - accuracy: 0.9369 - val_loss: 0.4994 - val_accuracy: 0.8759\n",
      "Epoch 289/2000\n",
      "412/412 [==============================] - 0s 66us/sample - loss: 0.3185 - accuracy: 0.9587 - val_loss: 0.5054 - val_accuracy: 0.8686\n",
      "Epoch 290/2000\n",
      "412/412 [==============================] - 0s 60us/sample - loss: 0.3539 - accuracy: 0.9223 - val_loss: 0.5126 - val_accuracy: 0.8613\n",
      "Epoch 291/2000\n",
      "412/412 [==============================] - 0s 60us/sample - loss: 0.3274 - accuracy: 0.9369 - val_loss: 0.5130 - val_accuracy: 0.8613\n",
      "Epoch 292/2000\n",
      "412/412 [==============================] - 0s 59us/sample - loss: 0.3109 - accuracy: 0.9466 - val_loss: 0.5072 - val_accuracy: 0.8540\n",
      "Epoch 293/2000\n",
      "412/412 [==============================] - 0s 58us/sample - loss: 0.3346 - accuracy: 0.9515 - val_loss: 0.5039 - val_accuracy: 0.8686\n",
      "Epoch 294/2000\n",
      "412/412 [==============================] - 0s 49us/sample - loss: 0.3314 - accuracy: 0.9248 - val_loss: 0.5033 - val_accuracy: 0.8832\n",
      "Epoch 295/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.3130 - accuracy: 0.9466 - val_loss: 0.5036 - val_accuracy: 0.8759\n",
      "Epoch 296/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.2963 - accuracy: 0.9612 - val_loss: 0.5058 - val_accuracy: 0.8686\n",
      "Epoch 297/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3041 - accuracy: 0.9587 - val_loss: 0.5059 - val_accuracy: 0.8759\n",
      "Epoch 298/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.3067 - accuracy: 0.9490 - val_loss: 0.5132 - val_accuracy: 0.8613\n",
      "Epoch 299/2000\n",
      "412/412 [==============================] - 0s 70us/sample - loss: 0.3359 - accuracy: 0.9296 - val_loss: 0.5211 - val_accuracy: 0.8540\n",
      "Epoch 300/2000\n",
      "412/412 [==============================] - 0s 60us/sample - loss: 0.3159 - accuracy: 0.9636 - val_loss: 0.5231 - val_accuracy: 0.8540\n",
      "Epoch 301/2000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 0.3112 - accuracy: 0.9466 - val_loss: 0.5077 - val_accuracy: 0.8613\n",
      "Epoch 302/2000\n",
      "412/412 [==============================] - 0s 58us/sample - loss: 0.2891 - accuracy: 0.9515 - val_loss: 0.5066 - val_accuracy: 0.8686\n",
      "Epoch 303/2000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 0.2982 - accuracy: 0.9515 - val_loss: 0.5007 - val_accuracy: 0.8686\n",
      "Epoch 304/2000\n",
      "412/412 [==============================] - 0s 57us/sample - loss: 0.3500 - accuracy: 0.9417 - val_loss: 0.4977 - val_accuracy: 0.8613\n",
      "Epoch 305/2000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 0.3219 - accuracy: 0.9466 - val_loss: 0.5079 - val_accuracy: 0.8613\n",
      "Epoch 306/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.3089 - accuracy: 0.9393 - val_loss: 0.5008 - val_accuracy: 0.8613\n",
      "Epoch 307/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3119 - accuracy: 0.9345 - val_loss: 0.5071 - val_accuracy: 0.8686\n",
      "Epoch 308/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3018 - accuracy: 0.9466 - val_loss: 0.4933 - val_accuracy: 0.8686\n",
      "Epoch 309/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3094 - accuracy: 0.9490 - val_loss: 0.5014 - val_accuracy: 0.8759\n",
      "Epoch 310/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3080 - accuracy: 0.9490 - val_loss: 0.5109 - val_accuracy: 0.8686\n",
      "Epoch 311/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3003 - accuracy: 0.9563 - val_loss: 0.5093 - val_accuracy: 0.8613\n",
      "Epoch 312/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3090 - accuracy: 0.9466 - val_loss: 0.4905 - val_accuracy: 0.8759\n",
      "Epoch 313/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3083 - accuracy: 0.9563 - val_loss: 0.5090 - val_accuracy: 0.8686\n",
      "Epoch 314/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.2724 - accuracy: 0.9612 - val_loss: 0.5064 - val_accuracy: 0.8686\n",
      "Epoch 315/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3144 - accuracy: 0.9442 - val_loss: 0.5144 - val_accuracy: 0.8540\n",
      "Epoch 316/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3083 - accuracy: 0.9563 - val_loss: 0.5139 - val_accuracy: 0.8467\n",
      "Epoch 317/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.2778 - accuracy: 0.9587 - val_loss: 0.5006 - val_accuracy: 0.8759\n",
      "Epoch 318/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3143 - accuracy: 0.9442 - val_loss: 0.5009 - val_accuracy: 0.8540\n",
      "Epoch 319/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.2907 - accuracy: 0.9587 - val_loss: 0.5107 - val_accuracy: 0.8613\n",
      "Epoch 320/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.2931 - accuracy: 0.9636 - val_loss: 0.5050 - val_accuracy: 0.8686\n",
      "Epoch 321/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.2860 - accuracy: 0.9587 - val_loss: 0.4934 - val_accuracy: 0.8686\n",
      "Epoch 322/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3343 - accuracy: 0.9272 - val_loss: 0.4971 - val_accuracy: 0.8613\n",
      "Epoch 323/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3023 - accuracy: 0.9539 - val_loss: 0.4998 - val_accuracy: 0.8686\n",
      "Epoch 324/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.2730 - accuracy: 0.9539 - val_loss: 0.4983 - val_accuracy: 0.8540\n",
      "Epoch 325/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3085 - accuracy: 0.9515 - val_loss: 0.4960 - val_accuracy: 0.8686\n",
      "Epoch 326/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3023 - accuracy: 0.9539 - val_loss: 0.4946 - val_accuracy: 0.8540\n",
      "Epoch 327/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.2851 - accuracy: 0.9417 - val_loss: 0.5074 - val_accuracy: 0.8613\n",
      "Epoch 328/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.2778 - accuracy: 0.9636 - val_loss: 0.4910 - val_accuracy: 0.8613\n",
      "Epoch 329/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.3184 - accuracy: 0.9345 - val_loss: 0.5072 - val_accuracy: 0.8540\n",
      "Epoch 330/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.2688 - accuracy: 0.9660 - val_loss: 0.5079 - val_accuracy: 0.8540\n",
      "Epoch 331/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.2738 - accuracy: 0.9563 - val_loss: 0.4966 - val_accuracy: 0.8759\n",
      "Epoch 332/2000\n",
      "412/412 [==============================] - 0s 49us/sample - loss: 0.2614 - accuracy: 0.9612 - val_loss: 0.5051 - val_accuracy: 0.8686\n",
      "Epoch 333/2000\n",
      "412/412 [==============================] - 0s 50us/sample - loss: 0.2752 - accuracy: 0.9539 - val_loss: 0.5028 - val_accuracy: 0.8686\n",
      "Epoch 334/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.2840 - accuracy: 0.9539 - val_loss: 0.5147 - val_accuracy: 0.8540\n",
      "Epoch 335/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.2887 - accuracy: 0.9490 - val_loss: 0.5084 - val_accuracy: 0.8540\n",
      "Epoch 336/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.2769 - accuracy: 0.9612 - val_loss: 0.5013 - val_accuracy: 0.8613\n",
      "Epoch 337/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.2797 - accuracy: 0.9587 - val_loss: 0.4971 - val_accuracy: 0.8613\n",
      "Epoch 338/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3019 - accuracy: 0.9442 - val_loss: 0.5050 - val_accuracy: 0.8686\n",
      "Epoch 339/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.2794 - accuracy: 0.9587 - val_loss: 0.4992 - val_accuracy: 0.8613\n",
      "Epoch 340/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 46us/sample - loss: 0.2865 - accuracy: 0.9442 - val_loss: 0.5043 - val_accuracy: 0.8540\n",
      "Epoch 341/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.3022 - accuracy: 0.9320 - val_loss: 0.5188 - val_accuracy: 0.8613\n",
      "Epoch 342/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.2884 - accuracy: 0.9563 - val_loss: 0.5070 - val_accuracy: 0.8613\n",
      "Epoch 343/2000\n",
      "412/412 [==============================] - 0s 49us/sample - loss: 0.2766 - accuracy: 0.9684 - val_loss: 0.5087 - val_accuracy: 0.8613\n",
      "Epoch 344/2000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 0.2852 - accuracy: 0.9490 - val_loss: 0.5025 - val_accuracy: 0.8613\n",
      "Epoch 345/2000\n",
      "412/412 [==============================] - 0s 57us/sample - loss: 0.2810 - accuracy: 0.9660 - val_loss: 0.5058 - val_accuracy: 0.8686\n",
      "Epoch 346/2000\n",
      "412/412 [==============================] - 0s 66us/sample - loss: 0.3015 - accuracy: 0.9490 - val_loss: 0.4970 - val_accuracy: 0.8613\n",
      "Epoch 347/2000\n",
      "412/412 [==============================] - 0s 67us/sample - loss: 0.2880 - accuracy: 0.9539 - val_loss: 0.5135 - val_accuracy: 0.8540\n",
      "Epoch 348/2000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 0.2991 - accuracy: 0.9417 - val_loss: 0.4985 - val_accuracy: 0.8759\n",
      "Epoch 349/2000\n",
      "412/412 [==============================] - 0s 66us/sample - loss: 0.2837 - accuracy: 0.9490 - val_loss: 0.5053 - val_accuracy: 0.8540\n",
      "Epoch 350/2000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 0.2679 - accuracy: 0.9442 - val_loss: 0.5238 - val_accuracy: 0.8467\n",
      "Epoch 351/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.2845 - accuracy: 0.9539 - val_loss: 0.5178 - val_accuracy: 0.8686\n",
      "Epoch 352/2000\n",
      "412/412 [==============================] - 0s 48us/sample - loss: 0.2628 - accuracy: 0.9587 - val_loss: 0.5050 - val_accuracy: 0.8686\n",
      "Epoch 353/2000\n",
      "412/412 [==============================] - 0s 45us/sample - loss: 0.2795 - accuracy: 0.9563 - val_loss: 0.5011 - val_accuracy: 0.8613\n",
      "Epoch 354/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.2714 - accuracy: 0.9539 - val_loss: 0.5069 - val_accuracy: 0.8613\n",
      "Epoch 355/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.2697 - accuracy: 0.9515 - val_loss: 0.5105 - val_accuracy: 0.8613\n",
      "Epoch 356/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.2757 - accuracy: 0.9515 - val_loss: 0.5155 - val_accuracy: 0.8686\n",
      "Epoch 357/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.2824 - accuracy: 0.9490 - val_loss: 0.5220 - val_accuracy: 0.8613\n",
      "Epoch 358/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.2713 - accuracy: 0.9612 - val_loss: 0.5131 - val_accuracy: 0.8540\n",
      "Epoch 359/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.2694 - accuracy: 0.9636 - val_loss: 0.4994 - val_accuracy: 0.8686\n",
      "Epoch 360/2000\n",
      "412/412 [==============================] - 0s 47us/sample - loss: 0.2718 - accuracy: 0.9490 - val_loss: 0.5110 - val_accuracy: 0.8613\n",
      "Epoch 361/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.2863 - accuracy: 0.9515 - val_loss: 0.5052 - val_accuracy: 0.8686\n",
      "Epoch 362/2000\n",
      "412/412 [==============================] - 0s 46us/sample - loss: 0.2710 - accuracy: 0.9515 - val_loss: 0.5122 - val_accuracy: 0.8613\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 2,062\n",
      "Trainable params: 2,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 515 samples, validate on 172 samples\n",
      "Epoch 1/2000\n",
      "515/515 [==============================] - 0s 842us/sample - loss: 2.6824 - accuracy: 0.0816 - val_loss: 2.6243 - val_accuracy: 0.1337\n",
      "Epoch 2/2000\n",
      "515/515 [==============================] - 0s 46us/sample - loss: 2.6095 - accuracy: 0.1223 - val_loss: 2.5891 - val_accuracy: 0.1453\n",
      "Epoch 3/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 2.5929 - accuracy: 0.1126 - val_loss: 2.5552 - val_accuracy: 0.1977\n",
      "Epoch 4/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 2.5528 - accuracy: 0.1650 - val_loss: 2.5239 - val_accuracy: 0.1919\n",
      "Epoch 5/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 2.5156 - accuracy: 0.1786 - val_loss: 2.4915 - val_accuracy: 0.2326\n",
      "Epoch 6/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 2.4937 - accuracy: 0.1650 - val_loss: 2.4635 - val_accuracy: 0.2500\n",
      "Epoch 7/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 2.4529 - accuracy: 0.2078 - val_loss: 2.4280 - val_accuracy: 0.2907\n",
      "Epoch 8/2000\n",
      "515/515 [==============================] - 0s 42us/sample - loss: 2.4309 - accuracy: 0.1981 - val_loss: 2.3965 - val_accuracy: 0.3256\n",
      "Epoch 9/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 2.3855 - accuracy: 0.2485 - val_loss: 2.3616 - val_accuracy: 0.3372\n",
      "Epoch 10/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 2.3719 - accuracy: 0.2388 - val_loss: 2.3295 - val_accuracy: 0.3953\n",
      "Epoch 11/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 2.3224 - accuracy: 0.3029 - val_loss: 2.2892 - val_accuracy: 0.4128\n",
      "Epoch 12/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 2.2864 - accuracy: 0.2913 - val_loss: 2.2530 - val_accuracy: 0.4012\n",
      "Epoch 13/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 2.2480 - accuracy: 0.3049 - val_loss: 2.2144 - val_accuracy: 0.4186\n",
      "Epoch 14/2000\n",
      "515/515 [==============================] - 0s 45us/sample - loss: 2.1968 - accuracy: 0.2990 - val_loss: 2.1777 - val_accuracy: 0.4244\n",
      "Epoch 15/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 2.1810 - accuracy: 0.3320 - val_loss: 2.1392 - val_accuracy: 0.4826\n",
      "Epoch 16/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 2.1514 - accuracy: 0.3243 - val_loss: 2.1080 - val_accuracy: 0.5174\n",
      "Epoch 17/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 2.1026 - accuracy: 0.3534 - val_loss: 2.0727 - val_accuracy: 0.4826\n",
      "Epoch 18/2000\n",
      "515/515 [==============================] - 0s 45us/sample - loss: 2.0893 - accuracy: 0.3864 - val_loss: 2.0426 - val_accuracy: 0.4826\n",
      "Epoch 19/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 2.0402 - accuracy: 0.4058 - val_loss: 2.0097 - val_accuracy: 0.5174\n",
      "Epoch 20/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 2.0079 - accuracy: 0.4000 - val_loss: 1.9778 - val_accuracy: 0.5233\n",
      "Epoch 21/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.9983 - accuracy: 0.3689 - val_loss: 1.9407 - val_accuracy: 0.5233\n",
      "Epoch 22/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.9736 - accuracy: 0.4078 - val_loss: 1.9114 - val_accuracy: 0.5523\n",
      "Epoch 23/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.9281 - accuracy: 0.4194 - val_loss: 1.8818 - val_accuracy: 0.5698\n",
      "Epoch 24/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.9326 - accuracy: 0.3825 - val_loss: 1.8534 - val_accuracy: 0.5349\n",
      "Epoch 25/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.8793 - accuracy: 0.4330 - val_loss: 1.8218 - val_accuracy: 0.5756\n",
      "Epoch 26/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.8588 - accuracy: 0.4427 - val_loss: 1.7953 - val_accuracy: 0.5872\n",
      "Epoch 27/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.8552 - accuracy: 0.4000 - val_loss: 1.7694 - val_accuracy: 0.6279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.7819 - accuracy: 0.4544 - val_loss: 1.7461 - val_accuracy: 0.6105\n",
      "Epoch 29/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.7849 - accuracy: 0.4272 - val_loss: 1.7164 - val_accuracy: 0.6453\n",
      "Epoch 30/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.7496 - accuracy: 0.4660 - val_loss: 1.6944 - val_accuracy: 0.6279\n",
      "Epoch 31/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.7356 - accuracy: 0.4718 - val_loss: 1.6675 - val_accuracy: 0.6453\n",
      "Epoch 32/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.6862 - accuracy: 0.5204 - val_loss: 1.6426 - val_accuracy: 0.6279\n",
      "Epoch 33/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.6670 - accuracy: 0.4757 - val_loss: 1.6221 - val_accuracy: 0.6628\n",
      "Epoch 34/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.6817 - accuracy: 0.4816 - val_loss: 1.5961 - val_accuracy: 0.7267\n",
      "Epoch 35/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.6488 - accuracy: 0.4932 - val_loss: 1.5736 - val_accuracy: 0.7384\n",
      "Epoch 36/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.6024 - accuracy: 0.5320 - val_loss: 1.5522 - val_accuracy: 0.7500\n",
      "Epoch 37/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.6076 - accuracy: 0.5126 - val_loss: 1.5351 - val_accuracy: 0.7500\n",
      "Epoch 38/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.5603 - accuracy: 0.5495 - val_loss: 1.5115 - val_accuracy: 0.7674\n",
      "Epoch 39/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.5639 - accuracy: 0.5301 - val_loss: 1.4914 - val_accuracy: 0.7849\n",
      "Epoch 40/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.5472 - accuracy: 0.5476 - val_loss: 1.4699 - val_accuracy: 0.7965\n",
      "Epoch 41/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.5377 - accuracy: 0.5650 - val_loss: 1.4533 - val_accuracy: 0.7442\n",
      "Epoch 42/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.4991 - accuracy: 0.5650 - val_loss: 1.4368 - val_accuracy: 0.7907\n",
      "Epoch 43/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.4898 - accuracy: 0.5495 - val_loss: 1.4164 - val_accuracy: 0.7791\n",
      "Epoch 44/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.4591 - accuracy: 0.5631 - val_loss: 1.3937 - val_accuracy: 0.8081\n",
      "Epoch 45/2000\n",
      "515/515 [==============================] - 0s 42us/sample - loss: 1.4636 - accuracy: 0.5534 - val_loss: 1.3745 - val_accuracy: 0.7849\n",
      "Epoch 46/2000\n",
      "515/515 [==============================] - 0s 45us/sample - loss: 1.4302 - accuracy: 0.5942 - val_loss: 1.3677 - val_accuracy: 0.7616\n",
      "Epoch 47/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.4304 - accuracy: 0.5689 - val_loss: 1.3427 - val_accuracy: 0.7965\n",
      "Epoch 48/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.4242 - accuracy: 0.6000 - val_loss: 1.3333 - val_accuracy: 0.8663\n",
      "Epoch 49/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.3863 - accuracy: 0.6039 - val_loss: 1.3166 - val_accuracy: 0.8605\n",
      "Epoch 50/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.3651 - accuracy: 0.6427 - val_loss: 1.2957 - val_accuracy: 0.8081\n",
      "Epoch 51/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.3423 - accuracy: 0.6000 - val_loss: 1.2791 - val_accuracy: 0.8081\n",
      "Epoch 52/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.3715 - accuracy: 0.6039 - val_loss: 1.2620 - val_accuracy: 0.8605\n",
      "Epoch 53/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.3061 - accuracy: 0.6777 - val_loss: 1.2507 - val_accuracy: 0.8663\n",
      "Epoch 54/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.3192 - accuracy: 0.6233 - val_loss: 1.2312 - val_accuracy: 0.8372\n",
      "Epoch 55/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.2863 - accuracy: 0.6524 - val_loss: 1.2142 - val_accuracy: 0.8140\n",
      "Epoch 56/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.2978 - accuracy: 0.6117 - val_loss: 1.1980 - val_accuracy: 0.8895\n",
      "Epoch 57/2000\n",
      "515/515 [==============================] - 0s 45us/sample - loss: 1.2632 - accuracy: 0.6621 - val_loss: 1.1795 - val_accuracy: 0.8837\n",
      "Epoch 58/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.2309 - accuracy: 0.6641 - val_loss: 1.1627 - val_accuracy: 0.8721\n",
      "Epoch 59/2000\n",
      "515/515 [==============================] - 0s 45us/sample - loss: 1.2165 - accuracy: 0.6738 - val_loss: 1.1501 - val_accuracy: 0.8605\n",
      "Epoch 60/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.2006 - accuracy: 0.6602 - val_loss: 1.1380 - val_accuracy: 0.8372\n",
      "Epoch 61/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.2132 - accuracy: 0.6505 - val_loss: 1.1221 - val_accuracy: 0.8605\n",
      "Epoch 62/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.1716 - accuracy: 0.7029 - val_loss: 1.1070 - val_accuracy: 0.8953\n",
      "Epoch 63/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.1780 - accuracy: 0.7029 - val_loss: 1.0941 - val_accuracy: 0.8837\n",
      "Epoch 64/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.1509 - accuracy: 0.7126 - val_loss: 1.0795 - val_accuracy: 0.8547\n",
      "Epoch 65/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.1661 - accuracy: 0.6796 - val_loss: 1.0661 - val_accuracy: 0.8895\n",
      "Epoch 66/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.1536 - accuracy: 0.6757 - val_loss: 1.0583 - val_accuracy: 0.9012\n",
      "Epoch 67/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.1508 - accuracy: 0.6777 - val_loss: 1.0477 - val_accuracy: 0.8895\n",
      "Epoch 68/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.1247 - accuracy: 0.6699 - val_loss: 1.0347 - val_accuracy: 0.8779\n",
      "Epoch 69/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.0951 - accuracy: 0.7010 - val_loss: 1.0210 - val_accuracy: 0.8488\n",
      "Epoch 70/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.0982 - accuracy: 0.7010 - val_loss: 1.0138 - val_accuracy: 0.8430\n",
      "Epoch 71/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.0679 - accuracy: 0.7010 - val_loss: 1.0025 - val_accuracy: 0.8779\n",
      "Epoch 72/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.0774 - accuracy: 0.7107 - val_loss: 0.9928 - val_accuracy: 0.8488\n",
      "Epoch 73/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.0178 - accuracy: 0.7612 - val_loss: 0.9769 - val_accuracy: 0.8953\n",
      "Epoch 74/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.0378 - accuracy: 0.7184 - val_loss: 0.9635 - val_accuracy: 0.8895\n",
      "Epoch 75/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 1.0238 - accuracy: 0.7340 - val_loss: 0.9570 - val_accuracy: 0.8837\n",
      "Epoch 76/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.0296 - accuracy: 0.7223 - val_loss: 0.9455 - val_accuracy: 0.8895\n",
      "Epoch 77/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 0.9726 - accuracy: 0.7476 - val_loss: 0.9363 - val_accuracy: 0.8779\n",
      "Epoch 78/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 1.0296 - accuracy: 0.7184 - val_loss: 0.9268 - val_accuracy: 0.8953\n",
      "Epoch 79/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 0.9815 - accuracy: 0.7340 - val_loss: 0.9160 - val_accuracy: 0.9012\n",
      "Epoch 80/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 0.9829 - accuracy: 0.7340 - val_loss: 0.9106 - val_accuracy: 0.8779\n",
      "Epoch 81/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 0.9740 - accuracy: 0.7495 - val_loss: 0.8920 - val_accuracy: 0.8721\n",
      "Epoch 82/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 0.9674 - accuracy: 0.7689 - val_loss: 0.8880 - val_accuracy: 0.8721\n",
      "Epoch 83/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - 0s 42us/sample - loss: 0.9330 - accuracy: 0.7650 - val_loss: 0.8703 - val_accuracy: 0.8779\n",
      "Epoch 84/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 0.9420 - accuracy: 0.7709 - val_loss: 0.8675 - val_accuracy: 0.8779\n",
      "Epoch 85/2000\n",
      "515/515 [==============================] - 0s 46us/sample - loss: 0.9525 - accuracy: 0.7592 - val_loss: 0.8614 - val_accuracy: 0.8953\n",
      "Epoch 86/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 0.9331 - accuracy: 0.7592 - val_loss: 0.8545 - val_accuracy: 0.9012\n",
      "Epoch 87/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 0.9354 - accuracy: 0.7670 - val_loss: 0.8424 - val_accuracy: 0.8895\n",
      "Epoch 88/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 0.8897 - accuracy: 0.7573 - val_loss: 0.8407 - val_accuracy: 0.9070\n",
      "Epoch 89/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 0.9017 - accuracy: 0.7689 - val_loss: 0.8236 - val_accuracy: 0.8953\n",
      "Epoch 90/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 0.8836 - accuracy: 0.7864 - val_loss: 0.8195 - val_accuracy: 0.8837\n",
      "Epoch 91/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 0.8865 - accuracy: 0.7573 - val_loss: 0.8093 - val_accuracy: 0.9012\n",
      "Epoch 92/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 0.8880 - accuracy: 0.8019 - val_loss: 0.8071 - val_accuracy: 0.9070\n",
      "Epoch 93/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 0.8571 - accuracy: 0.8019 - val_loss: 0.7978 - val_accuracy: 0.8953\n",
      "Epoch 94/2000\n",
      "515/515 [==============================] - 0s 46us/sample - loss: 0.8517 - accuracy: 0.8058 - val_loss: 0.7911 - val_accuracy: 0.8953\n",
      "Epoch 95/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 0.8518 - accuracy: 0.7728 - val_loss: 0.7869 - val_accuracy: 0.9012\n",
      "Epoch 96/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 0.8603 - accuracy: 0.7728 - val_loss: 0.7762 - val_accuracy: 0.9070\n",
      "Epoch 97/2000\n",
      "515/515 [==============================] - 0s 47us/sample - loss: 0.8427 - accuracy: 0.7786 - val_loss: 0.7707 - val_accuracy: 0.8895\n",
      "Epoch 98/2000\n",
      "515/515 [==============================] - 0s 45us/sample - loss: 0.8242 - accuracy: 0.8117 - val_loss: 0.7643 - val_accuracy: 0.9012\n",
      "Epoch 99/2000\n",
      "515/515 [==============================] - 0s 47us/sample - loss: 0.8400 - accuracy: 0.7942 - val_loss: 0.7577 - val_accuracy: 0.9128\n",
      "Epoch 100/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.7875 - accuracy: 0.8214 - val_loss: 0.7511 - val_accuracy: 0.8837\n",
      "Epoch 101/2000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 0.8145 - accuracy: 0.8175 - val_loss: 0.7494 - val_accuracy: 0.8953\n",
      "Epoch 102/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.8018 - accuracy: 0.8155 - val_loss: 0.7377 - val_accuracy: 0.8779\n",
      "Epoch 103/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.7992 - accuracy: 0.8155 - val_loss: 0.7289 - val_accuracy: 0.8953\n",
      "Epoch 104/2000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 0.8278 - accuracy: 0.7709 - val_loss: 0.7296 - val_accuracy: 0.8837\n",
      "Epoch 105/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.7907 - accuracy: 0.8039 - val_loss: 0.7264 - val_accuracy: 0.9128\n",
      "Epoch 106/2000\n",
      "515/515 [==============================] - 0s 54us/sample - loss: 0.7805 - accuracy: 0.8233 - val_loss: 0.7136 - val_accuracy: 0.9128\n",
      "Epoch 107/2000\n",
      "515/515 [==============================] - 0s 47us/sample - loss: 0.7999 - accuracy: 0.7806 - val_loss: 0.7115 - val_accuracy: 0.9070\n",
      "Epoch 108/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 0.7639 - accuracy: 0.7981 - val_loss: 0.7041 - val_accuracy: 0.9128\n",
      "Epoch 109/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 0.7386 - accuracy: 0.8252 - val_loss: 0.6997 - val_accuracy: 0.8953\n",
      "Epoch 110/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 0.7548 - accuracy: 0.8019 - val_loss: 0.6960 - val_accuracy: 0.8837\n",
      "Epoch 111/2000\n",
      "515/515 [==============================] - 0s 44us/sample - loss: 0.7305 - accuracy: 0.8408 - val_loss: 0.6893 - val_accuracy: 0.9012\n",
      "Epoch 112/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 0.7501 - accuracy: 0.8311 - val_loss: 0.6899 - val_accuracy: 0.8953\n",
      "Epoch 113/2000\n",
      "515/515 [==============================] - 0s 43us/sample - loss: 0.7205 - accuracy: 0.8155 - val_loss: 0.6739 - val_accuracy: 0.9128\n",
      "Epoch 114/2000\n",
      "515/515 [==============================] - 0s 49us/sample - loss: 0.7008 - accuracy: 0.8252 - val_loss: 0.6763 - val_accuracy: 0.9186\n",
      "Epoch 115/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.7252 - accuracy: 0.8136 - val_loss: 0.6710 - val_accuracy: 0.9128\n",
      "Epoch 116/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.7200 - accuracy: 0.8058 - val_loss: 0.6656 - val_accuracy: 0.8953\n",
      "Epoch 117/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.6954 - accuracy: 0.8680 - val_loss: 0.6549 - val_accuracy: 0.9012\n",
      "Epoch 118/2000\n",
      "515/515 [==============================] - 0s 55us/sample - loss: 0.7066 - accuracy: 0.8388 - val_loss: 0.6513 - val_accuracy: 0.9128\n",
      "Epoch 119/2000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 0.7193 - accuracy: 0.8175 - val_loss: 0.6521 - val_accuracy: 0.9186\n",
      "Epoch 120/2000\n",
      "515/515 [==============================] - 0s 55us/sample - loss: 0.6832 - accuracy: 0.8660 - val_loss: 0.6417 - val_accuracy: 0.9244\n",
      "Epoch 121/2000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 0.6935 - accuracy: 0.8311 - val_loss: 0.6454 - val_accuracy: 0.9128\n",
      "Epoch 122/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.7108 - accuracy: 0.8291 - val_loss: 0.6397 - val_accuracy: 0.9070\n",
      "Epoch 123/2000\n",
      "515/515 [==============================] - 0s 69us/sample - loss: 0.7032 - accuracy: 0.8175 - val_loss: 0.6339 - val_accuracy: 0.8895\n",
      "Epoch 124/2000\n",
      "515/515 [==============================] - 0s 71us/sample - loss: 0.6755 - accuracy: 0.8544 - val_loss: 0.6284 - val_accuracy: 0.8953\n",
      "Epoch 125/2000\n",
      "515/515 [==============================] - 0s 93us/sample - loss: 0.7079 - accuracy: 0.8058 - val_loss: 0.6181 - val_accuracy: 0.8953\n",
      "Epoch 126/2000\n",
      "515/515 [==============================] - 0s 71us/sample - loss: 0.7002 - accuracy: 0.8350 - val_loss: 0.6178 - val_accuracy: 0.9070\n",
      "Epoch 127/2000\n",
      "515/515 [==============================] - 0s 70us/sample - loss: 0.6744 - accuracy: 0.8291 - val_loss: 0.6165 - val_accuracy: 0.9012\n",
      "Epoch 128/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.6407 - accuracy: 0.8466 - val_loss: 0.6166 - val_accuracy: 0.9012\n",
      "Epoch 129/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.6397 - accuracy: 0.8369 - val_loss: 0.6182 - val_accuracy: 0.8895\n",
      "Epoch 130/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.6424 - accuracy: 0.8621 - val_loss: 0.6105 - val_accuracy: 0.8837\n",
      "Epoch 131/2000\n",
      "515/515 [==============================] - 0s 66us/sample - loss: 0.6757 - accuracy: 0.8350 - val_loss: 0.6057 - val_accuracy: 0.9012\n",
      "Epoch 132/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.6243 - accuracy: 0.8641 - val_loss: 0.5937 - val_accuracy: 0.9012\n",
      "Epoch 133/2000\n",
      "515/515 [==============================] - 0s 66us/sample - loss: 0.6366 - accuracy: 0.8408 - val_loss: 0.5891 - val_accuracy: 0.9186\n",
      "Epoch 134/2000\n",
      "515/515 [==============================] - 0s 66us/sample - loss: 0.6272 - accuracy: 0.8388 - val_loss: 0.5882 - val_accuracy: 0.8953\n",
      "Epoch 135/2000\n",
      "515/515 [==============================] - 0s 66us/sample - loss: 0.6377 - accuracy: 0.8311 - val_loss: 0.5857 - val_accuracy: 0.9070\n",
      "Epoch 136/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.6084 - accuracy: 0.8544 - val_loss: 0.5805 - val_accuracy: 0.9128\n",
      "Epoch 137/2000\n",
      "515/515 [==============================] - 0s 66us/sample - loss: 0.6297 - accuracy: 0.8505 - val_loss: 0.5785 - val_accuracy: 0.9012\n",
      "Epoch 138/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - 0s 53us/sample - loss: 0.6279 - accuracy: 0.8544 - val_loss: 0.5804 - val_accuracy: 0.9070\n",
      "Epoch 139/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.6346 - accuracy: 0.8330 - val_loss: 0.5732 - val_accuracy: 0.8953\n",
      "Epoch 140/2000\n",
      "515/515 [==============================] - 0s 48us/sample - loss: 0.6253 - accuracy: 0.8388 - val_loss: 0.5775 - val_accuracy: 0.8953\n",
      "Epoch 141/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.6177 - accuracy: 0.8447 - val_loss: 0.5736 - val_accuracy: 0.9186\n",
      "Epoch 142/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.6453 - accuracy: 0.8505 - val_loss: 0.5709 - val_accuracy: 0.9186\n",
      "Epoch 143/2000\n",
      "515/515 [==============================] - 0s 47us/sample - loss: 0.6072 - accuracy: 0.8563 - val_loss: 0.5655 - val_accuracy: 0.9186\n",
      "Epoch 144/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.6164 - accuracy: 0.8447 - val_loss: 0.5748 - val_accuracy: 0.9070\n",
      "Epoch 145/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.6005 - accuracy: 0.8602 - val_loss: 0.5681 - val_accuracy: 0.9070\n",
      "Epoch 146/2000\n",
      "515/515 [==============================] - 0s 47us/sample - loss: 0.6122 - accuracy: 0.8563 - val_loss: 0.5660 - val_accuracy: 0.8953\n",
      "Epoch 147/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.5793 - accuracy: 0.8699 - val_loss: 0.5606 - val_accuracy: 0.9128\n",
      "Epoch 148/2000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 0.5797 - accuracy: 0.8796 - val_loss: 0.5506 - val_accuracy: 0.9012\n",
      "Epoch 149/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.6200 - accuracy: 0.8427 - val_loss: 0.5511 - val_accuracy: 0.8953\n",
      "Epoch 150/2000\n",
      "515/515 [==============================] - 0s 55us/sample - loss: 0.6068 - accuracy: 0.8466 - val_loss: 0.5501 - val_accuracy: 0.9012\n",
      "Epoch 151/2000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 0.6091 - accuracy: 0.8408 - val_loss: 0.5560 - val_accuracy: 0.8953\n",
      "Epoch 152/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.5690 - accuracy: 0.8874 - val_loss: 0.5406 - val_accuracy: 0.9070\n",
      "Epoch 153/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.5899 - accuracy: 0.8680 - val_loss: 0.5432 - val_accuracy: 0.9012\n",
      "Epoch 154/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.5627 - accuracy: 0.8796 - val_loss: 0.5362 - val_accuracy: 0.9012\n",
      "Epoch 155/2000\n",
      "515/515 [==============================] - 0s 49us/sample - loss: 0.5787 - accuracy: 0.8738 - val_loss: 0.5386 - val_accuracy: 0.8953\n",
      "Epoch 156/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.5843 - accuracy: 0.8563 - val_loss: 0.5320 - val_accuracy: 0.8895\n",
      "Epoch 157/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.5746 - accuracy: 0.8544 - val_loss: 0.5333 - val_accuracy: 0.9012\n",
      "Epoch 158/2000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 0.5648 - accuracy: 0.8563 - val_loss: 0.5348 - val_accuracy: 0.9128\n",
      "Epoch 159/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.5354 - accuracy: 0.8738 - val_loss: 0.5241 - val_accuracy: 0.9128\n",
      "Epoch 160/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.5561 - accuracy: 0.8641 - val_loss: 0.5237 - val_accuracy: 0.9012\n",
      "Epoch 161/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.5250 - accuracy: 0.8913 - val_loss: 0.5140 - val_accuracy: 0.9128\n",
      "Epoch 162/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.5559 - accuracy: 0.8660 - val_loss: 0.5277 - val_accuracy: 0.8953\n",
      "Epoch 163/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.5482 - accuracy: 0.8738 - val_loss: 0.5178 - val_accuracy: 0.8953\n",
      "Epoch 164/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.5604 - accuracy: 0.8583 - val_loss: 0.5179 - val_accuracy: 0.9186\n",
      "Epoch 165/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.5582 - accuracy: 0.8680 - val_loss: 0.5198 - val_accuracy: 0.9012\n",
      "Epoch 166/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.5351 - accuracy: 0.8796 - val_loss: 0.5143 - val_accuracy: 0.9012\n",
      "Epoch 167/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.5530 - accuracy: 0.8621 - val_loss: 0.5145 - val_accuracy: 0.9128\n",
      "Epoch 168/2000\n",
      "515/515 [==============================] - 0s 55us/sample - loss: 0.5469 - accuracy: 0.8699 - val_loss: 0.5148 - val_accuracy: 0.8953\n",
      "Epoch 169/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.5198 - accuracy: 0.8641 - val_loss: 0.5081 - val_accuracy: 0.9012\n",
      "Epoch 170/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.5406 - accuracy: 0.8738 - val_loss: 0.5075 - val_accuracy: 0.9070\n",
      "Epoch 171/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.5170 - accuracy: 0.9029 - val_loss: 0.5058 - val_accuracy: 0.8895\n",
      "Epoch 172/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.5161 - accuracy: 0.8816 - val_loss: 0.5004 - val_accuracy: 0.8953\n",
      "Epoch 173/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.5411 - accuracy: 0.8563 - val_loss: 0.5030 - val_accuracy: 0.8953\n",
      "Epoch 174/2000\n",
      "515/515 [==============================] - 0s 54us/sample - loss: 0.5391 - accuracy: 0.8738 - val_loss: 0.5062 - val_accuracy: 0.8895\n",
      "Epoch 175/2000\n",
      "515/515 [==============================] - 0s 50us/sample - loss: 0.5098 - accuracy: 0.8777 - val_loss: 0.5063 - val_accuracy: 0.9012\n",
      "Epoch 176/2000\n",
      "515/515 [==============================] - 0s 54us/sample - loss: 0.5434 - accuracy: 0.8602 - val_loss: 0.4948 - val_accuracy: 0.9128\n",
      "Epoch 177/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.5187 - accuracy: 0.8699 - val_loss: 0.4939 - val_accuracy: 0.9012\n",
      "Epoch 178/2000\n",
      "515/515 [==============================] - 0s 50us/sample - loss: 0.4981 - accuracy: 0.8913 - val_loss: 0.4892 - val_accuracy: 0.9128\n",
      "Epoch 179/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.5253 - accuracy: 0.8738 - val_loss: 0.4888 - val_accuracy: 0.9128\n",
      "Epoch 180/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.4947 - accuracy: 0.8893 - val_loss: 0.4901 - val_accuracy: 0.8895\n",
      "Epoch 181/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.5032 - accuracy: 0.8874 - val_loss: 0.4865 - val_accuracy: 0.9070\n",
      "Epoch 182/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.5117 - accuracy: 0.8874 - val_loss: 0.4846 - val_accuracy: 0.9128\n",
      "Epoch 183/2000\n",
      "515/515 [==============================] - 0s 90us/sample - loss: 0.5261 - accuracy: 0.8835 - val_loss: 0.4828 - val_accuracy: 0.9070\n",
      "Epoch 184/2000\n",
      "515/515 [==============================] - 0s 97us/sample - loss: 0.5169 - accuracy: 0.8932 - val_loss: 0.4860 - val_accuracy: 0.9128\n",
      "Epoch 185/2000\n",
      "515/515 [==============================] - 0s 89us/sample - loss: 0.5135 - accuracy: 0.8699 - val_loss: 0.4828 - val_accuracy: 0.9128\n",
      "Epoch 186/2000\n",
      "515/515 [==============================] - 0s 73us/sample - loss: 0.4739 - accuracy: 0.9029 - val_loss: 0.4774 - val_accuracy: 0.9012\n",
      "Epoch 187/2000\n",
      "515/515 [==============================] - 0s 86us/sample - loss: 0.4968 - accuracy: 0.8913 - val_loss: 0.4832 - val_accuracy: 0.8953\n",
      "Epoch 188/2000\n",
      "515/515 [==============================] - 0s 81us/sample - loss: 0.4678 - accuracy: 0.9068 - val_loss: 0.4759 - val_accuracy: 0.9012\n",
      "Epoch 189/2000\n",
      "515/515 [==============================] - 0s 99us/sample - loss: 0.4860 - accuracy: 0.8854 - val_loss: 0.4765 - val_accuracy: 0.8895\n",
      "Epoch 190/2000\n",
      "515/515 [==============================] - 0s 67us/sample - loss: 0.4925 - accuracy: 0.8757 - val_loss: 0.4706 - val_accuracy: 0.9070\n",
      "Epoch 191/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.4690 - accuracy: 0.9146 - val_loss: 0.4705 - val_accuracy: 0.9070\n",
      "Epoch 192/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.4825 - accuracy: 0.8835 - val_loss: 0.4717 - val_accuracy: 0.9012\n",
      "Epoch 193/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - 0s 61us/sample - loss: 0.4928 - accuracy: 0.8816 - val_loss: 0.4780 - val_accuracy: 0.8953\n",
      "Epoch 194/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.4562 - accuracy: 0.9049 - val_loss: 0.4709 - val_accuracy: 0.8953\n",
      "Epoch 195/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.4859 - accuracy: 0.8913 - val_loss: 0.4685 - val_accuracy: 0.8895\n",
      "Epoch 196/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.4955 - accuracy: 0.9029 - val_loss: 0.4684 - val_accuracy: 0.9070\n",
      "Epoch 197/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.4791 - accuracy: 0.8874 - val_loss: 0.4672 - val_accuracy: 0.9070\n",
      "Epoch 198/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.4855 - accuracy: 0.8971 - val_loss: 0.4685 - val_accuracy: 0.9012\n",
      "Epoch 199/2000\n",
      "515/515 [==============================] - 0s 55us/sample - loss: 0.4771 - accuracy: 0.8893 - val_loss: 0.4667 - val_accuracy: 0.9070\n",
      "Epoch 200/2000\n",
      "515/515 [==============================] - 0s 48us/sample - loss: 0.4608 - accuracy: 0.9165 - val_loss: 0.4630 - val_accuracy: 0.9128\n",
      "Epoch 201/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.4396 - accuracy: 0.9223 - val_loss: 0.4729 - val_accuracy: 0.8953\n",
      "Epoch 202/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.4581 - accuracy: 0.9204 - val_loss: 0.4625 - val_accuracy: 0.9012\n",
      "Epoch 203/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.4830 - accuracy: 0.8777 - val_loss: 0.4625 - val_accuracy: 0.9128\n",
      "Epoch 204/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.4431 - accuracy: 0.9029 - val_loss: 0.4628 - val_accuracy: 0.9070\n",
      "Epoch 205/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.4604 - accuracy: 0.8913 - val_loss: 0.4595 - val_accuracy: 0.9012\n",
      "Epoch 206/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.4415 - accuracy: 0.8971 - val_loss: 0.4534 - val_accuracy: 0.8953\n",
      "Epoch 207/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.4605 - accuracy: 0.8971 - val_loss: 0.4526 - val_accuracy: 0.9128\n",
      "Epoch 208/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.4389 - accuracy: 0.9107 - val_loss: 0.4510 - val_accuracy: 0.9070\n",
      "Epoch 209/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.4584 - accuracy: 0.8835 - val_loss: 0.4573 - val_accuracy: 0.9012\n",
      "Epoch 210/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.4283 - accuracy: 0.9107 - val_loss: 0.4537 - val_accuracy: 0.9070\n",
      "Epoch 211/2000\n",
      "515/515 [==============================] - 0s 55us/sample - loss: 0.4427 - accuracy: 0.9087 - val_loss: 0.4532 - val_accuracy: 0.8953\n",
      "Epoch 212/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.4419 - accuracy: 0.8990 - val_loss: 0.4554 - val_accuracy: 0.9128\n",
      "Epoch 213/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.4516 - accuracy: 0.9010 - val_loss: 0.4590 - val_accuracy: 0.8895\n",
      "Epoch 214/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.4510 - accuracy: 0.8990 - val_loss: 0.4542 - val_accuracy: 0.8953\n",
      "Epoch 215/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.4591 - accuracy: 0.8796 - val_loss: 0.4534 - val_accuracy: 0.8953\n",
      "Epoch 216/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.4545 - accuracy: 0.9049 - val_loss: 0.4540 - val_accuracy: 0.8895\n",
      "Epoch 217/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.4368 - accuracy: 0.9010 - val_loss: 0.4472 - val_accuracy: 0.8953\n",
      "Epoch 218/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.4257 - accuracy: 0.9010 - val_loss: 0.4475 - val_accuracy: 0.8953\n",
      "Epoch 219/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.4348 - accuracy: 0.8971 - val_loss: 0.4479 - val_accuracy: 0.8895\n",
      "Epoch 220/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.4307 - accuracy: 0.9068 - val_loss: 0.4441 - val_accuracy: 0.8895\n",
      "Epoch 221/2000\n",
      "515/515 [==============================] - 0s 51us/sample - loss: 0.4164 - accuracy: 0.9107 - val_loss: 0.4438 - val_accuracy: 0.9012\n",
      "Epoch 222/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.4034 - accuracy: 0.9126 - val_loss: 0.4418 - val_accuracy: 0.8953\n",
      "Epoch 223/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.4191 - accuracy: 0.9165 - val_loss: 0.4451 - val_accuracy: 0.8837\n",
      "Epoch 224/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.4470 - accuracy: 0.9010 - val_loss: 0.4352 - val_accuracy: 0.9012\n",
      "Epoch 225/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.4273 - accuracy: 0.9126 - val_loss: 0.4384 - val_accuracy: 0.9070\n",
      "Epoch 226/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.4471 - accuracy: 0.9010 - val_loss: 0.4432 - val_accuracy: 0.9128\n",
      "Epoch 227/2000\n",
      "515/515 [==============================] - 0s 54us/sample - loss: 0.4086 - accuracy: 0.9243 - val_loss: 0.4401 - val_accuracy: 0.9186\n",
      "Epoch 228/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.4132 - accuracy: 0.9204 - val_loss: 0.4369 - val_accuracy: 0.9070\n",
      "Epoch 229/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.4332 - accuracy: 0.9107 - val_loss: 0.4327 - val_accuracy: 0.9070\n",
      "Epoch 230/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.4224 - accuracy: 0.9010 - val_loss: 0.4294 - val_accuracy: 0.9128\n",
      "Epoch 231/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.4237 - accuracy: 0.9087 - val_loss: 0.4358 - val_accuracy: 0.8953\n",
      "Epoch 232/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.4164 - accuracy: 0.8971 - val_loss: 0.4374 - val_accuracy: 0.8837\n",
      "Epoch 233/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.4177 - accuracy: 0.8951 - val_loss: 0.4416 - val_accuracy: 0.9070\n",
      "Epoch 234/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.3986 - accuracy: 0.9107 - val_loss: 0.4318 - val_accuracy: 0.9012\n",
      "Epoch 235/2000\n",
      "515/515 [==============================] - 0s 51us/sample - loss: 0.4178 - accuracy: 0.9126 - val_loss: 0.4313 - val_accuracy: 0.9012\n",
      "Epoch 236/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.4150 - accuracy: 0.9049 - val_loss: 0.4287 - val_accuracy: 0.9012\n",
      "Epoch 237/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.4287 - accuracy: 0.9029 - val_loss: 0.4298 - val_accuracy: 0.8953\n",
      "Epoch 238/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.4095 - accuracy: 0.9068 - val_loss: 0.4324 - val_accuracy: 0.8953\n",
      "Epoch 239/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.4044 - accuracy: 0.9049 - val_loss: 0.4284 - val_accuracy: 0.8953\n",
      "Epoch 240/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.4107 - accuracy: 0.8932 - val_loss: 0.4289 - val_accuracy: 0.8953\n",
      "Epoch 241/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.4203 - accuracy: 0.8971 - val_loss: 0.4238 - val_accuracy: 0.9070\n",
      "Epoch 242/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3991 - accuracy: 0.9126 - val_loss: 0.4268 - val_accuracy: 0.8953\n",
      "Epoch 243/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.4077 - accuracy: 0.8932 - val_loss: 0.4252 - val_accuracy: 0.8953\n",
      "Epoch 244/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.3770 - accuracy: 0.9301 - val_loss: 0.4282 - val_accuracy: 0.8895\n",
      "Epoch 245/2000\n",
      "515/515 [==============================] - 0s 69us/sample - loss: 0.3877 - accuracy: 0.9223 - val_loss: 0.4245 - val_accuracy: 0.8895\n",
      "Epoch 246/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3917 - accuracy: 0.9243 - val_loss: 0.4180 - val_accuracy: 0.9012\n",
      "Epoch 247/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.3874 - accuracy: 0.9165 - val_loss: 0.4217 - val_accuracy: 0.8895\n",
      "Epoch 248/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - 0s 59us/sample - loss: 0.3951 - accuracy: 0.9243 - val_loss: 0.4183 - val_accuracy: 0.8953\n",
      "Epoch 249/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.3786 - accuracy: 0.9282 - val_loss: 0.4209 - val_accuracy: 0.9012\n",
      "Epoch 250/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3986 - accuracy: 0.9262 - val_loss: 0.4231 - val_accuracy: 0.9012\n",
      "Epoch 251/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.3838 - accuracy: 0.9204 - val_loss: 0.4232 - val_accuracy: 0.8953\n",
      "Epoch 252/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.3950 - accuracy: 0.9165 - val_loss: 0.4195 - val_accuracy: 0.9012\n",
      "Epoch 253/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.3842 - accuracy: 0.9184 - val_loss: 0.4229 - val_accuracy: 0.8953\n",
      "Epoch 254/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.3631 - accuracy: 0.9301 - val_loss: 0.4186 - val_accuracy: 0.8895\n",
      "Epoch 255/2000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 0.3811 - accuracy: 0.9146 - val_loss: 0.4212 - val_accuracy: 0.8895\n",
      "Epoch 256/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.3984 - accuracy: 0.9107 - val_loss: 0.4094 - val_accuracy: 0.9012\n",
      "Epoch 257/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.4057 - accuracy: 0.9087 - val_loss: 0.4075 - val_accuracy: 0.9128\n",
      "Epoch 258/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3716 - accuracy: 0.9282 - val_loss: 0.4157 - val_accuracy: 0.9012\n",
      "Epoch 259/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.3798 - accuracy: 0.9204 - val_loss: 0.4121 - val_accuracy: 0.8953\n",
      "Epoch 260/2000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 0.3740 - accuracy: 0.9301 - val_loss: 0.4125 - val_accuracy: 0.9012\n",
      "Epoch 261/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3751 - accuracy: 0.9107 - val_loss: 0.4107 - val_accuracy: 0.8953\n",
      "Epoch 262/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.4198 - accuracy: 0.9087 - val_loss: 0.4132 - val_accuracy: 0.9012\n",
      "Epoch 263/2000\n",
      "515/515 [==============================] - 0s 94us/sample - loss: 0.3707 - accuracy: 0.9243 - val_loss: 0.4091 - val_accuracy: 0.8953\n",
      "Epoch 264/2000\n",
      "515/515 [==============================] - 0s 91us/sample - loss: 0.3818 - accuracy: 0.9107 - val_loss: 0.4150 - val_accuracy: 0.8895\n",
      "Epoch 265/2000\n",
      "515/515 [==============================] - 0s 90us/sample - loss: 0.4102 - accuracy: 0.9184 - val_loss: 0.4112 - val_accuracy: 0.8953\n",
      "Epoch 266/2000\n",
      "515/515 [==============================] - 0s 90us/sample - loss: 0.3956 - accuracy: 0.9165 - val_loss: 0.4097 - val_accuracy: 0.8953\n",
      "Epoch 267/2000\n",
      "515/515 [==============================] - 0s 92us/sample - loss: 0.3737 - accuracy: 0.9223 - val_loss: 0.4047 - val_accuracy: 0.9012\n",
      "Epoch 268/2000\n",
      "515/515 [==============================] - 0s 75us/sample - loss: 0.3648 - accuracy: 0.9243 - val_loss: 0.4169 - val_accuracy: 0.8895\n",
      "Epoch 269/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.3863 - accuracy: 0.9184 - val_loss: 0.4088 - val_accuracy: 0.9012\n",
      "Epoch 270/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.3867 - accuracy: 0.9165 - val_loss: 0.4097 - val_accuracy: 0.8953\n",
      "Epoch 271/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.3443 - accuracy: 0.9476 - val_loss: 0.4013 - val_accuracy: 0.9128\n",
      "Epoch 272/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.3833 - accuracy: 0.9126 - val_loss: 0.4066 - val_accuracy: 0.8953\n",
      "Epoch 273/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.3756 - accuracy: 0.9184 - val_loss: 0.4058 - val_accuracy: 0.8953\n",
      "Epoch 274/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.3708 - accuracy: 0.9262 - val_loss: 0.4035 - val_accuracy: 0.9070\n",
      "Epoch 275/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.3778 - accuracy: 0.9204 - val_loss: 0.4032 - val_accuracy: 0.9070\n",
      "Epoch 276/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3967 - accuracy: 0.9068 - val_loss: 0.4020 - val_accuracy: 0.9070\n",
      "Epoch 277/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.3683 - accuracy: 0.9165 - val_loss: 0.4045 - val_accuracy: 0.8895\n",
      "Epoch 278/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3541 - accuracy: 0.9243 - val_loss: 0.4131 - val_accuracy: 0.9070\n",
      "Epoch 279/2000\n",
      "515/515 [==============================] - 0s 47us/sample - loss: 0.3536 - accuracy: 0.9282 - val_loss: 0.4025 - val_accuracy: 0.9012\n",
      "Epoch 280/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.3542 - accuracy: 0.9282 - val_loss: 0.4038 - val_accuracy: 0.8953\n",
      "Epoch 281/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.3681 - accuracy: 0.9165 - val_loss: 0.4018 - val_accuracy: 0.9012\n",
      "Epoch 282/2000\n",
      "515/515 [==============================] - 0s 68us/sample - loss: 0.3715 - accuracy: 0.9146 - val_loss: 0.4055 - val_accuracy: 0.8953\n",
      "Epoch 283/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3612 - accuracy: 0.9146 - val_loss: 0.4060 - val_accuracy: 0.8895\n",
      "Epoch 284/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3575 - accuracy: 0.9320 - val_loss: 0.4021 - val_accuracy: 0.8953\n",
      "Epoch 285/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3487 - accuracy: 0.9320 - val_loss: 0.4039 - val_accuracy: 0.9186\n",
      "Epoch 286/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.3405 - accuracy: 0.9262 - val_loss: 0.3990 - val_accuracy: 0.8953\n",
      "Epoch 287/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.3649 - accuracy: 0.9184 - val_loss: 0.4029 - val_accuracy: 0.8953\n",
      "Epoch 288/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3793 - accuracy: 0.9262 - val_loss: 0.4066 - val_accuracy: 0.9012\n",
      "Epoch 289/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3619 - accuracy: 0.9262 - val_loss: 0.3972 - val_accuracy: 0.8953\n",
      "Epoch 290/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.3698 - accuracy: 0.9204 - val_loss: 0.3936 - val_accuracy: 0.9070\n",
      "Epoch 291/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.3510 - accuracy: 0.9184 - val_loss: 0.4013 - val_accuracy: 0.8895\n",
      "Epoch 292/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.3299 - accuracy: 0.9340 - val_loss: 0.3910 - val_accuracy: 0.8953\n",
      "Epoch 293/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.3859 - accuracy: 0.9049 - val_loss: 0.3986 - val_accuracy: 0.8837\n",
      "Epoch 294/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3427 - accuracy: 0.9243 - val_loss: 0.4032 - val_accuracy: 0.8837\n",
      "Epoch 295/2000\n",
      "515/515 [==============================] - 0s 66us/sample - loss: 0.3476 - accuracy: 0.9398 - val_loss: 0.3984 - val_accuracy: 0.8837\n",
      "Epoch 296/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.3649 - accuracy: 0.9320 - val_loss: 0.4037 - val_accuracy: 0.8953\n",
      "Epoch 297/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.3206 - accuracy: 0.9437 - val_loss: 0.3976 - val_accuracy: 0.9012\n",
      "Epoch 298/2000\n",
      "515/515 [==============================] - 0s 66us/sample - loss: 0.3468 - accuracy: 0.9320 - val_loss: 0.3979 - val_accuracy: 0.8837\n",
      "Epoch 299/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.3562 - accuracy: 0.9320 - val_loss: 0.3937 - val_accuracy: 0.8953\n",
      "Epoch 300/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.3594 - accuracy: 0.9301 - val_loss: 0.3941 - val_accuracy: 0.8895\n",
      "Epoch 301/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.3418 - accuracy: 0.9456 - val_loss: 0.3953 - val_accuracy: 0.8953\n",
      "Epoch 302/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.3334 - accuracy: 0.9398 - val_loss: 0.4003 - val_accuracy: 0.8837\n",
      "Epoch 303/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3503 - accuracy: 0.9262 - val_loss: 0.3952 - val_accuracy: 0.9012\n",
      "Epoch 304/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3519 - accuracy: 0.9223 - val_loss: 0.3984 - val_accuracy: 0.8953\n",
      "Epoch 305/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3282 - accuracy: 0.9456 - val_loss: 0.3971 - val_accuracy: 0.8895\n",
      "Epoch 306/2000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 0.3250 - accuracy: 0.9476 - val_loss: 0.3948 - val_accuracy: 0.8837\n",
      "Epoch 307/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3262 - accuracy: 0.9301 - val_loss: 0.3954 - val_accuracy: 0.8837\n",
      "Epoch 308/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3443 - accuracy: 0.9301 - val_loss: 0.3914 - val_accuracy: 0.8895\n",
      "Epoch 309/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.3489 - accuracy: 0.9359 - val_loss: 0.3967 - val_accuracy: 0.8953\n",
      "Epoch 310/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3372 - accuracy: 0.9437 - val_loss: 0.3994 - val_accuracy: 0.8837\n",
      "Epoch 311/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3332 - accuracy: 0.9359 - val_loss: 0.3908 - val_accuracy: 0.9070\n",
      "Epoch 312/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3396 - accuracy: 0.9282 - val_loss: 0.3963 - val_accuracy: 0.8837\n",
      "Epoch 313/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.3297 - accuracy: 0.9301 - val_loss: 0.3923 - val_accuracy: 0.8895\n",
      "Epoch 314/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.3225 - accuracy: 0.9476 - val_loss: 0.3957 - val_accuracy: 0.8721\n",
      "Epoch 315/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3252 - accuracy: 0.9456 - val_loss: 0.3866 - val_accuracy: 0.8895\n",
      "Epoch 316/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3732 - accuracy: 0.9165 - val_loss: 0.3871 - val_accuracy: 0.8953\n",
      "Epoch 317/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.3370 - accuracy: 0.9301 - val_loss: 0.3854 - val_accuracy: 0.9070\n",
      "Epoch 318/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3498 - accuracy: 0.9184 - val_loss: 0.3846 - val_accuracy: 0.9070\n",
      "Epoch 319/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.3283 - accuracy: 0.9379 - val_loss: 0.3885 - val_accuracy: 0.8895\n",
      "Epoch 320/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.3234 - accuracy: 0.9359 - val_loss: 0.3869 - val_accuracy: 0.9070\n",
      "Epoch 321/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3216 - accuracy: 0.9359 - val_loss: 0.3926 - val_accuracy: 0.8895\n",
      "Epoch 322/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3517 - accuracy: 0.9301 - val_loss: 0.3925 - val_accuracy: 0.8779\n",
      "Epoch 323/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.3225 - accuracy: 0.9417 - val_loss: 0.3897 - val_accuracy: 0.8953\n",
      "Epoch 324/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.3335 - accuracy: 0.9223 - val_loss: 0.3933 - val_accuracy: 0.8895\n",
      "Epoch 325/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.3227 - accuracy: 0.9223 - val_loss: 0.3913 - val_accuracy: 0.8895\n",
      "Epoch 326/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.3390 - accuracy: 0.9340 - val_loss: 0.3923 - val_accuracy: 0.8895\n",
      "Epoch 327/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.3285 - accuracy: 0.9320 - val_loss: 0.3872 - val_accuracy: 0.8779\n",
      "Epoch 328/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3153 - accuracy: 0.9476 - val_loss: 0.3832 - val_accuracy: 0.9012\n",
      "Epoch 329/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.3273 - accuracy: 0.9417 - val_loss: 0.3844 - val_accuracy: 0.9070\n",
      "Epoch 330/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.3380 - accuracy: 0.9340 - val_loss: 0.3813 - val_accuracy: 0.9012\n",
      "Epoch 331/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.3186 - accuracy: 0.9320 - val_loss: 0.3808 - val_accuracy: 0.9012\n",
      "Epoch 332/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.3207 - accuracy: 0.9476 - val_loss: 0.3811 - val_accuracy: 0.9070\n",
      "Epoch 333/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3223 - accuracy: 0.9359 - val_loss: 0.3893 - val_accuracy: 0.8895\n",
      "Epoch 334/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.3215 - accuracy: 0.9398 - val_loss: 0.3878 - val_accuracy: 0.8837\n",
      "Epoch 335/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3511 - accuracy: 0.9146 - val_loss: 0.3805 - val_accuracy: 0.9128\n",
      "Epoch 336/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.3456 - accuracy: 0.9301 - val_loss: 0.3845 - val_accuracy: 0.8953\n",
      "Epoch 337/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.3241 - accuracy: 0.9398 - val_loss: 0.3871 - val_accuracy: 0.8953\n",
      "Epoch 338/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3314 - accuracy: 0.9340 - val_loss: 0.3820 - val_accuracy: 0.8953\n",
      "Epoch 339/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.3229 - accuracy: 0.9320 - val_loss: 0.3765 - val_accuracy: 0.9012\n",
      "Epoch 340/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3189 - accuracy: 0.9379 - val_loss: 0.3842 - val_accuracy: 0.8895\n",
      "Epoch 341/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.3133 - accuracy: 0.9476 - val_loss: 0.3785 - val_accuracy: 0.8953\n",
      "Epoch 342/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3186 - accuracy: 0.9437 - val_loss: 0.3891 - val_accuracy: 0.8721\n",
      "Epoch 343/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.3152 - accuracy: 0.9476 - val_loss: 0.3872 - val_accuracy: 0.8721\n",
      "Epoch 344/2000\n",
      "515/515 [==============================] - 0s 51us/sample - loss: 0.2930 - accuracy: 0.9437 - val_loss: 0.3884 - val_accuracy: 0.8837\n",
      "Epoch 345/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.3063 - accuracy: 0.9476 - val_loss: 0.3775 - val_accuracy: 0.8953\n",
      "Epoch 346/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3049 - accuracy: 0.9476 - val_loss: 0.3833 - val_accuracy: 0.8953\n",
      "Epoch 347/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.3190 - accuracy: 0.9456 - val_loss: 0.3819 - val_accuracy: 0.8721\n",
      "Epoch 348/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.3207 - accuracy: 0.9301 - val_loss: 0.3874 - val_accuracy: 0.8721\n",
      "Epoch 349/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3178 - accuracy: 0.9359 - val_loss: 0.3819 - val_accuracy: 0.8895\n",
      "Epoch 350/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.2980 - accuracy: 0.9476 - val_loss: 0.3882 - val_accuracy: 0.8721\n",
      "Epoch 351/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.3171 - accuracy: 0.9301 - val_loss: 0.3924 - val_accuracy: 0.8837\n",
      "Epoch 352/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.3045 - accuracy: 0.9417 - val_loss: 0.3942 - val_accuracy: 0.8837\n",
      "Epoch 353/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.3096 - accuracy: 0.9417 - val_loss: 0.3779 - val_accuracy: 0.8953\n",
      "Epoch 354/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.3227 - accuracy: 0.9301 - val_loss: 0.3747 - val_accuracy: 0.8953\n",
      "Epoch 355/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.2972 - accuracy: 0.9437 - val_loss: 0.3819 - val_accuracy: 0.8837\n",
      "Epoch 356/2000\n",
      "515/515 [==============================] - 0s 89us/sample - loss: 0.2947 - accuracy: 0.9553 - val_loss: 0.3834 - val_accuracy: 0.8895\n",
      "Epoch 357/2000\n",
      "515/515 [==============================] - 0s 114us/sample - loss: 0.3296 - accuracy: 0.9223 - val_loss: 0.3832 - val_accuracy: 0.8779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/2000\n",
      "515/515 [==============================] - 0s 88us/sample - loss: 0.3030 - accuracy: 0.9456 - val_loss: 0.3788 - val_accuracy: 0.8895\n",
      "Epoch 359/2000\n",
      "515/515 [==============================] - 0s 69us/sample - loss: 0.3146 - accuracy: 0.9437 - val_loss: 0.3702 - val_accuracy: 0.9070\n",
      "Epoch 360/2000\n",
      "515/515 [==============================] - 0s 78us/sample - loss: 0.3286 - accuracy: 0.9262 - val_loss: 0.3737 - val_accuracy: 0.8953\n",
      "Epoch 361/2000\n",
      "515/515 [==============================] - 0s 88us/sample - loss: 0.3011 - accuracy: 0.9417 - val_loss: 0.3876 - val_accuracy: 0.8895\n",
      "Epoch 362/2000\n",
      "515/515 [==============================] - 0s 85us/sample - loss: 0.3162 - accuracy: 0.9456 - val_loss: 0.3758 - val_accuracy: 0.9012\n",
      "Epoch 363/2000\n",
      "515/515 [==============================] - 0s 83us/sample - loss: 0.2946 - accuracy: 0.9515 - val_loss: 0.3787 - val_accuracy: 0.9012\n",
      "Epoch 364/2000\n",
      "515/515 [==============================] - 0s 87us/sample - loss: 0.3179 - accuracy: 0.9282 - val_loss: 0.3736 - val_accuracy: 0.9070\n",
      "Epoch 365/2000\n",
      "515/515 [==============================] - 0s 92us/sample - loss: 0.2940 - accuracy: 0.9437 - val_loss: 0.3760 - val_accuracy: 0.8895\n",
      "Epoch 366/2000\n",
      "515/515 [==============================] - 0s 84us/sample - loss: 0.2952 - accuracy: 0.9476 - val_loss: 0.3750 - val_accuracy: 0.9070\n",
      "Epoch 367/2000\n",
      "515/515 [==============================] - 0s 68us/sample - loss: 0.2966 - accuracy: 0.9456 - val_loss: 0.3725 - val_accuracy: 0.9128\n",
      "Epoch 368/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2935 - accuracy: 0.9437 - val_loss: 0.3739 - val_accuracy: 0.8895\n",
      "Epoch 369/2000\n",
      "515/515 [==============================] - 0s 50us/sample - loss: 0.3131 - accuracy: 0.9379 - val_loss: 0.3761 - val_accuracy: 0.8953\n",
      "Epoch 370/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.2942 - accuracy: 0.9398 - val_loss: 0.3766 - val_accuracy: 0.9070\n",
      "Epoch 371/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.3229 - accuracy: 0.9243 - val_loss: 0.3765 - val_accuracy: 0.9070\n",
      "Epoch 372/2000\n",
      "515/515 [==============================] - 0s 50us/sample - loss: 0.2925 - accuracy: 0.9398 - val_loss: 0.3728 - val_accuracy: 0.8895\n",
      "Epoch 373/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.2783 - accuracy: 0.9553 - val_loss: 0.3790 - val_accuracy: 0.8837\n",
      "Epoch 374/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2884 - accuracy: 0.9515 - val_loss: 0.3743 - val_accuracy: 0.9070\n",
      "Epoch 375/2000\n",
      "515/515 [==============================] - 0s 51us/sample - loss: 0.3038 - accuracy: 0.9320 - val_loss: 0.3758 - val_accuracy: 0.8953\n",
      "Epoch 376/2000\n",
      "515/515 [==============================] - 0s 50us/sample - loss: 0.2898 - accuracy: 0.9476 - val_loss: 0.3777 - val_accuracy: 0.9012\n",
      "Epoch 377/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2881 - accuracy: 0.9495 - val_loss: 0.3695 - val_accuracy: 0.9070\n",
      "Epoch 378/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.2966 - accuracy: 0.9340 - val_loss: 0.3721 - val_accuracy: 0.9012\n",
      "Epoch 379/2000\n",
      "515/515 [==============================] - 0s 51us/sample - loss: 0.3105 - accuracy: 0.9359 - val_loss: 0.3751 - val_accuracy: 0.9012\n",
      "Epoch 380/2000\n",
      "515/515 [==============================] - 0s 54us/sample - loss: 0.2970 - accuracy: 0.9476 - val_loss: 0.3808 - val_accuracy: 0.8895\n",
      "Epoch 381/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2878 - accuracy: 0.9534 - val_loss: 0.3745 - val_accuracy: 0.8837\n",
      "Epoch 382/2000\n",
      "515/515 [==============================] - 0s 50us/sample - loss: 0.3131 - accuracy: 0.9359 - val_loss: 0.3795 - val_accuracy: 0.8895\n",
      "Epoch 383/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.2945 - accuracy: 0.9340 - val_loss: 0.3752 - val_accuracy: 0.8895\n",
      "Epoch 384/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2948 - accuracy: 0.9437 - val_loss: 0.3771 - val_accuracy: 0.8953\n",
      "Epoch 385/2000\n",
      "515/515 [==============================] - 0s 51us/sample - loss: 0.2912 - accuracy: 0.9417 - val_loss: 0.3711 - val_accuracy: 0.8837\n",
      "Epoch 386/2000\n",
      "515/515 [==============================] - 0s 49us/sample - loss: 0.2859 - accuracy: 0.9456 - val_loss: 0.3728 - val_accuracy: 0.9012\n",
      "Epoch 387/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2892 - accuracy: 0.9495 - val_loss: 0.3702 - val_accuracy: 0.8895\n",
      "Epoch 388/2000\n",
      "515/515 [==============================] - 0s 54us/sample - loss: 0.2933 - accuracy: 0.9359 - val_loss: 0.3665 - val_accuracy: 0.9012\n",
      "Epoch 389/2000\n",
      "515/515 [==============================] - 0s 50us/sample - loss: 0.2885 - accuracy: 0.9437 - val_loss: 0.3724 - val_accuracy: 0.8953\n",
      "Epoch 390/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2837 - accuracy: 0.9495 - val_loss: 0.3693 - val_accuracy: 0.8953\n",
      "Epoch 391/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.2837 - accuracy: 0.9476 - val_loss: 0.3676 - val_accuracy: 0.9070\n",
      "Epoch 392/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.2846 - accuracy: 0.9495 - val_loss: 0.3703 - val_accuracy: 0.9012\n",
      "Epoch 393/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.2837 - accuracy: 0.9515 - val_loss: 0.3662 - val_accuracy: 0.8895\n",
      "Epoch 394/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2817 - accuracy: 0.9515 - val_loss: 0.3682 - val_accuracy: 0.8895\n",
      "Epoch 395/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.3104 - accuracy: 0.9320 - val_loss: 0.3713 - val_accuracy: 0.8837\n",
      "Epoch 396/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.3221 - accuracy: 0.9282 - val_loss: 0.3770 - val_accuracy: 0.8779\n",
      "Epoch 397/2000\n",
      "515/515 [==============================] - 0s 51us/sample - loss: 0.3267 - accuracy: 0.9243 - val_loss: 0.3784 - val_accuracy: 0.8837\n",
      "Epoch 398/2000\n",
      "515/515 [==============================] - 0s 48us/sample - loss: 0.2965 - accuracy: 0.9301 - val_loss: 0.3757 - val_accuracy: 0.8895\n",
      "Epoch 399/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2759 - accuracy: 0.9650 - val_loss: 0.3635 - val_accuracy: 0.8953\n",
      "Epoch 400/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.2967 - accuracy: 0.9437 - val_loss: 0.3723 - val_accuracy: 0.8779\n",
      "Epoch 401/2000\n",
      "515/515 [==============================] - 0s 51us/sample - loss: 0.2982 - accuracy: 0.9398 - val_loss: 0.3686 - val_accuracy: 0.8895\n",
      "Epoch 402/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2826 - accuracy: 0.9417 - val_loss: 0.3742 - val_accuracy: 0.8779\n",
      "Epoch 403/2000\n",
      "515/515 [==============================] - 0s 51us/sample - loss: 0.2822 - accuracy: 0.9456 - val_loss: 0.3701 - val_accuracy: 0.9012\n",
      "Epoch 404/2000\n",
      "515/515 [==============================] - 0s 49us/sample - loss: 0.3026 - accuracy: 0.9359 - val_loss: 0.3630 - val_accuracy: 0.8953\n",
      "Epoch 405/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2613 - accuracy: 0.9573 - val_loss: 0.3607 - val_accuracy: 0.9012\n",
      "Epoch 406/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2817 - accuracy: 0.9417 - val_loss: 0.3634 - val_accuracy: 0.9012\n",
      "Epoch 407/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2876 - accuracy: 0.9379 - val_loss: 0.3604 - val_accuracy: 0.9012\n",
      "Epoch 408/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.2790 - accuracy: 0.9515 - val_loss: 0.3634 - val_accuracy: 0.9012\n",
      "Epoch 409/2000\n",
      "515/515 [==============================] - 0s 51us/sample - loss: 0.2957 - accuracy: 0.9417 - val_loss: 0.3672 - val_accuracy: 0.9070\n",
      "Epoch 410/2000\n",
      "515/515 [==============================] - 0s 54us/sample - loss: 0.2763 - accuracy: 0.9476 - val_loss: 0.3743 - val_accuracy: 0.8837\n",
      "Epoch 411/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2901 - accuracy: 0.9437 - val_loss: 0.3776 - val_accuracy: 0.8837\n",
      "Epoch 412/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.2702 - accuracy: 0.9534 - val_loss: 0.3671 - val_accuracy: 0.8895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413/2000\n",
      "515/515 [==============================] - 0s 49us/sample - loss: 0.2682 - accuracy: 0.9612 - val_loss: 0.3654 - val_accuracy: 0.8953\n",
      "Epoch 414/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.3040 - accuracy: 0.9398 - val_loss: 0.3673 - val_accuracy: 0.8895\n",
      "Epoch 415/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2851 - accuracy: 0.9476 - val_loss: 0.3732 - val_accuracy: 0.8837\n",
      "Epoch 416/2000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 0.2859 - accuracy: 0.9359 - val_loss: 0.3662 - val_accuracy: 0.8953\n",
      "Epoch 417/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2842 - accuracy: 0.9476 - val_loss: 0.3749 - val_accuracy: 0.8779\n",
      "Epoch 418/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2650 - accuracy: 0.9456 - val_loss: 0.3676 - val_accuracy: 0.8895\n",
      "Epoch 419/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2852 - accuracy: 0.9417 - val_loss: 0.3670 - val_accuracy: 0.8837\n",
      "Epoch 420/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2908 - accuracy: 0.9417 - val_loss: 0.3630 - val_accuracy: 0.9070\n",
      "Epoch 421/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2893 - accuracy: 0.9495 - val_loss: 0.3628 - val_accuracy: 0.9012\n",
      "Epoch 422/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.2772 - accuracy: 0.9515 - val_loss: 0.3652 - val_accuracy: 0.8895\n",
      "Epoch 423/2000\n",
      "515/515 [==============================] - 0s 55us/sample - loss: 0.2744 - accuracy: 0.9495 - val_loss: 0.3605 - val_accuracy: 0.9070\n",
      "Epoch 424/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.2883 - accuracy: 0.9417 - val_loss: 0.3609 - val_accuracy: 0.9128\n",
      "Epoch 425/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2939 - accuracy: 0.9417 - val_loss: 0.3649 - val_accuracy: 0.8837\n",
      "Epoch 426/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2769 - accuracy: 0.9534 - val_loss: 0.3839 - val_accuracy: 0.8721\n",
      "Epoch 427/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2518 - accuracy: 0.9476 - val_loss: 0.3621 - val_accuracy: 0.8895\n",
      "Epoch 428/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2859 - accuracy: 0.9437 - val_loss: 0.3655 - val_accuracy: 0.8953\n",
      "Epoch 429/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2695 - accuracy: 0.9495 - val_loss: 0.3644 - val_accuracy: 0.8895\n",
      "Epoch 430/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2891 - accuracy: 0.9320 - val_loss: 0.3687 - val_accuracy: 0.9012\n",
      "Epoch 431/2000\n",
      "515/515 [==============================] - 0s 67us/sample - loss: 0.2944 - accuracy: 0.9476 - val_loss: 0.3664 - val_accuracy: 0.8895\n",
      "Epoch 432/2000\n",
      "515/515 [==============================] - 0s 71us/sample - loss: 0.2809 - accuracy: 0.9515 - val_loss: 0.3679 - val_accuracy: 0.8837\n",
      "Epoch 433/2000\n",
      "515/515 [==============================] - 0s 77us/sample - loss: 0.2830 - accuracy: 0.9243 - val_loss: 0.3791 - val_accuracy: 0.8895\n",
      "Epoch 434/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.2834 - accuracy: 0.9476 - val_loss: 0.3891 - val_accuracy: 0.8895\n",
      "Epoch 435/2000\n",
      "515/515 [==============================] - 0s 70us/sample - loss: 0.2676 - accuracy: 0.9437 - val_loss: 0.3698 - val_accuracy: 0.8895\n",
      "Epoch 436/2000\n",
      "515/515 [==============================] - 0s 67us/sample - loss: 0.2638 - accuracy: 0.9553 - val_loss: 0.3558 - val_accuracy: 0.8953\n",
      "Epoch 437/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.2737 - accuracy: 0.9495 - val_loss: 0.3628 - val_accuracy: 0.8953\n",
      "Epoch 438/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.2911 - accuracy: 0.9417 - val_loss: 0.3629 - val_accuracy: 0.9012\n",
      "Epoch 439/2000\n",
      "515/515 [==============================] - 0s 67us/sample - loss: 0.2626 - accuracy: 0.9650 - val_loss: 0.3657 - val_accuracy: 0.8895\n",
      "Epoch 440/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.2429 - accuracy: 0.9592 - val_loss: 0.3680 - val_accuracy: 0.9012\n",
      "Epoch 441/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.2895 - accuracy: 0.9476 - val_loss: 0.3598 - val_accuracy: 0.8953\n",
      "Epoch 442/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.2747 - accuracy: 0.9417 - val_loss: 0.3633 - val_accuracy: 0.8953\n",
      "Epoch 443/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.2775 - accuracy: 0.9495 - val_loss: 0.3654 - val_accuracy: 0.9012\n",
      "Epoch 444/2000\n",
      "515/515 [==============================] - 0s 73us/sample - loss: 0.2715 - accuracy: 0.9495 - val_loss: 0.3632 - val_accuracy: 0.8837\n",
      "Epoch 445/2000\n",
      "515/515 [==============================] - 0s 66us/sample - loss: 0.2924 - accuracy: 0.9301 - val_loss: 0.3639 - val_accuracy: 0.8837\n",
      "Epoch 446/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.2651 - accuracy: 0.9456 - val_loss: 0.3659 - val_accuracy: 0.8953\n",
      "Epoch 447/2000\n",
      "515/515 [==============================] - 0s 66us/sample - loss: 0.2780 - accuracy: 0.9437 - val_loss: 0.3661 - val_accuracy: 0.8895\n",
      "Epoch 448/2000\n",
      "515/515 [==============================] - 0s 67us/sample - loss: 0.2745 - accuracy: 0.9534 - val_loss: 0.3654 - val_accuracy: 0.9012\n",
      "Epoch 449/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.2780 - accuracy: 0.9553 - val_loss: 0.3615 - val_accuracy: 0.9070\n",
      "Epoch 450/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.2633 - accuracy: 0.9456 - val_loss: 0.3646 - val_accuracy: 0.8895\n",
      "Epoch 451/2000\n",
      "515/515 [==============================] - 0s 49us/sample - loss: 0.2608 - accuracy: 0.9573 - val_loss: 0.3582 - val_accuracy: 0.8953\n",
      "Epoch 452/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.2823 - accuracy: 0.9437 - val_loss: 0.3663 - val_accuracy: 0.8953\n",
      "Epoch 453/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2690 - accuracy: 0.9495 - val_loss: 0.3599 - val_accuracy: 0.9070\n",
      "Epoch 454/2000\n",
      "515/515 [==============================] - 0s 49us/sample - loss: 0.2529 - accuracy: 0.9515 - val_loss: 0.3581 - val_accuracy: 0.9012\n",
      "Epoch 455/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.2695 - accuracy: 0.9553 - val_loss: 0.3606 - val_accuracy: 0.8953\n",
      "Epoch 456/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2553 - accuracy: 0.9553 - val_loss: 0.3623 - val_accuracy: 0.8837\n",
      "Epoch 457/2000\n",
      "515/515 [==============================] - 0s 48us/sample - loss: 0.2754 - accuracy: 0.9476 - val_loss: 0.3571 - val_accuracy: 0.8953\n",
      "Epoch 458/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.2661 - accuracy: 0.9534 - val_loss: 0.3609 - val_accuracy: 0.8953\n",
      "Epoch 459/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2640 - accuracy: 0.9573 - val_loss: 0.3593 - val_accuracy: 0.8895\n",
      "Epoch 460/2000\n",
      "515/515 [==============================] - 0s 49us/sample - loss: 0.2548 - accuracy: 0.9592 - val_loss: 0.3613 - val_accuracy: 0.8953\n",
      "Epoch 461/2000\n",
      "515/515 [==============================] - 0s 51us/sample - loss: 0.2675 - accuracy: 0.9456 - val_loss: 0.3586 - val_accuracy: 0.8953\n",
      "Epoch 462/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2521 - accuracy: 0.9592 - val_loss: 0.3641 - val_accuracy: 0.9012\n",
      "Epoch 463/2000\n",
      "515/515 [==============================] - 0s 48us/sample - loss: 0.2581 - accuracy: 0.9495 - val_loss: 0.3524 - val_accuracy: 0.9012\n",
      "Epoch 464/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.2743 - accuracy: 0.9417 - val_loss: 0.3525 - val_accuracy: 0.8953\n",
      "Epoch 465/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2410 - accuracy: 0.9670 - val_loss: 0.3616 - val_accuracy: 0.8953\n",
      "Epoch 466/2000\n",
      "515/515 [==============================] - 0s 48us/sample - loss: 0.2500 - accuracy: 0.9612 - val_loss: 0.3603 - val_accuracy: 0.9012\n",
      "Epoch 467/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2644 - accuracy: 0.9476 - val_loss: 0.3601 - val_accuracy: 0.8953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2498 - accuracy: 0.9612 - val_loss: 0.3654 - val_accuracy: 0.8953\n",
      "Epoch 469/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2800 - accuracy: 0.9359 - val_loss: 0.3542 - val_accuracy: 0.9128\n",
      "Epoch 470/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2693 - accuracy: 0.9417 - val_loss: 0.3537 - val_accuracy: 0.8953\n",
      "Epoch 471/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2693 - accuracy: 0.9495 - val_loss: 0.3546 - val_accuracy: 0.9128\n",
      "Epoch 472/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.2560 - accuracy: 0.9495 - val_loss: 0.3609 - val_accuracy: 0.8953\n",
      "Epoch 473/2000\n",
      "515/515 [==============================] - 0s 68us/sample - loss: 0.2512 - accuracy: 0.9515 - val_loss: 0.3548 - val_accuracy: 0.8953\n",
      "Epoch 474/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.2603 - accuracy: 0.9495 - val_loss: 0.3650 - val_accuracy: 0.8953\n",
      "Epoch 475/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2706 - accuracy: 0.9456 - val_loss: 0.3594 - val_accuracy: 0.8895\n",
      "Epoch 476/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2760 - accuracy: 0.9456 - val_loss: 0.3580 - val_accuracy: 0.8953\n",
      "Epoch 477/2000\n",
      "515/515 [==============================] - 0s 48us/sample - loss: 0.2661 - accuracy: 0.9573 - val_loss: 0.3603 - val_accuracy: 0.8895\n",
      "Epoch 478/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.2635 - accuracy: 0.9417 - val_loss: 0.3517 - val_accuracy: 0.9012\n",
      "Epoch 479/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.2701 - accuracy: 0.9359 - val_loss: 0.3605 - val_accuracy: 0.8895\n",
      "Epoch 480/2000\n",
      "515/515 [==============================] - 0s 47us/sample - loss: 0.2571 - accuracy: 0.9437 - val_loss: 0.3556 - val_accuracy: 0.9012\n",
      "Epoch 481/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.2841 - accuracy: 0.9398 - val_loss: 0.3629 - val_accuracy: 0.8953\n",
      "Epoch 482/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2571 - accuracy: 0.9398 - val_loss: 0.3667 - val_accuracy: 0.9070\n",
      "Epoch 483/2000\n",
      "515/515 [==============================] - 0s 47us/sample - loss: 0.2580 - accuracy: 0.9515 - val_loss: 0.3553 - val_accuracy: 0.9012\n",
      "Epoch 484/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.2637 - accuracy: 0.9476 - val_loss: 0.3583 - val_accuracy: 0.8895\n",
      "Epoch 485/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2611 - accuracy: 0.9515 - val_loss: 0.3612 - val_accuracy: 0.8953\n",
      "Epoch 486/2000\n",
      "515/515 [==============================] - 0s 48us/sample - loss: 0.2599 - accuracy: 0.9515 - val_loss: 0.3657 - val_accuracy: 0.8895\n",
      "Epoch 487/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.2502 - accuracy: 0.9515 - val_loss: 0.3590 - val_accuracy: 0.8895\n",
      "Epoch 488/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2544 - accuracy: 0.9670 - val_loss: 0.3623 - val_accuracy: 0.8895\n",
      "Epoch 489/2000\n",
      "515/515 [==============================] - 0s 47us/sample - loss: 0.2482 - accuracy: 0.9573 - val_loss: 0.3560 - val_accuracy: 0.8895\n",
      "Epoch 490/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.2688 - accuracy: 0.9359 - val_loss: 0.3456 - val_accuracy: 0.9070\n",
      "Epoch 491/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2458 - accuracy: 0.9631 - val_loss: 0.3627 - val_accuracy: 0.9128\n",
      "Epoch 492/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2588 - accuracy: 0.9476 - val_loss: 0.3670 - val_accuracy: 0.8953\n",
      "Epoch 493/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2440 - accuracy: 0.9592 - val_loss: 0.3515 - val_accuracy: 0.8953\n",
      "Epoch 494/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.2450 - accuracy: 0.9573 - val_loss: 0.3586 - val_accuracy: 0.9012\n",
      "Epoch 495/2000\n",
      "515/515 [==============================] - 0s 49us/sample - loss: 0.2275 - accuracy: 0.9689 - val_loss: 0.3521 - val_accuracy: 0.8837\n",
      "Epoch 496/2000\n",
      "515/515 [==============================] - 0s 54us/sample - loss: 0.2388 - accuracy: 0.9612 - val_loss: 0.3585 - val_accuracy: 0.9012\n",
      "Epoch 497/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2449 - accuracy: 0.9612 - val_loss: 0.3527 - val_accuracy: 0.9012\n",
      "Epoch 498/2000\n",
      "515/515 [==============================] - 0s 48us/sample - loss: 0.2353 - accuracy: 0.9709 - val_loss: 0.3514 - val_accuracy: 0.9012\n",
      "Epoch 499/2000\n",
      "515/515 [==============================] - 0s 55us/sample - loss: 0.2453 - accuracy: 0.9534 - val_loss: 0.3517 - val_accuracy: 0.8953\n",
      "Epoch 500/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2852 - accuracy: 0.9340 - val_loss: 0.3517 - val_accuracy: 0.8895\n",
      "Epoch 501/2000\n",
      "515/515 [==============================] - 0s 55us/sample - loss: 0.2608 - accuracy: 0.9534 - val_loss: 0.3505 - val_accuracy: 0.8837\n",
      "Epoch 502/2000\n",
      "515/515 [==============================] - 0s 49us/sample - loss: 0.2560 - accuracy: 0.9573 - val_loss: 0.3531 - val_accuracy: 0.8953\n",
      "Epoch 503/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.2414 - accuracy: 0.9553 - val_loss: 0.3523 - val_accuracy: 0.8953\n",
      "Epoch 504/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2484 - accuracy: 0.9515 - val_loss: 0.3474 - val_accuracy: 0.8953\n",
      "Epoch 505/2000\n",
      "515/515 [==============================] - 0s 49us/sample - loss: 0.2562 - accuracy: 0.9476 - val_loss: 0.3485 - val_accuracy: 0.8837\n",
      "Epoch 506/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.2297 - accuracy: 0.9612 - val_loss: 0.3557 - val_accuracy: 0.8895\n",
      "Epoch 507/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2633 - accuracy: 0.9417 - val_loss: 0.3515 - val_accuracy: 0.8895\n",
      "Epoch 508/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.2344 - accuracy: 0.9553 - val_loss: 0.3524 - val_accuracy: 0.9128\n",
      "Epoch 509/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.2423 - accuracy: 0.9592 - val_loss: 0.3680 - val_accuracy: 0.8895\n",
      "Epoch 510/2000\n",
      "515/515 [==============================] - 0s 49us/sample - loss: 0.2425 - accuracy: 0.9534 - val_loss: 0.3624 - val_accuracy: 0.8953\n",
      "Epoch 511/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2483 - accuracy: 0.9553 - val_loss: 0.3540 - val_accuracy: 0.8895\n",
      "Epoch 512/2000\n",
      "515/515 [==============================] - 0s 54us/sample - loss: 0.2620 - accuracy: 0.9534 - val_loss: 0.3577 - val_accuracy: 0.8953\n",
      "Epoch 513/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2552 - accuracy: 0.9612 - val_loss: 0.3572 - val_accuracy: 0.9070\n",
      "Epoch 514/2000\n",
      "515/515 [==============================] - 0s 47us/sample - loss: 0.2538 - accuracy: 0.9476 - val_loss: 0.3494 - val_accuracy: 0.9012\n",
      "Epoch 515/2000\n",
      "515/515 [==============================] - 0s 54us/sample - loss: 0.2339 - accuracy: 0.9670 - val_loss: 0.3565 - val_accuracy: 0.9070\n",
      "Epoch 516/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2516 - accuracy: 0.9437 - val_loss: 0.3613 - val_accuracy: 0.9012\n",
      "Epoch 517/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.2418 - accuracy: 0.9515 - val_loss: 0.3609 - val_accuracy: 0.8953\n",
      "Epoch 518/2000\n",
      "515/515 [==============================] - 0s 47us/sample - loss: 0.2319 - accuracy: 0.9689 - val_loss: 0.3547 - val_accuracy: 0.8953\n",
      "Epoch 519/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2493 - accuracy: 0.9553 - val_loss: 0.3510 - val_accuracy: 0.9070\n",
      "Epoch 520/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2489 - accuracy: 0.9515 - val_loss: 0.3479 - val_accuracy: 0.9012\n",
      "Epoch 521/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2547 - accuracy: 0.9650 - val_loss: 0.3489 - val_accuracy: 0.9012\n",
      "Epoch 522/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2429 - accuracy: 0.9534 - val_loss: 0.3498 - val_accuracy: 0.9012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.2254 - accuracy: 0.9650 - val_loss: 0.3527 - val_accuracy: 0.9070\n",
      "Epoch 524/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2530 - accuracy: 0.9417 - val_loss: 0.3544 - val_accuracy: 0.9012\n",
      "Epoch 525/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2642 - accuracy: 0.9417 - val_loss: 0.3513 - val_accuracy: 0.9012\n",
      "Epoch 526/2000\n",
      "515/515 [==============================] - 0s 68us/sample - loss: 0.2472 - accuracy: 0.9592 - val_loss: 0.3507 - val_accuracy: 0.9070\n",
      "Epoch 527/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2447 - accuracy: 0.9534 - val_loss: 0.3552 - val_accuracy: 0.9070\n",
      "Epoch 528/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2418 - accuracy: 0.9631 - val_loss: 0.3482 - val_accuracy: 0.9012\n",
      "Epoch 529/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2399 - accuracy: 0.9573 - val_loss: 0.3476 - val_accuracy: 0.9070\n",
      "Epoch 530/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2556 - accuracy: 0.9456 - val_loss: 0.3509 - val_accuracy: 0.9012\n",
      "Epoch 531/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2491 - accuracy: 0.9456 - val_loss: 0.3569 - val_accuracy: 0.9070\n",
      "Epoch 532/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.2643 - accuracy: 0.9495 - val_loss: 0.3593 - val_accuracy: 0.8953\n",
      "Epoch 533/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.2426 - accuracy: 0.9631 - val_loss: 0.3539 - val_accuracy: 0.8895\n",
      "Epoch 534/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2259 - accuracy: 0.9689 - val_loss: 0.3435 - val_accuracy: 0.9012\n",
      "Epoch 535/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2298 - accuracy: 0.9670 - val_loss: 0.3505 - val_accuracy: 0.9070\n",
      "Epoch 536/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2536 - accuracy: 0.9437 - val_loss: 0.3502 - val_accuracy: 0.8953\n",
      "Epoch 537/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2406 - accuracy: 0.9592 - val_loss: 0.3474 - val_accuracy: 0.9070\n",
      "Epoch 538/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2284 - accuracy: 0.9612 - val_loss: 0.3506 - val_accuracy: 0.9012\n",
      "Epoch 539/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2316 - accuracy: 0.9534 - val_loss: 0.3486 - val_accuracy: 0.9012\n",
      "Epoch 540/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2286 - accuracy: 0.9612 - val_loss: 0.3481 - val_accuracy: 0.9070\n",
      "Epoch 541/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.2570 - accuracy: 0.9515 - val_loss: 0.3582 - val_accuracy: 0.9070\n",
      "Epoch 542/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.2312 - accuracy: 0.9631 - val_loss: 0.3386 - val_accuracy: 0.8953\n",
      "Epoch 543/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2448 - accuracy: 0.9495 - val_loss: 0.3399 - val_accuracy: 0.9012\n",
      "Epoch 544/2000\n",
      "515/515 [==============================] - 0s 66us/sample - loss: 0.2275 - accuracy: 0.9592 - val_loss: 0.3441 - val_accuracy: 0.8953\n",
      "Epoch 545/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2356 - accuracy: 0.9573 - val_loss: 0.3428 - val_accuracy: 0.8953\n",
      "Epoch 546/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2351 - accuracy: 0.9495 - val_loss: 0.3487 - val_accuracy: 0.9128\n",
      "Epoch 547/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2572 - accuracy: 0.9495 - val_loss: 0.3528 - val_accuracy: 0.9012\n",
      "Epoch 548/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2340 - accuracy: 0.9573 - val_loss: 0.3508 - val_accuracy: 0.9128\n",
      "Epoch 549/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2557 - accuracy: 0.9476 - val_loss: 0.3536 - val_accuracy: 0.9012\n",
      "Epoch 550/2000\n",
      "515/515 [==============================] - 0s 55us/sample - loss: 0.2294 - accuracy: 0.9612 - val_loss: 0.3479 - val_accuracy: 0.8895\n",
      "Epoch 551/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2168 - accuracy: 0.9709 - val_loss: 0.3578 - val_accuracy: 0.9128\n",
      "Epoch 552/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2246 - accuracy: 0.9476 - val_loss: 0.3466 - val_accuracy: 0.9128\n",
      "Epoch 553/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2338 - accuracy: 0.9631 - val_loss: 0.3463 - val_accuracy: 0.9012\n",
      "Epoch 554/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2396 - accuracy: 0.9573 - val_loss: 0.3505 - val_accuracy: 0.9012\n",
      "Epoch 555/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2429 - accuracy: 0.9456 - val_loss: 0.3566 - val_accuracy: 0.9012\n",
      "Epoch 556/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2406 - accuracy: 0.9495 - val_loss: 0.3529 - val_accuracy: 0.9070\n",
      "Epoch 557/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.2437 - accuracy: 0.9689 - val_loss: 0.3582 - val_accuracy: 0.8953\n",
      "Epoch 558/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2131 - accuracy: 0.9748 - val_loss: 0.3515 - val_accuracy: 0.9070\n",
      "Epoch 559/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.2461 - accuracy: 0.9456 - val_loss: 0.3474 - val_accuracy: 0.9070\n",
      "Epoch 560/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2382 - accuracy: 0.9612 - val_loss: 0.3460 - val_accuracy: 0.8953\n",
      "Epoch 561/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2310 - accuracy: 0.9573 - val_loss: 0.3495 - val_accuracy: 0.9128\n",
      "Epoch 562/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2493 - accuracy: 0.9495 - val_loss: 0.3496 - val_accuracy: 0.9012\n",
      "Epoch 563/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2134 - accuracy: 0.9650 - val_loss: 0.3497 - val_accuracy: 0.9012\n",
      "Epoch 564/2000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 0.2444 - accuracy: 0.9456 - val_loss: 0.3539 - val_accuracy: 0.8953\n",
      "Epoch 565/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2360 - accuracy: 0.9631 - val_loss: 0.3490 - val_accuracy: 0.9012\n",
      "Epoch 566/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2257 - accuracy: 0.9592 - val_loss: 0.3436 - val_accuracy: 0.9070\n",
      "Epoch 567/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.2381 - accuracy: 0.9437 - val_loss: 0.3400 - val_accuracy: 0.9012\n",
      "Epoch 568/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2359 - accuracy: 0.9534 - val_loss: 0.3435 - val_accuracy: 0.9012\n",
      "Epoch 569/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2216 - accuracy: 0.9612 - val_loss: 0.3411 - val_accuracy: 0.9012\n",
      "Epoch 570/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2373 - accuracy: 0.9534 - val_loss: 0.3379 - val_accuracy: 0.9070\n",
      "Epoch 571/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2273 - accuracy: 0.9670 - val_loss: 0.3442 - val_accuracy: 0.9070\n",
      "Epoch 572/2000\n",
      "515/515 [==============================] - 0s 49us/sample - loss: 0.2397 - accuracy: 0.9515 - val_loss: 0.3517 - val_accuracy: 0.8953\n",
      "Epoch 573/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2447 - accuracy: 0.9437 - val_loss: 0.3487 - val_accuracy: 0.9070\n",
      "Epoch 574/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2460 - accuracy: 0.9515 - val_loss: 0.3449 - val_accuracy: 0.9128\n",
      "Epoch 575/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2178 - accuracy: 0.9592 - val_loss: 0.3430 - val_accuracy: 0.9070\n",
      "Epoch 576/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2323 - accuracy: 0.9592 - val_loss: 0.3305 - val_accuracy: 0.9244\n",
      "Epoch 577/2000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 0.2392 - accuracy: 0.9553 - val_loss: 0.3400 - val_accuracy: 0.8953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 578/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2315 - accuracy: 0.9592 - val_loss: 0.3554 - val_accuracy: 0.9012\n",
      "Epoch 579/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2326 - accuracy: 0.9534 - val_loss: 0.3453 - val_accuracy: 0.9070\n",
      "Epoch 580/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2473 - accuracy: 0.9495 - val_loss: 0.3369 - val_accuracy: 0.9012\n",
      "Epoch 581/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2279 - accuracy: 0.9650 - val_loss: 0.3446 - val_accuracy: 0.9070\n",
      "Epoch 582/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.2300 - accuracy: 0.9592 - val_loss: 0.3451 - val_accuracy: 0.9012\n",
      "Epoch 583/2000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 0.2149 - accuracy: 0.9728 - val_loss: 0.3520 - val_accuracy: 0.9128\n",
      "Epoch 584/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.2122 - accuracy: 0.9748 - val_loss: 0.3384 - val_accuracy: 0.9128\n",
      "Epoch 585/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.2214 - accuracy: 0.9670 - val_loss: 0.3411 - val_accuracy: 0.9012\n",
      "Epoch 586/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2331 - accuracy: 0.9573 - val_loss: 0.3326 - val_accuracy: 0.9070\n",
      "Epoch 587/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2194 - accuracy: 0.9689 - val_loss: 0.3413 - val_accuracy: 0.9070\n",
      "Epoch 588/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2274 - accuracy: 0.9592 - val_loss: 0.3390 - val_accuracy: 0.9070\n",
      "Epoch 589/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2181 - accuracy: 0.9689 - val_loss: 0.3452 - val_accuracy: 0.9070\n",
      "Epoch 590/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2241 - accuracy: 0.9650 - val_loss: 0.3467 - val_accuracy: 0.9012\n",
      "Epoch 591/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2088 - accuracy: 0.9748 - val_loss: 0.3441 - val_accuracy: 0.9012\n",
      "Epoch 592/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2229 - accuracy: 0.9767 - val_loss: 0.3501 - val_accuracy: 0.9070\n",
      "Epoch 593/2000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 0.2195 - accuracy: 0.9689 - val_loss: 0.3580 - val_accuracy: 0.9012\n",
      "Epoch 594/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.2338 - accuracy: 0.9534 - val_loss: 0.3473 - val_accuracy: 0.8953\n",
      "Epoch 595/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.2050 - accuracy: 0.9767 - val_loss: 0.3449 - val_accuracy: 0.9012\n",
      "Epoch 596/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.2490 - accuracy: 0.9553 - val_loss: 0.3395 - val_accuracy: 0.9012\n",
      "Epoch 597/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2314 - accuracy: 0.9612 - val_loss: 0.3365 - val_accuracy: 0.9012\n",
      "Epoch 598/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.2219 - accuracy: 0.9709 - val_loss: 0.3557 - val_accuracy: 0.9012\n",
      "Epoch 599/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.2317 - accuracy: 0.9631 - val_loss: 0.3379 - val_accuracy: 0.9012\n",
      "Epoch 600/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.2298 - accuracy: 0.9553 - val_loss: 0.3402 - val_accuracy: 0.9012\n",
      "Epoch 601/2000\n",
      "515/515 [==============================] - 0s 68us/sample - loss: 0.2128 - accuracy: 0.9573 - val_loss: 0.3461 - val_accuracy: 0.8953\n",
      "Epoch 602/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.2318 - accuracy: 0.9573 - val_loss: 0.3307 - val_accuracy: 0.9070\n",
      "Epoch 603/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2144 - accuracy: 0.9650 - val_loss: 0.3323 - val_accuracy: 0.9070\n",
      "Epoch 604/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2243 - accuracy: 0.9612 - val_loss: 0.3445 - val_accuracy: 0.9070\n",
      "Epoch 605/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2142 - accuracy: 0.9748 - val_loss: 0.3369 - val_accuracy: 0.9070\n",
      "Epoch 606/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.2325 - accuracy: 0.9534 - val_loss: 0.3418 - val_accuracy: 0.9012\n",
      "Epoch 607/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.2285 - accuracy: 0.9534 - val_loss: 0.3393 - val_accuracy: 0.9070\n",
      "Epoch 608/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2078 - accuracy: 0.9689 - val_loss: 0.3407 - val_accuracy: 0.9012\n",
      "Epoch 609/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2306 - accuracy: 0.9612 - val_loss: 0.3425 - val_accuracy: 0.9070\n",
      "Epoch 610/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2328 - accuracy: 0.9592 - val_loss: 0.3453 - val_accuracy: 0.9012\n",
      "Epoch 611/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2316 - accuracy: 0.9612 - val_loss: 0.3402 - val_accuracy: 0.9012\n",
      "Epoch 612/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2213 - accuracy: 0.9573 - val_loss: 0.3494 - val_accuracy: 0.9070\n",
      "Epoch 613/2000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 0.2215 - accuracy: 0.9670 - val_loss: 0.3411 - val_accuracy: 0.9070\n",
      "Epoch 614/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2231 - accuracy: 0.9631 - val_loss: 0.3438 - val_accuracy: 0.9012\n",
      "Epoch 615/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2281 - accuracy: 0.9553 - val_loss: 0.3439 - val_accuracy: 0.9070\n",
      "Epoch 616/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.2281 - accuracy: 0.9612 - val_loss: 0.3363 - val_accuracy: 0.9128\n",
      "Epoch 617/2000\n",
      "515/515 [==============================] - 0s 60us/sample - loss: 0.2070 - accuracy: 0.9709 - val_loss: 0.3336 - val_accuracy: 0.9070\n",
      "Epoch 618/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2363 - accuracy: 0.9534 - val_loss: 0.3506 - val_accuracy: 0.9012\n",
      "Epoch 619/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2042 - accuracy: 0.9709 - val_loss: 0.3381 - val_accuracy: 0.9186\n",
      "Epoch 620/2000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 0.1855 - accuracy: 0.9806 - val_loss: 0.3438 - val_accuracy: 0.9070\n",
      "Epoch 621/2000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 0.2177 - accuracy: 0.9592 - val_loss: 0.3326 - val_accuracy: 0.9012\n",
      "Epoch 622/2000\n",
      "515/515 [==============================] - 0s 62us/sample - loss: 0.2225 - accuracy: 0.9631 - val_loss: 0.3372 - val_accuracy: 0.9012\n",
      "Epoch 623/2000\n",
      "515/515 [==============================] - 0s 61us/sample - loss: 0.2035 - accuracy: 0.9728 - val_loss: 0.3419 - val_accuracy: 0.9012\n",
      "Epoch 624/2000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 0.2107 - accuracy: 0.9650 - val_loss: 0.3388 - val_accuracy: 0.9012\n",
      "Epoch 625/2000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 0.2090 - accuracy: 0.9689 - val_loss: 0.3360 - val_accuracy: 0.9070\n",
      "Epoch 626/2000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 0.2187 - accuracy: 0.9534 - val_loss: 0.3355 - val_accuracy: 0.9012\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 2,062\n",
      "Trainable params: 2,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 618 samples, validate on 206 samples\n",
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618/618 [==============================] - 0s 628us/sample - loss: 2.6377 - accuracy: 0.0971 - val_loss: 2.5802 - val_accuracy: 0.1165\n",
      "Epoch 2/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 2.5799 - accuracy: 0.1262 - val_loss: 2.5401 - val_accuracy: 0.1165\n",
      "Epoch 3/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 2.5532 - accuracy: 0.1246 - val_loss: 2.4981 - val_accuracy: 0.1748\n",
      "Epoch 4/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 2.5055 - accuracy: 0.1359 - val_loss: 2.4597 - val_accuracy: 0.2961\n",
      "Epoch 5/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 2.4623 - accuracy: 0.2023 - val_loss: 2.4179 - val_accuracy: 0.3204\n",
      "Epoch 6/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 2.4282 - accuracy: 0.2006 - val_loss: 2.3746 - val_accuracy: 0.3738\n",
      "Epoch 7/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 2.3972 - accuracy: 0.2427 - val_loss: 2.3302 - val_accuracy: 0.4563\n",
      "Epoch 8/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 2.3472 - accuracy: 0.2492 - val_loss: 2.2847 - val_accuracy: 0.4951\n",
      "Epoch 9/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 2.2917 - accuracy: 0.2994 - val_loss: 2.2405 - val_accuracy: 0.4903\n",
      "Epoch 10/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 2.2433 - accuracy: 0.3155 - val_loss: 2.1842 - val_accuracy: 0.5049\n",
      "Epoch 11/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 2.2024 - accuracy: 0.3285 - val_loss: 2.1417 - val_accuracy: 0.5340\n",
      "Epoch 12/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 2.1768 - accuracy: 0.3625 - val_loss: 2.0976 - val_accuracy: 0.5291\n",
      "Epoch 13/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 2.1114 - accuracy: 0.3641 - val_loss: 2.0541 - val_accuracy: 0.5291\n",
      "Epoch 14/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 2.0868 - accuracy: 0.3398 - val_loss: 2.0089 - val_accuracy: 0.5777\n",
      "Epoch 15/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 2.0555 - accuracy: 0.3592 - val_loss: 1.9648 - val_accuracy: 0.5583\n",
      "Epoch 16/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 1.9972 - accuracy: 0.3900 - val_loss: 1.9270 - val_accuracy: 0.5825\n",
      "Epoch 17/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 1.9632 - accuracy: 0.4272 - val_loss: 1.8861 - val_accuracy: 0.6068\n",
      "Epoch 18/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 1.9146 - accuracy: 0.4401 - val_loss: 1.8457 - val_accuracy: 0.6117\n",
      "Epoch 19/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 1.8877 - accuracy: 0.4385 - val_loss: 1.8104 - val_accuracy: 0.6699\n",
      "Epoch 20/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 1.8471 - accuracy: 0.4644 - val_loss: 1.7715 - val_accuracy: 0.6748\n",
      "Epoch 21/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 1.8255 - accuracy: 0.4466 - val_loss: 1.7362 - val_accuracy: 0.7379\n",
      "Epoch 22/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 1.7652 - accuracy: 0.5129 - val_loss: 1.7015 - val_accuracy: 0.7379\n",
      "Epoch 23/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 1.7801 - accuracy: 0.4676 - val_loss: 1.6727 - val_accuracy: 0.7427\n",
      "Epoch 24/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 1.7597 - accuracy: 0.4838 - val_loss: 1.6400 - val_accuracy: 0.7621\n",
      "Epoch 25/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 1.7063 - accuracy: 0.4984 - val_loss: 1.6093 - val_accuracy: 0.7816\n",
      "Epoch 26/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 1.6647 - accuracy: 0.4935 - val_loss: 1.5776 - val_accuracy: 0.7816\n",
      "Epoch 27/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 1.6673 - accuracy: 0.5049 - val_loss: 1.5523 - val_accuracy: 0.8058\n",
      "Epoch 28/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 1.6022 - accuracy: 0.5615 - val_loss: 1.5208 - val_accuracy: 0.7767\n",
      "Epoch 29/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 1.5885 - accuracy: 0.5437 - val_loss: 1.4891 - val_accuracy: 0.8010\n",
      "Epoch 30/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 1.5225 - accuracy: 0.6084 - val_loss: 1.4592 - val_accuracy: 0.8107\n",
      "Epoch 31/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 1.5586 - accuracy: 0.5437 - val_loss: 1.4336 - val_accuracy: 0.8350\n",
      "Epoch 32/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 1.5055 - accuracy: 0.5696 - val_loss: 1.4111 - val_accuracy: 0.8301\n",
      "Epoch 33/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 1.4640 - accuracy: 0.5728 - val_loss: 1.3864 - val_accuracy: 0.8252\n",
      "Epoch 34/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 1.4758 - accuracy: 0.5793 - val_loss: 1.3665 - val_accuracy: 0.8350\n",
      "Epoch 35/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 1.4359 - accuracy: 0.6100 - val_loss: 1.3438 - val_accuracy: 0.8252\n",
      "Epoch 36/2000\n",
      "618/618 [==============================] - 0s 59us/sample - loss: 1.4214 - accuracy: 0.6068 - val_loss: 1.3211 - val_accuracy: 0.8398\n",
      "Epoch 37/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 1.3691 - accuracy: 0.6246 - val_loss: 1.2946 - val_accuracy: 0.8107\n",
      "Epoch 38/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 1.3906 - accuracy: 0.6084 - val_loss: 1.2757 - val_accuracy: 0.8350\n",
      "Epoch 39/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 1.3416 - accuracy: 0.6343 - val_loss: 1.2592 - val_accuracy: 0.8301\n",
      "Epoch 40/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 1.3080 - accuracy: 0.6505 - val_loss: 1.2337 - val_accuracy: 0.8252\n",
      "Epoch 41/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 1.3312 - accuracy: 0.6278 - val_loss: 1.2177 - val_accuracy: 0.8252\n",
      "Epoch 42/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 1.2724 - accuracy: 0.6634 - val_loss: 1.1974 - val_accuracy: 0.8204\n",
      "Epoch 43/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 1.2778 - accuracy: 0.6505 - val_loss: 1.1734 - val_accuracy: 0.8107\n",
      "Epoch 44/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 1.2492 - accuracy: 0.6845 - val_loss: 1.1557 - val_accuracy: 0.8204\n",
      "Epoch 45/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 1.2393 - accuracy: 0.6537 - val_loss: 1.1370 - val_accuracy: 0.8301\n",
      "Epoch 46/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 1.2145 - accuracy: 0.6618 - val_loss: 1.1237 - val_accuracy: 0.8447\n",
      "Epoch 47/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 1.1880 - accuracy: 0.6877 - val_loss: 1.1036 - val_accuracy: 0.8544\n",
      "Epoch 48/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 1.1702 - accuracy: 0.6780 - val_loss: 1.0819 - val_accuracy: 0.8544\n",
      "Epoch 49/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 1.1771 - accuracy: 0.6683 - val_loss: 1.0706 - val_accuracy: 0.8544\n",
      "Epoch 50/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 1.1314 - accuracy: 0.6893 - val_loss: 1.0519 - val_accuracy: 0.8641\n",
      "Epoch 51/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 1.1410 - accuracy: 0.6942 - val_loss: 1.0439 - val_accuracy: 0.8786\n",
      "Epoch 52/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 1.0912 - accuracy: 0.7184 - val_loss: 1.0207 - val_accuracy: 0.8398\n",
      "Epoch 53/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 1.1476 - accuracy: 0.6990 - val_loss: 1.0121 - val_accuracy: 0.8398\n",
      "Epoch 54/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 1.1233 - accuracy: 0.6958 - val_loss: 0.9973 - val_accuracy: 0.8835\n",
      "Epoch 55/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 1.0790 - accuracy: 0.7217 - val_loss: 0.9865 - val_accuracy: 0.8592\n",
      "Epoch 56/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618/618 [==============================] - 0s 55us/sample - loss: 1.0594 - accuracy: 0.7427 - val_loss: 0.9702 - val_accuracy: 0.8641\n",
      "Epoch 57/2000\n",
      "618/618 [==============================] - 0s 58us/sample - loss: 1.0509 - accuracy: 0.7476 - val_loss: 0.9528 - val_accuracy: 0.8835\n",
      "Epoch 58/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 1.0666 - accuracy: 0.7071 - val_loss: 0.9411 - val_accuracy: 0.8689\n",
      "Epoch 59/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 1.0472 - accuracy: 0.7282 - val_loss: 0.9312 - val_accuracy: 0.8689\n",
      "Epoch 60/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 1.0150 - accuracy: 0.7427 - val_loss: 0.9218 - val_accuracy: 0.8592\n",
      "Epoch 61/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 1.0163 - accuracy: 0.7427 - val_loss: 0.9068 - val_accuracy: 0.8689\n",
      "Epoch 62/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.9990 - accuracy: 0.7395 - val_loss: 0.8995 - val_accuracy: 0.8738\n",
      "Epoch 63/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.9777 - accuracy: 0.7751 - val_loss: 0.8829 - val_accuracy: 0.8738\n",
      "Epoch 64/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 1.0005 - accuracy: 0.7427 - val_loss: 0.8703 - val_accuracy: 0.8641\n",
      "Epoch 65/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.9560 - accuracy: 0.7492 - val_loss: 0.8586 - val_accuracy: 0.8786\n",
      "Epoch 66/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.9176 - accuracy: 0.7718 - val_loss: 0.8497 - val_accuracy: 0.8883\n",
      "Epoch 67/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.9880 - accuracy: 0.7233 - val_loss: 0.8495 - val_accuracy: 0.8738\n",
      "Epoch 68/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.9212 - accuracy: 0.7783 - val_loss: 0.8235 - val_accuracy: 0.8738\n",
      "Epoch 69/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.8999 - accuracy: 0.7880 - val_loss: 0.8218 - val_accuracy: 0.8592\n",
      "Epoch 70/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.8956 - accuracy: 0.7994 - val_loss: 0.8098 - val_accuracy: 0.8786\n",
      "Epoch 71/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.8860 - accuracy: 0.7880 - val_loss: 0.8031 - val_accuracy: 0.8786\n",
      "Epoch 72/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.9039 - accuracy: 0.7621 - val_loss: 0.7885 - val_accuracy: 0.8786\n",
      "Epoch 73/2000\n",
      "618/618 [==============================] - 0s 58us/sample - loss: 0.8864 - accuracy: 0.7589 - val_loss: 0.7792 - val_accuracy: 0.8883\n",
      "Epoch 74/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.8516 - accuracy: 0.7913 - val_loss: 0.7727 - val_accuracy: 0.8883\n",
      "Epoch 75/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.8090 - accuracy: 0.8155 - val_loss: 0.7584 - val_accuracy: 0.8786\n",
      "Epoch 76/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.8368 - accuracy: 0.7961 - val_loss: 0.7545 - val_accuracy: 0.8786\n",
      "Epoch 77/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.8573 - accuracy: 0.7508 - val_loss: 0.7472 - val_accuracy: 0.8786\n",
      "Epoch 78/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.8413 - accuracy: 0.8010 - val_loss: 0.7390 - val_accuracy: 0.8689\n",
      "Epoch 79/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.8491 - accuracy: 0.7913 - val_loss: 0.7345 - val_accuracy: 0.8738\n",
      "Epoch 80/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.8124 - accuracy: 0.8026 - val_loss: 0.7213 - val_accuracy: 0.8835\n",
      "Epoch 81/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.8240 - accuracy: 0.7913 - val_loss: 0.7219 - val_accuracy: 0.8835\n",
      "Epoch 82/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.7868 - accuracy: 0.8010 - val_loss: 0.7128 - val_accuracy: 0.8786\n",
      "Epoch 83/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.7977 - accuracy: 0.7994 - val_loss: 0.7106 - val_accuracy: 0.8786\n",
      "Epoch 84/2000\n",
      "618/618 [==============================] - 0s 58us/sample - loss: 0.7917 - accuracy: 0.8042 - val_loss: 0.7037 - val_accuracy: 0.8738\n",
      "Epoch 85/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.7724 - accuracy: 0.8398 - val_loss: 0.6975 - val_accuracy: 0.8786\n",
      "Epoch 86/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.7891 - accuracy: 0.7929 - val_loss: 0.6887 - val_accuracy: 0.8786\n",
      "Epoch 87/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.7485 - accuracy: 0.8172 - val_loss: 0.6777 - val_accuracy: 0.8738\n",
      "Epoch 88/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.7260 - accuracy: 0.8511 - val_loss: 0.6728 - val_accuracy: 0.8689\n",
      "Epoch 89/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.7459 - accuracy: 0.8172 - val_loss: 0.6674 - val_accuracy: 0.8786\n",
      "Epoch 90/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.7662 - accuracy: 0.8220 - val_loss: 0.6607 - val_accuracy: 0.8689\n",
      "Epoch 91/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.7539 - accuracy: 0.8172 - val_loss: 0.6581 - val_accuracy: 0.8786\n",
      "Epoch 92/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.7240 - accuracy: 0.8155 - val_loss: 0.6494 - val_accuracy: 0.8738\n",
      "Epoch 93/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.7124 - accuracy: 0.8269 - val_loss: 0.6445 - val_accuracy: 0.8738\n",
      "Epoch 94/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.7361 - accuracy: 0.8172 - val_loss: 0.6401 - val_accuracy: 0.8835\n",
      "Epoch 95/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.7204 - accuracy: 0.8301 - val_loss: 0.6301 - val_accuracy: 0.8835\n",
      "Epoch 96/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.6827 - accuracy: 0.8479 - val_loss: 0.6295 - val_accuracy: 0.8932\n",
      "Epoch 97/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.6698 - accuracy: 0.8398 - val_loss: 0.6308 - val_accuracy: 0.8835\n",
      "Epoch 98/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 0.7004 - accuracy: 0.8269 - val_loss: 0.6172 - val_accuracy: 0.8883\n",
      "Epoch 99/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.6877 - accuracy: 0.8463 - val_loss: 0.6153 - val_accuracy: 0.8738\n",
      "Epoch 100/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.7054 - accuracy: 0.8317 - val_loss: 0.6162 - val_accuracy: 0.8786\n",
      "Epoch 101/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.6704 - accuracy: 0.8463 - val_loss: 0.6087 - val_accuracy: 0.8835\n",
      "Epoch 102/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.6655 - accuracy: 0.8430 - val_loss: 0.6030 - val_accuracy: 0.8835\n",
      "Epoch 103/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.6841 - accuracy: 0.8366 - val_loss: 0.5942 - val_accuracy: 0.8883\n",
      "Epoch 104/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.6464 - accuracy: 0.8641 - val_loss: 0.5895 - val_accuracy: 0.8883\n",
      "Epoch 105/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.6555 - accuracy: 0.8252 - val_loss: 0.5787 - val_accuracy: 0.8883\n",
      "Epoch 106/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.6349 - accuracy: 0.8495 - val_loss: 0.5888 - val_accuracy: 0.8738\n",
      "Epoch 107/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.6593 - accuracy: 0.8350 - val_loss: 0.5761 - val_accuracy: 0.8835\n",
      "Epoch 108/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.6347 - accuracy: 0.8463 - val_loss: 0.5748 - val_accuracy: 0.8883\n",
      "Epoch 109/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.6404 - accuracy: 0.8414 - val_loss: 0.5718 - val_accuracy: 0.8835\n",
      "Epoch 110/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.6168 - accuracy: 0.8463 - val_loss: 0.5655 - val_accuracy: 0.8883\n",
      "Epoch 111/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618/618 [==============================] - 0s 56us/sample - loss: 0.6666 - accuracy: 0.8220 - val_loss: 0.5662 - val_accuracy: 0.8932\n",
      "Epoch 112/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.6124 - accuracy: 0.8544 - val_loss: 0.5610 - val_accuracy: 0.8932\n",
      "Epoch 113/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.6078 - accuracy: 0.8851 - val_loss: 0.5617 - val_accuracy: 0.8932\n",
      "Epoch 114/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.5873 - accuracy: 0.8641 - val_loss: 0.5505 - val_accuracy: 0.8835\n",
      "Epoch 115/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.6152 - accuracy: 0.8528 - val_loss: 0.5500 - val_accuracy: 0.8786\n",
      "Epoch 116/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.5938 - accuracy: 0.8738 - val_loss: 0.5472 - val_accuracy: 0.8835\n",
      "Epoch 117/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.6165 - accuracy: 0.8463 - val_loss: 0.5493 - val_accuracy: 0.8786\n",
      "Epoch 118/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.5745 - accuracy: 0.8803 - val_loss: 0.5376 - val_accuracy: 0.8883\n",
      "Epoch 119/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.5600 - accuracy: 0.8803 - val_loss: 0.5424 - val_accuracy: 0.8835\n",
      "Epoch 120/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.5826 - accuracy: 0.8657 - val_loss: 0.5305 - val_accuracy: 0.8835\n",
      "Epoch 121/2000\n",
      "618/618 [==============================] - 0s 58us/sample - loss: 0.5759 - accuracy: 0.8657 - val_loss: 0.5308 - val_accuracy: 0.8932\n",
      "Epoch 122/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.5731 - accuracy: 0.8528 - val_loss: 0.5322 - val_accuracy: 0.8786\n",
      "Epoch 123/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.5776 - accuracy: 0.8576 - val_loss: 0.5281 - val_accuracy: 0.8932\n",
      "Epoch 124/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.5668 - accuracy: 0.8786 - val_loss: 0.5320 - val_accuracy: 0.8883\n",
      "Epoch 125/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.5755 - accuracy: 0.8673 - val_loss: 0.5271 - val_accuracy: 0.8883\n",
      "Epoch 126/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.5823 - accuracy: 0.8528 - val_loss: 0.5183 - val_accuracy: 0.8932\n",
      "Epoch 127/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.5303 - accuracy: 0.8819 - val_loss: 0.5202 - val_accuracy: 0.8932\n",
      "Epoch 128/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.5681 - accuracy: 0.8657 - val_loss: 0.5108 - val_accuracy: 0.8981\n",
      "Epoch 129/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.5418 - accuracy: 0.8900 - val_loss: 0.5097 - val_accuracy: 0.8932\n",
      "Epoch 130/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.5487 - accuracy: 0.8803 - val_loss: 0.5072 - val_accuracy: 0.8883\n",
      "Epoch 131/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 0.5535 - accuracy: 0.8932 - val_loss: 0.5095 - val_accuracy: 0.8786\n",
      "Epoch 132/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.5386 - accuracy: 0.8819 - val_loss: 0.5070 - val_accuracy: 0.8932\n",
      "Epoch 133/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.5253 - accuracy: 0.8883 - val_loss: 0.5025 - val_accuracy: 0.8786\n",
      "Epoch 134/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.5310 - accuracy: 0.8803 - val_loss: 0.5002 - val_accuracy: 0.8883\n",
      "Epoch 135/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 0.5335 - accuracy: 0.8819 - val_loss: 0.4969 - val_accuracy: 0.8883\n",
      "Epoch 136/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.5316 - accuracy: 0.8738 - val_loss: 0.4980 - val_accuracy: 0.8883\n",
      "Epoch 137/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 0.5142 - accuracy: 0.8981 - val_loss: 0.5051 - val_accuracy: 0.8883\n",
      "Epoch 138/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.5231 - accuracy: 0.8770 - val_loss: 0.4890 - val_accuracy: 0.8883\n",
      "Epoch 139/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.5221 - accuracy: 0.8883 - val_loss: 0.4968 - val_accuracy: 0.8883\n",
      "Epoch 140/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.4880 - accuracy: 0.9110 - val_loss: 0.4933 - val_accuracy: 0.8883\n",
      "Epoch 141/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.5254 - accuracy: 0.8819 - val_loss: 0.4913 - val_accuracy: 0.8835\n",
      "Epoch 142/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.5167 - accuracy: 0.8867 - val_loss: 0.4870 - val_accuracy: 0.8883\n",
      "Epoch 143/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.5044 - accuracy: 0.8981 - val_loss: 0.4819 - val_accuracy: 0.8835\n",
      "Epoch 144/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 0.5124 - accuracy: 0.8900 - val_loss: 0.4884 - val_accuracy: 0.8835\n",
      "Epoch 145/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.5020 - accuracy: 0.8883 - val_loss: 0.4807 - val_accuracy: 0.8835\n",
      "Epoch 146/2000\n",
      "618/618 [==============================] - 0s 59us/sample - loss: 0.4956 - accuracy: 0.9029 - val_loss: 0.4811 - val_accuracy: 0.8883\n",
      "Epoch 147/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.4957 - accuracy: 0.8819 - val_loss: 0.4832 - val_accuracy: 0.8932\n",
      "Epoch 148/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.4984 - accuracy: 0.8883 - val_loss: 0.4809 - val_accuracy: 0.8835\n",
      "Epoch 149/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.5177 - accuracy: 0.8657 - val_loss: 0.4777 - val_accuracy: 0.8883\n",
      "Epoch 150/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 0.4783 - accuracy: 0.9061 - val_loss: 0.4748 - val_accuracy: 0.8883\n",
      "Epoch 151/2000\n",
      "618/618 [==============================] - 0s 60us/sample - loss: 0.4633 - accuracy: 0.8916 - val_loss: 0.4790 - val_accuracy: 0.8932\n",
      "Epoch 152/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.4743 - accuracy: 0.9061 - val_loss: 0.4724 - val_accuracy: 0.8883\n",
      "Epoch 153/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.4808 - accuracy: 0.8916 - val_loss: 0.4735 - val_accuracy: 0.8932\n",
      "Epoch 154/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.4947 - accuracy: 0.8948 - val_loss: 0.4619 - val_accuracy: 0.8932\n",
      "Epoch 155/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.5021 - accuracy: 0.8738 - val_loss: 0.4763 - val_accuracy: 0.8932\n",
      "Epoch 156/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.4821 - accuracy: 0.8916 - val_loss: 0.4666 - val_accuracy: 0.8883\n",
      "Epoch 157/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.4615 - accuracy: 0.9159 - val_loss: 0.4612 - val_accuracy: 0.8883\n",
      "Epoch 158/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.4667 - accuracy: 0.9078 - val_loss: 0.4603 - val_accuracy: 0.8883\n",
      "Epoch 159/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.4702 - accuracy: 0.8981 - val_loss: 0.4707 - val_accuracy: 0.8932\n",
      "Epoch 160/2000\n",
      "618/618 [==============================] - 0s 60us/sample - loss: 0.4825 - accuracy: 0.8867 - val_loss: 0.4648 - val_accuracy: 0.8883\n",
      "Epoch 161/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.4475 - accuracy: 0.9142 - val_loss: 0.4560 - val_accuracy: 0.8883\n",
      "Epoch 162/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.4626 - accuracy: 0.8981 - val_loss: 0.4540 - val_accuracy: 0.8883\n",
      "Epoch 163/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.4467 - accuracy: 0.9207 - val_loss: 0.4529 - val_accuracy: 0.8883\n",
      "Epoch 164/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.4561 - accuracy: 0.8981 - val_loss: 0.4536 - val_accuracy: 0.8883\n",
      "Epoch 165/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.4223 - accuracy: 0.9288 - val_loss: 0.4607 - val_accuracy: 0.8932\n",
      "Epoch 166/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618/618 [==============================] - 0s 56us/sample - loss: 0.4495 - accuracy: 0.9094 - val_loss: 0.4543 - val_accuracy: 0.8883\n",
      "Epoch 167/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.4610 - accuracy: 0.8964 - val_loss: 0.4533 - val_accuracy: 0.9029\n",
      "Epoch 168/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.4392 - accuracy: 0.9078 - val_loss: 0.4461 - val_accuracy: 0.8883\n",
      "Epoch 169/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.4633 - accuracy: 0.8900 - val_loss: 0.4467 - val_accuracy: 0.8932\n",
      "Epoch 170/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.4455 - accuracy: 0.9029 - val_loss: 0.4539 - val_accuracy: 0.8835\n",
      "Epoch 171/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.4471 - accuracy: 0.8916 - val_loss: 0.4395 - val_accuracy: 0.8932\n",
      "Epoch 172/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.4633 - accuracy: 0.9045 - val_loss: 0.4507 - val_accuracy: 0.8932\n",
      "Epoch 173/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.4481 - accuracy: 0.9013 - val_loss: 0.4476 - val_accuracy: 0.8932\n",
      "Epoch 174/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.4321 - accuracy: 0.9045 - val_loss: 0.4471 - val_accuracy: 0.8883\n",
      "Epoch 175/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.4275 - accuracy: 0.9078 - val_loss: 0.4565 - val_accuracy: 0.8981\n",
      "Epoch 176/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.4300 - accuracy: 0.9061 - val_loss: 0.4470 - val_accuracy: 0.8932\n",
      "Epoch 177/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.4464 - accuracy: 0.8981 - val_loss: 0.4432 - val_accuracy: 0.8883\n",
      "Epoch 178/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.4336 - accuracy: 0.9142 - val_loss: 0.4413 - val_accuracy: 0.8932\n",
      "Epoch 179/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.4289 - accuracy: 0.9045 - val_loss: 0.4350 - val_accuracy: 0.8981\n",
      "Epoch 180/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.4231 - accuracy: 0.9061 - val_loss: 0.4331 - val_accuracy: 0.8981\n",
      "Epoch 181/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.4099 - accuracy: 0.9126 - val_loss: 0.4404 - val_accuracy: 0.8981\n",
      "Epoch 182/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.4337 - accuracy: 0.8997 - val_loss: 0.4449 - val_accuracy: 0.8981\n",
      "Epoch 183/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.4148 - accuracy: 0.9110 - val_loss: 0.4406 - val_accuracy: 0.8932\n",
      "Epoch 184/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.3921 - accuracy: 0.9272 - val_loss: 0.4314 - val_accuracy: 0.8932\n",
      "Epoch 185/2000\n",
      "618/618 [==============================] - 0s 59us/sample - loss: 0.4145 - accuracy: 0.9078 - val_loss: 0.4357 - val_accuracy: 0.8981\n",
      "Epoch 186/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.4334 - accuracy: 0.8997 - val_loss: 0.4274 - val_accuracy: 0.8932\n",
      "Epoch 187/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.4193 - accuracy: 0.9223 - val_loss: 0.4264 - val_accuracy: 0.8932\n",
      "Epoch 188/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.4229 - accuracy: 0.9061 - val_loss: 0.4298 - val_accuracy: 0.8981\n",
      "Epoch 189/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.4082 - accuracy: 0.9126 - val_loss: 0.4446 - val_accuracy: 0.8981\n",
      "Epoch 190/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.3757 - accuracy: 0.9385 - val_loss: 0.4251 - val_accuracy: 0.8932\n",
      "Epoch 191/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.4089 - accuracy: 0.9272 - val_loss: 0.4273 - val_accuracy: 0.8883\n",
      "Epoch 192/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.3936 - accuracy: 0.9223 - val_loss: 0.4223 - val_accuracy: 0.8932\n",
      "Epoch 193/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.3895 - accuracy: 0.9142 - val_loss: 0.4188 - val_accuracy: 0.8981\n",
      "Epoch 194/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.4025 - accuracy: 0.9239 - val_loss: 0.4232 - val_accuracy: 0.8981\n",
      "Epoch 195/2000\n",
      "618/618 [==============================] - 0s 91us/sample - loss: 0.4053 - accuracy: 0.9061 - val_loss: 0.4351 - val_accuracy: 0.8932\n",
      "Epoch 196/2000\n",
      "618/618 [==============================] - 0s 91us/sample - loss: 0.4135 - accuracy: 0.9110 - val_loss: 0.4252 - val_accuracy: 0.8932\n",
      "Epoch 197/2000\n",
      "618/618 [==============================] - 0s 94us/sample - loss: 0.4045 - accuracy: 0.9110 - val_loss: 0.4286 - val_accuracy: 0.8981\n",
      "Epoch 198/2000\n",
      "618/618 [==============================] - 0s 84us/sample - loss: 0.3991 - accuracy: 0.9159 - val_loss: 0.4352 - val_accuracy: 0.8981\n",
      "Epoch 199/2000\n",
      "618/618 [==============================] - 0s 80us/sample - loss: 0.3866 - accuracy: 0.9239 - val_loss: 0.4275 - val_accuracy: 0.8932\n",
      "Epoch 200/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.4087 - accuracy: 0.9207 - val_loss: 0.4295 - val_accuracy: 0.8932\n",
      "Epoch 201/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.4012 - accuracy: 0.9142 - val_loss: 0.4267 - val_accuracy: 0.8932\n",
      "Epoch 202/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.3830 - accuracy: 0.9159 - val_loss: 0.4239 - val_accuracy: 0.8981\n",
      "Epoch 203/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.4205 - accuracy: 0.8997 - val_loss: 0.4197 - val_accuracy: 0.8932\n",
      "Epoch 204/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.3930 - accuracy: 0.9175 - val_loss: 0.4297 - val_accuracy: 0.8981\n",
      "Epoch 205/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.4084 - accuracy: 0.9239 - val_loss: 0.4199 - val_accuracy: 0.8932\n",
      "Epoch 206/2000\n",
      "618/618 [==============================] - 0s 60us/sample - loss: 0.3768 - accuracy: 0.9256 - val_loss: 0.4167 - val_accuracy: 0.8981\n",
      "Epoch 207/2000\n",
      "618/618 [==============================] - 0s 74us/sample - loss: 0.3862 - accuracy: 0.9239 - val_loss: 0.4097 - val_accuracy: 0.8981\n",
      "Epoch 208/2000\n",
      "618/618 [==============================] - 0s 69us/sample - loss: 0.4018 - accuracy: 0.9110 - val_loss: 0.4232 - val_accuracy: 0.8932\n",
      "Epoch 209/2000\n",
      "618/618 [==============================] - 0s 83us/sample - loss: 0.3823 - accuracy: 0.9191 - val_loss: 0.4207 - val_accuracy: 0.8932\n",
      "Epoch 210/2000\n",
      "618/618 [==============================] - 0s 82us/sample - loss: 0.3802 - accuracy: 0.9320 - val_loss: 0.4196 - val_accuracy: 0.8932\n",
      "Epoch 211/2000\n",
      "618/618 [==============================] - 0s 75us/sample - loss: 0.3756 - accuracy: 0.9385 - val_loss: 0.4169 - val_accuracy: 0.8932\n",
      "Epoch 212/2000\n",
      "618/618 [==============================] - 0s 83us/sample - loss: 0.3691 - accuracy: 0.9320 - val_loss: 0.4126 - val_accuracy: 0.8932\n",
      "Epoch 213/2000\n",
      "618/618 [==============================] - 0s 63us/sample - loss: 0.3701 - accuracy: 0.9304 - val_loss: 0.4069 - val_accuracy: 0.8932\n",
      "Epoch 214/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.3843 - accuracy: 0.9239 - val_loss: 0.4104 - val_accuracy: 0.8981\n",
      "Epoch 215/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.3679 - accuracy: 0.9337 - val_loss: 0.4201 - val_accuracy: 0.8932\n",
      "Epoch 216/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.3672 - accuracy: 0.9207 - val_loss: 0.4214 - val_accuracy: 0.8932\n",
      "Epoch 217/2000\n",
      "618/618 [==============================] - 0s 45us/sample - loss: 0.3706 - accuracy: 0.9353 - val_loss: 0.4101 - val_accuracy: 0.8981\n",
      "Epoch 218/2000\n",
      "618/618 [==============================] - 0s 47us/sample - loss: 0.3678 - accuracy: 0.9239 - val_loss: 0.4162 - val_accuracy: 0.8932\n",
      "Epoch 219/2000\n",
      "618/618 [==============================] - 0s 60us/sample - loss: 0.3674 - accuracy: 0.9175 - val_loss: 0.4113 - val_accuracy: 0.8981\n",
      "Epoch 220/2000\n",
      "618/618 [==============================] - 0s 48us/sample - loss: 0.3785 - accuracy: 0.9078 - val_loss: 0.4102 - val_accuracy: 0.8981\n",
      "Epoch 221/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618/618 [==============================] - 0s 51us/sample - loss: 0.3713 - accuracy: 0.9320 - val_loss: 0.4044 - val_accuracy: 0.8981\n",
      "Epoch 222/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.3803 - accuracy: 0.9110 - val_loss: 0.4199 - val_accuracy: 0.8981\n",
      "Epoch 223/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.3709 - accuracy: 0.9304 - val_loss: 0.4155 - val_accuracy: 0.8932\n",
      "Epoch 224/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.3545 - accuracy: 0.9320 - val_loss: 0.4196 - val_accuracy: 0.8932\n",
      "Epoch 225/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.3683 - accuracy: 0.9288 - val_loss: 0.4118 - val_accuracy: 0.8981\n",
      "Epoch 226/2000\n",
      "618/618 [==============================] - 0s 48us/sample - loss: 0.3753 - accuracy: 0.9320 - val_loss: 0.4067 - val_accuracy: 0.8932\n",
      "Epoch 227/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.3587 - accuracy: 0.9272 - val_loss: 0.4066 - val_accuracy: 0.8932\n",
      "Epoch 228/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.3315 - accuracy: 0.9369 - val_loss: 0.4121 - val_accuracy: 0.8981\n",
      "Epoch 229/2000\n",
      "618/618 [==============================] - 0s 81us/sample - loss: 0.3449 - accuracy: 0.9191 - val_loss: 0.4032 - val_accuracy: 0.8981\n",
      "Epoch 230/2000\n",
      "618/618 [==============================] - 0s 95us/sample - loss: 0.3618 - accuracy: 0.9320 - val_loss: 0.4022 - val_accuracy: 0.8981\n",
      "Epoch 231/2000\n",
      "618/618 [==============================] - 0s 90us/sample - loss: 0.3670 - accuracy: 0.9223 - val_loss: 0.4027 - val_accuracy: 0.8981\n",
      "Epoch 232/2000\n",
      "618/618 [==============================] - 0s 80us/sample - loss: 0.3555 - accuracy: 0.9353 - val_loss: 0.4021 - val_accuracy: 0.9029\n",
      "Epoch 233/2000\n",
      "618/618 [==============================] - 0s 77us/sample - loss: 0.3602 - accuracy: 0.9223 - val_loss: 0.4075 - val_accuracy: 0.8981\n",
      "Epoch 234/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.3536 - accuracy: 0.9337 - val_loss: 0.4031 - val_accuracy: 0.8981\n",
      "Epoch 235/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.3317 - accuracy: 0.9466 - val_loss: 0.3975 - val_accuracy: 0.8981\n",
      "Epoch 236/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.3417 - accuracy: 0.9353 - val_loss: 0.4140 - val_accuracy: 0.8981\n",
      "Epoch 237/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 0.3720 - accuracy: 0.9159 - val_loss: 0.4058 - val_accuracy: 0.8981\n",
      "Epoch 238/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.3432 - accuracy: 0.9337 - val_loss: 0.4064 - val_accuracy: 0.8981\n",
      "Epoch 239/2000\n",
      "618/618 [==============================] - 0s 65us/sample - loss: 0.3506 - accuracy: 0.9207 - val_loss: 0.4072 - val_accuracy: 0.8981\n",
      "Epoch 240/2000\n",
      "618/618 [==============================] - 0s 83us/sample - loss: 0.3512 - accuracy: 0.9256 - val_loss: 0.4031 - val_accuracy: 0.9029\n",
      "Epoch 241/2000\n",
      "618/618 [==============================] - 0s 76us/sample - loss: 0.3581 - accuracy: 0.9337 - val_loss: 0.4066 - val_accuracy: 0.9029\n",
      "Epoch 242/2000\n",
      "618/618 [==============================] - 0s 79us/sample - loss: 0.3410 - accuracy: 0.9320 - val_loss: 0.3997 - val_accuracy: 0.8981\n",
      "Epoch 243/2000\n",
      "618/618 [==============================] - 0s 73us/sample - loss: 0.3373 - accuracy: 0.9369 - val_loss: 0.4025 - val_accuracy: 0.8981\n",
      "Epoch 244/2000\n",
      "618/618 [==============================] - 0s 48us/sample - loss: 0.3589 - accuracy: 0.9401 - val_loss: 0.4060 - val_accuracy: 0.9029\n",
      "Epoch 245/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.3473 - accuracy: 0.9320 - val_loss: 0.4077 - val_accuracy: 0.8981\n",
      "Epoch 246/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.3387 - accuracy: 0.9272 - val_loss: 0.4017 - val_accuracy: 0.9029\n",
      "Epoch 247/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.3497 - accuracy: 0.9175 - val_loss: 0.4065 - val_accuracy: 0.8981\n",
      "Epoch 248/2000\n",
      "618/618 [==============================] - 0s 58us/sample - loss: 0.3370 - accuracy: 0.9353 - val_loss: 0.4023 - val_accuracy: 0.9029\n",
      "Epoch 249/2000\n",
      "618/618 [==============================] - 0s 75us/sample - loss: 0.3247 - accuracy: 0.9272 - val_loss: 0.4103 - val_accuracy: 0.8981\n",
      "Epoch 250/2000\n",
      "618/618 [==============================] - 0s 87us/sample - loss: 0.3219 - accuracy: 0.9385 - val_loss: 0.3962 - val_accuracy: 0.9029\n",
      "Epoch 251/2000\n",
      "618/618 [==============================] - 0s 85us/sample - loss: 0.3527 - accuracy: 0.9304 - val_loss: 0.3953 - val_accuracy: 0.8981\n",
      "Epoch 252/2000\n",
      "618/618 [==============================] - 0s 90us/sample - loss: 0.3472 - accuracy: 0.9353 - val_loss: 0.4023 - val_accuracy: 0.9029\n",
      "Epoch 253/2000\n",
      "618/618 [==============================] - 0s 87us/sample - loss: 0.3488 - accuracy: 0.9223 - val_loss: 0.3966 - val_accuracy: 0.9029\n",
      "Epoch 254/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.3223 - accuracy: 0.9337 - val_loss: 0.3969 - val_accuracy: 0.9029\n",
      "Epoch 255/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.3445 - accuracy: 0.9320 - val_loss: 0.3993 - val_accuracy: 0.8981\n",
      "Epoch 256/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.3265 - accuracy: 0.9385 - val_loss: 0.3934 - val_accuracy: 0.8981\n",
      "Epoch 257/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.3312 - accuracy: 0.9369 - val_loss: 0.3853 - val_accuracy: 0.8981\n",
      "Epoch 258/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.3353 - accuracy: 0.9288 - val_loss: 0.3920 - val_accuracy: 0.8981\n",
      "Epoch 259/2000\n",
      "618/618 [==============================] - 0s 62us/sample - loss: 0.3187 - accuracy: 0.9353 - val_loss: 0.3931 - val_accuracy: 0.8981\n",
      "Epoch 260/2000\n",
      "618/618 [==============================] - 0s 90us/sample - loss: 0.3039 - accuracy: 0.9547 - val_loss: 0.3921 - val_accuracy: 0.8981\n",
      "Epoch 261/2000\n",
      "618/618 [==============================] - 0s 85us/sample - loss: 0.3138 - accuracy: 0.9385 - val_loss: 0.4043 - val_accuracy: 0.8981\n",
      "Epoch 262/2000\n",
      "618/618 [==============================] - 0s 81us/sample - loss: 0.3154 - accuracy: 0.9450 - val_loss: 0.4001 - val_accuracy: 0.9029\n",
      "Epoch 263/2000\n",
      "618/618 [==============================] - 0s 79us/sample - loss: 0.3275 - accuracy: 0.9417 - val_loss: 0.3940 - val_accuracy: 0.8981\n",
      "Epoch 264/2000\n",
      "618/618 [==============================] - 0s 66us/sample - loss: 0.3085 - accuracy: 0.9450 - val_loss: 0.3980 - val_accuracy: 0.9029\n",
      "Epoch 265/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.3335 - accuracy: 0.9337 - val_loss: 0.3956 - val_accuracy: 0.8981\n",
      "Epoch 266/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.3096 - accuracy: 0.9482 - val_loss: 0.3895 - val_accuracy: 0.8981\n",
      "Epoch 267/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.3238 - accuracy: 0.9369 - val_loss: 0.3917 - val_accuracy: 0.8981\n",
      "Epoch 268/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.3321 - accuracy: 0.9337 - val_loss: 0.3959 - val_accuracy: 0.9029\n",
      "Epoch 269/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.3234 - accuracy: 0.9369 - val_loss: 0.4013 - val_accuracy: 0.9029\n",
      "Epoch 270/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.3127 - accuracy: 0.9417 - val_loss: 0.4032 - val_accuracy: 0.9029\n",
      "Epoch 271/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.3214 - accuracy: 0.9353 - val_loss: 0.4004 - val_accuracy: 0.8981\n",
      "Epoch 272/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.3206 - accuracy: 0.9320 - val_loss: 0.3972 - val_accuracy: 0.9029\n",
      "Epoch 273/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.2942 - accuracy: 0.9466 - val_loss: 0.4038 - val_accuracy: 0.9029\n",
      "Epoch 274/2000\n",
      "618/618 [==============================] - 0s 58us/sample - loss: 0.3137 - accuracy: 0.9434 - val_loss: 0.4043 - val_accuracy: 0.9029\n",
      "Epoch 275/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.3108 - accuracy: 0.9401 - val_loss: 0.3940 - val_accuracy: 0.9029\n",
      "Epoch 276/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618/618 [==============================] - 0s 49us/sample - loss: 0.3086 - accuracy: 0.9401 - val_loss: 0.3954 - val_accuracy: 0.8981\n",
      "Epoch 277/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.3042 - accuracy: 0.9417 - val_loss: 0.4054 - val_accuracy: 0.8981\n",
      "Epoch 278/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.3224 - accuracy: 0.9256 - val_loss: 0.3932 - val_accuracy: 0.9029\n",
      "Epoch 279/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.3076 - accuracy: 0.9320 - val_loss: 0.3917 - val_accuracy: 0.9029\n",
      "Epoch 280/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.3108 - accuracy: 0.9401 - val_loss: 0.3934 - val_accuracy: 0.9029\n",
      "Epoch 281/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.3197 - accuracy: 0.9304 - val_loss: 0.3996 - val_accuracy: 0.9029\n",
      "Epoch 282/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.3350 - accuracy: 0.9126 - val_loss: 0.3982 - val_accuracy: 0.9029\n",
      "Epoch 283/2000\n",
      "618/618 [==============================] - 0s 83us/sample - loss: 0.3222 - accuracy: 0.9207 - val_loss: 0.3930 - val_accuracy: 0.9029\n",
      "Epoch 284/2000\n",
      "618/618 [==============================] - 0s 81us/sample - loss: 0.3163 - accuracy: 0.9353 - val_loss: 0.3954 - val_accuracy: 0.9029\n",
      "Epoch 285/2000\n",
      "618/618 [==============================] - 0s 80us/sample - loss: 0.3045 - accuracy: 0.9466 - val_loss: 0.4020 - val_accuracy: 0.9029\n",
      "Epoch 286/2000\n",
      "618/618 [==============================] - 0s 81us/sample - loss: 0.3100 - accuracy: 0.9434 - val_loss: 0.3880 - val_accuracy: 0.8981\n",
      "Epoch 287/2000\n",
      "618/618 [==============================] - 0s 77us/sample - loss: 0.3213 - accuracy: 0.9320 - val_loss: 0.3897 - val_accuracy: 0.8981\n",
      "Epoch 288/2000\n",
      "618/618 [==============================] - 0s 74us/sample - loss: 0.3122 - accuracy: 0.9434 - val_loss: 0.3883 - val_accuracy: 0.8981\n",
      "Epoch 289/2000\n",
      "618/618 [==============================] - 0s 80us/sample - loss: 0.3049 - accuracy: 0.9466 - val_loss: 0.3884 - val_accuracy: 0.8981\n",
      "Epoch 290/2000\n",
      "618/618 [==============================] - 0s 76us/sample - loss: 0.2868 - accuracy: 0.9498 - val_loss: 0.3871 - val_accuracy: 0.9029\n",
      "Epoch 291/2000\n",
      "618/618 [==============================] - 0s 72us/sample - loss: 0.3224 - accuracy: 0.9369 - val_loss: 0.3827 - val_accuracy: 0.9029\n",
      "Epoch 292/2000\n",
      "618/618 [==============================] - 0s 77us/sample - loss: 0.3195 - accuracy: 0.9369 - val_loss: 0.3859 - val_accuracy: 0.9029\n",
      "Epoch 293/2000\n",
      "618/618 [==============================] - 0s 76us/sample - loss: 0.3006 - accuracy: 0.9434 - val_loss: 0.3878 - val_accuracy: 0.9029\n",
      "Epoch 294/2000\n",
      "618/618 [==============================] - 0s 78us/sample - loss: 0.2970 - accuracy: 0.9466 - val_loss: 0.3935 - val_accuracy: 0.9029\n",
      "Epoch 295/2000\n",
      "618/618 [==============================] - 0s 76us/sample - loss: 0.3144 - accuracy: 0.9401 - val_loss: 0.3874 - val_accuracy: 0.9029\n",
      "Epoch 296/2000\n",
      "618/618 [==============================] - 0s 83us/sample - loss: 0.3040 - accuracy: 0.9434 - val_loss: 0.3929 - val_accuracy: 0.8981\n",
      "Epoch 297/2000\n",
      "618/618 [==============================] - 0s 71us/sample - loss: 0.2961 - accuracy: 0.9353 - val_loss: 0.3948 - val_accuracy: 0.9029\n",
      "Epoch 298/2000\n",
      "618/618 [==============================] - 0s 86us/sample - loss: 0.2943 - accuracy: 0.9515 - val_loss: 0.3913 - val_accuracy: 0.8981\n",
      "Epoch 299/2000\n",
      "618/618 [==============================] - 0s 86us/sample - loss: 0.3113 - accuracy: 0.9417 - val_loss: 0.3927 - val_accuracy: 0.9029\n",
      "Epoch 300/2000\n",
      "618/618 [==============================] - 0s 76us/sample - loss: 0.3132 - accuracy: 0.9482 - val_loss: 0.4022 - val_accuracy: 0.8981\n",
      "Epoch 301/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.3089 - accuracy: 0.9434 - val_loss: 0.3978 - val_accuracy: 0.8981\n",
      "Epoch 302/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.3010 - accuracy: 0.9434 - val_loss: 0.3955 - val_accuracy: 0.9029\n",
      "Epoch 303/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.2881 - accuracy: 0.9450 - val_loss: 0.3846 - val_accuracy: 0.9029\n",
      "Epoch 304/2000\n",
      "618/618 [==============================] - 0s 58us/sample - loss: 0.2937 - accuracy: 0.9401 - val_loss: 0.3821 - val_accuracy: 0.8981\n",
      "Epoch 305/2000\n",
      "618/618 [==============================] - 0s 61us/sample - loss: 0.2908 - accuracy: 0.9466 - val_loss: 0.3874 - val_accuracy: 0.8981\n",
      "Epoch 306/2000\n",
      "618/618 [==============================] - 0s 59us/sample - loss: 0.3027 - accuracy: 0.9434 - val_loss: 0.3865 - val_accuracy: 0.9029\n",
      "Epoch 307/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.2963 - accuracy: 0.9482 - val_loss: 0.3896 - val_accuracy: 0.9029\n",
      "Epoch 308/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.2923 - accuracy: 0.9531 - val_loss: 0.3919 - val_accuracy: 0.9029\n",
      "Epoch 309/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.3037 - accuracy: 0.9417 - val_loss: 0.3877 - val_accuracy: 0.9029\n",
      "Epoch 310/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.2938 - accuracy: 0.9450 - val_loss: 0.3893 - val_accuracy: 0.9029\n",
      "Epoch 311/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.2977 - accuracy: 0.9223 - val_loss: 0.3939 - val_accuracy: 0.9029\n",
      "Epoch 312/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.3027 - accuracy: 0.9466 - val_loss: 0.3872 - val_accuracy: 0.9029\n",
      "Epoch 313/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.2836 - accuracy: 0.9498 - val_loss: 0.3922 - val_accuracy: 0.9029\n",
      "Epoch 314/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.2941 - accuracy: 0.9434 - val_loss: 0.4015 - val_accuracy: 0.9029\n",
      "Epoch 315/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.3096 - accuracy: 0.9337 - val_loss: 0.3824 - val_accuracy: 0.8981\n",
      "Epoch 316/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.2844 - accuracy: 0.9385 - val_loss: 0.3793 - val_accuracy: 0.8981\n",
      "Epoch 317/2000\n",
      "618/618 [==============================] - 0s 44us/sample - loss: 0.2851 - accuracy: 0.9482 - val_loss: 0.3766 - val_accuracy: 0.8981\n",
      "Epoch 318/2000\n",
      "618/618 [==============================] - 0s 47us/sample - loss: 0.2752 - accuracy: 0.9563 - val_loss: 0.3879 - val_accuracy: 0.9029\n",
      "Epoch 319/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.2712 - accuracy: 0.9547 - val_loss: 0.3880 - val_accuracy: 0.9029\n",
      "Epoch 320/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.2892 - accuracy: 0.9417 - val_loss: 0.3972 - val_accuracy: 0.9029\n",
      "Epoch 321/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.2854 - accuracy: 0.9353 - val_loss: 0.3964 - val_accuracy: 0.9029\n",
      "Epoch 322/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.2866 - accuracy: 0.9385 - val_loss: 0.3866 - val_accuracy: 0.9029\n",
      "Epoch 323/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.2778 - accuracy: 0.9515 - val_loss: 0.3936 - val_accuracy: 0.9029\n",
      "Epoch 324/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.2856 - accuracy: 0.9450 - val_loss: 0.3858 - val_accuracy: 0.9078\n",
      "Epoch 325/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.2870 - accuracy: 0.9498 - val_loss: 0.3887 - val_accuracy: 0.8981\n",
      "Epoch 326/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.2797 - accuracy: 0.9498 - val_loss: 0.3841 - val_accuracy: 0.8981\n",
      "Epoch 327/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.2810 - accuracy: 0.9450 - val_loss: 0.3813 - val_accuracy: 0.8981\n",
      "Epoch 328/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.2707 - accuracy: 0.9547 - val_loss: 0.3904 - val_accuracy: 0.8981\n",
      "Epoch 329/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.3026 - accuracy: 0.9337 - val_loss: 0.3931 - val_accuracy: 0.9029\n",
      "Epoch 330/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.2624 - accuracy: 0.9515 - val_loss: 0.3883 - val_accuracy: 0.9029\n",
      "Epoch 331/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618/618 [==============================] - 0s 51us/sample - loss: 0.2748 - accuracy: 0.9482 - val_loss: 0.3920 - val_accuracy: 0.9029\n",
      "Epoch 332/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.3027 - accuracy: 0.9369 - val_loss: 0.3883 - val_accuracy: 0.9029\n",
      "Epoch 333/2000\n",
      "618/618 [==============================] - 0s 48us/sample - loss: 0.2879 - accuracy: 0.9417 - val_loss: 0.3968 - val_accuracy: 0.8981\n",
      "Epoch 334/2000\n",
      "618/618 [==============================] - 0s 58us/sample - loss: 0.2928 - accuracy: 0.9401 - val_loss: 0.3904 - val_accuracy: 0.9078\n",
      "Epoch 335/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.2753 - accuracy: 0.9482 - val_loss: 0.3809 - val_accuracy: 0.9029\n",
      "Epoch 336/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 0.2671 - accuracy: 0.9612 - val_loss: 0.3818 - val_accuracy: 0.8981\n",
      "Epoch 337/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.2866 - accuracy: 0.9498 - val_loss: 0.4003 - val_accuracy: 0.9029\n",
      "Epoch 338/2000\n",
      "618/618 [==============================] - 0s 53us/sample - loss: 0.2679 - accuracy: 0.9595 - val_loss: 0.3883 - val_accuracy: 0.9029\n",
      "Epoch 339/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.2967 - accuracy: 0.9401 - val_loss: 0.3846 - val_accuracy: 0.9029\n",
      "Epoch 340/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.2794 - accuracy: 0.9466 - val_loss: 0.3949 - val_accuracy: 0.9078\n",
      "Epoch 341/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.2813 - accuracy: 0.9417 - val_loss: 0.3792 - val_accuracy: 0.9029\n",
      "Epoch 342/2000\n",
      "618/618 [==============================] - 0s 50us/sample - loss: 0.2792 - accuracy: 0.9498 - val_loss: 0.3802 - val_accuracy: 0.8981\n",
      "Epoch 343/2000\n",
      "618/618 [==============================] - 0s 54us/sample - loss: 0.2892 - accuracy: 0.9385 - val_loss: 0.3842 - val_accuracy: 0.9029\n",
      "Epoch 344/2000\n",
      "618/618 [==============================] - 0s 49us/sample - loss: 0.2797 - accuracy: 0.9450 - val_loss: 0.3867 - val_accuracy: 0.9029\n",
      "Epoch 345/2000\n",
      "618/618 [==============================] - 0s 45us/sample - loss: 0.2689 - accuracy: 0.9466 - val_loss: 0.3856 - val_accuracy: 0.9029\n",
      "Epoch 346/2000\n",
      "618/618 [==============================] - 0s 47us/sample - loss: 0.2667 - accuracy: 0.9531 - val_loss: 0.3909 - val_accuracy: 0.9029\n",
      "Epoch 347/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 0.2878 - accuracy: 0.9434 - val_loss: 0.3872 - val_accuracy: 0.9078\n",
      "Epoch 348/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 0.2486 - accuracy: 0.9644 - val_loss: 0.3874 - val_accuracy: 0.9029\n",
      "Epoch 349/2000\n",
      "618/618 [==============================] - 0s 46us/sample - loss: 0.2606 - accuracy: 0.9547 - val_loss: 0.3820 - val_accuracy: 0.9078\n",
      "Epoch 350/2000\n",
      "618/618 [==============================] - 0s 47us/sample - loss: 0.2702 - accuracy: 0.9498 - val_loss: 0.3873 - val_accuracy: 0.9078\n",
      "Epoch 351/2000\n",
      "618/618 [==============================] - 0s 52us/sample - loss: 0.2770 - accuracy: 0.9369 - val_loss: 0.3869 - val_accuracy: 0.9029\n",
      "Epoch 352/2000\n",
      "618/618 [==============================] - 0s 48us/sample - loss: 0.2693 - accuracy: 0.9466 - val_loss: 0.3981 - val_accuracy: 0.9078\n",
      "Epoch 353/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.2894 - accuracy: 0.9498 - val_loss: 0.3800 - val_accuracy: 0.8981\n",
      "Epoch 354/2000\n",
      "618/618 [==============================] - 0s 45us/sample - loss: 0.2733 - accuracy: 0.9434 - val_loss: 0.3895 - val_accuracy: 0.9078\n",
      "Epoch 355/2000\n",
      "618/618 [==============================] - 0s 45us/sample - loss: 0.2757 - accuracy: 0.9450 - val_loss: 0.3970 - val_accuracy: 0.9078\n",
      "Epoch 356/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.2730 - accuracy: 0.9434 - val_loss: 0.3917 - val_accuracy: 0.9078\n",
      "Epoch 357/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 0.2660 - accuracy: 0.9498 - val_loss: 0.3784 - val_accuracy: 0.9029\n",
      "Epoch 358/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 0.2792 - accuracy: 0.9466 - val_loss: 0.3824 - val_accuracy: 0.9029\n",
      "Epoch 359/2000\n",
      "618/618 [==============================] - 0s 58us/sample - loss: 0.2698 - accuracy: 0.9531 - val_loss: 0.3819 - val_accuracy: 0.9078\n",
      "Epoch 360/2000\n",
      "618/618 [==============================] - 0s 51us/sample - loss: 0.2820 - accuracy: 0.9515 - val_loss: 0.3778 - val_accuracy: 0.9029\n",
      "Epoch 361/2000\n",
      "618/618 [==============================] - 0s 45us/sample - loss: 0.2591 - accuracy: 0.9515 - val_loss: 0.3853 - val_accuracy: 0.9078\n",
      "Epoch 362/2000\n",
      "618/618 [==============================] - 0s 46us/sample - loss: 0.2522 - accuracy: 0.9563 - val_loss: 0.3943 - val_accuracy: 0.9029\n",
      "Epoch 363/2000\n",
      "618/618 [==============================] - 0s 55us/sample - loss: 0.2594 - accuracy: 0.9612 - val_loss: 0.3827 - val_accuracy: 0.9078\n",
      "Epoch 364/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 0.2683 - accuracy: 0.9579 - val_loss: 0.3806 - val_accuracy: 0.9078\n",
      "Epoch 365/2000\n",
      "618/618 [==============================] - 0s 57us/sample - loss: 0.2741 - accuracy: 0.9466 - val_loss: 0.3854 - val_accuracy: 0.9078\n",
      "Epoch 366/2000\n",
      "618/618 [==============================] - 0s 58us/sample - loss: 0.2589 - accuracy: 0.9482 - val_loss: 0.3773 - val_accuracy: 0.9078\n",
      "Epoch 367/2000\n",
      "618/618 [==============================] - 0s 56us/sample - loss: 0.2710 - accuracy: 0.9434 - val_loss: 0.3777 - val_accuracy: 0.9029\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 2,062\n",
      "Trainable params: 2,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 721 samples, validate on 241 samples\n",
      "Epoch 1/2000\n",
      "721/721 [==============================] - 0s 488us/sample - loss: 2.6324 - accuracy: 0.0902 - val_loss: 2.5878 - val_accuracy: 0.1203\n",
      "Epoch 2/2000\n",
      "721/721 [==============================] - 0s 45us/sample - loss: 2.5732 - accuracy: 0.1373 - val_loss: 2.5227 - val_accuracy: 0.2863\n",
      "Epoch 3/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 2.5172 - accuracy: 0.1748 - val_loss: 2.4688 - val_accuracy: 0.3154\n",
      "Epoch 4/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 2.4600 - accuracy: 0.2164 - val_loss: 2.4149 - val_accuracy: 0.3278\n",
      "Epoch 5/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 2.4079 - accuracy: 0.2524 - val_loss: 2.3556 - val_accuracy: 0.4232\n",
      "Epoch 6/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 2.3557 - accuracy: 0.2691 - val_loss: 2.3029 - val_accuracy: 0.5685\n",
      "Epoch 7/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 2.3000 - accuracy: 0.3121 - val_loss: 2.2471 - val_accuracy: 0.5726\n",
      "Epoch 8/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 2.2386 - accuracy: 0.3703 - val_loss: 2.1798 - val_accuracy: 0.6017\n",
      "Epoch 9/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 2.1722 - accuracy: 0.4022 - val_loss: 2.1210 - val_accuracy: 0.6349\n",
      "Epoch 10/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 2.1304 - accuracy: 0.4008 - val_loss: 2.0669 - val_accuracy: 0.6888\n",
      "Epoch 11/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 2.0691 - accuracy: 0.4202 - val_loss: 2.0105 - val_accuracy: 0.6888\n",
      "Epoch 12/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 2.0529 - accuracy: 0.4133 - val_loss: 1.9590 - val_accuracy: 0.7344\n",
      "Epoch 13/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 1.9833 - accuracy: 0.4411 - val_loss: 1.9070 - val_accuracy: 0.7427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 1.9474 - accuracy: 0.4757 - val_loss: 1.8602 - val_accuracy: 0.7469\n",
      "Epoch 15/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 1.8976 - accuracy: 0.4438 - val_loss: 1.8099 - val_accuracy: 0.7676\n",
      "Epoch 16/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 1.8510 - accuracy: 0.4813 - val_loss: 1.7628 - val_accuracy: 0.7925\n",
      "Epoch 17/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 1.8142 - accuracy: 0.4951 - val_loss: 1.7200 - val_accuracy: 0.8050\n",
      "Epoch 18/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 1.7787 - accuracy: 0.5062 - val_loss: 1.6782 - val_accuracy: 0.8133\n",
      "Epoch 19/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 1.7337 - accuracy: 0.5132 - val_loss: 1.6427 - val_accuracy: 0.8340\n",
      "Epoch 20/2000\n",
      "721/721 [==============================] - 0s 40us/sample - loss: 1.6805 - accuracy: 0.5340 - val_loss: 1.6026 - val_accuracy: 0.8257\n",
      "Epoch 21/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 1.6513 - accuracy: 0.5492 - val_loss: 1.5661 - val_accuracy: 0.8174\n",
      "Epoch 22/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 1.5799 - accuracy: 0.5645 - val_loss: 1.5256 - val_accuracy: 0.8340\n",
      "Epoch 23/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 1.5818 - accuracy: 0.5825 - val_loss: 1.4936 - val_accuracy: 0.8257\n",
      "Epoch 24/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 1.5639 - accuracy: 0.5908 - val_loss: 1.4629 - val_accuracy: 0.8465\n",
      "Epoch 25/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 1.5225 - accuracy: 0.5922 - val_loss: 1.4307 - val_accuracy: 0.8672\n",
      "Epoch 26/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 1.4803 - accuracy: 0.6117 - val_loss: 1.3994 - val_accuracy: 0.8631\n",
      "Epoch 27/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 1.4642 - accuracy: 0.5673 - val_loss: 1.3677 - val_accuracy: 0.8465\n",
      "Epoch 28/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 1.4237 - accuracy: 0.6200 - val_loss: 1.3406 - val_accuracy: 0.8631\n",
      "Epoch 29/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 1.3900 - accuracy: 0.6241 - val_loss: 1.3055 - val_accuracy: 0.8589\n",
      "Epoch 30/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 1.3890 - accuracy: 0.6380 - val_loss: 1.2798 - val_accuracy: 0.8548\n",
      "Epoch 31/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 1.3554 - accuracy: 0.5992 - val_loss: 1.2536 - val_accuracy: 0.8755\n",
      "Epoch 32/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 1.3312 - accuracy: 0.6657 - val_loss: 1.2255 - val_accuracy: 0.8672\n",
      "Epoch 33/2000\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 1.3102 - accuracy: 0.6463 - val_loss: 1.2012 - val_accuracy: 0.8714\n",
      "Epoch 34/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 1.2879 - accuracy: 0.6755 - val_loss: 1.1732 - val_accuracy: 0.8797\n",
      "Epoch 35/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 1.2619 - accuracy: 0.6560 - val_loss: 1.1531 - val_accuracy: 0.8714\n",
      "Epoch 36/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 1.2178 - accuracy: 0.6838 - val_loss: 1.1263 - val_accuracy: 0.8838\n",
      "Epoch 37/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 1.2200 - accuracy: 0.6879 - val_loss: 1.1037 - val_accuracy: 0.8921\n",
      "Epoch 38/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 1.2111 - accuracy: 0.6588 - val_loss: 1.0870 - val_accuracy: 0.8838\n",
      "Epoch 39/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 1.1747 - accuracy: 0.6921 - val_loss: 1.0623 - val_accuracy: 0.8921\n",
      "Epoch 40/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 1.1735 - accuracy: 0.7087 - val_loss: 1.0475 - val_accuracy: 0.8838\n",
      "Epoch 41/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 1.1489 - accuracy: 0.6976 - val_loss: 1.0219 - val_accuracy: 0.9046\n",
      "Epoch 42/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 1.1351 - accuracy: 0.7074 - val_loss: 1.0010 - val_accuracy: 0.9004\n",
      "Epoch 43/2000\n",
      "721/721 [==============================] - 0s 57us/sample - loss: 1.0965 - accuracy: 0.7157 - val_loss: 0.9862 - val_accuracy: 0.9087\n",
      "Epoch 44/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 1.0715 - accuracy: 0.7198 - val_loss: 0.9687 - val_accuracy: 0.8755\n",
      "Epoch 45/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 1.0773 - accuracy: 0.7004 - val_loss: 0.9501 - val_accuracy: 0.9046\n",
      "Epoch 46/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 1.0686 - accuracy: 0.7115 - val_loss: 0.9317 - val_accuracy: 0.9046\n",
      "Epoch 47/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 1.0266 - accuracy: 0.7406 - val_loss: 0.9147 - val_accuracy: 0.8880\n",
      "Epoch 48/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 1.0138 - accuracy: 0.7240 - val_loss: 0.8988 - val_accuracy: 0.8963\n",
      "Epoch 49/2000\n",
      "721/721 [==============================] - 0s 40us/sample - loss: 1.0223 - accuracy: 0.7462 - val_loss: 0.8818 - val_accuracy: 0.9046\n",
      "Epoch 50/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.9770 - accuracy: 0.7503 - val_loss: 0.8647 - val_accuracy: 0.9087\n",
      "Epoch 51/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.9771 - accuracy: 0.7420 - val_loss: 0.8482 - val_accuracy: 0.9046\n",
      "Epoch 52/2000\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 0.9941 - accuracy: 0.7337 - val_loss: 0.8450 - val_accuracy: 0.8880\n",
      "Epoch 53/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.9649 - accuracy: 0.7448 - val_loss: 0.8262 - val_accuracy: 0.9087\n",
      "Epoch 54/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.9451 - accuracy: 0.7545 - val_loss: 0.8094 - val_accuracy: 0.9129\n",
      "Epoch 55/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.9178 - accuracy: 0.7656 - val_loss: 0.8022 - val_accuracy: 0.9129\n",
      "Epoch 56/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.9058 - accuracy: 0.7684 - val_loss: 0.7880 - val_accuracy: 0.9046\n",
      "Epoch 57/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.9307 - accuracy: 0.7545 - val_loss: 0.7808 - val_accuracy: 0.9087\n",
      "Epoch 58/2000\n",
      "721/721 [==============================] - 0s 57us/sample - loss: 0.8830 - accuracy: 0.7836 - val_loss: 0.7693 - val_accuracy: 0.9170\n",
      "Epoch 59/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.8866 - accuracy: 0.7822 - val_loss: 0.7561 - val_accuracy: 0.9004\n",
      "Epoch 60/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.8658 - accuracy: 0.7795 - val_loss: 0.7376 - val_accuracy: 0.9129\n",
      "Epoch 61/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.8515 - accuracy: 0.7878 - val_loss: 0.7300 - val_accuracy: 0.9170\n",
      "Epoch 62/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.8682 - accuracy: 0.7753 - val_loss: 0.7210 - val_accuracy: 0.9087\n",
      "Epoch 63/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.8085 - accuracy: 0.8128 - val_loss: 0.7082 - val_accuracy: 0.9129\n",
      "Epoch 64/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.8234 - accuracy: 0.7892 - val_loss: 0.7008 - val_accuracy: 0.9129\n",
      "Epoch 65/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.8088 - accuracy: 0.8114 - val_loss: 0.6879 - val_accuracy: 0.9087\n",
      "Epoch 66/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.7917 - accuracy: 0.7947 - val_loss: 0.6777 - val_accuracy: 0.9253\n",
      "Epoch 67/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.7885 - accuracy: 0.7975 - val_loss: 0.6720 - val_accuracy: 0.9129\n",
      "Epoch 68/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.8089 - accuracy: 0.7961 - val_loss: 0.6665 - val_accuracy: 0.9046\n",
      "Epoch 69/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/721 [==============================] - 0s 48us/sample - loss: 0.7945 - accuracy: 0.8239 - val_loss: 0.6579 - val_accuracy: 0.9004\n",
      "Epoch 70/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.7536 - accuracy: 0.8266 - val_loss: 0.6553 - val_accuracy: 0.9046\n",
      "Epoch 71/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.7880 - accuracy: 0.7809 - val_loss: 0.6415 - val_accuracy: 0.9087\n",
      "Epoch 72/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.7540 - accuracy: 0.8003 - val_loss: 0.6323 - val_accuracy: 0.9129\n",
      "Epoch 73/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.7305 - accuracy: 0.8003 - val_loss: 0.6240 - val_accuracy: 0.9129\n",
      "Epoch 74/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.7158 - accuracy: 0.8419 - val_loss: 0.6186 - val_accuracy: 0.9170\n",
      "Epoch 75/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.7661 - accuracy: 0.7975 - val_loss: 0.6079 - val_accuracy: 0.9212\n",
      "Epoch 76/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.7286 - accuracy: 0.8017 - val_loss: 0.6057 - val_accuracy: 0.9253\n",
      "Epoch 77/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.7054 - accuracy: 0.8460 - val_loss: 0.5952 - val_accuracy: 0.9087\n",
      "Epoch 78/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.7250 - accuracy: 0.8058 - val_loss: 0.5891 - val_accuracy: 0.9212\n",
      "Epoch 79/2000\n",
      "721/721 [==============================] - 0s 42us/sample - loss: 0.7028 - accuracy: 0.8363 - val_loss: 0.5831 - val_accuracy: 0.9170\n",
      "Epoch 80/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.6910 - accuracy: 0.8197 - val_loss: 0.5799 - val_accuracy: 0.9378\n",
      "Epoch 81/2000\n",
      "721/721 [==============================] - 0s 40us/sample - loss: 0.7012 - accuracy: 0.8266 - val_loss: 0.5727 - val_accuracy: 0.9212\n",
      "Epoch 82/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.6764 - accuracy: 0.8280 - val_loss: 0.5657 - val_accuracy: 0.9253\n",
      "Epoch 83/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.6739 - accuracy: 0.8405 - val_loss: 0.5625 - val_accuracy: 0.9378\n",
      "Epoch 84/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.6578 - accuracy: 0.8377 - val_loss: 0.5585 - val_accuracy: 0.9336\n",
      "Epoch 85/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.6692 - accuracy: 0.8336 - val_loss: 0.5522 - val_accuracy: 0.9212\n",
      "Epoch 86/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.6534 - accuracy: 0.8433 - val_loss: 0.5544 - val_accuracy: 0.9212\n",
      "Epoch 87/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.6544 - accuracy: 0.8363 - val_loss: 0.5434 - val_accuracy: 0.9336\n",
      "Epoch 88/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.6536 - accuracy: 0.8266 - val_loss: 0.5404 - val_accuracy: 0.9170\n",
      "Epoch 89/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.6420 - accuracy: 0.8433 - val_loss: 0.5326 - val_accuracy: 0.9295\n",
      "Epoch 90/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.6323 - accuracy: 0.8585 - val_loss: 0.5275 - val_accuracy: 0.9295\n",
      "Epoch 91/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.6412 - accuracy: 0.8336 - val_loss: 0.5260 - val_accuracy: 0.9295\n",
      "Epoch 92/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.6455 - accuracy: 0.8225 - val_loss: 0.5211 - val_accuracy: 0.9419\n",
      "Epoch 93/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.6317 - accuracy: 0.8377 - val_loss: 0.5161 - val_accuracy: 0.9212\n",
      "Epoch 94/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.6082 - accuracy: 0.8613 - val_loss: 0.5099 - val_accuracy: 0.9295\n",
      "Epoch 95/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.6121 - accuracy: 0.8460 - val_loss: 0.5065 - val_accuracy: 0.9336\n",
      "Epoch 96/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.5835 - accuracy: 0.8599 - val_loss: 0.5003 - val_accuracy: 0.9336\n",
      "Epoch 97/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.6200 - accuracy: 0.8377 - val_loss: 0.5007 - val_accuracy: 0.9336\n",
      "Epoch 98/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.5941 - accuracy: 0.8613 - val_loss: 0.5004 - val_accuracy: 0.9336\n",
      "Epoch 99/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.6244 - accuracy: 0.8516 - val_loss: 0.4978 - val_accuracy: 0.9378\n",
      "Epoch 100/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.5743 - accuracy: 0.8724 - val_loss: 0.4939 - val_accuracy: 0.9336\n",
      "Epoch 101/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.5986 - accuracy: 0.8516 - val_loss: 0.4871 - val_accuracy: 0.9253\n",
      "Epoch 102/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.5970 - accuracy: 0.8530 - val_loss: 0.4828 - val_accuracy: 0.9378\n",
      "Epoch 103/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.5827 - accuracy: 0.8766 - val_loss: 0.4790 - val_accuracy: 0.9336\n",
      "Epoch 104/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.5781 - accuracy: 0.8613 - val_loss: 0.4811 - val_accuracy: 0.9378\n",
      "Epoch 105/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.6016 - accuracy: 0.8447 - val_loss: 0.4761 - val_accuracy: 0.9336\n",
      "Epoch 106/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.5644 - accuracy: 0.8863 - val_loss: 0.4685 - val_accuracy: 0.9253\n",
      "Epoch 107/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.5748 - accuracy: 0.8530 - val_loss: 0.4660 - val_accuracy: 0.9212\n",
      "Epoch 108/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.5689 - accuracy: 0.8738 - val_loss: 0.4646 - val_accuracy: 0.9378\n",
      "Epoch 109/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.5557 - accuracy: 0.8821 - val_loss: 0.4598 - val_accuracy: 0.9336\n",
      "Epoch 110/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.5868 - accuracy: 0.8488 - val_loss: 0.4610 - val_accuracy: 0.9336\n",
      "Epoch 111/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.5591 - accuracy: 0.8627 - val_loss: 0.4596 - val_accuracy: 0.9336\n",
      "Epoch 112/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.5411 - accuracy: 0.8682 - val_loss: 0.4515 - val_accuracy: 0.9336\n",
      "Epoch 113/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.5642 - accuracy: 0.8585 - val_loss: 0.4471 - val_accuracy: 0.9336\n",
      "Epoch 114/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.5246 - accuracy: 0.8863 - val_loss: 0.4457 - val_accuracy: 0.9336\n",
      "Epoch 115/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.5428 - accuracy: 0.8738 - val_loss: 0.4446 - val_accuracy: 0.9336\n",
      "Epoch 116/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.5456 - accuracy: 0.8669 - val_loss: 0.4461 - val_accuracy: 0.9336\n",
      "Epoch 117/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.5118 - accuracy: 0.8807 - val_loss: 0.4411 - val_accuracy: 0.9378\n",
      "Epoch 118/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.5382 - accuracy: 0.8863 - val_loss: 0.4368 - val_accuracy: 0.9378\n",
      "Epoch 119/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.5304 - accuracy: 0.8655 - val_loss: 0.4370 - val_accuracy: 0.9295\n",
      "Epoch 120/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.5164 - accuracy: 0.8724 - val_loss: 0.4321 - val_accuracy: 0.9253\n",
      "Epoch 121/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.5287 - accuracy: 0.8655 - val_loss: 0.4282 - val_accuracy: 0.9419\n",
      "Epoch 122/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.5216 - accuracy: 0.8779 - val_loss: 0.4301 - val_accuracy: 0.9295\n",
      "Epoch 123/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.5013 - accuracy: 0.8807 - val_loss: 0.4265 - val_accuracy: 0.9378\n",
      "Epoch 124/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/721 [==============================] - 0s 51us/sample - loss: 0.5273 - accuracy: 0.8696 - val_loss: 0.4265 - val_accuracy: 0.9336\n",
      "Epoch 125/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.5291 - accuracy: 0.8696 - val_loss: 0.4249 - val_accuracy: 0.9419\n",
      "Epoch 126/2000\n",
      "721/721 [==============================] - 0s 40us/sample - loss: 0.5154 - accuracy: 0.8682 - val_loss: 0.4250 - val_accuracy: 0.9378\n",
      "Epoch 127/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.5278 - accuracy: 0.8710 - val_loss: 0.4215 - val_accuracy: 0.9461\n",
      "Epoch 128/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.4932 - accuracy: 0.8682 - val_loss: 0.4194 - val_accuracy: 0.9378\n",
      "Epoch 129/2000\n",
      "721/721 [==============================] - 0s 57us/sample - loss: 0.5068 - accuracy: 0.8752 - val_loss: 0.4182 - val_accuracy: 0.9336\n",
      "Epoch 130/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.4968 - accuracy: 0.8849 - val_loss: 0.4142 - val_accuracy: 0.9336\n",
      "Epoch 131/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.5030 - accuracy: 0.8807 - val_loss: 0.4191 - val_accuracy: 0.9378\n",
      "Epoch 132/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.5068 - accuracy: 0.8863 - val_loss: 0.4121 - val_accuracy: 0.9378\n",
      "Epoch 133/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.4938 - accuracy: 0.8779 - val_loss: 0.4107 - val_accuracy: 0.9378\n",
      "Epoch 134/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.4990 - accuracy: 0.8849 - val_loss: 0.4107 - val_accuracy: 0.9295\n",
      "Epoch 135/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.4709 - accuracy: 0.8960 - val_loss: 0.4040 - val_accuracy: 0.9378\n",
      "Epoch 136/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.4782 - accuracy: 0.8932 - val_loss: 0.4029 - val_accuracy: 0.9336\n",
      "Epoch 137/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.4833 - accuracy: 0.8904 - val_loss: 0.4031 - val_accuracy: 0.9336\n",
      "Epoch 138/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.4798 - accuracy: 0.8877 - val_loss: 0.3993 - val_accuracy: 0.9419\n",
      "Epoch 139/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.4701 - accuracy: 0.8960 - val_loss: 0.3998 - val_accuracy: 0.9336\n",
      "Epoch 140/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.4770 - accuracy: 0.8890 - val_loss: 0.4019 - val_accuracy: 0.9336\n",
      "Epoch 141/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.4952 - accuracy: 0.8835 - val_loss: 0.3975 - val_accuracy: 0.9378\n",
      "Epoch 142/2000\n",
      "721/721 [==============================] - 0s 57us/sample - loss: 0.4558 - accuracy: 0.8974 - val_loss: 0.3939 - val_accuracy: 0.9419\n",
      "Epoch 143/2000\n",
      "721/721 [==============================] - 0s 42us/sample - loss: 0.4694 - accuracy: 0.9029 - val_loss: 0.3962 - val_accuracy: 0.9461\n",
      "Epoch 144/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.4698 - accuracy: 0.8793 - val_loss: 0.3921 - val_accuracy: 0.9378\n",
      "Epoch 145/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.4624 - accuracy: 0.9001 - val_loss: 0.3906 - val_accuracy: 0.9378\n",
      "Epoch 146/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.4482 - accuracy: 0.9001 - val_loss: 0.3838 - val_accuracy: 0.9378\n",
      "Epoch 147/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.4759 - accuracy: 0.8793 - val_loss: 0.3888 - val_accuracy: 0.9378\n",
      "Epoch 148/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.4520 - accuracy: 0.8946 - val_loss: 0.3803 - val_accuracy: 0.9419\n",
      "Epoch 149/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.4695 - accuracy: 0.8877 - val_loss: 0.3819 - val_accuracy: 0.9336\n",
      "Epoch 150/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.4319 - accuracy: 0.9029 - val_loss: 0.3835 - val_accuracy: 0.9336\n",
      "Epoch 151/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.4516 - accuracy: 0.8835 - val_loss: 0.3880 - val_accuracy: 0.9253\n",
      "Epoch 152/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.4512 - accuracy: 0.9154 - val_loss: 0.3789 - val_accuracy: 0.9336\n",
      "Epoch 153/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.4617 - accuracy: 0.8877 - val_loss: 0.3794 - val_accuracy: 0.9295\n",
      "Epoch 154/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.4657 - accuracy: 0.8863 - val_loss: 0.3756 - val_accuracy: 0.9336\n",
      "Epoch 155/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.4611 - accuracy: 0.8904 - val_loss: 0.3803 - val_accuracy: 0.9378\n",
      "Epoch 156/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.4260 - accuracy: 0.9265 - val_loss: 0.3760 - val_accuracy: 0.9378\n",
      "Epoch 157/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.4511 - accuracy: 0.9015 - val_loss: 0.3734 - val_accuracy: 0.9336\n",
      "Epoch 158/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.4568 - accuracy: 0.8890 - val_loss: 0.3777 - val_accuracy: 0.9336\n",
      "Epoch 159/2000\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 0.4310 - accuracy: 0.9098 - val_loss: 0.3730 - val_accuracy: 0.9461\n",
      "Epoch 160/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.4285 - accuracy: 0.8988 - val_loss: 0.3764 - val_accuracy: 0.9336\n",
      "Epoch 161/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.4267 - accuracy: 0.9071 - val_loss: 0.3675 - val_accuracy: 0.9378\n",
      "Epoch 162/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.4261 - accuracy: 0.8988 - val_loss: 0.3678 - val_accuracy: 0.9461\n",
      "Epoch 163/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.4096 - accuracy: 0.9140 - val_loss: 0.3657 - val_accuracy: 0.9295\n",
      "Epoch 164/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.4238 - accuracy: 0.9057 - val_loss: 0.3686 - val_accuracy: 0.9295\n",
      "Epoch 165/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.4140 - accuracy: 0.9126 - val_loss: 0.3647 - val_accuracy: 0.9419\n",
      "Epoch 166/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.4068 - accuracy: 0.9071 - val_loss: 0.3603 - val_accuracy: 0.9336\n",
      "Epoch 167/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.4030 - accuracy: 0.9223 - val_loss: 0.3613 - val_accuracy: 0.9336\n",
      "Epoch 168/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.4051 - accuracy: 0.9057 - val_loss: 0.3601 - val_accuracy: 0.9378\n",
      "Epoch 169/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.4123 - accuracy: 0.9126 - val_loss: 0.3597 - val_accuracy: 0.9378\n",
      "Epoch 170/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.4136 - accuracy: 0.8988 - val_loss: 0.3600 - val_accuracy: 0.9378\n",
      "Epoch 171/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.4231 - accuracy: 0.8918 - val_loss: 0.3635 - val_accuracy: 0.9336\n",
      "Epoch 172/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.4273 - accuracy: 0.9029 - val_loss: 0.3607 - val_accuracy: 0.9378\n",
      "Epoch 173/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.4000 - accuracy: 0.9126 - val_loss: 0.3572 - val_accuracy: 0.9419\n",
      "Epoch 174/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.4100 - accuracy: 0.9154 - val_loss: 0.3564 - val_accuracy: 0.9419\n",
      "Epoch 175/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.3943 - accuracy: 0.9154 - val_loss: 0.3570 - val_accuracy: 0.9295\n",
      "Epoch 176/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.3935 - accuracy: 0.9209 - val_loss: 0.3521 - val_accuracy: 0.9461\n",
      "Epoch 177/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.4133 - accuracy: 0.9043 - val_loss: 0.3554 - val_accuracy: 0.9336\n",
      "Epoch 178/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.3906 - accuracy: 0.9098 - val_loss: 0.3541 - val_accuracy: 0.9419\n",
      "Epoch 179/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/721 [==============================] - 0s 54us/sample - loss: 0.3915 - accuracy: 0.9057 - val_loss: 0.3525 - val_accuracy: 0.9336\n",
      "Epoch 180/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.4070 - accuracy: 0.9001 - val_loss: 0.3562 - val_accuracy: 0.9378\n",
      "Epoch 181/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3934 - accuracy: 0.9223 - val_loss: 0.3548 - val_accuracy: 0.9295\n",
      "Epoch 182/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.3986 - accuracy: 0.9057 - val_loss: 0.3520 - val_accuracy: 0.9378\n",
      "Epoch 183/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.3882 - accuracy: 0.9182 - val_loss: 0.3519 - val_accuracy: 0.9378\n",
      "Epoch 184/2000\n",
      "721/721 [==============================] - 0s 42us/sample - loss: 0.3990 - accuracy: 0.9168 - val_loss: 0.3488 - val_accuracy: 0.9336\n",
      "Epoch 185/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.3814 - accuracy: 0.9251 - val_loss: 0.3443 - val_accuracy: 0.9378\n",
      "Epoch 186/2000\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 0.3829 - accuracy: 0.9154 - val_loss: 0.3445 - val_accuracy: 0.9461\n",
      "Epoch 187/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.3699 - accuracy: 0.9293 - val_loss: 0.3444 - val_accuracy: 0.9419\n",
      "Epoch 188/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.3999 - accuracy: 0.9043 - val_loss: 0.3495 - val_accuracy: 0.9295\n",
      "Epoch 189/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.3723 - accuracy: 0.9182 - val_loss: 0.3389 - val_accuracy: 0.9378\n",
      "Epoch 190/2000\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 0.4083 - accuracy: 0.8946 - val_loss: 0.3452 - val_accuracy: 0.9419\n",
      "Epoch 191/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.4049 - accuracy: 0.9001 - val_loss: 0.3479 - val_accuracy: 0.9336\n",
      "Epoch 192/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3970 - accuracy: 0.9085 - val_loss: 0.3450 - val_accuracy: 0.9378\n",
      "Epoch 193/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3779 - accuracy: 0.9182 - val_loss: 0.3451 - val_accuracy: 0.9336\n",
      "Epoch 194/2000\n",
      "721/721 [==============================] - 0s 40us/sample - loss: 0.4106 - accuracy: 0.8988 - val_loss: 0.3437 - val_accuracy: 0.9336\n",
      "Epoch 195/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3812 - accuracy: 0.9237 - val_loss: 0.3447 - val_accuracy: 0.9336\n",
      "Epoch 196/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3723 - accuracy: 0.9251 - val_loss: 0.3413 - val_accuracy: 0.9295\n",
      "Epoch 197/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.3719 - accuracy: 0.9265 - val_loss: 0.3372 - val_accuracy: 0.9378\n",
      "Epoch 198/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.3931 - accuracy: 0.9085 - val_loss: 0.3387 - val_accuracy: 0.9378\n",
      "Epoch 199/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3822 - accuracy: 0.9071 - val_loss: 0.3381 - val_accuracy: 0.9336\n",
      "Epoch 200/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3964 - accuracy: 0.8974 - val_loss: 0.3390 - val_accuracy: 0.9378\n",
      "Epoch 201/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3537 - accuracy: 0.9279 - val_loss: 0.3419 - val_accuracy: 0.9295\n",
      "Epoch 202/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3899 - accuracy: 0.9029 - val_loss: 0.3438 - val_accuracy: 0.9295\n",
      "Epoch 203/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.3683 - accuracy: 0.9265 - val_loss: 0.3393 - val_accuracy: 0.9295\n",
      "Epoch 204/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.3980 - accuracy: 0.9001 - val_loss: 0.3451 - val_accuracy: 0.9378\n",
      "Epoch 205/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3694 - accuracy: 0.9251 - val_loss: 0.3428 - val_accuracy: 0.9336\n",
      "Epoch 206/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3589 - accuracy: 0.9251 - val_loss: 0.3378 - val_accuracy: 0.9378\n",
      "Epoch 207/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3527 - accuracy: 0.9265 - val_loss: 0.3321 - val_accuracy: 0.9461\n",
      "Epoch 208/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.3539 - accuracy: 0.9251 - val_loss: 0.3338 - val_accuracy: 0.9336\n",
      "Epoch 209/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.3614 - accuracy: 0.9251 - val_loss: 0.3330 - val_accuracy: 0.9419\n",
      "Epoch 210/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3731 - accuracy: 0.9168 - val_loss: 0.3366 - val_accuracy: 0.9295\n",
      "Epoch 211/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3687 - accuracy: 0.9348 - val_loss: 0.3320 - val_accuracy: 0.9295\n",
      "Epoch 212/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3744 - accuracy: 0.9112 - val_loss: 0.3364 - val_accuracy: 0.9295\n",
      "Epoch 213/2000\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 0.3693 - accuracy: 0.9154 - val_loss: 0.3350 - val_accuracy: 0.9378\n",
      "Epoch 214/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.3635 - accuracy: 0.9265 - val_loss: 0.3356 - val_accuracy: 0.9295\n",
      "Epoch 215/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.3365 - accuracy: 0.9293 - val_loss: 0.3308 - val_accuracy: 0.9378\n",
      "Epoch 216/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.3674 - accuracy: 0.9182 - val_loss: 0.3374 - val_accuracy: 0.9253\n",
      "Epoch 217/2000\n",
      "721/721 [==============================] - 0s 40us/sample - loss: 0.3624 - accuracy: 0.9154 - val_loss: 0.3314 - val_accuracy: 0.9295\n",
      "Epoch 218/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.3489 - accuracy: 0.9320 - val_loss: 0.3299 - val_accuracy: 0.9295\n",
      "Epoch 219/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.3502 - accuracy: 0.9348 - val_loss: 0.3277 - val_accuracy: 0.9378\n",
      "Epoch 220/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3527 - accuracy: 0.9209 - val_loss: 0.3280 - val_accuracy: 0.9419\n",
      "Epoch 221/2000\n",
      "721/721 [==============================] - 0s 61us/sample - loss: 0.3470 - accuracy: 0.9307 - val_loss: 0.3264 - val_accuracy: 0.9336\n",
      "Epoch 222/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3503 - accuracy: 0.9404 - val_loss: 0.3280 - val_accuracy: 0.9295\n",
      "Epoch 223/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.3540 - accuracy: 0.9279 - val_loss: 0.3279 - val_accuracy: 0.9336\n",
      "Epoch 224/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.3687 - accuracy: 0.9168 - val_loss: 0.3268 - val_accuracy: 0.9378\n",
      "Epoch 225/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3461 - accuracy: 0.9293 - val_loss: 0.3268 - val_accuracy: 0.9295\n",
      "Epoch 226/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.3539 - accuracy: 0.9279 - val_loss: 0.3316 - val_accuracy: 0.9378\n",
      "Epoch 227/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.3796 - accuracy: 0.9015 - val_loss: 0.3322 - val_accuracy: 0.9295\n",
      "Epoch 228/2000\n",
      "721/721 [==============================] - 0s 40us/sample - loss: 0.3380 - accuracy: 0.9251 - val_loss: 0.3279 - val_accuracy: 0.9378\n",
      "Epoch 229/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.3451 - accuracy: 0.9196 - val_loss: 0.3226 - val_accuracy: 0.9378\n",
      "Epoch 230/2000\n",
      "721/721 [==============================] - 0s 42us/sample - loss: 0.3444 - accuracy: 0.9279 - val_loss: 0.3307 - val_accuracy: 0.9253\n",
      "Epoch 231/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3397 - accuracy: 0.9334 - val_loss: 0.3205 - val_accuracy: 0.9419\n",
      "Epoch 232/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.3505 - accuracy: 0.9223 - val_loss: 0.3236 - val_accuracy: 0.9378\n",
      "Epoch 233/2000\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 0.3610 - accuracy: 0.9140 - val_loss: 0.3269 - val_accuracy: 0.9336\n",
      "Epoch 234/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/721 [==============================] - 0s 48us/sample - loss: 0.3580 - accuracy: 0.9223 - val_loss: 0.3287 - val_accuracy: 0.9378\n",
      "Epoch 235/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3179 - accuracy: 0.9376 - val_loss: 0.3245 - val_accuracy: 0.9295\n",
      "Epoch 236/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.3488 - accuracy: 0.9237 - val_loss: 0.3240 - val_accuracy: 0.9295\n",
      "Epoch 237/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.3336 - accuracy: 0.9251 - val_loss: 0.3239 - val_accuracy: 0.9295\n",
      "Epoch 238/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.3387 - accuracy: 0.9209 - val_loss: 0.3247 - val_accuracy: 0.9295\n",
      "Epoch 239/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.3568 - accuracy: 0.9237 - val_loss: 0.3205 - val_accuracy: 0.9378\n",
      "Epoch 240/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.3298 - accuracy: 0.9376 - val_loss: 0.3205 - val_accuracy: 0.9419\n",
      "Epoch 241/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3408 - accuracy: 0.9307 - val_loss: 0.3205 - val_accuracy: 0.9378\n",
      "Epoch 242/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3290 - accuracy: 0.9390 - val_loss: 0.3194 - val_accuracy: 0.9419\n",
      "Epoch 243/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.3322 - accuracy: 0.9209 - val_loss: 0.3214 - val_accuracy: 0.9336\n",
      "Epoch 244/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.3280 - accuracy: 0.9376 - val_loss: 0.3199 - val_accuracy: 0.9295\n",
      "Epoch 245/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.3279 - accuracy: 0.9320 - val_loss: 0.3213 - val_accuracy: 0.9253\n",
      "Epoch 246/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3285 - accuracy: 0.9376 - val_loss: 0.3215 - val_accuracy: 0.9295\n",
      "Epoch 247/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3388 - accuracy: 0.9223 - val_loss: 0.3200 - val_accuracy: 0.9253\n",
      "Epoch 248/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.3287 - accuracy: 0.9390 - val_loss: 0.3203 - val_accuracy: 0.9253\n",
      "Epoch 249/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.3383 - accuracy: 0.9334 - val_loss: 0.3182 - val_accuracy: 0.9336\n",
      "Epoch 250/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3290 - accuracy: 0.9348 - val_loss: 0.3171 - val_accuracy: 0.9336\n",
      "Epoch 251/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.3250 - accuracy: 0.9251 - val_loss: 0.3180 - val_accuracy: 0.9378\n",
      "Epoch 252/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.3224 - accuracy: 0.9307 - val_loss: 0.3157 - val_accuracy: 0.9419\n",
      "Epoch 253/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3107 - accuracy: 0.9404 - val_loss: 0.3173 - val_accuracy: 0.9295\n",
      "Epoch 254/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.3152 - accuracy: 0.9251 - val_loss: 0.3154 - val_accuracy: 0.9295\n",
      "Epoch 255/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.3375 - accuracy: 0.9293 - val_loss: 0.3155 - val_accuracy: 0.9336\n",
      "Epoch 256/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.3261 - accuracy: 0.9265 - val_loss: 0.3203 - val_accuracy: 0.9336\n",
      "Epoch 257/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.3303 - accuracy: 0.9307 - val_loss: 0.3169 - val_accuracy: 0.9253\n",
      "Epoch 258/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.3339 - accuracy: 0.9237 - val_loss: 0.3152 - val_accuracy: 0.9336\n",
      "Epoch 259/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.3177 - accuracy: 0.9320 - val_loss: 0.3129 - val_accuracy: 0.9336\n",
      "Epoch 260/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.3138 - accuracy: 0.9417 - val_loss: 0.3123 - val_accuracy: 0.9419\n",
      "Epoch 261/2000\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 0.3299 - accuracy: 0.9279 - val_loss: 0.3135 - val_accuracy: 0.9336\n",
      "Epoch 262/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.3150 - accuracy: 0.9279 - val_loss: 0.3173 - val_accuracy: 0.9336\n",
      "Epoch 263/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.3214 - accuracy: 0.9307 - val_loss: 0.3101 - val_accuracy: 0.9336\n",
      "Epoch 264/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3035 - accuracy: 0.9404 - val_loss: 0.3129 - val_accuracy: 0.9336\n",
      "Epoch 265/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.3151 - accuracy: 0.9376 - val_loss: 0.3124 - val_accuracy: 0.9336\n",
      "Epoch 266/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3185 - accuracy: 0.9417 - val_loss: 0.3172 - val_accuracy: 0.9295\n",
      "Epoch 267/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2888 - accuracy: 0.9445 - val_loss: 0.3093 - val_accuracy: 0.9378\n",
      "Epoch 268/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3305 - accuracy: 0.9112 - val_loss: 0.3126 - val_accuracy: 0.9419\n",
      "Epoch 269/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.2967 - accuracy: 0.9417 - val_loss: 0.3140 - val_accuracy: 0.9253\n",
      "Epoch 270/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.3199 - accuracy: 0.9293 - val_loss: 0.3182 - val_accuracy: 0.9378\n",
      "Epoch 271/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.3080 - accuracy: 0.9307 - val_loss: 0.3115 - val_accuracy: 0.9336\n",
      "Epoch 272/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3100 - accuracy: 0.9334 - val_loss: 0.3115 - val_accuracy: 0.9378\n",
      "Epoch 273/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.3204 - accuracy: 0.9265 - val_loss: 0.3091 - val_accuracy: 0.9419\n",
      "Epoch 274/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.3073 - accuracy: 0.9334 - val_loss: 0.3072 - val_accuracy: 0.9461\n",
      "Epoch 275/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.3056 - accuracy: 0.9390 - val_loss: 0.3089 - val_accuracy: 0.9419\n",
      "Epoch 276/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.3064 - accuracy: 0.9404 - val_loss: 0.3080 - val_accuracy: 0.9378\n",
      "Epoch 277/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.3102 - accuracy: 0.9431 - val_loss: 0.3078 - val_accuracy: 0.9336\n",
      "Epoch 278/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2905 - accuracy: 0.9431 - val_loss: 0.3082 - val_accuracy: 0.9295\n",
      "Epoch 279/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.3045 - accuracy: 0.9293 - val_loss: 0.3081 - val_accuracy: 0.9378\n",
      "Epoch 280/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.3117 - accuracy: 0.9320 - val_loss: 0.3090 - val_accuracy: 0.9336\n",
      "Epoch 281/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.2964 - accuracy: 0.9376 - val_loss: 0.3075 - val_accuracy: 0.9378\n",
      "Epoch 282/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.2903 - accuracy: 0.9376 - val_loss: 0.3062 - val_accuracy: 0.9336\n",
      "Epoch 283/2000\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 0.3101 - accuracy: 0.9293 - val_loss: 0.3065 - val_accuracy: 0.9336\n",
      "Epoch 284/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.2913 - accuracy: 0.9445 - val_loss: 0.3056 - val_accuracy: 0.9419\n",
      "Epoch 285/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2906 - accuracy: 0.9404 - val_loss: 0.3084 - val_accuracy: 0.9253\n",
      "Epoch 286/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2997 - accuracy: 0.9376 - val_loss: 0.3042 - val_accuracy: 0.9336\n",
      "Epoch 287/2000\n",
      "721/721 [==============================] - 0s 42us/sample - loss: 0.3037 - accuracy: 0.9362 - val_loss: 0.3039 - val_accuracy: 0.9419\n",
      "Epoch 288/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3046 - accuracy: 0.9390 - val_loss: 0.3049 - val_accuracy: 0.9378\n",
      "Epoch 289/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/721 [==============================] - 0s 42us/sample - loss: 0.3038 - accuracy: 0.9320 - val_loss: 0.3046 - val_accuracy: 0.9419\n",
      "Epoch 290/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.3000 - accuracy: 0.9404 - val_loss: 0.3072 - val_accuracy: 0.9336\n",
      "Epoch 291/2000\n",
      "721/721 [==============================] - 0s 40us/sample - loss: 0.2950 - accuracy: 0.9431 - val_loss: 0.3034 - val_accuracy: 0.9336\n",
      "Epoch 292/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3000 - accuracy: 0.9265 - val_loss: 0.3068 - val_accuracy: 0.9378\n",
      "Epoch 293/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.3105 - accuracy: 0.9320 - val_loss: 0.3009 - val_accuracy: 0.9378\n",
      "Epoch 294/2000\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 0.2941 - accuracy: 0.9417 - val_loss: 0.3034 - val_accuracy: 0.9461\n",
      "Epoch 295/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2926 - accuracy: 0.9459 - val_loss: 0.3034 - val_accuracy: 0.9419\n",
      "Epoch 296/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2804 - accuracy: 0.9528 - val_loss: 0.2999 - val_accuracy: 0.9419\n",
      "Epoch 297/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.3166 - accuracy: 0.9348 - val_loss: 0.3059 - val_accuracy: 0.9336\n",
      "Epoch 298/2000\n",
      "721/721 [==============================] - 0s 40us/sample - loss: 0.2976 - accuracy: 0.9445 - val_loss: 0.3062 - val_accuracy: 0.9336\n",
      "Epoch 299/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2799 - accuracy: 0.9473 - val_loss: 0.3055 - val_accuracy: 0.9336\n",
      "Epoch 300/2000\n",
      "721/721 [==============================] - 0s 45us/sample - loss: 0.2958 - accuracy: 0.9348 - val_loss: 0.3017 - val_accuracy: 0.9336\n",
      "Epoch 301/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.2889 - accuracy: 0.9445 - val_loss: 0.3041 - val_accuracy: 0.9336\n",
      "Epoch 302/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.2776 - accuracy: 0.9445 - val_loss: 0.3038 - val_accuracy: 0.9336\n",
      "Epoch 303/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.2784 - accuracy: 0.9487 - val_loss: 0.3020 - val_accuracy: 0.9253\n",
      "Epoch 304/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.2771 - accuracy: 0.9404 - val_loss: 0.3065 - val_accuracy: 0.9253\n",
      "Epoch 305/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.3097 - accuracy: 0.9459 - val_loss: 0.3040 - val_accuracy: 0.9419\n",
      "Epoch 306/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2887 - accuracy: 0.9404 - val_loss: 0.3039 - val_accuracy: 0.9336\n",
      "Epoch 307/2000\n",
      "721/721 [==============================] - 0s 42us/sample - loss: 0.2939 - accuracy: 0.9404 - val_loss: 0.3020 - val_accuracy: 0.9461\n",
      "Epoch 308/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.2807 - accuracy: 0.9487 - val_loss: 0.3017 - val_accuracy: 0.9295\n",
      "Epoch 309/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2747 - accuracy: 0.9404 - val_loss: 0.2993 - val_accuracy: 0.9461\n",
      "Epoch 310/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2709 - accuracy: 0.9390 - val_loss: 0.2975 - val_accuracy: 0.9378\n",
      "Epoch 311/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.2837 - accuracy: 0.9459 - val_loss: 0.2976 - val_accuracy: 0.9336\n",
      "Epoch 312/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2846 - accuracy: 0.9404 - val_loss: 0.2970 - val_accuracy: 0.9378\n",
      "Epoch 313/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2732 - accuracy: 0.9515 - val_loss: 0.2974 - val_accuracy: 0.9378\n",
      "Epoch 314/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2766 - accuracy: 0.9431 - val_loss: 0.3033 - val_accuracy: 0.9378\n",
      "Epoch 315/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2875 - accuracy: 0.9473 - val_loss: 0.2984 - val_accuracy: 0.9419\n",
      "Epoch 316/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2977 - accuracy: 0.9390 - val_loss: 0.3033 - val_accuracy: 0.9419\n",
      "Epoch 317/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2761 - accuracy: 0.9431 - val_loss: 0.2983 - val_accuracy: 0.9336\n",
      "Epoch 318/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.2762 - accuracy: 0.9515 - val_loss: 0.2998 - val_accuracy: 0.9378\n",
      "Epoch 319/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.2809 - accuracy: 0.9417 - val_loss: 0.2982 - val_accuracy: 0.9336\n",
      "Epoch 320/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2655 - accuracy: 0.9445 - val_loss: 0.3015 - val_accuracy: 0.9295\n",
      "Epoch 321/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2950 - accuracy: 0.9307 - val_loss: 0.2998 - val_accuracy: 0.9336\n",
      "Epoch 322/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2897 - accuracy: 0.9431 - val_loss: 0.3002 - val_accuracy: 0.9378\n",
      "Epoch 323/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2645 - accuracy: 0.9528 - val_loss: 0.2982 - val_accuracy: 0.9295\n",
      "Epoch 324/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2707 - accuracy: 0.9459 - val_loss: 0.2986 - val_accuracy: 0.9336\n",
      "Epoch 325/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2820 - accuracy: 0.9473 - val_loss: 0.3013 - val_accuracy: 0.9378\n",
      "Epoch 326/2000\n",
      "721/721 [==============================] - 0s 44us/sample - loss: 0.2770 - accuracy: 0.9417 - val_loss: 0.3012 - val_accuracy: 0.9336\n",
      "Epoch 327/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.2746 - accuracy: 0.9515 - val_loss: 0.2998 - val_accuracy: 0.9295\n",
      "Epoch 328/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.2756 - accuracy: 0.9417 - val_loss: 0.2980 - val_accuracy: 0.9419\n",
      "Epoch 329/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.2895 - accuracy: 0.9376 - val_loss: 0.2967 - val_accuracy: 0.9378\n",
      "Epoch 330/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.2915 - accuracy: 0.9348 - val_loss: 0.3005 - val_accuracy: 0.9419\n",
      "Epoch 331/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2854 - accuracy: 0.9431 - val_loss: 0.3000 - val_accuracy: 0.9295\n",
      "Epoch 332/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2883 - accuracy: 0.9417 - val_loss: 0.3010 - val_accuracy: 0.9295\n",
      "Epoch 333/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.2875 - accuracy: 0.9417 - val_loss: 0.3006 - val_accuracy: 0.9378\n",
      "Epoch 334/2000\n",
      "721/721 [==============================] - 0s 40us/sample - loss: 0.2810 - accuracy: 0.9348 - val_loss: 0.3053 - val_accuracy: 0.9295\n",
      "Epoch 335/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2666 - accuracy: 0.9612 - val_loss: 0.2953 - val_accuracy: 0.9378\n",
      "Epoch 336/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2840 - accuracy: 0.9362 - val_loss: 0.3000 - val_accuracy: 0.9336\n",
      "Epoch 337/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2616 - accuracy: 0.9487 - val_loss: 0.2960 - val_accuracy: 0.9378\n",
      "Epoch 338/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2705 - accuracy: 0.9459 - val_loss: 0.2984 - val_accuracy: 0.9378\n",
      "Epoch 339/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2743 - accuracy: 0.9473 - val_loss: 0.2980 - val_accuracy: 0.9419\n",
      "Epoch 340/2000\n",
      "721/721 [==============================] - 0s 42us/sample - loss: 0.2708 - accuracy: 0.9487 - val_loss: 0.2971 - val_accuracy: 0.9378\n",
      "Epoch 341/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2793 - accuracy: 0.9459 - val_loss: 0.3028 - val_accuracy: 0.9253\n",
      "Epoch 342/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2938 - accuracy: 0.9348 - val_loss: 0.2958 - val_accuracy: 0.9378\n",
      "Epoch 343/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2696 - accuracy: 0.9473 - val_loss: 0.2983 - val_accuracy: 0.9419\n",
      "Epoch 344/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2549 - accuracy: 0.9487 - val_loss: 0.3017 - val_accuracy: 0.9419\n",
      "Epoch 345/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2843 - accuracy: 0.9362 - val_loss: 0.2973 - val_accuracy: 0.9378\n",
      "Epoch 346/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2417 - accuracy: 0.9570 - val_loss: 0.2983 - val_accuracy: 0.9336\n",
      "Epoch 347/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2654 - accuracy: 0.9570 - val_loss: 0.2945 - val_accuracy: 0.9295\n",
      "Epoch 348/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2908 - accuracy: 0.9320 - val_loss: 0.2963 - val_accuracy: 0.9295\n",
      "Epoch 349/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2761 - accuracy: 0.9459 - val_loss: 0.2966 - val_accuracy: 0.9378\n",
      "Epoch 350/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.2782 - accuracy: 0.9417 - val_loss: 0.2987 - val_accuracy: 0.9336\n",
      "Epoch 351/2000\n",
      "721/721 [==============================] - 0s 57us/sample - loss: 0.2712 - accuracy: 0.9459 - val_loss: 0.2993 - val_accuracy: 0.9295\n",
      "Epoch 352/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.2589 - accuracy: 0.9542 - val_loss: 0.3004 - val_accuracy: 0.9336\n",
      "Epoch 353/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2599 - accuracy: 0.9487 - val_loss: 0.3013 - val_accuracy: 0.9419\n",
      "Epoch 354/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.2560 - accuracy: 0.9570 - val_loss: 0.2938 - val_accuracy: 0.9378\n",
      "Epoch 355/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.2694 - accuracy: 0.9528 - val_loss: 0.2967 - val_accuracy: 0.9378\n",
      "Epoch 356/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2673 - accuracy: 0.9431 - val_loss: 0.2979 - val_accuracy: 0.9295\n",
      "Epoch 357/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2554 - accuracy: 0.9515 - val_loss: 0.2947 - val_accuracy: 0.9419\n",
      "Epoch 358/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.2731 - accuracy: 0.9404 - val_loss: 0.2948 - val_accuracy: 0.9378\n",
      "Epoch 359/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2522 - accuracy: 0.9501 - val_loss: 0.2917 - val_accuracy: 0.9336\n",
      "Epoch 360/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2614 - accuracy: 0.9431 - val_loss: 0.2935 - val_accuracy: 0.9378\n",
      "Epoch 361/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.2670 - accuracy: 0.9459 - val_loss: 0.2944 - val_accuracy: 0.9253\n",
      "Epoch 362/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2646 - accuracy: 0.9445 - val_loss: 0.2952 - val_accuracy: 0.9295\n",
      "Epoch 363/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2692 - accuracy: 0.9417 - val_loss: 0.2964 - val_accuracy: 0.9336\n",
      "Epoch 364/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2381 - accuracy: 0.9639 - val_loss: 0.2921 - val_accuracy: 0.9212\n",
      "Epoch 365/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.2690 - accuracy: 0.9487 - val_loss: 0.2903 - val_accuracy: 0.9378\n",
      "Epoch 366/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.2420 - accuracy: 0.9515 - val_loss: 0.2960 - val_accuracy: 0.9336\n",
      "Epoch 367/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.2679 - accuracy: 0.9348 - val_loss: 0.2958 - val_accuracy: 0.9295\n",
      "Epoch 368/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.2752 - accuracy: 0.9362 - val_loss: 0.2961 - val_accuracy: 0.9378\n",
      "Epoch 369/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2847 - accuracy: 0.9417 - val_loss: 0.2902 - val_accuracy: 0.9378\n",
      "Epoch 370/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2542 - accuracy: 0.9473 - val_loss: 0.2916 - val_accuracy: 0.9419\n",
      "Epoch 371/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2539 - accuracy: 0.9473 - val_loss: 0.2886 - val_accuracy: 0.9336\n",
      "Epoch 372/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.2388 - accuracy: 0.9626 - val_loss: 0.2879 - val_accuracy: 0.9461\n",
      "Epoch 373/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2460 - accuracy: 0.9431 - val_loss: 0.2934 - val_accuracy: 0.9419\n",
      "Epoch 374/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.2571 - accuracy: 0.9390 - val_loss: 0.2945 - val_accuracy: 0.9336\n",
      "Epoch 375/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2571 - accuracy: 0.9626 - val_loss: 0.2926 - val_accuracy: 0.9419\n",
      "Epoch 376/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.2602 - accuracy: 0.9473 - val_loss: 0.2882 - val_accuracy: 0.9461\n",
      "Epoch 377/2000\n",
      "721/721 [==============================] - 0s 57us/sample - loss: 0.2631 - accuracy: 0.9459 - val_loss: 0.2915 - val_accuracy: 0.9378\n",
      "Epoch 378/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.2529 - accuracy: 0.9667 - val_loss: 0.2896 - val_accuracy: 0.9419\n",
      "Epoch 379/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.2589 - accuracy: 0.9584 - val_loss: 0.2938 - val_accuracy: 0.9378\n",
      "Epoch 380/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2559 - accuracy: 0.9612 - val_loss: 0.2908 - val_accuracy: 0.9378\n",
      "Epoch 381/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2502 - accuracy: 0.9487 - val_loss: 0.2955 - val_accuracy: 0.9378\n",
      "Epoch 382/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2603 - accuracy: 0.9459 - val_loss: 0.2903 - val_accuracy: 0.9378\n",
      "Epoch 383/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2438 - accuracy: 0.9626 - val_loss: 0.2943 - val_accuracy: 0.9378\n",
      "Epoch 384/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2677 - accuracy: 0.9390 - val_loss: 0.2913 - val_accuracy: 0.9378\n",
      "Epoch 385/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2495 - accuracy: 0.9556 - val_loss: 0.2906 - val_accuracy: 0.9295\n",
      "Epoch 386/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2538 - accuracy: 0.9459 - val_loss: 0.2918 - val_accuracy: 0.9378\n",
      "Epoch 387/2000\n",
      "721/721 [==============================] - 0s 42us/sample - loss: 0.2539 - accuracy: 0.9501 - val_loss: 0.2927 - val_accuracy: 0.9378\n",
      "Epoch 388/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2583 - accuracy: 0.9431 - val_loss: 0.2926 - val_accuracy: 0.9419\n",
      "Epoch 389/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2549 - accuracy: 0.9501 - val_loss: 0.2880 - val_accuracy: 0.9378\n",
      "Epoch 390/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.2633 - accuracy: 0.9445 - val_loss: 0.2949 - val_accuracy: 0.9336\n",
      "Epoch 391/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2497 - accuracy: 0.9542 - val_loss: 0.2906 - val_accuracy: 0.9295\n",
      "Epoch 392/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2569 - accuracy: 0.9431 - val_loss: 0.2928 - val_accuracy: 0.9295\n",
      "Epoch 393/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2490 - accuracy: 0.9556 - val_loss: 0.2926 - val_accuracy: 0.9336\n",
      "Epoch 394/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.2326 - accuracy: 0.9528 - val_loss: 0.2954 - val_accuracy: 0.9295\n",
      "Epoch 395/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2541 - accuracy: 0.9501 - val_loss: 0.2903 - val_accuracy: 0.9378\n",
      "Epoch 396/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.2483 - accuracy: 0.9487 - val_loss: 0.2900 - val_accuracy: 0.9378\n",
      "Epoch 397/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2432 - accuracy: 0.9501 - val_loss: 0.2875 - val_accuracy: 0.9378\n",
      "Epoch 398/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2617 - accuracy: 0.9445 - val_loss: 0.2930 - val_accuracy: 0.9336\n",
      "Epoch 399/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2358 - accuracy: 0.9584 - val_loss: 0.2891 - val_accuracy: 0.9336\n",
      "Epoch 400/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.2397 - accuracy: 0.9612 - val_loss: 0.2883 - val_accuracy: 0.9419\n",
      "Epoch 401/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.2495 - accuracy: 0.9542 - val_loss: 0.2953 - val_accuracy: 0.9253\n",
      "Epoch 402/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.2514 - accuracy: 0.9473 - val_loss: 0.2936 - val_accuracy: 0.9336\n",
      "Epoch 403/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2503 - accuracy: 0.9515 - val_loss: 0.2881 - val_accuracy: 0.9336\n",
      "Epoch 404/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2439 - accuracy: 0.9515 - val_loss: 0.2872 - val_accuracy: 0.9378\n",
      "Epoch 405/2000\n",
      "721/721 [==============================] - 0s 40us/sample - loss: 0.2838 - accuracy: 0.9362 - val_loss: 0.2897 - val_accuracy: 0.9295\n",
      "Epoch 406/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2389 - accuracy: 0.9667 - val_loss: 0.2874 - val_accuracy: 0.9378\n",
      "Epoch 407/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2539 - accuracy: 0.9473 - val_loss: 0.2880 - val_accuracy: 0.9336\n",
      "Epoch 408/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2405 - accuracy: 0.9556 - val_loss: 0.2918 - val_accuracy: 0.9295\n",
      "Epoch 409/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2431 - accuracy: 0.9584 - val_loss: 0.2914 - val_accuracy: 0.9419\n",
      "Epoch 410/2000\n",
      "721/721 [==============================] - 0s 59us/sample - loss: 0.2506 - accuracy: 0.9542 - val_loss: 0.2901 - val_accuracy: 0.9378\n",
      "Epoch 411/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2363 - accuracy: 0.9598 - val_loss: 0.2910 - val_accuracy: 0.9295\n",
      "Epoch 412/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.2283 - accuracy: 0.9598 - val_loss: 0.2852 - val_accuracy: 0.9378\n",
      "Epoch 413/2000\n",
      "721/721 [==============================] - 0s 60us/sample - loss: 0.2342 - accuracy: 0.9515 - val_loss: 0.2833 - val_accuracy: 0.9336\n",
      "Epoch 414/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2472 - accuracy: 0.9515 - val_loss: 0.2870 - val_accuracy: 0.9419\n",
      "Epoch 415/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2422 - accuracy: 0.9542 - val_loss: 0.2890 - val_accuracy: 0.9378\n",
      "Epoch 416/2000\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 0.2490 - accuracy: 0.9473 - val_loss: 0.2861 - val_accuracy: 0.9419\n",
      "Epoch 417/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.2508 - accuracy: 0.9542 - val_loss: 0.2897 - val_accuracy: 0.9378\n",
      "Epoch 418/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2472 - accuracy: 0.9431 - val_loss: 0.2863 - val_accuracy: 0.9419\n",
      "Epoch 419/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2524 - accuracy: 0.9515 - val_loss: 0.2877 - val_accuracy: 0.9419\n",
      "Epoch 420/2000\n",
      "721/721 [==============================] - 0s 40us/sample - loss: 0.2534 - accuracy: 0.9487 - val_loss: 0.2858 - val_accuracy: 0.9419\n",
      "Epoch 421/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.2277 - accuracy: 0.9570 - val_loss: 0.2877 - val_accuracy: 0.9419\n",
      "Epoch 422/2000\n",
      "721/721 [==============================] - 0s 44us/sample - loss: 0.2352 - accuracy: 0.9584 - val_loss: 0.2885 - val_accuracy: 0.9461\n",
      "Epoch 423/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2340 - accuracy: 0.9570 - val_loss: 0.2918 - val_accuracy: 0.9295\n",
      "Epoch 424/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.2368 - accuracy: 0.9542 - val_loss: 0.2888 - val_accuracy: 0.9295\n",
      "Epoch 425/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2336 - accuracy: 0.9528 - val_loss: 0.2932 - val_accuracy: 0.9295\n",
      "Epoch 426/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2380 - accuracy: 0.9584 - val_loss: 0.2888 - val_accuracy: 0.9378\n",
      "Epoch 427/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2415 - accuracy: 0.9542 - val_loss: 0.2880 - val_accuracy: 0.9419\n",
      "Epoch 428/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2337 - accuracy: 0.9515 - val_loss: 0.2834 - val_accuracy: 0.9378\n",
      "Epoch 429/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2297 - accuracy: 0.9681 - val_loss: 0.2846 - val_accuracy: 0.9378\n",
      "Epoch 430/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.2321 - accuracy: 0.9598 - val_loss: 0.2853 - val_accuracy: 0.9336\n",
      "Epoch 431/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2168 - accuracy: 0.9639 - val_loss: 0.2818 - val_accuracy: 0.9378\n",
      "Epoch 432/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.2261 - accuracy: 0.9570 - val_loss: 0.2773 - val_accuracy: 0.9461\n",
      "Epoch 433/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.2275 - accuracy: 0.9626 - val_loss: 0.2851 - val_accuracy: 0.9378\n",
      "Epoch 434/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2444 - accuracy: 0.9445 - val_loss: 0.2875 - val_accuracy: 0.9378\n",
      "Epoch 435/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2357 - accuracy: 0.9542 - val_loss: 0.2900 - val_accuracy: 0.9378\n",
      "Epoch 436/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.2290 - accuracy: 0.9612 - val_loss: 0.2915 - val_accuracy: 0.9295\n",
      "Epoch 437/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2407 - accuracy: 0.9626 - val_loss: 0.2901 - val_accuracy: 0.9295\n",
      "Epoch 438/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2401 - accuracy: 0.9515 - val_loss: 0.2884 - val_accuracy: 0.9336\n",
      "Epoch 439/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2267 - accuracy: 0.9584 - val_loss: 0.2940 - val_accuracy: 0.9295\n",
      "Epoch 440/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.2522 - accuracy: 0.9501 - val_loss: 0.2891 - val_accuracy: 0.9336\n",
      "Epoch 441/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2346 - accuracy: 0.9570 - val_loss: 0.2894 - val_accuracy: 0.9336\n",
      "Epoch 442/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2331 - accuracy: 0.9584 - val_loss: 0.2883 - val_accuracy: 0.9336\n",
      "Epoch 443/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.2397 - accuracy: 0.9501 - val_loss: 0.2833 - val_accuracy: 0.9336\n",
      "Epoch 444/2000\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 0.2653 - accuracy: 0.9362 - val_loss: 0.2852 - val_accuracy: 0.9336\n",
      "Epoch 445/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2160 - accuracy: 0.9639 - val_loss: 0.2819 - val_accuracy: 0.9378\n",
      "Epoch 446/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2221 - accuracy: 0.9556 - val_loss: 0.2819 - val_accuracy: 0.9419\n",
      "Epoch 447/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.2394 - accuracy: 0.9542 - val_loss: 0.2859 - val_accuracy: 0.9295\n",
      "Epoch 448/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2240 - accuracy: 0.9626 - val_loss: 0.2841 - val_accuracy: 0.9295\n",
      "Epoch 449/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.2195 - accuracy: 0.9570 - val_loss: 0.2854 - val_accuracy: 0.9419\n",
      "Epoch 450/2000\n",
      "721/721 [==============================] - 0s 43us/sample - loss: 0.2404 - accuracy: 0.9570 - val_loss: 0.2812 - val_accuracy: 0.9378\n",
      "Epoch 451/2000\n",
      "721/721 [==============================] - 0s 57us/sample - loss: 0.2443 - accuracy: 0.9431 - val_loss: 0.2832 - val_accuracy: 0.9378\n",
      "Epoch 452/2000\n",
      "721/721 [==============================] - 0s 51us/sample - loss: 0.2316 - accuracy: 0.9542 - val_loss: 0.2870 - val_accuracy: 0.9336\n",
      "Epoch 453/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2212 - accuracy: 0.9653 - val_loss: 0.2898 - val_accuracy: 0.9336\n",
      "Epoch 454/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2553 - accuracy: 0.9445 - val_loss: 0.2869 - val_accuracy: 0.9378\n",
      "Epoch 455/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2318 - accuracy: 0.9598 - val_loss: 0.2840 - val_accuracy: 0.9378\n",
      "Epoch 456/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2359 - accuracy: 0.9459 - val_loss: 0.2849 - val_accuracy: 0.9419\n",
      "Epoch 457/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.2132 - accuracy: 0.9556 - val_loss: 0.2867 - val_accuracy: 0.9378\n",
      "Epoch 458/2000\n",
      "721/721 [==============================] - 0s 53us/sample - loss: 0.2374 - accuracy: 0.9501 - val_loss: 0.2847 - val_accuracy: 0.9419\n",
      "Epoch 459/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2308 - accuracy: 0.9556 - val_loss: 0.2843 - val_accuracy: 0.9336\n",
      "Epoch 460/2000\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 0.2431 - accuracy: 0.9473 - val_loss: 0.2850 - val_accuracy: 0.9461\n",
      "Epoch 461/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2164 - accuracy: 0.9626 - val_loss: 0.2877 - val_accuracy: 0.9336\n",
      "Epoch 462/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2242 - accuracy: 0.9584 - val_loss: 0.2845 - val_accuracy: 0.9336\n",
      "Epoch 463/2000\n",
      "721/721 [==============================] - 0s 46us/sample - loss: 0.2132 - accuracy: 0.9626 - val_loss: 0.2858 - val_accuracy: 0.9295\n",
      "Epoch 464/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2610 - accuracy: 0.9334 - val_loss: 0.2846 - val_accuracy: 0.9295\n",
      "Epoch 465/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.2238 - accuracy: 0.9667 - val_loss: 0.2822 - val_accuracy: 0.9378\n",
      "Epoch 466/2000\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 0.2323 - accuracy: 0.9570 - val_loss: 0.2832 - val_accuracy: 0.9378\n",
      "Epoch 467/2000\n",
      "721/721 [==============================] - 0s 52us/sample - loss: 0.2278 - accuracy: 0.9584 - val_loss: 0.2871 - val_accuracy: 0.9336\n",
      "Epoch 468/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2257 - accuracy: 0.9542 - val_loss: 0.2895 - val_accuracy: 0.9295\n",
      "Epoch 469/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2295 - accuracy: 0.9528 - val_loss: 0.2876 - val_accuracy: 0.9336\n",
      "Epoch 470/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2253 - accuracy: 0.9639 - val_loss: 0.2808 - val_accuracy: 0.9419\n",
      "Epoch 471/2000\n",
      "721/721 [==============================] - 0s 50us/sample - loss: 0.2339 - accuracy: 0.9501 - val_loss: 0.2848 - val_accuracy: 0.9378\n",
      "Epoch 472/2000\n",
      "721/721 [==============================] - 0s 41us/sample - loss: 0.2266 - accuracy: 0.9598 - val_loss: 0.2844 - val_accuracy: 0.9295\n",
      "Epoch 473/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2084 - accuracy: 0.9612 - val_loss: 0.2835 - val_accuracy: 0.9336\n",
      "Epoch 474/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.2422 - accuracy: 0.9570 - val_loss: 0.2860 - val_accuracy: 0.9461\n",
      "Epoch 475/2000\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 0.2468 - accuracy: 0.9487 - val_loss: 0.2812 - val_accuracy: 0.9295\n",
      "Epoch 476/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2253 - accuracy: 0.9612 - val_loss: 0.2848 - val_accuracy: 0.9336\n",
      "Epoch 477/2000\n",
      "721/721 [==============================] - 0s 48us/sample - loss: 0.2250 - accuracy: 0.9570 - val_loss: 0.2841 - val_accuracy: 0.9336\n",
      "Epoch 478/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2262 - accuracy: 0.9584 - val_loss: 0.2817 - val_accuracy: 0.9336\n",
      "Epoch 479/2000\n",
      "721/721 [==============================] - 0s 49us/sample - loss: 0.2221 - accuracy: 0.9570 - val_loss: 0.2781 - val_accuracy: 0.9419\n",
      "Epoch 480/2000\n",
      "721/721 [==============================] - 0s 47us/sample - loss: 0.2280 - accuracy: 0.9528 - val_loss: 0.2826 - val_accuracy: 0.9336\n",
      "Epoch 481/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.1997 - accuracy: 0.9764 - val_loss: 0.2788 - val_accuracy: 0.9378\n",
      "Epoch 482/2000\n",
      "721/721 [==============================] - 0s 55us/sample - loss: 0.2316 - accuracy: 0.9598 - val_loss: 0.2818 - val_accuracy: 0.9378\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 2,062\n",
      "Trainable params: 2,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 824 samples, validate on 275 samples\n",
      "Epoch 1/2000\n",
      "824/824 [==============================] - 0s 521us/sample - loss: 2.6507 - accuracy: 0.0837 - val_loss: 2.5917 - val_accuracy: 0.2073\n",
      "Epoch 2/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 2.5967 - accuracy: 0.1456 - val_loss: 2.5499 - val_accuracy: 0.3091\n",
      "Epoch 3/2000\n",
      "824/824 [==============================] - 0s 51us/sample - loss: 2.5639 - accuracy: 0.1578 - val_loss: 2.5092 - val_accuracy: 0.3745\n",
      "Epoch 4/2000\n",
      "824/824 [==============================] - 0s 49us/sample - loss: 2.5098 - accuracy: 0.2002 - val_loss: 2.4570 - val_accuracy: 0.4364\n",
      "Epoch 5/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 2.4523 - accuracy: 0.2476 - val_loss: 2.4035 - val_accuracy: 0.4145\n",
      "Epoch 6/2000\n",
      "824/824 [==============================] - 0s 51us/sample - loss: 2.4007 - accuracy: 0.2925 - val_loss: 2.3424 - val_accuracy: 0.4364\n",
      "Epoch 7/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 2.3470 - accuracy: 0.2767 - val_loss: 2.2815 - val_accuracy: 0.4509\n",
      "Epoch 8/2000\n",
      "824/824 [==============================] - 0s 48us/sample - loss: 2.2806 - accuracy: 0.3180 - val_loss: 2.2187 - val_accuracy: 0.4909\n",
      "Epoch 9/2000\n",
      "824/824 [==============================] - 0s 39us/sample - loss: 2.2232 - accuracy: 0.3568 - val_loss: 2.1563 - val_accuracy: 0.4582\n",
      "Epoch 10/2000\n",
      "824/824 [==============================] - 0s 49us/sample - loss: 2.1581 - accuracy: 0.3532 - val_loss: 2.0974 - val_accuracy: 0.5236\n",
      "Epoch 11/2000\n",
      "824/824 [==============================] - 0s 43us/sample - loss: 2.1047 - accuracy: 0.3896 - val_loss: 2.0386 - val_accuracy: 0.5273\n",
      "Epoch 12/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 2.0546 - accuracy: 0.3823 - val_loss: 1.9825 - val_accuracy: 0.5636\n",
      "Epoch 13/2000\n",
      "824/824 [==============================] - 0s 50us/sample - loss: 1.9923 - accuracy: 0.4199 - val_loss: 1.9274 - val_accuracy: 0.5891\n",
      "Epoch 14/2000\n",
      "824/824 [==============================] - 0s 39us/sample - loss: 1.9406 - accuracy: 0.4478 - val_loss: 1.8728 - val_accuracy: 0.6364\n",
      "Epoch 15/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 1.9138 - accuracy: 0.4405 - val_loss: 1.8268 - val_accuracy: 0.6291\n",
      "Epoch 16/2000\n",
      "824/824 [==============================] - 0s 46us/sample - loss: 1.8662 - accuracy: 0.4551 - val_loss: 1.7768 - val_accuracy: 0.6909\n",
      "Epoch 17/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 1.7937 - accuracy: 0.4782 - val_loss: 1.7277 - val_accuracy: 0.6691\n",
      "Epoch 18/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 1.7557 - accuracy: 0.4891 - val_loss: 1.6838 - val_accuracy: 0.7091\n",
      "Epoch 19/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 1.7141 - accuracy: 0.4903 - val_loss: 1.6429 - val_accuracy: 0.7200\n",
      "Epoch 20/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 1.6919 - accuracy: 0.5158 - val_loss: 1.6062 - val_accuracy: 0.7055\n",
      "Epoch 21/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 1.6243 - accuracy: 0.5498 - val_loss: 1.5629 - val_accuracy: 0.7455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 1.6107 - accuracy: 0.5267 - val_loss: 1.5308 - val_accuracy: 0.7564\n",
      "Epoch 23/2000\n",
      "824/824 [==============================] - 0s 54us/sample - loss: 1.5898 - accuracy: 0.5388 - val_loss: 1.4889 - val_accuracy: 0.7527\n",
      "Epoch 24/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 1.5719 - accuracy: 0.5194 - val_loss: 1.4553 - val_accuracy: 0.7745\n",
      "Epoch 25/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 1.5115 - accuracy: 0.5570 - val_loss: 1.4239 - val_accuracy: 0.7891\n",
      "Epoch 26/2000\n",
      "824/824 [==============================] - 0s 48us/sample - loss: 1.4729 - accuracy: 0.5777 - val_loss: 1.3907 - val_accuracy: 0.7636\n",
      "Epoch 27/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 1.4637 - accuracy: 0.5752 - val_loss: 1.3607 - val_accuracy: 0.7964\n",
      "Epoch 28/2000\n",
      "824/824 [==============================] - 0s 51us/sample - loss: 1.4425 - accuracy: 0.5777 - val_loss: 1.3319 - val_accuracy: 0.7964\n",
      "Epoch 29/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 1.3932 - accuracy: 0.6371 - val_loss: 1.2980 - val_accuracy: 0.8182\n",
      "Epoch 30/2000\n",
      "824/824 [==============================] - 0s 53us/sample - loss: 1.3826 - accuracy: 0.6141 - val_loss: 1.2720 - val_accuracy: 0.8364\n",
      "Epoch 31/2000\n",
      "824/824 [==============================] - 0s 50us/sample - loss: 1.3703 - accuracy: 0.6019 - val_loss: 1.2464 - val_accuracy: 0.8291\n",
      "Epoch 32/2000\n",
      "824/824 [==============================] - 0s 39us/sample - loss: 1.3136 - accuracy: 0.6383 - val_loss: 1.2227 - val_accuracy: 0.8436\n",
      "Epoch 33/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 1.2705 - accuracy: 0.6383 - val_loss: 1.1905 - val_accuracy: 0.8400\n",
      "Epoch 34/2000\n",
      "824/824 [==============================] - 0s 49us/sample - loss: 1.2686 - accuracy: 0.6432 - val_loss: 1.1713 - val_accuracy: 0.8291\n",
      "Epoch 35/2000\n",
      "824/824 [==============================] - 0s 38us/sample - loss: 1.2737 - accuracy: 0.6456 - val_loss: 1.1471 - val_accuracy: 0.8473\n",
      "Epoch 36/2000\n",
      "824/824 [==============================] - 0s 51us/sample - loss: 1.2438 - accuracy: 0.6420 - val_loss: 1.1284 - val_accuracy: 0.8364\n",
      "Epoch 37/2000\n",
      "824/824 [==============================] - 0s 48us/sample - loss: 1.1845 - accuracy: 0.6857 - val_loss: 1.1062 - val_accuracy: 0.8364\n",
      "Epoch 38/2000\n",
      "824/824 [==============================] - 0s 50us/sample - loss: 1.1556 - accuracy: 0.6930 - val_loss: 1.0812 - val_accuracy: 0.8400\n",
      "Epoch 39/2000\n",
      "824/824 [==============================] - 0s 51us/sample - loss: 1.1524 - accuracy: 0.6881 - val_loss: 1.0630 - val_accuracy: 0.8473\n",
      "Epoch 40/2000\n",
      "824/824 [==============================] - 0s 40us/sample - loss: 1.1577 - accuracy: 0.6893 - val_loss: 1.0504 - val_accuracy: 0.8473\n",
      "Epoch 41/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 1.1038 - accuracy: 0.7148 - val_loss: 1.0194 - val_accuracy: 0.8618\n",
      "Epoch 42/2000\n",
      "824/824 [==============================] - 0s 49us/sample - loss: 1.0870 - accuracy: 0.7051 - val_loss: 1.0116 - val_accuracy: 0.8545\n",
      "Epoch 43/2000\n",
      "824/824 [==============================] - 0s 38us/sample - loss: 1.0759 - accuracy: 0.7245 - val_loss: 0.9907 - val_accuracy: 0.8473\n",
      "Epoch 44/2000\n",
      "824/824 [==============================] - 0s 50us/sample - loss: 1.0523 - accuracy: 0.7075 - val_loss: 0.9679 - val_accuracy: 0.8509\n",
      "Epoch 45/2000\n",
      "824/824 [==============================] - 0s 48us/sample - loss: 1.0567 - accuracy: 0.7063 - val_loss: 0.9559 - val_accuracy: 0.8473\n",
      "Epoch 46/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 1.0203 - accuracy: 0.7112 - val_loss: 0.9450 - val_accuracy: 0.8400\n",
      "Epoch 47/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 1.0005 - accuracy: 0.7257 - val_loss: 0.9341 - val_accuracy: 0.8545\n",
      "Epoch 48/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.9632 - accuracy: 0.7245 - val_loss: 0.9138 - val_accuracy: 0.8582\n",
      "Epoch 49/2000\n",
      "824/824 [==============================] - 0s 53us/sample - loss: 0.9430 - accuracy: 0.7731 - val_loss: 0.9045 - val_accuracy: 0.8618\n",
      "Epoch 50/2000\n",
      "824/824 [==============================] - 0s 48us/sample - loss: 0.9729 - accuracy: 0.7464 - val_loss: 0.8793 - val_accuracy: 0.8582\n",
      "Epoch 51/2000\n",
      "824/824 [==============================] - 0s 38us/sample - loss: 0.9361 - accuracy: 0.7706 - val_loss: 0.8706 - val_accuracy: 0.8655\n",
      "Epoch 52/2000\n",
      "824/824 [==============================] - 0s 46us/sample - loss: 0.9263 - accuracy: 0.7597 - val_loss: 0.8630 - val_accuracy: 0.8582\n",
      "Epoch 53/2000\n",
      "824/824 [==============================] - 0s 40us/sample - loss: 0.8940 - accuracy: 0.7888 - val_loss: 0.8481 - val_accuracy: 0.8618\n",
      "Epoch 54/2000\n",
      "824/824 [==============================] - 0s 49us/sample - loss: 0.8889 - accuracy: 0.7852 - val_loss: 0.8327 - val_accuracy: 0.8691\n",
      "Epoch 55/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.8612 - accuracy: 0.8010 - val_loss: 0.8313 - val_accuracy: 0.8655\n",
      "Epoch 56/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.8660 - accuracy: 0.7828 - val_loss: 0.8252 - val_accuracy: 0.8691\n",
      "Epoch 57/2000\n",
      "824/824 [==============================] - 0s 48us/sample - loss: 0.8712 - accuracy: 0.7767 - val_loss: 0.8144 - val_accuracy: 0.8545\n",
      "Epoch 58/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.8495 - accuracy: 0.7803 - val_loss: 0.8025 - val_accuracy: 0.8655\n",
      "Epoch 59/2000\n",
      "824/824 [==============================] - 0s 54us/sample - loss: 0.8291 - accuracy: 0.7913 - val_loss: 0.7945 - val_accuracy: 0.8691\n",
      "Epoch 60/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.8222 - accuracy: 0.8046 - val_loss: 0.7846 - val_accuracy: 0.8691\n",
      "Epoch 61/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.8046 - accuracy: 0.8010 - val_loss: 0.7702 - val_accuracy: 0.8691\n",
      "Epoch 62/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.8134 - accuracy: 0.8046 - val_loss: 0.7689 - val_accuracy: 0.8618\n",
      "Epoch 63/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.8122 - accuracy: 0.7949 - val_loss: 0.7577 - val_accuracy: 0.8618\n",
      "Epoch 64/2000\n",
      "824/824 [==============================] - 0s 54us/sample - loss: 0.7755 - accuracy: 0.8022 - val_loss: 0.7549 - val_accuracy: 0.8691\n",
      "Epoch 65/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.7338 - accuracy: 0.8301 - val_loss: 0.7421 - val_accuracy: 0.8727\n",
      "Epoch 66/2000\n",
      "824/824 [==============================] - 0s 53us/sample - loss: 0.7559 - accuracy: 0.8143 - val_loss: 0.7429 - val_accuracy: 0.8727\n",
      "Epoch 67/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.7348 - accuracy: 0.8289 - val_loss: 0.7256 - val_accuracy: 0.8727\n",
      "Epoch 68/2000\n",
      "824/824 [==============================] - 0s 54us/sample - loss: 0.7271 - accuracy: 0.8277 - val_loss: 0.7294 - val_accuracy: 0.8727\n",
      "Epoch 69/2000\n",
      "824/824 [==============================] - 0s 46us/sample - loss: 0.7144 - accuracy: 0.8277 - val_loss: 0.7102 - val_accuracy: 0.8764\n",
      "Epoch 70/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.7231 - accuracy: 0.8119 - val_loss: 0.7220 - val_accuracy: 0.8727\n",
      "Epoch 71/2000\n",
      "824/824 [==============================] - 0s 50us/sample - loss: 0.7044 - accuracy: 0.8240 - val_loss: 0.7087 - val_accuracy: 0.8764\n",
      "Epoch 72/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.6867 - accuracy: 0.8398 - val_loss: 0.6981 - val_accuracy: 0.8800\n",
      "Epoch 73/2000\n",
      "824/824 [==============================] - 0s 54us/sample - loss: 0.6839 - accuracy: 0.8301 - val_loss: 0.6989 - val_accuracy: 0.8764\n",
      "Epoch 74/2000\n",
      "824/824 [==============================] - 0s 46us/sample - loss: 0.6658 - accuracy: 0.8532 - val_loss: 0.6904 - val_accuracy: 0.8764\n",
      "Epoch 75/2000\n",
      "824/824 [==============================] - 0s 50us/sample - loss: 0.6504 - accuracy: 0.8556 - val_loss: 0.6873 - val_accuracy: 0.8764\n",
      "Epoch 76/2000\n",
      "824/824 [==============================] - 0s 48us/sample - loss: 0.6585 - accuracy: 0.8519 - val_loss: 0.6785 - val_accuracy: 0.8727\n",
      "Epoch 77/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824/824 [==============================] - 0s 44us/sample - loss: 0.6636 - accuracy: 0.8544 - val_loss: 0.6906 - val_accuracy: 0.8727\n",
      "Epoch 78/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.6420 - accuracy: 0.8483 - val_loss: 0.6821 - val_accuracy: 0.8764\n",
      "Epoch 79/2000\n",
      "824/824 [==============================] - 0s 48us/sample - loss: 0.6305 - accuracy: 0.8434 - val_loss: 0.6793 - val_accuracy: 0.8873\n",
      "Epoch 80/2000\n",
      "824/824 [==============================] - 0s 39us/sample - loss: 0.6433 - accuracy: 0.8507 - val_loss: 0.6553 - val_accuracy: 0.8836\n",
      "Epoch 81/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.6317 - accuracy: 0.8495 - val_loss: 0.6679 - val_accuracy: 0.8764\n",
      "Epoch 82/2000\n",
      "824/824 [==============================] - 0s 48us/sample - loss: 0.6301 - accuracy: 0.8398 - val_loss: 0.6585 - val_accuracy: 0.8764\n",
      "Epoch 83/2000\n",
      "824/824 [==============================] - 0s 47us/sample - loss: 0.6264 - accuracy: 0.8544 - val_loss: 0.6639 - val_accuracy: 0.8800\n",
      "Epoch 84/2000\n",
      "824/824 [==============================] - 0s 49us/sample - loss: 0.6245 - accuracy: 0.8447 - val_loss: 0.6593 - val_accuracy: 0.8873\n",
      "Epoch 85/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.6095 - accuracy: 0.8701 - val_loss: 0.6673 - val_accuracy: 0.8727\n",
      "Epoch 86/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.6010 - accuracy: 0.8495 - val_loss: 0.6624 - val_accuracy: 0.8873\n",
      "Epoch 87/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.6032 - accuracy: 0.8604 - val_loss: 0.6522 - val_accuracy: 0.8873\n",
      "Epoch 88/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.5812 - accuracy: 0.8689 - val_loss: 0.6438 - val_accuracy: 0.8800\n",
      "Epoch 89/2000\n",
      "824/824 [==============================] - 0s 53us/sample - loss: 0.5807 - accuracy: 0.8629 - val_loss: 0.6564 - val_accuracy: 0.8836\n",
      "Epoch 90/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.5791 - accuracy: 0.8677 - val_loss: 0.6484 - val_accuracy: 0.8618\n",
      "Epoch 91/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.5726 - accuracy: 0.8714 - val_loss: 0.6651 - val_accuracy: 0.8800\n",
      "Epoch 92/2000\n",
      "824/824 [==============================] - 0s 51us/sample - loss: 0.5616 - accuracy: 0.8786 - val_loss: 0.6433 - val_accuracy: 0.8764\n",
      "Epoch 93/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.5782 - accuracy: 0.8617 - val_loss: 0.6560 - val_accuracy: 0.8873\n",
      "Epoch 94/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.5556 - accuracy: 0.8786 - val_loss: 0.6407 - val_accuracy: 0.8873\n",
      "Epoch 95/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.5496 - accuracy: 0.8859 - val_loss: 0.6367 - val_accuracy: 0.8800\n",
      "Epoch 96/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.5475 - accuracy: 0.8726 - val_loss: 0.6442 - val_accuracy: 0.8800\n",
      "Epoch 97/2000\n",
      "824/824 [==============================] - 0s 51us/sample - loss: 0.5350 - accuracy: 0.8823 - val_loss: 0.6291 - val_accuracy: 0.8945\n",
      "Epoch 98/2000\n",
      "824/824 [==============================] - 0s 47us/sample - loss: 0.5356 - accuracy: 0.8738 - val_loss: 0.6264 - val_accuracy: 0.8909\n",
      "Epoch 99/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.5452 - accuracy: 0.8799 - val_loss: 0.6479 - val_accuracy: 0.8800\n",
      "Epoch 100/2000\n",
      "824/824 [==============================] - 0s 53us/sample - loss: 0.5029 - accuracy: 0.8944 - val_loss: 0.6320 - val_accuracy: 0.8873\n",
      "Epoch 101/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.5341 - accuracy: 0.8786 - val_loss: 0.6329 - val_accuracy: 0.8873\n",
      "Epoch 102/2000\n",
      "824/824 [==============================] - 0s 53us/sample - loss: 0.5370 - accuracy: 0.8823 - val_loss: 0.6411 - val_accuracy: 0.8836\n",
      "Epoch 103/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.4959 - accuracy: 0.8920 - val_loss: 0.6430 - val_accuracy: 0.8800\n",
      "Epoch 104/2000\n",
      "824/824 [==============================] - 0s 47us/sample - loss: 0.4943 - accuracy: 0.8956 - val_loss: 0.6331 - val_accuracy: 0.8836\n",
      "Epoch 105/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.5189 - accuracy: 0.8750 - val_loss: 0.6293 - val_accuracy: 0.8800\n",
      "Epoch 106/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.4924 - accuracy: 0.8956 - val_loss: 0.6159 - val_accuracy: 0.8909\n",
      "Epoch 107/2000\n",
      "824/824 [==============================] - 0s 53us/sample - loss: 0.4918 - accuracy: 0.8871 - val_loss: 0.6457 - val_accuracy: 0.8873\n",
      "Epoch 108/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.5265 - accuracy: 0.8823 - val_loss: 0.6484 - val_accuracy: 0.8836\n",
      "Epoch 109/2000\n",
      "824/824 [==============================] - 0s 54us/sample - loss: 0.5098 - accuracy: 0.8701 - val_loss: 0.6378 - val_accuracy: 0.8836\n",
      "Epoch 110/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.5014 - accuracy: 0.8908 - val_loss: 0.6164 - val_accuracy: 0.8836\n",
      "Epoch 111/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.4928 - accuracy: 0.9005 - val_loss: 0.6217 - val_accuracy: 0.8873\n",
      "Epoch 112/2000\n",
      "824/824 [==============================] - 0s 55us/sample - loss: 0.4676 - accuracy: 0.8993 - val_loss: 0.6148 - val_accuracy: 0.8945\n",
      "Epoch 113/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.4701 - accuracy: 0.9114 - val_loss: 0.6235 - val_accuracy: 0.8909\n",
      "Epoch 114/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.4677 - accuracy: 0.9066 - val_loss: 0.6224 - val_accuracy: 0.8800\n",
      "Epoch 115/2000\n",
      "824/824 [==============================] - 0s 46us/sample - loss: 0.4635 - accuracy: 0.9066 - val_loss: 0.6109 - val_accuracy: 0.8909\n",
      "Epoch 116/2000\n",
      "824/824 [==============================] - 0s 50us/sample - loss: 0.4578 - accuracy: 0.9078 - val_loss: 0.6108 - val_accuracy: 0.8873\n",
      "Epoch 117/2000\n",
      "824/824 [==============================] - 0s 50us/sample - loss: 0.4643 - accuracy: 0.8908 - val_loss: 0.6328 - val_accuracy: 0.8836\n",
      "Epoch 118/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.4714 - accuracy: 0.8944 - val_loss: 0.6264 - val_accuracy: 0.8764\n",
      "Epoch 119/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.4447 - accuracy: 0.9017 - val_loss: 0.6342 - val_accuracy: 0.8909\n",
      "Epoch 120/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.4782 - accuracy: 0.8871 - val_loss: 0.6127 - val_accuracy: 0.8909\n",
      "Epoch 121/2000\n",
      "824/824 [==============================] - 0s 54us/sample - loss: 0.4485 - accuracy: 0.9078 - val_loss: 0.6352 - val_accuracy: 0.8800\n",
      "Epoch 122/2000\n",
      "824/824 [==============================] - 0s 47us/sample - loss: 0.4584 - accuracy: 0.9041 - val_loss: 0.6182 - val_accuracy: 0.8873\n",
      "Epoch 123/2000\n",
      "824/824 [==============================] - 0s 48us/sample - loss: 0.4526 - accuracy: 0.9041 - val_loss: 0.6470 - val_accuracy: 0.8873\n",
      "Epoch 124/2000\n",
      "824/824 [==============================] - 0s 48us/sample - loss: 0.4534 - accuracy: 0.8835 - val_loss: 0.6139 - val_accuracy: 0.8909\n",
      "Epoch 125/2000\n",
      "824/824 [==============================] - 0s 46us/sample - loss: 0.4471 - accuracy: 0.9066 - val_loss: 0.6077 - val_accuracy: 0.8873\n",
      "Epoch 126/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.4537 - accuracy: 0.8859 - val_loss: 0.6261 - val_accuracy: 0.8909\n",
      "Epoch 127/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.4283 - accuracy: 0.9005 - val_loss: 0.6355 - val_accuracy: 0.8909\n",
      "Epoch 128/2000\n",
      "824/824 [==============================] - 0s 54us/sample - loss: 0.4448 - accuracy: 0.8981 - val_loss: 0.6250 - val_accuracy: 0.8873\n",
      "Epoch 129/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.4390 - accuracy: 0.9066 - val_loss: 0.6318 - val_accuracy: 0.8873\n",
      "Epoch 130/2000\n",
      "824/824 [==============================] - 0s 51us/sample - loss: 0.4422 - accuracy: 0.9005 - val_loss: 0.6290 - val_accuracy: 0.8873\n",
      "Epoch 131/2000\n",
      "824/824 [==============================] - 0s 49us/sample - loss: 0.4252 - accuracy: 0.9078 - val_loss: 0.6148 - val_accuracy: 0.8873\n",
      "Epoch 132/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824/824 [==============================] - 0s 46us/sample - loss: 0.4322 - accuracy: 0.9078 - val_loss: 0.6258 - val_accuracy: 0.8945\n",
      "Epoch 133/2000\n",
      "824/824 [==============================] - 0s 53us/sample - loss: 0.4377 - accuracy: 0.9017 - val_loss: 0.6231 - val_accuracy: 0.8836\n",
      "Epoch 134/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.4329 - accuracy: 0.9102 - val_loss: 0.6256 - val_accuracy: 0.8800\n",
      "Epoch 135/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.4321 - accuracy: 0.9066 - val_loss: 0.6252 - val_accuracy: 0.8909\n",
      "Epoch 136/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.4120 - accuracy: 0.9150 - val_loss: 0.6171 - val_accuracy: 0.8873\n",
      "Epoch 137/2000\n",
      "824/824 [==============================] - 0s 43us/sample - loss: 0.4239 - accuracy: 0.9041 - val_loss: 0.6274 - val_accuracy: 0.8909\n",
      "Epoch 138/2000\n",
      "824/824 [==============================] - 0s 40us/sample - loss: 0.4130 - accuracy: 0.9126 - val_loss: 0.6322 - val_accuracy: 0.8909\n",
      "Epoch 139/2000\n",
      "824/824 [==============================] - 0s 43us/sample - loss: 0.4056 - accuracy: 0.9163 - val_loss: 0.6133 - val_accuracy: 0.8982\n",
      "Epoch 140/2000\n",
      "824/824 [==============================] - 0s 47us/sample - loss: 0.4322 - accuracy: 0.9017 - val_loss: 0.6131 - val_accuracy: 0.8873\n",
      "Epoch 141/2000\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.3948 - accuracy: 0.9150 - val_loss: 0.6267 - val_accuracy: 0.8800\n",
      "Epoch 142/2000\n",
      "824/824 [==============================] - 0s 91us/sample - loss: 0.3988 - accuracy: 0.9163 - val_loss: 0.6181 - val_accuracy: 0.8945\n",
      "Epoch 143/2000\n",
      "824/824 [==============================] - 0s 79us/sample - loss: 0.3967 - accuracy: 0.9223 - val_loss: 0.6298 - val_accuracy: 0.8836\n",
      "Epoch 144/2000\n",
      "824/824 [==============================] - 0s 78us/sample - loss: 0.3896 - accuracy: 0.9150 - val_loss: 0.6319 - val_accuracy: 0.8909\n",
      "Epoch 145/2000\n",
      "824/824 [==============================] - 0s 75us/sample - loss: 0.3954 - accuracy: 0.9296 - val_loss: 0.6427 - val_accuracy: 0.8800\n",
      "Epoch 146/2000\n",
      "824/824 [==============================] - 0s 76us/sample - loss: 0.3957 - accuracy: 0.9163 - val_loss: 0.6328 - val_accuracy: 0.8873\n",
      "Epoch 147/2000\n",
      "824/824 [==============================] - 0s 68us/sample - loss: 0.3757 - accuracy: 0.9199 - val_loss: 0.6238 - val_accuracy: 0.8800\n",
      "Epoch 148/2000\n",
      "824/824 [==============================] - 0s 47us/sample - loss: 0.3929 - accuracy: 0.9163 - val_loss: 0.6351 - val_accuracy: 0.8945\n",
      "Epoch 149/2000\n",
      "824/824 [==============================] - 0s 48us/sample - loss: 0.4194 - accuracy: 0.9126 - val_loss: 0.6440 - val_accuracy: 0.8945\n",
      "Epoch 150/2000\n",
      "824/824 [==============================] - 0s 46us/sample - loss: 0.3778 - accuracy: 0.9296 - val_loss: 0.6264 - val_accuracy: 0.8836\n",
      "Epoch 151/2000\n",
      "824/824 [==============================] - 0s 49us/sample - loss: 0.3798 - accuracy: 0.9260 - val_loss: 0.6593 - val_accuracy: 0.8873\n",
      "Epoch 152/2000\n",
      "824/824 [==============================] - 0s 66us/sample - loss: 0.3773 - accuracy: 0.9333 - val_loss: 0.6160 - val_accuracy: 0.8909\n",
      "Epoch 153/2000\n",
      "824/824 [==============================] - 0s 75us/sample - loss: 0.4064 - accuracy: 0.9150 - val_loss: 0.6241 - val_accuracy: 0.8945\n",
      "Epoch 154/2000\n",
      "824/824 [==============================] - 0s 71us/sample - loss: 0.3799 - accuracy: 0.9248 - val_loss: 0.6335 - val_accuracy: 0.8909\n",
      "Epoch 155/2000\n",
      "824/824 [==============================] - 0s 59us/sample - loss: 0.3873 - accuracy: 0.9175 - val_loss: 0.6456 - val_accuracy: 0.8909\n",
      "Epoch 156/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.3762 - accuracy: 0.9284 - val_loss: 0.6445 - val_accuracy: 0.8909\n",
      "Epoch 157/2000\n",
      "824/824 [==============================] - 0s 50us/sample - loss: 0.3778 - accuracy: 0.9199 - val_loss: 0.6361 - val_accuracy: 0.8909\n",
      "Epoch 158/2000\n",
      "824/824 [==============================] - 0s 39us/sample - loss: 0.3906 - accuracy: 0.9187 - val_loss: 0.6296 - val_accuracy: 0.8945\n",
      "Epoch 159/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.3778 - accuracy: 0.9284 - val_loss: 0.6430 - val_accuracy: 0.8800\n",
      "Epoch 160/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.3689 - accuracy: 0.9272 - val_loss: 0.6697 - val_accuracy: 0.8873\n",
      "Epoch 161/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.3572 - accuracy: 0.9393 - val_loss: 0.6356 - val_accuracy: 0.8873\n",
      "Epoch 162/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.3677 - accuracy: 0.9260 - val_loss: 0.6415 - val_accuracy: 0.8909\n",
      "Epoch 163/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.3550 - accuracy: 0.9393 - val_loss: 0.6485 - val_accuracy: 0.8873\n",
      "Epoch 164/2000\n",
      "824/824 [==============================] - 0s 53us/sample - loss: 0.3711 - accuracy: 0.9211 - val_loss: 0.6537 - val_accuracy: 0.8945\n",
      "Epoch 165/2000\n",
      "824/824 [==============================] - 0s 45us/sample - loss: 0.3601 - accuracy: 0.9272 - val_loss: 0.6477 - val_accuracy: 0.8909\n",
      "Epoch 166/2000\n",
      "824/824 [==============================] - 0s 44us/sample - loss: 0.3830 - accuracy: 0.9041 - val_loss: 0.6483 - val_accuracy: 0.8836\n",
      "Epoch 167/2000\n",
      "824/824 [==============================] - 0s 39us/sample - loss: 0.3670 - accuracy: 0.9150 - val_loss: 0.6741 - val_accuracy: 0.8909\n",
      "Epoch 168/2000\n",
      "824/824 [==============================] - 0s 43us/sample - loss: 0.3602 - accuracy: 0.9308 - val_loss: 0.6621 - val_accuracy: 0.8909\n",
      "Epoch 169/2000\n",
      "824/824 [==============================] - 0s 50us/sample - loss: 0.3763 - accuracy: 0.9223 - val_loss: 0.6505 - val_accuracy: 0.8909\n",
      "Epoch 170/2000\n",
      "824/824 [==============================] - 0s 46us/sample - loss: 0.3787 - accuracy: 0.9223 - val_loss: 0.6695 - val_accuracy: 0.8836\n",
      "Epoch 171/2000\n",
      "824/824 [==============================] - 0s 54us/sample - loss: 0.3690 - accuracy: 0.9163 - val_loss: 0.6264 - val_accuracy: 0.8909\n",
      "Epoch 172/2000\n",
      "824/824 [==============================] - 0s 46us/sample - loss: 0.3716 - accuracy: 0.9284 - val_loss: 0.6517 - val_accuracy: 0.8873\n",
      "Epoch 173/2000\n",
      "824/824 [==============================] - 0s 52us/sample - loss: 0.3701 - accuracy: 0.9223 - val_loss: 0.6527 - val_accuracy: 0.8836\n",
      "Epoch 174/2000\n",
      "824/824 [==============================] - 0s 46us/sample - loss: 0.3477 - accuracy: 0.9369 - val_loss: 0.6450 - val_accuracy: 0.8873\n",
      "Epoch 175/2000\n",
      "824/824 [==============================] - 0s 48us/sample - loss: 0.3506 - accuracy: 0.9235 - val_loss: 0.6572 - val_accuracy: 0.8873\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 2,062\n",
      "Trainable params: 2,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 927 samples, validate on 309 samples\n",
      "Epoch 1/2000\n",
      "927/927 [==============================] - 0s 389us/sample - loss: 2.6664 - accuracy: 0.0658 - val_loss: 2.6278 - val_accuracy: 0.0550\n",
      "Epoch 2/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 2.6062 - accuracy: 0.0949 - val_loss: 2.5756 - val_accuracy: 0.1294\n",
      "Epoch 3/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 2.5469 - accuracy: 0.1510 - val_loss: 2.5161 - val_accuracy: 0.3042\n",
      "Epoch 4/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 2.4844 - accuracy: 0.2125 - val_loss: 2.4569 - val_accuracy: 0.3269\n",
      "Epoch 5/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 2.4276 - accuracy: 0.2309 - val_loss: 2.3915 - val_accuracy: 0.3883\n",
      "Epoch 6/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 2.3654 - accuracy: 0.2600 - val_loss: 2.3237 - val_accuracy: 0.4142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 2.3047 - accuracy: 0.3031 - val_loss: 2.2552 - val_accuracy: 0.4369\n",
      "Epoch 8/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 2.2406 - accuracy: 0.2934 - val_loss: 2.1869 - val_accuracy: 0.4951\n",
      "Epoch 9/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 2.1644 - accuracy: 0.3323 - val_loss: 2.1176 - val_accuracy: 0.5405\n",
      "Epoch 10/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 2.1166 - accuracy: 0.3474 - val_loss: 2.0545 - val_accuracy: 0.5307\n",
      "Epoch 11/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 2.0593 - accuracy: 0.3581 - val_loss: 1.9904 - val_accuracy: 0.5534\n",
      "Epoch 12/2000\n",
      "927/927 [==============================] - 0s 44us/sample - loss: 1.9900 - accuracy: 0.4142 - val_loss: 1.9246 - val_accuracy: 0.5566\n",
      "Epoch 13/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 1.9489 - accuracy: 0.4132 - val_loss: 1.8703 - val_accuracy: 0.5825\n",
      "Epoch 14/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 1.8847 - accuracy: 0.4132 - val_loss: 1.8142 - val_accuracy: 0.6311\n",
      "Epoch 15/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 1.8615 - accuracy: 0.4315 - val_loss: 1.7603 - val_accuracy: 0.6602\n",
      "Epoch 16/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 1.7886 - accuracy: 0.4800 - val_loss: 1.7070 - val_accuracy: 0.7184\n",
      "Epoch 17/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 1.7604 - accuracy: 0.4746 - val_loss: 1.6601 - val_accuracy: 0.7702\n",
      "Epoch 18/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 1.7128 - accuracy: 0.4649 - val_loss: 1.6092 - val_accuracy: 0.7864\n",
      "Epoch 19/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 1.6529 - accuracy: 0.5221 - val_loss: 1.5609 - val_accuracy: 0.8155\n",
      "Epoch 20/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 1.6323 - accuracy: 0.5167 - val_loss: 1.5196 - val_accuracy: 0.8123\n",
      "Epoch 21/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 1.6012 - accuracy: 0.5221 - val_loss: 1.4747 - val_accuracy: 0.8285\n",
      "Epoch 22/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 1.5865 - accuracy: 0.5448 - val_loss: 1.4356 - val_accuracy: 0.8350\n",
      "Epoch 23/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 1.5107 - accuracy: 0.5653 - val_loss: 1.3901 - val_accuracy: 0.8285\n",
      "Epoch 24/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 1.4930 - accuracy: 0.5685 - val_loss: 1.3532 - val_accuracy: 0.8479\n",
      "Epoch 25/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 1.4382 - accuracy: 0.5912 - val_loss: 1.3118 - val_accuracy: 0.8544\n",
      "Epoch 26/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 1.4211 - accuracy: 0.5901 - val_loss: 1.2773 - val_accuracy: 0.8576\n",
      "Epoch 27/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 1.4022 - accuracy: 0.6030 - val_loss: 1.2463 - val_accuracy: 0.8479\n",
      "Epoch 28/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 1.3485 - accuracy: 0.6235 - val_loss: 1.2140 - val_accuracy: 0.8544\n",
      "Epoch 29/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 1.3163 - accuracy: 0.6408 - val_loss: 1.1714 - val_accuracy: 0.8803\n",
      "Epoch 30/2000\n",
      "927/927 [==============================] - 0s 44us/sample - loss: 1.2839 - accuracy: 0.6559 - val_loss: 1.1425 - val_accuracy: 0.8900\n",
      "Epoch 31/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 1.2493 - accuracy: 0.6753 - val_loss: 1.1101 - val_accuracy: 0.8770\n",
      "Epoch 32/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 1.2409 - accuracy: 0.6570 - val_loss: 1.0874 - val_accuracy: 0.8770\n",
      "Epoch 33/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 1.2300 - accuracy: 0.6624 - val_loss: 1.0561 - val_accuracy: 0.8770\n",
      "Epoch 34/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 1.1803 - accuracy: 0.6850 - val_loss: 1.0265 - val_accuracy: 0.8770\n",
      "Epoch 35/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 1.1539 - accuracy: 0.7012 - val_loss: 1.0023 - val_accuracy: 0.8738\n",
      "Epoch 36/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 1.1324 - accuracy: 0.6839 - val_loss: 0.9763 - val_accuracy: 0.8900\n",
      "Epoch 37/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 1.1239 - accuracy: 0.6990 - val_loss: 0.9534 - val_accuracy: 0.8835\n",
      "Epoch 38/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 1.0880 - accuracy: 0.6926 - val_loss: 0.9296 - val_accuracy: 0.8900\n",
      "Epoch 39/2000\n",
      "927/927 [==============================] - 0s 50us/sample - loss: 1.0563 - accuracy: 0.7411 - val_loss: 0.9066 - val_accuracy: 0.8835\n",
      "Epoch 40/2000\n",
      "927/927 [==============================] - 0s 41us/sample - loss: 1.0392 - accuracy: 0.7422 - val_loss: 0.8894 - val_accuracy: 0.8900\n",
      "Epoch 41/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 1.0220 - accuracy: 0.7389 - val_loss: 0.8656 - val_accuracy: 0.8932\n",
      "Epoch 42/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.9843 - accuracy: 0.7638 - val_loss: 0.8489 - val_accuracy: 0.8932\n",
      "Epoch 43/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.9953 - accuracy: 0.7389 - val_loss: 0.8284 - val_accuracy: 0.8900\n",
      "Epoch 44/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.9623 - accuracy: 0.7443 - val_loss: 0.8110 - val_accuracy: 0.9061\n",
      "Epoch 45/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.9581 - accuracy: 0.7605 - val_loss: 0.7965 - val_accuracy: 0.8964\n",
      "Epoch 46/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.9254 - accuracy: 0.7735 - val_loss: 0.7794 - val_accuracy: 0.9029\n",
      "Epoch 47/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.9284 - accuracy: 0.7659 - val_loss: 0.7648 - val_accuracy: 0.9061\n",
      "Epoch 48/2000\n",
      "927/927 [==============================] - 0s 37us/sample - loss: 0.8773 - accuracy: 0.7929 - val_loss: 0.7487 - val_accuracy: 0.8997\n",
      "Epoch 49/2000\n",
      "927/927 [==============================] - 0s 51us/sample - loss: 0.8936 - accuracy: 0.7616 - val_loss: 0.7363 - val_accuracy: 0.9029\n",
      "Epoch 50/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.8793 - accuracy: 0.7756 - val_loss: 0.7236 - val_accuracy: 0.8997\n",
      "Epoch 51/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.8589 - accuracy: 0.7724 - val_loss: 0.7096 - val_accuracy: 0.9126\n",
      "Epoch 52/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.8522 - accuracy: 0.7681 - val_loss: 0.6986 - val_accuracy: 0.9061\n",
      "Epoch 53/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.8379 - accuracy: 0.7821 - val_loss: 0.6864 - val_accuracy: 0.9126\n",
      "Epoch 54/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.7911 - accuracy: 0.8252 - val_loss: 0.6709 - val_accuracy: 0.9191\n",
      "Epoch 55/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.8108 - accuracy: 0.7896 - val_loss: 0.6610 - val_accuracy: 0.9094\n",
      "Epoch 56/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.7981 - accuracy: 0.8069 - val_loss: 0.6506 - val_accuracy: 0.9159\n",
      "Epoch 57/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.7927 - accuracy: 0.8123 - val_loss: 0.6387 - val_accuracy: 0.9159\n",
      "Epoch 58/2000\n",
      "927/927 [==============================] - 0s 41us/sample - loss: 0.7612 - accuracy: 0.8209 - val_loss: 0.6320 - val_accuracy: 0.9126\n",
      "Epoch 59/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.7599 - accuracy: 0.8091 - val_loss: 0.6194 - val_accuracy: 0.9191\n",
      "Epoch 60/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.7631 - accuracy: 0.8101 - val_loss: 0.6152 - val_accuracy: 0.9159\n",
      "Epoch 61/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.7504 - accuracy: 0.8166 - val_loss: 0.6002 - val_accuracy: 0.9223\n",
      "Epoch 62/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927/927 [==============================] - 0s 37us/sample - loss: 0.7100 - accuracy: 0.8479 - val_loss: 0.5948 - val_accuracy: 0.9191\n",
      "Epoch 63/2000\n",
      "927/927 [==============================] - 0s 50us/sample - loss: 0.7330 - accuracy: 0.8123 - val_loss: 0.5827 - val_accuracy: 0.9159\n",
      "Epoch 64/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.7191 - accuracy: 0.8296 - val_loss: 0.5817 - val_accuracy: 0.9126\n",
      "Epoch 65/2000\n",
      "927/927 [==============================] - 0s 44us/sample - loss: 0.6989 - accuracy: 0.8360 - val_loss: 0.5699 - val_accuracy: 0.9159\n",
      "Epoch 66/2000\n",
      "927/927 [==============================] - 0s 42us/sample - loss: 0.6991 - accuracy: 0.8285 - val_loss: 0.5642 - val_accuracy: 0.9126\n",
      "Epoch 67/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.6933 - accuracy: 0.8285 - val_loss: 0.5550 - val_accuracy: 0.9223\n",
      "Epoch 68/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 0.6702 - accuracy: 0.8393 - val_loss: 0.5500 - val_accuracy: 0.9126\n",
      "Epoch 69/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.6559 - accuracy: 0.8619 - val_loss: 0.5384 - val_accuracy: 0.9191\n",
      "Epoch 70/2000\n",
      "927/927 [==============================] - 0s 44us/sample - loss: 0.6499 - accuracy: 0.8403 - val_loss: 0.5349 - val_accuracy: 0.9159\n",
      "Epoch 71/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.6537 - accuracy: 0.8598 - val_loss: 0.5289 - val_accuracy: 0.9191\n",
      "Epoch 72/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.6438 - accuracy: 0.8522 - val_loss: 0.5212 - val_accuracy: 0.9159\n",
      "Epoch 73/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.6412 - accuracy: 0.8350 - val_loss: 0.5191 - val_accuracy: 0.9159\n",
      "Epoch 74/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 0.6402 - accuracy: 0.8371 - val_loss: 0.5152 - val_accuracy: 0.9191\n",
      "Epoch 75/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.6322 - accuracy: 0.8587 - val_loss: 0.5143 - val_accuracy: 0.9256\n",
      "Epoch 76/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.6391 - accuracy: 0.8554 - val_loss: 0.5057 - val_accuracy: 0.9256\n",
      "Epoch 77/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.6065 - accuracy: 0.8727 - val_loss: 0.4967 - val_accuracy: 0.9191\n",
      "Epoch 78/2000\n",
      "927/927 [==============================] - 0s 41us/sample - loss: 0.6032 - accuracy: 0.8533 - val_loss: 0.4896 - val_accuracy: 0.9191\n",
      "Epoch 79/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.5807 - accuracy: 0.8673 - val_loss: 0.4849 - val_accuracy: 0.9256\n",
      "Epoch 80/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.5770 - accuracy: 0.8673 - val_loss: 0.4870 - val_accuracy: 0.9191\n",
      "Epoch 81/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.5753 - accuracy: 0.8781 - val_loss: 0.4807 - val_accuracy: 0.9288\n",
      "Epoch 82/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 0.5659 - accuracy: 0.8598 - val_loss: 0.4729 - val_accuracy: 0.9256\n",
      "Epoch 83/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.5709 - accuracy: 0.8706 - val_loss: 0.4706 - val_accuracy: 0.9288\n",
      "Epoch 84/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.5672 - accuracy: 0.8587 - val_loss: 0.4733 - val_accuracy: 0.9159\n",
      "Epoch 85/2000\n",
      "927/927 [==============================] - 0s 41us/sample - loss: 0.5686 - accuracy: 0.8695 - val_loss: 0.4647 - val_accuracy: 0.9223\n",
      "Epoch 86/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.5481 - accuracy: 0.8716 - val_loss: 0.4592 - val_accuracy: 0.9223\n",
      "Epoch 87/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.5489 - accuracy: 0.8803 - val_loss: 0.4554 - val_accuracy: 0.9288\n",
      "Epoch 88/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.5655 - accuracy: 0.8662 - val_loss: 0.4534 - val_accuracy: 0.9256\n",
      "Epoch 89/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.5433 - accuracy: 0.8813 - val_loss: 0.4509 - val_accuracy: 0.9191\n",
      "Epoch 90/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.5424 - accuracy: 0.8759 - val_loss: 0.4481 - val_accuracy: 0.9256\n",
      "Epoch 91/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.5521 - accuracy: 0.8608 - val_loss: 0.4456 - val_accuracy: 0.9256\n",
      "Epoch 92/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.5258 - accuracy: 0.8792 - val_loss: 0.4391 - val_accuracy: 0.9288\n",
      "Epoch 93/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.5360 - accuracy: 0.8813 - val_loss: 0.4362 - val_accuracy: 0.9320\n",
      "Epoch 94/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.5346 - accuracy: 0.8727 - val_loss: 0.4322 - val_accuracy: 0.9288\n",
      "Epoch 95/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.5195 - accuracy: 0.8878 - val_loss: 0.4314 - val_accuracy: 0.9191\n",
      "Epoch 96/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.5069 - accuracy: 0.8878 - val_loss: 0.4246 - val_accuracy: 0.9288\n",
      "Epoch 97/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.5139 - accuracy: 0.8867 - val_loss: 0.4239 - val_accuracy: 0.9256\n",
      "Epoch 98/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.5100 - accuracy: 0.8910 - val_loss: 0.4193 - val_accuracy: 0.9320\n",
      "Epoch 99/2000\n",
      "927/927 [==============================] - 0s 41us/sample - loss: 0.4951 - accuracy: 0.8878 - val_loss: 0.4171 - val_accuracy: 0.9256\n",
      "Epoch 100/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.5036 - accuracy: 0.8824 - val_loss: 0.4170 - val_accuracy: 0.9320\n",
      "Epoch 101/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.4854 - accuracy: 0.8932 - val_loss: 0.4138 - val_accuracy: 0.9320\n",
      "Epoch 102/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.4735 - accuracy: 0.8954 - val_loss: 0.4115 - val_accuracy: 0.9256\n",
      "Epoch 103/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.4878 - accuracy: 0.8975 - val_loss: 0.4056 - val_accuracy: 0.9288\n",
      "Epoch 104/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.4804 - accuracy: 0.8986 - val_loss: 0.4028 - val_accuracy: 0.9353\n",
      "Epoch 105/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.4940 - accuracy: 0.8835 - val_loss: 0.4009 - val_accuracy: 0.9320\n",
      "Epoch 106/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.4762 - accuracy: 0.8921 - val_loss: 0.4066 - val_accuracy: 0.9256\n",
      "Epoch 107/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.4700 - accuracy: 0.8964 - val_loss: 0.4052 - val_accuracy: 0.9256\n",
      "Epoch 108/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.4625 - accuracy: 0.9018 - val_loss: 0.3957 - val_accuracy: 0.9353\n",
      "Epoch 109/2000\n",
      "927/927 [==============================] - 0s 37us/sample - loss: 0.4653 - accuracy: 0.8964 - val_loss: 0.3974 - val_accuracy: 0.9288\n",
      "Epoch 110/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.4643 - accuracy: 0.8997 - val_loss: 0.3936 - val_accuracy: 0.9256\n",
      "Epoch 111/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.4631 - accuracy: 0.9083 - val_loss: 0.3883 - val_accuracy: 0.9353\n",
      "Epoch 112/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.4360 - accuracy: 0.9083 - val_loss: 0.3864 - val_accuracy: 0.9353\n",
      "Epoch 113/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.4334 - accuracy: 0.9061 - val_loss: 0.3829 - val_accuracy: 0.9353\n",
      "Epoch 114/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.4359 - accuracy: 0.9040 - val_loss: 0.3821 - val_accuracy: 0.9385\n",
      "Epoch 115/2000\n",
      "927/927 [==============================] - 0s 42us/sample - loss: 0.4371 - accuracy: 0.9105 - val_loss: 0.3853 - val_accuracy: 0.9353\n",
      "Epoch 116/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.4452 - accuracy: 0.8975 - val_loss: 0.3810 - val_accuracy: 0.9353\n",
      "Epoch 117/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927/927 [==============================] - 0s 38us/sample - loss: 0.4479 - accuracy: 0.9040 - val_loss: 0.3819 - val_accuracy: 0.9320\n",
      "Epoch 118/2000\n",
      "927/927 [==============================] - 0s 51us/sample - loss: 0.4533 - accuracy: 0.9051 - val_loss: 0.3820 - val_accuracy: 0.9353\n",
      "Epoch 119/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 0.4220 - accuracy: 0.9061 - val_loss: 0.3770 - val_accuracy: 0.9353\n",
      "Epoch 120/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.4417 - accuracy: 0.9051 - val_loss: 0.3724 - val_accuracy: 0.9417\n",
      "Epoch 121/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.4455 - accuracy: 0.9018 - val_loss: 0.3723 - val_accuracy: 0.9385\n",
      "Epoch 122/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.4382 - accuracy: 0.8986 - val_loss: 0.3688 - val_accuracy: 0.9320\n",
      "Epoch 123/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.4106 - accuracy: 0.9148 - val_loss: 0.3738 - val_accuracy: 0.9385\n",
      "Epoch 124/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.4284 - accuracy: 0.9051 - val_loss: 0.3714 - val_accuracy: 0.9385\n",
      "Epoch 125/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.4387 - accuracy: 0.8997 - val_loss: 0.3651 - val_accuracy: 0.9385\n",
      "Epoch 126/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.4078 - accuracy: 0.9191 - val_loss: 0.3658 - val_accuracy: 0.9353\n",
      "Epoch 127/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.4078 - accuracy: 0.9180 - val_loss: 0.3664 - val_accuracy: 0.9353\n",
      "Epoch 128/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.4102 - accuracy: 0.9159 - val_loss: 0.3621 - val_accuracy: 0.9353\n",
      "Epoch 129/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.4279 - accuracy: 0.9115 - val_loss: 0.3620 - val_accuracy: 0.9353\n",
      "Epoch 130/2000\n",
      "927/927 [==============================] - 0s 52us/sample - loss: 0.4183 - accuracy: 0.9061 - val_loss: 0.3588 - val_accuracy: 0.9385\n",
      "Epoch 131/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3946 - accuracy: 0.9191 - val_loss: 0.3584 - val_accuracy: 0.9417\n",
      "Epoch 132/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.4235 - accuracy: 0.9040 - val_loss: 0.3591 - val_accuracy: 0.9385\n",
      "Epoch 133/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.4034 - accuracy: 0.9180 - val_loss: 0.3596 - val_accuracy: 0.9385\n",
      "Epoch 134/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 0.3928 - accuracy: 0.9299 - val_loss: 0.3532 - val_accuracy: 0.9385\n",
      "Epoch 135/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.4096 - accuracy: 0.9018 - val_loss: 0.3534 - val_accuracy: 0.9417\n",
      "Epoch 136/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.4128 - accuracy: 0.9061 - val_loss: 0.3565 - val_accuracy: 0.9385\n",
      "Epoch 137/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.4187 - accuracy: 0.9051 - val_loss: 0.3525 - val_accuracy: 0.9353\n",
      "Epoch 138/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 0.3932 - accuracy: 0.9266 - val_loss: 0.3484 - val_accuracy: 0.9450\n",
      "Epoch 139/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3880 - accuracy: 0.9169 - val_loss: 0.3498 - val_accuracy: 0.9417\n",
      "Epoch 140/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.3906 - accuracy: 0.9234 - val_loss: 0.3457 - val_accuracy: 0.9417\n",
      "Epoch 141/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.3892 - accuracy: 0.9137 - val_loss: 0.3467 - val_accuracy: 0.9417\n",
      "Epoch 142/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.3928 - accuracy: 0.9115 - val_loss: 0.3464 - val_accuracy: 0.9417\n",
      "Epoch 143/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3839 - accuracy: 0.9115 - val_loss: 0.3499 - val_accuracy: 0.9385\n",
      "Epoch 144/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3909 - accuracy: 0.9169 - val_loss: 0.3440 - val_accuracy: 0.9450\n",
      "Epoch 145/2000\n",
      "927/927 [==============================] - 0s 44us/sample - loss: 0.3885 - accuracy: 0.9169 - val_loss: 0.3436 - val_accuracy: 0.9417\n",
      "Epoch 146/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 0.3935 - accuracy: 0.9180 - val_loss: 0.3459 - val_accuracy: 0.9417\n",
      "Epoch 147/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.3722 - accuracy: 0.9245 - val_loss: 0.3426 - val_accuracy: 0.9450\n",
      "Epoch 148/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.3805 - accuracy: 0.9094 - val_loss: 0.3399 - val_accuracy: 0.9417\n",
      "Epoch 149/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3755 - accuracy: 0.9223 - val_loss: 0.3399 - val_accuracy: 0.9417\n",
      "Epoch 150/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.3664 - accuracy: 0.9256 - val_loss: 0.3397 - val_accuracy: 0.9450\n",
      "Epoch 151/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.3684 - accuracy: 0.9169 - val_loss: 0.3391 - val_accuracy: 0.9417\n",
      "Epoch 152/2000\n",
      "927/927 [==============================] - 0s 37us/sample - loss: 0.3925 - accuracy: 0.9072 - val_loss: 0.3408 - val_accuracy: 0.9417\n",
      "Epoch 153/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.3732 - accuracy: 0.9234 - val_loss: 0.3337 - val_accuracy: 0.9450\n",
      "Epoch 154/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.3697 - accuracy: 0.9180 - val_loss: 0.3389 - val_accuracy: 0.9385\n",
      "Epoch 155/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.3646 - accuracy: 0.9159 - val_loss: 0.3401 - val_accuracy: 0.9353\n",
      "Epoch 156/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 0.3797 - accuracy: 0.9148 - val_loss: 0.3405 - val_accuracy: 0.9385\n",
      "Epoch 157/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.3858 - accuracy: 0.9148 - val_loss: 0.3400 - val_accuracy: 0.9450\n",
      "Epoch 158/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 0.3791 - accuracy: 0.9180 - val_loss: 0.3386 - val_accuracy: 0.9385\n",
      "Epoch 159/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.3549 - accuracy: 0.9223 - val_loss: 0.3390 - val_accuracy: 0.9417\n",
      "Epoch 160/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.3596 - accuracy: 0.9277 - val_loss: 0.3344 - val_accuracy: 0.9417\n",
      "Epoch 161/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.3547 - accuracy: 0.9234 - val_loss: 0.3378 - val_accuracy: 0.9385\n",
      "Epoch 162/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.3494 - accuracy: 0.9288 - val_loss: 0.3320 - val_accuracy: 0.9450\n",
      "Epoch 163/2000\n",
      "927/927 [==============================] - 0s 37us/sample - loss: 0.3684 - accuracy: 0.9191 - val_loss: 0.3287 - val_accuracy: 0.9450\n",
      "Epoch 164/2000\n",
      "927/927 [==============================] - 0s 52us/sample - loss: 0.3467 - accuracy: 0.9277 - val_loss: 0.3344 - val_accuracy: 0.9385\n",
      "Epoch 165/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.3439 - accuracy: 0.9223 - val_loss: 0.3352 - val_accuracy: 0.9385\n",
      "Epoch 166/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.3663 - accuracy: 0.9191 - val_loss: 0.3291 - val_accuracy: 0.9450\n",
      "Epoch 167/2000\n",
      "927/927 [==============================] - 0s 41us/sample - loss: 0.3613 - accuracy: 0.9234 - val_loss: 0.3284 - val_accuracy: 0.9482\n",
      "Epoch 168/2000\n",
      "927/927 [==============================] - 0s 42us/sample - loss: 0.3404 - accuracy: 0.9353 - val_loss: 0.3323 - val_accuracy: 0.9417\n",
      "Epoch 169/2000\n",
      "927/927 [==============================] - 0s 37us/sample - loss: 0.3574 - accuracy: 0.9256 - val_loss: 0.3235 - val_accuracy: 0.9450\n",
      "Epoch 170/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.3355 - accuracy: 0.9396 - val_loss: 0.3302 - val_accuracy: 0.9417\n",
      "Epoch 171/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.3564 - accuracy: 0.9277 - val_loss: 0.3250 - val_accuracy: 0.9482\n",
      "Epoch 172/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927/927 [==============================] - 0s 42us/sample - loss: 0.3359 - accuracy: 0.9331 - val_loss: 0.3257 - val_accuracy: 0.9482\n",
      "Epoch 173/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3492 - accuracy: 0.9299 - val_loss: 0.3239 - val_accuracy: 0.9482\n",
      "Epoch 174/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.3304 - accuracy: 0.9428 - val_loss: 0.3217 - val_accuracy: 0.9482\n",
      "Epoch 175/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.3548 - accuracy: 0.9277 - val_loss: 0.3209 - val_accuracy: 0.9450\n",
      "Epoch 176/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3214 - accuracy: 0.9450 - val_loss: 0.3245 - val_accuracy: 0.9385\n",
      "Epoch 177/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.3426 - accuracy: 0.9277 - val_loss: 0.3270 - val_accuracy: 0.9450\n",
      "Epoch 178/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3439 - accuracy: 0.9256 - val_loss: 0.3135 - val_accuracy: 0.9482\n",
      "Epoch 179/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.3355 - accuracy: 0.9299 - val_loss: 0.3270 - val_accuracy: 0.9482\n",
      "Epoch 180/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3223 - accuracy: 0.9364 - val_loss: 0.3249 - val_accuracy: 0.9482\n",
      "Epoch 181/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.3369 - accuracy: 0.9288 - val_loss: 0.3168 - val_accuracy: 0.9450\n",
      "Epoch 182/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3294 - accuracy: 0.9310 - val_loss: 0.3179 - val_accuracy: 0.9450\n",
      "Epoch 183/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.3111 - accuracy: 0.9288 - val_loss: 0.3175 - val_accuracy: 0.9482\n",
      "Epoch 184/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.3230 - accuracy: 0.9439 - val_loss: 0.3259 - val_accuracy: 0.9353\n",
      "Epoch 185/2000\n",
      "927/927 [==============================] - 0s 41us/sample - loss: 0.3262 - accuracy: 0.9353 - val_loss: 0.3176 - val_accuracy: 0.9450\n",
      "Epoch 186/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.3272 - accuracy: 0.9331 - val_loss: 0.3229 - val_accuracy: 0.9417\n",
      "Epoch 187/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.3212 - accuracy: 0.9364 - val_loss: 0.3163 - val_accuracy: 0.9515\n",
      "Epoch 188/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.3164 - accuracy: 0.9407 - val_loss: 0.3221 - val_accuracy: 0.9547\n",
      "Epoch 189/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3333 - accuracy: 0.9342 - val_loss: 0.3135 - val_accuracy: 0.9482\n",
      "Epoch 190/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3085 - accuracy: 0.9439 - val_loss: 0.3195 - val_accuracy: 0.9515\n",
      "Epoch 191/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.3074 - accuracy: 0.9439 - val_loss: 0.3203 - val_accuracy: 0.9482\n",
      "Epoch 192/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.3224 - accuracy: 0.9374 - val_loss: 0.3184 - val_accuracy: 0.9547\n",
      "Epoch 193/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.3215 - accuracy: 0.9396 - val_loss: 0.3116 - val_accuracy: 0.9515\n",
      "Epoch 194/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3277 - accuracy: 0.9288 - val_loss: 0.3077 - val_accuracy: 0.9482\n",
      "Epoch 195/2000\n",
      "927/927 [==============================] - 0s 37us/sample - loss: 0.3193 - accuracy: 0.9417 - val_loss: 0.3152 - val_accuracy: 0.9515\n",
      "Epoch 196/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.3068 - accuracy: 0.9374 - val_loss: 0.3106 - val_accuracy: 0.9482\n",
      "Epoch 197/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.3047 - accuracy: 0.9331 - val_loss: 0.3094 - val_accuracy: 0.9482\n",
      "Epoch 198/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3207 - accuracy: 0.9385 - val_loss: 0.3100 - val_accuracy: 0.9482\n",
      "Epoch 199/2000\n",
      "927/927 [==============================] - 0s 42us/sample - loss: 0.3176 - accuracy: 0.9342 - val_loss: 0.3103 - val_accuracy: 0.9482\n",
      "Epoch 200/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.2921 - accuracy: 0.9439 - val_loss: 0.3045 - val_accuracy: 0.9515\n",
      "Epoch 201/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.3000 - accuracy: 0.9439 - val_loss: 0.3114 - val_accuracy: 0.9482\n",
      "Epoch 202/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.3040 - accuracy: 0.9353 - val_loss: 0.3089 - val_accuracy: 0.9515\n",
      "Epoch 203/2000\n",
      "927/927 [==============================] - 0s 41us/sample - loss: 0.3112 - accuracy: 0.9320 - val_loss: 0.3101 - val_accuracy: 0.9515\n",
      "Epoch 204/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.3091 - accuracy: 0.9450 - val_loss: 0.3110 - val_accuracy: 0.9482\n",
      "Epoch 205/2000\n",
      "927/927 [==============================] - 0s 41us/sample - loss: 0.3044 - accuracy: 0.9374 - val_loss: 0.3134 - val_accuracy: 0.9547\n",
      "Epoch 206/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3042 - accuracy: 0.9428 - val_loss: 0.3098 - val_accuracy: 0.9515\n",
      "Epoch 207/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.2873 - accuracy: 0.9471 - val_loss: 0.3137 - val_accuracy: 0.9515\n",
      "Epoch 208/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.3305 - accuracy: 0.9234 - val_loss: 0.3117 - val_accuracy: 0.9417\n",
      "Epoch 209/2000\n",
      "927/927 [==============================] - 0s 37us/sample - loss: 0.3009 - accuracy: 0.9417 - val_loss: 0.3098 - val_accuracy: 0.9450\n",
      "Epoch 210/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.3143 - accuracy: 0.9299 - val_loss: 0.3224 - val_accuracy: 0.9417\n",
      "Epoch 211/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.3047 - accuracy: 0.9342 - val_loss: 0.3078 - val_accuracy: 0.9515\n",
      "Epoch 212/2000\n",
      "927/927 [==============================] - 0s 43us/sample - loss: 0.2867 - accuracy: 0.9525 - val_loss: 0.3145 - val_accuracy: 0.9515\n",
      "Epoch 213/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 0.2954 - accuracy: 0.9385 - val_loss: 0.3076 - val_accuracy: 0.9515\n",
      "Epoch 214/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.2933 - accuracy: 0.9439 - val_loss: 0.3099 - val_accuracy: 0.9515\n",
      "Epoch 215/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2957 - accuracy: 0.9471 - val_loss: 0.3154 - val_accuracy: 0.9417\n",
      "Epoch 216/2000\n",
      "927/927 [==============================] - 0s 43us/sample - loss: 0.3002 - accuracy: 0.9417 - val_loss: 0.3085 - val_accuracy: 0.9515\n",
      "Epoch 217/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.2997 - accuracy: 0.9396 - val_loss: 0.3087 - val_accuracy: 0.9482\n",
      "Epoch 218/2000\n",
      "927/927 [==============================] - 0s 42us/sample - loss: 0.3013 - accuracy: 0.9353 - val_loss: 0.3053 - val_accuracy: 0.9482\n",
      "Epoch 219/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.3103 - accuracy: 0.9277 - val_loss: 0.3160 - val_accuracy: 0.9482\n",
      "Epoch 220/2000\n",
      "927/927 [==============================] - 0s 43us/sample - loss: 0.2890 - accuracy: 0.9407 - val_loss: 0.3094 - val_accuracy: 0.9547\n",
      "Epoch 221/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2863 - accuracy: 0.9407 - val_loss: 0.3002 - val_accuracy: 0.9515\n",
      "Epoch 222/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.2812 - accuracy: 0.9450 - val_loss: 0.3076 - val_accuracy: 0.9547\n",
      "Epoch 223/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.2829 - accuracy: 0.9482 - val_loss: 0.3135 - val_accuracy: 0.9515\n",
      "Epoch 224/2000\n",
      "927/927 [==============================] - 0s 41us/sample - loss: 0.3052 - accuracy: 0.9353 - val_loss: 0.3073 - val_accuracy: 0.9547\n",
      "Epoch 225/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2925 - accuracy: 0.9396 - val_loss: 0.3084 - val_accuracy: 0.9515\n",
      "Epoch 226/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.2904 - accuracy: 0.9439 - val_loss: 0.3099 - val_accuracy: 0.9450\n",
      "Epoch 227/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2800 - accuracy: 0.9428 - val_loss: 0.3097 - val_accuracy: 0.9450\n",
      "Epoch 228/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.2784 - accuracy: 0.9439 - val_loss: 0.3087 - val_accuracy: 0.9515\n",
      "Epoch 229/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.2840 - accuracy: 0.9482 - val_loss: 0.3075 - val_accuracy: 0.9515\n",
      "Epoch 230/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.2866 - accuracy: 0.9417 - val_loss: 0.2995 - val_accuracy: 0.9547\n",
      "Epoch 231/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.2965 - accuracy: 0.9353 - val_loss: 0.3067 - val_accuracy: 0.9515\n",
      "Epoch 232/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.2794 - accuracy: 0.9407 - val_loss: 0.3161 - val_accuracy: 0.9482\n",
      "Epoch 233/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.2776 - accuracy: 0.9428 - val_loss: 0.3038 - val_accuracy: 0.9547\n",
      "Epoch 234/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.2771 - accuracy: 0.9471 - val_loss: 0.3038 - val_accuracy: 0.9515\n",
      "Epoch 235/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2914 - accuracy: 0.9342 - val_loss: 0.3033 - val_accuracy: 0.9547\n",
      "Epoch 236/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.2937 - accuracy: 0.9385 - val_loss: 0.2963 - val_accuracy: 0.9515\n",
      "Epoch 237/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.2842 - accuracy: 0.9450 - val_loss: 0.3055 - val_accuracy: 0.9515\n",
      "Epoch 238/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.2927 - accuracy: 0.9439 - val_loss: 0.3114 - val_accuracy: 0.9515\n",
      "Epoch 239/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.2860 - accuracy: 0.9450 - val_loss: 0.2994 - val_accuracy: 0.9515\n",
      "Epoch 240/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.2817 - accuracy: 0.9417 - val_loss: 0.3054 - val_accuracy: 0.9547\n",
      "Epoch 241/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2796 - accuracy: 0.9525 - val_loss: 0.3010 - val_accuracy: 0.9547\n",
      "Epoch 242/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.2644 - accuracy: 0.9569 - val_loss: 0.3022 - val_accuracy: 0.9579\n",
      "Epoch 243/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.2763 - accuracy: 0.9504 - val_loss: 0.3057 - val_accuracy: 0.9515\n",
      "Epoch 244/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.2954 - accuracy: 0.9385 - val_loss: 0.3084 - val_accuracy: 0.9515\n",
      "Epoch 245/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.2847 - accuracy: 0.9471 - val_loss: 0.2991 - val_accuracy: 0.9547\n",
      "Epoch 246/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.2521 - accuracy: 0.9579 - val_loss: 0.3092 - val_accuracy: 0.9450\n",
      "Epoch 247/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2771 - accuracy: 0.9558 - val_loss: 0.2911 - val_accuracy: 0.9547\n",
      "Epoch 248/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.2754 - accuracy: 0.9450 - val_loss: 0.3035 - val_accuracy: 0.9579\n",
      "Epoch 249/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.2747 - accuracy: 0.9493 - val_loss: 0.3088 - val_accuracy: 0.9482\n",
      "Epoch 250/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.2773 - accuracy: 0.9374 - val_loss: 0.3055 - val_accuracy: 0.9515\n",
      "Epoch 251/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.2607 - accuracy: 0.9482 - val_loss: 0.2969 - val_accuracy: 0.9579\n",
      "Epoch 252/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.2770 - accuracy: 0.9482 - val_loss: 0.3035 - val_accuracy: 0.9547\n",
      "Epoch 253/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.2531 - accuracy: 0.9515 - val_loss: 0.3012 - val_accuracy: 0.9547\n",
      "Epoch 254/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.2750 - accuracy: 0.9482 - val_loss: 0.3069 - val_accuracy: 0.9515\n",
      "Epoch 255/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2782 - accuracy: 0.9439 - val_loss: 0.2961 - val_accuracy: 0.9579\n",
      "Epoch 256/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.2780 - accuracy: 0.9407 - val_loss: 0.3024 - val_accuracy: 0.9547\n",
      "Epoch 257/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.2816 - accuracy: 0.9450 - val_loss: 0.3046 - val_accuracy: 0.9547\n",
      "Epoch 258/2000\n",
      "927/927 [==============================] - 0s 44us/sample - loss: 0.2709 - accuracy: 0.9353 - val_loss: 0.3021 - val_accuracy: 0.9579\n",
      "Epoch 259/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.2763 - accuracy: 0.9471 - val_loss: 0.2943 - val_accuracy: 0.9579\n",
      "Epoch 260/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 0.2769 - accuracy: 0.9482 - val_loss: 0.2946 - val_accuracy: 0.9547\n",
      "Epoch 261/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.2606 - accuracy: 0.9601 - val_loss: 0.2996 - val_accuracy: 0.9579\n",
      "Epoch 262/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.2681 - accuracy: 0.9515 - val_loss: 0.3044 - val_accuracy: 0.9547\n",
      "Epoch 263/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.2690 - accuracy: 0.9471 - val_loss: 0.2996 - val_accuracy: 0.9579\n",
      "Epoch 264/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.2614 - accuracy: 0.9525 - val_loss: 0.2945 - val_accuracy: 0.9547\n",
      "Epoch 265/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.2795 - accuracy: 0.9396 - val_loss: 0.2995 - val_accuracy: 0.9579\n",
      "Epoch 266/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.2564 - accuracy: 0.9579 - val_loss: 0.3091 - val_accuracy: 0.9579\n",
      "Epoch 267/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2596 - accuracy: 0.9536 - val_loss: 0.3047 - val_accuracy: 0.9482\n",
      "Epoch 268/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.2613 - accuracy: 0.9525 - val_loss: 0.2918 - val_accuracy: 0.9579\n",
      "Epoch 269/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.2770 - accuracy: 0.9439 - val_loss: 0.2981 - val_accuracy: 0.9579\n",
      "Epoch 270/2000\n",
      "927/927 [==============================] - 0s 41us/sample - loss: 0.2638 - accuracy: 0.9547 - val_loss: 0.2980 - val_accuracy: 0.9579\n",
      "Epoch 271/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2557 - accuracy: 0.9536 - val_loss: 0.2946 - val_accuracy: 0.9579\n",
      "Epoch 272/2000\n",
      "927/927 [==============================] - 0s 41us/sample - loss: 0.2622 - accuracy: 0.9482 - val_loss: 0.2977 - val_accuracy: 0.9579\n",
      "Epoch 273/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2632 - accuracy: 0.9547 - val_loss: 0.3027 - val_accuracy: 0.9547\n",
      "Epoch 274/2000\n",
      "927/927 [==============================] - 0s 41us/sample - loss: 0.2521 - accuracy: 0.9612 - val_loss: 0.3013 - val_accuracy: 0.9515\n",
      "Epoch 275/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.2521 - accuracy: 0.9601 - val_loss: 0.2957 - val_accuracy: 0.9612\n",
      "Epoch 276/2000\n",
      "927/927 [==============================] - 0s 37us/sample - loss: 0.2678 - accuracy: 0.9471 - val_loss: 0.2970 - val_accuracy: 0.9579\n",
      "Epoch 277/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2672 - accuracy: 0.9482 - val_loss: 0.2958 - val_accuracy: 0.9579\n",
      "Epoch 278/2000\n",
      "927/927 [==============================] - 0s 44us/sample - loss: 0.2632 - accuracy: 0.9504 - val_loss: 0.2931 - val_accuracy: 0.9579\n",
      "Epoch 279/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2583 - accuracy: 0.9493 - val_loss: 0.3092 - val_accuracy: 0.9547\n",
      "Epoch 280/2000\n",
      "927/927 [==============================] - 0s 40us/sample - loss: 0.2908 - accuracy: 0.9331 - val_loss: 0.2998 - val_accuracy: 0.9547\n",
      "Epoch 281/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.2473 - accuracy: 0.9569 - val_loss: 0.2973 - val_accuracy: 0.9547\n",
      "Epoch 282/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927/927 [==============================] - 0s 37us/sample - loss: 0.2528 - accuracy: 0.9536 - val_loss: 0.2987 - val_accuracy: 0.9547\n",
      "Epoch 283/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.2405 - accuracy: 0.9644 - val_loss: 0.3021 - val_accuracy: 0.9547\n",
      "Epoch 284/2000\n",
      "927/927 [==============================] - 0s 43us/sample - loss: 0.2344 - accuracy: 0.9633 - val_loss: 0.2961 - val_accuracy: 0.9579\n",
      "Epoch 285/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2448 - accuracy: 0.9536 - val_loss: 0.3001 - val_accuracy: 0.9579\n",
      "Epoch 286/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.2627 - accuracy: 0.9450 - val_loss: 0.3020 - val_accuracy: 0.9547\n",
      "Epoch 287/2000\n",
      "927/927 [==============================] - 0s 45us/sample - loss: 0.2700 - accuracy: 0.9493 - val_loss: 0.3039 - val_accuracy: 0.9547\n",
      "Epoch 288/2000\n",
      "927/927 [==============================] - 0s 39us/sample - loss: 0.2439 - accuracy: 0.9536 - val_loss: 0.2971 - val_accuracy: 0.9547\n",
      "Epoch 289/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.2685 - accuracy: 0.9504 - val_loss: 0.3049 - val_accuracy: 0.9579\n",
      "Epoch 290/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.2680 - accuracy: 0.9439 - val_loss: 0.2999 - val_accuracy: 0.9579\n",
      "Epoch 291/2000\n",
      "927/927 [==============================] - 0s 47us/sample - loss: 0.2562 - accuracy: 0.9471 - val_loss: 0.2960 - val_accuracy: 0.9579\n",
      "Epoch 292/2000\n",
      "927/927 [==============================] - 0s 41us/sample - loss: 0.2571 - accuracy: 0.9525 - val_loss: 0.3044 - val_accuracy: 0.9579\n",
      "Epoch 293/2000\n",
      "927/927 [==============================] - 0s 46us/sample - loss: 0.2534 - accuracy: 0.9461 - val_loss: 0.3023 - val_accuracy: 0.9612\n",
      "Epoch 294/2000\n",
      "927/927 [==============================] - 0s 38us/sample - loss: 0.2573 - accuracy: 0.9515 - val_loss: 0.3066 - val_accuracy: 0.9547\n",
      "Epoch 295/2000\n",
      "927/927 [==============================] - 0s 49us/sample - loss: 0.2484 - accuracy: 0.9515 - val_loss: 0.2940 - val_accuracy: 0.9612\n",
      "Epoch 296/2000\n",
      "927/927 [==============================] - 0s 37us/sample - loss: 0.2454 - accuracy: 0.9601 - val_loss: 0.2977 - val_accuracy: 0.9579\n",
      "Epoch 297/2000\n",
      "927/927 [==============================] - 0s 48us/sample - loss: 0.2517 - accuracy: 0.9493 - val_loss: 0.3017 - val_accuracy: 0.9547\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 14)                910       \n",
      "=================================================================\n",
      "Total params: 2,062\n",
      "Trainable params: 2,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1030 samples, validate on 344 samples\n",
      "Epoch 1/2000\n",
      "1030/1030 [==============================] - 0s 445us/sample - loss: 2.6654 - accuracy: 0.0913 - val_loss: 2.6020 - val_accuracy: 0.1744\n",
      "Epoch 2/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 2.5896 - accuracy: 0.1408 - val_loss: 2.5487 - val_accuracy: 0.2703\n",
      "Epoch 3/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 2.5364 - accuracy: 0.1621 - val_loss: 2.4940 - val_accuracy: 0.2936\n",
      "Epoch 4/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 2.4754 - accuracy: 0.2165 - val_loss: 2.4373 - val_accuracy: 0.3372\n",
      "Epoch 5/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 2.4260 - accuracy: 0.2456 - val_loss: 2.3712 - val_accuracy: 0.3517\n",
      "Epoch 6/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 2.3644 - accuracy: 0.2786 - val_loss: 2.3022 - val_accuracy: 0.4506\n",
      "Epoch 7/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 2.3045 - accuracy: 0.2922 - val_loss: 2.2314 - val_accuracy: 0.5436\n",
      "Epoch 8/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 2.2184 - accuracy: 0.3398 - val_loss: 2.1611 - val_accuracy: 0.5814\n",
      "Epoch 9/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 2.1673 - accuracy: 0.3485 - val_loss: 2.0909 - val_accuracy: 0.6512\n",
      "Epoch 10/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 2.1000 - accuracy: 0.3786 - val_loss: 2.0219 - val_accuracy: 0.6744\n",
      "Epoch 11/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 2.0342 - accuracy: 0.4087 - val_loss: 1.9528 - val_accuracy: 0.6686\n",
      "Epoch 12/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.9738 - accuracy: 0.4126 - val_loss: 1.8926 - val_accuracy: 0.7093\n",
      "Epoch 13/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 1.9094 - accuracy: 0.4437 - val_loss: 1.8305 - val_accuracy: 0.7238\n",
      "Epoch 14/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 1.8537 - accuracy: 0.4524 - val_loss: 1.7661 - val_accuracy: 0.7558\n",
      "Epoch 15/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 1.8099 - accuracy: 0.4524 - val_loss: 1.7055 - val_accuracy: 0.7907\n",
      "Epoch 16/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 1.7776 - accuracy: 0.4641 - val_loss: 1.6548 - val_accuracy: 0.8430\n",
      "Epoch 17/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 1.6990 - accuracy: 0.5087 - val_loss: 1.5985 - val_accuracy: 0.8692\n",
      "Epoch 18/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 1.6676 - accuracy: 0.5282 - val_loss: 1.5436 - val_accuracy: 0.8343\n",
      "Epoch 19/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.6331 - accuracy: 0.5311 - val_loss: 1.4953 - val_accuracy: 0.8401\n",
      "Epoch 20/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 1.5591 - accuracy: 0.5631 - val_loss: 1.4483 - val_accuracy: 0.8808\n",
      "Epoch 21/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 1.5538 - accuracy: 0.5437 - val_loss: 1.3995 - val_accuracy: 0.8663\n",
      "Epoch 22/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 1.5112 - accuracy: 0.5660 - val_loss: 1.3637 - val_accuracy: 0.8779\n",
      "Epoch 23/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 1.4529 - accuracy: 0.6078 - val_loss: 1.3197 - val_accuracy: 0.8866\n",
      "Epoch 24/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 1.4064 - accuracy: 0.5874 - val_loss: 1.2722 - val_accuracy: 0.8779\n",
      "Epoch 25/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.4002 - accuracy: 0.6097 - val_loss: 1.2398 - val_accuracy: 0.9041\n",
      "Epoch 26/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 1.3612 - accuracy: 0.6049 - val_loss: 1.1999 - val_accuracy: 0.8983\n",
      "Epoch 27/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 1.3414 - accuracy: 0.6350 - val_loss: 1.1667 - val_accuracy: 0.9099\n",
      "Epoch 28/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.3001 - accuracy: 0.6573 - val_loss: 1.1302 - val_accuracy: 0.9070\n",
      "Epoch 29/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 1.2266 - accuracy: 0.6816 - val_loss: 1.1028 - val_accuracy: 0.9099\n",
      "Epoch 30/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 1.2161 - accuracy: 0.6854 - val_loss: 1.0698 - val_accuracy: 0.9157\n",
      "Epoch 31/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 1.1870 - accuracy: 0.6913 - val_loss: 1.0381 - val_accuracy: 0.9157\n",
      "Epoch 32/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 1.1816 - accuracy: 0.6786 - val_loss: 1.0151 - val_accuracy: 0.9128\n",
      "Epoch 33/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 1.1600 - accuracy: 0.7010 - val_loss: 0.9916 - val_accuracy: 0.9128\n",
      "Epoch 34/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 46us/sample - loss: 1.1344 - accuracy: 0.6913 - val_loss: 0.9599 - val_accuracy: 0.9128\n",
      "Epoch 35/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 1.1136 - accuracy: 0.6951 - val_loss: 0.9399 - val_accuracy: 0.9186\n",
      "Epoch 36/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 1.0656 - accuracy: 0.7214 - val_loss: 0.9152 - val_accuracy: 0.9157\n",
      "Epoch 37/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 1.0388 - accuracy: 0.7311 - val_loss: 0.8940 - val_accuracy: 0.9099\n",
      "Epoch 38/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.0163 - accuracy: 0.7563 - val_loss: 0.8697 - val_accuracy: 0.9157\n",
      "Epoch 39/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 1.0122 - accuracy: 0.7485 - val_loss: 0.8495 - val_accuracy: 0.9186\n",
      "Epoch 40/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.9779 - accuracy: 0.7553 - val_loss: 0.8276 - val_accuracy: 0.9099\n",
      "Epoch 41/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.9430 - accuracy: 0.7757 - val_loss: 0.8103 - val_accuracy: 0.9186\n",
      "Epoch 42/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.9303 - accuracy: 0.7641 - val_loss: 0.7918 - val_accuracy: 0.9215\n",
      "Epoch 43/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.9305 - accuracy: 0.7641 - val_loss: 0.7805 - val_accuracy: 0.9215\n",
      "Epoch 44/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.9384 - accuracy: 0.7553 - val_loss: 0.7605 - val_accuracy: 0.9186\n",
      "Epoch 45/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.8903 - accuracy: 0.7689 - val_loss: 0.7445 - val_accuracy: 0.9157\n",
      "Epoch 46/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.8615 - accuracy: 0.7864 - val_loss: 0.7370 - val_accuracy: 0.9244\n",
      "Epoch 47/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.8591 - accuracy: 0.7796 - val_loss: 0.7095 - val_accuracy: 0.9215\n",
      "Epoch 48/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.8412 - accuracy: 0.7806 - val_loss: 0.7005 - val_accuracy: 0.9215\n",
      "Epoch 49/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.8289 - accuracy: 0.7854 - val_loss: 0.6902 - val_accuracy: 0.9244\n",
      "Epoch 50/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.8032 - accuracy: 0.7971 - val_loss: 0.6772 - val_accuracy: 0.9302\n",
      "Epoch 51/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.8149 - accuracy: 0.8010 - val_loss: 0.6698 - val_accuracy: 0.9157\n",
      "Epoch 52/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.7869 - accuracy: 0.8010 - val_loss: 0.6530 - val_accuracy: 0.9157\n",
      "Epoch 53/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.7765 - accuracy: 0.8204 - val_loss: 0.6485 - val_accuracy: 0.9302\n",
      "Epoch 54/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.7611 - accuracy: 0.8126 - val_loss: 0.6294 - val_accuracy: 0.9215\n",
      "Epoch 55/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.7453 - accuracy: 0.8165 - val_loss: 0.6251 - val_accuracy: 0.9215\n",
      "Epoch 56/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.7395 - accuracy: 0.8223 - val_loss: 0.6182 - val_accuracy: 0.9186\n",
      "Epoch 57/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.7266 - accuracy: 0.8039 - val_loss: 0.6047 - val_accuracy: 0.9302\n",
      "Epoch 58/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.7267 - accuracy: 0.8107 - val_loss: 0.6034 - val_accuracy: 0.9186\n",
      "Epoch 59/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.7241 - accuracy: 0.8136 - val_loss: 0.5926 - val_accuracy: 0.9331\n",
      "Epoch 60/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.6808 - accuracy: 0.8398 - val_loss: 0.5790 - val_accuracy: 0.9244\n",
      "Epoch 61/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.6950 - accuracy: 0.8291 - val_loss: 0.5700 - val_accuracy: 0.9302\n",
      "Epoch 62/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.6758 - accuracy: 0.8379 - val_loss: 0.5629 - val_accuracy: 0.9302\n",
      "Epoch 63/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.6782 - accuracy: 0.8320 - val_loss: 0.5562 - val_accuracy: 0.9273\n",
      "Epoch 64/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.6822 - accuracy: 0.8223 - val_loss: 0.5604 - val_accuracy: 0.9244\n",
      "Epoch 65/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.6549 - accuracy: 0.8388 - val_loss: 0.5424 - val_accuracy: 0.9273\n",
      "Epoch 66/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.6323 - accuracy: 0.8553 - val_loss: 0.5404 - val_accuracy: 0.9215\n",
      "Epoch 67/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.6210 - accuracy: 0.8534 - val_loss: 0.5339 - val_accuracy: 0.9302\n",
      "Epoch 68/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.6537 - accuracy: 0.8301 - val_loss: 0.5259 - val_accuracy: 0.9360\n",
      "Epoch 69/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.6299 - accuracy: 0.8534 - val_loss: 0.5213 - val_accuracy: 0.9273\n",
      "Epoch 70/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.6422 - accuracy: 0.8350 - val_loss: 0.5160 - val_accuracy: 0.9331\n",
      "Epoch 71/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.6100 - accuracy: 0.8534 - val_loss: 0.5103 - val_accuracy: 0.9273\n",
      "Epoch 72/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.6016 - accuracy: 0.8515 - val_loss: 0.5084 - val_accuracy: 0.9302\n",
      "Epoch 73/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.5965 - accuracy: 0.8612 - val_loss: 0.4998 - val_accuracy: 0.9273\n",
      "Epoch 74/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.5664 - accuracy: 0.8621 - val_loss: 0.4996 - val_accuracy: 0.9360\n",
      "Epoch 75/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.5968 - accuracy: 0.8602 - val_loss: 0.4897 - val_accuracy: 0.9302\n",
      "Epoch 76/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.5742 - accuracy: 0.8612 - val_loss: 0.4896 - val_accuracy: 0.9302\n",
      "Epoch 77/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.5628 - accuracy: 0.8728 - val_loss: 0.4831 - val_accuracy: 0.9360\n",
      "Epoch 78/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.5701 - accuracy: 0.8621 - val_loss: 0.4764 - val_accuracy: 0.9273\n",
      "Epoch 79/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.5789 - accuracy: 0.8573 - val_loss: 0.4739 - val_accuracy: 0.9390\n",
      "Epoch 80/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.5247 - accuracy: 0.8951 - val_loss: 0.4705 - val_accuracy: 0.9331\n",
      "Epoch 81/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.5638 - accuracy: 0.8592 - val_loss: 0.4655 - val_accuracy: 0.9360\n",
      "Epoch 82/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.5467 - accuracy: 0.8602 - val_loss: 0.4653 - val_accuracy: 0.9331\n",
      "Epoch 83/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.5232 - accuracy: 0.8738 - val_loss: 0.4590 - val_accuracy: 0.9331\n",
      "Epoch 84/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.5479 - accuracy: 0.8767 - val_loss: 0.4582 - val_accuracy: 0.9331\n",
      "Epoch 85/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.5184 - accuracy: 0.8854 - val_loss: 0.4577 - val_accuracy: 0.9331\n",
      "Epoch 86/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.5288 - accuracy: 0.8689 - val_loss: 0.4524 - val_accuracy: 0.9360\n",
      "Epoch 87/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.5390 - accuracy: 0.8631 - val_loss: 0.4496 - val_accuracy: 0.9360\n",
      "Epoch 88/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.5437 - accuracy: 0.8612 - val_loss: 0.4468 - val_accuracy: 0.9331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.5186 - accuracy: 0.8670 - val_loss: 0.4405 - val_accuracy: 0.9360\n",
      "Epoch 90/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.5255 - accuracy: 0.8767 - val_loss: 0.4395 - val_accuracy: 0.9360\n",
      "Epoch 91/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.5301 - accuracy: 0.8728 - val_loss: 0.4336 - val_accuracy: 0.9302\n",
      "Epoch 92/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.5242 - accuracy: 0.8680 - val_loss: 0.4384 - val_accuracy: 0.9331\n",
      "Epoch 93/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.5127 - accuracy: 0.8767 - val_loss: 0.4331 - val_accuracy: 0.9360\n",
      "Epoch 94/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.4782 - accuracy: 0.8893 - val_loss: 0.4246 - val_accuracy: 0.9331\n",
      "Epoch 95/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.4983 - accuracy: 0.8767 - val_loss: 0.4273 - val_accuracy: 0.9419\n",
      "Epoch 96/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.4681 - accuracy: 0.8990 - val_loss: 0.4210 - val_accuracy: 0.9302\n",
      "Epoch 97/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.4985 - accuracy: 0.8806 - val_loss: 0.4190 - val_accuracy: 0.9302\n",
      "Epoch 98/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.4801 - accuracy: 0.8883 - val_loss: 0.4163 - val_accuracy: 0.9360\n",
      "Epoch 99/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.4940 - accuracy: 0.8845 - val_loss: 0.4137 - val_accuracy: 0.9331\n",
      "Epoch 100/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.4859 - accuracy: 0.8806 - val_loss: 0.4141 - val_accuracy: 0.9390\n",
      "Epoch 101/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.4599 - accuracy: 0.8913 - val_loss: 0.4101 - val_accuracy: 0.9360\n",
      "Epoch 102/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.4709 - accuracy: 0.9000 - val_loss: 0.4080 - val_accuracy: 0.9360\n",
      "Epoch 103/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.4429 - accuracy: 0.9068 - val_loss: 0.4105 - val_accuracy: 0.9360\n",
      "Epoch 104/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.4594 - accuracy: 0.8903 - val_loss: 0.4061 - val_accuracy: 0.9360\n",
      "Epoch 105/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.4541 - accuracy: 0.8883 - val_loss: 0.4058 - val_accuracy: 0.9331\n",
      "Epoch 106/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.4407 - accuracy: 0.9029 - val_loss: 0.4014 - val_accuracy: 0.9302\n",
      "Epoch 107/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.4398 - accuracy: 0.9019 - val_loss: 0.4008 - val_accuracy: 0.9360\n",
      "Epoch 108/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.4398 - accuracy: 0.9049 - val_loss: 0.3984 - val_accuracy: 0.9390\n",
      "Epoch 109/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.4605 - accuracy: 0.8981 - val_loss: 0.3966 - val_accuracy: 0.9360\n",
      "Epoch 110/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.4459 - accuracy: 0.9068 - val_loss: 0.4004 - val_accuracy: 0.9360\n",
      "Epoch 111/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.4371 - accuracy: 0.9087 - val_loss: 0.3941 - val_accuracy: 0.9360\n",
      "Epoch 112/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.4319 - accuracy: 0.9078 - val_loss: 0.3947 - val_accuracy: 0.9360\n",
      "Epoch 113/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.4302 - accuracy: 0.8981 - val_loss: 0.3932 - val_accuracy: 0.9390\n",
      "Epoch 114/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.4296 - accuracy: 0.8951 - val_loss: 0.3892 - val_accuracy: 0.9360\n",
      "Epoch 115/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.4421 - accuracy: 0.8942 - val_loss: 0.3898 - val_accuracy: 0.9419\n",
      "Epoch 116/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.4313 - accuracy: 0.9039 - val_loss: 0.3894 - val_accuracy: 0.9302\n",
      "Epoch 117/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.4330 - accuracy: 0.8961 - val_loss: 0.3899 - val_accuracy: 0.9360\n",
      "Epoch 118/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.4001 - accuracy: 0.9214 - val_loss: 0.3842 - val_accuracy: 0.9360\n",
      "Epoch 119/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.4139 - accuracy: 0.9087 - val_loss: 0.3807 - val_accuracy: 0.9360\n",
      "Epoch 120/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.4121 - accuracy: 0.9029 - val_loss: 0.3861 - val_accuracy: 0.9419\n",
      "Epoch 121/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.4120 - accuracy: 0.9058 - val_loss: 0.3815 - val_accuracy: 0.9448\n",
      "Epoch 122/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.4222 - accuracy: 0.8990 - val_loss: 0.3778 - val_accuracy: 0.9360\n",
      "Epoch 123/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.4255 - accuracy: 0.9068 - val_loss: 0.3774 - val_accuracy: 0.9360\n",
      "Epoch 124/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.4233 - accuracy: 0.9049 - val_loss: 0.3792 - val_accuracy: 0.9419\n",
      "Epoch 125/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.4136 - accuracy: 0.9029 - val_loss: 0.3777 - val_accuracy: 0.9477\n",
      "Epoch 126/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.4047 - accuracy: 0.9107 - val_loss: 0.3781 - val_accuracy: 0.9390\n",
      "Epoch 127/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.4001 - accuracy: 0.9175 - val_loss: 0.3745 - val_accuracy: 0.9360\n",
      "Epoch 128/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3949 - accuracy: 0.9146 - val_loss: 0.3724 - val_accuracy: 0.9331\n",
      "Epoch 129/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.4138 - accuracy: 0.9097 - val_loss: 0.3689 - val_accuracy: 0.9448\n",
      "Epoch 130/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.4214 - accuracy: 0.9019 - val_loss: 0.3740 - val_accuracy: 0.9390\n",
      "Epoch 131/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3759 - accuracy: 0.9117 - val_loss: 0.3656 - val_accuracy: 0.9360\n",
      "Epoch 132/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.3844 - accuracy: 0.9146 - val_loss: 0.3679 - val_accuracy: 0.9360\n",
      "Epoch 133/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3885 - accuracy: 0.9039 - val_loss: 0.3674 - val_accuracy: 0.9390\n",
      "Epoch 134/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3820 - accuracy: 0.9146 - val_loss: 0.3675 - val_accuracy: 0.9419\n",
      "Epoch 135/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3986 - accuracy: 0.9019 - val_loss: 0.3677 - val_accuracy: 0.9390\n",
      "Epoch 136/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.3775 - accuracy: 0.9165 - val_loss: 0.3646 - val_accuracy: 0.9419\n",
      "Epoch 137/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3795 - accuracy: 0.9136 - val_loss: 0.3615 - val_accuracy: 0.9360\n",
      "Epoch 138/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3714 - accuracy: 0.9194 - val_loss: 0.3594 - val_accuracy: 0.9419\n",
      "Epoch 139/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.3896 - accuracy: 0.9184 - val_loss: 0.3609 - val_accuracy: 0.9419\n",
      "Epoch 140/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.3667 - accuracy: 0.9243 - val_loss: 0.3627 - val_accuracy: 0.9419\n",
      "Epoch 141/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.3978 - accuracy: 0.9117 - val_loss: 0.3635 - val_accuracy: 0.9360\n",
      "Epoch 142/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.3847 - accuracy: 0.9252 - val_loss: 0.3573 - val_accuracy: 0.9390\n",
      "Epoch 143/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.3924 - accuracy: 0.9039 - val_loss: 0.3635 - val_accuracy: 0.9331\n",
      "Epoch 144/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.3567 - accuracy: 0.9320 - val_loss: 0.3600 - val_accuracy: 0.9390\n",
      "Epoch 145/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3716 - accuracy: 0.9175 - val_loss: 0.3521 - val_accuracy: 0.9419\n",
      "Epoch 146/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3787 - accuracy: 0.9175 - val_loss: 0.3524 - val_accuracy: 0.9390\n",
      "Epoch 147/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3770 - accuracy: 0.9272 - val_loss: 0.3617 - val_accuracy: 0.9360\n",
      "Epoch 148/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.3565 - accuracy: 0.9252 - val_loss: 0.3552 - val_accuracy: 0.9390\n",
      "Epoch 149/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3560 - accuracy: 0.9223 - val_loss: 0.3547 - val_accuracy: 0.9448\n",
      "Epoch 150/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3554 - accuracy: 0.9282 - val_loss: 0.3546 - val_accuracy: 0.9448\n",
      "Epoch 151/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.3853 - accuracy: 0.9078 - val_loss: 0.3539 - val_accuracy: 0.9360\n",
      "Epoch 152/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3702 - accuracy: 0.9136 - val_loss: 0.3537 - val_accuracy: 0.9448\n",
      "Epoch 153/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3554 - accuracy: 0.9214 - val_loss: 0.3489 - val_accuracy: 0.9419\n",
      "Epoch 154/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.3798 - accuracy: 0.9184 - val_loss: 0.3462 - val_accuracy: 0.9419\n",
      "Epoch 155/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.3531 - accuracy: 0.9117 - val_loss: 0.3471 - val_accuracy: 0.9448\n",
      "Epoch 156/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3502 - accuracy: 0.9252 - val_loss: 0.3496 - val_accuracy: 0.9448\n",
      "Epoch 157/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.3586 - accuracy: 0.9252 - val_loss: 0.3495 - val_accuracy: 0.9448\n",
      "Epoch 158/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.3488 - accuracy: 0.9272 - val_loss: 0.3458 - val_accuracy: 0.9419\n",
      "Epoch 159/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.3654 - accuracy: 0.9223 - val_loss: 0.3468 - val_accuracy: 0.9506\n",
      "Epoch 160/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3431 - accuracy: 0.9194 - val_loss: 0.3436 - val_accuracy: 0.9419\n",
      "Epoch 161/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.3483 - accuracy: 0.9204 - val_loss: 0.3449 - val_accuracy: 0.9477\n",
      "Epoch 162/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3564 - accuracy: 0.9291 - val_loss: 0.3472 - val_accuracy: 0.9419\n",
      "Epoch 163/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3347 - accuracy: 0.9262 - val_loss: 0.3452 - val_accuracy: 0.9419\n",
      "Epoch 164/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3384 - accuracy: 0.9330 - val_loss: 0.3456 - val_accuracy: 0.9390\n",
      "Epoch 165/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3474 - accuracy: 0.9262 - val_loss: 0.3442 - val_accuracy: 0.9448\n",
      "Epoch 166/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3455 - accuracy: 0.9252 - val_loss: 0.3439 - val_accuracy: 0.9419\n",
      "Epoch 167/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3331 - accuracy: 0.9350 - val_loss: 0.3457 - val_accuracy: 0.9390\n",
      "Epoch 168/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.3495 - accuracy: 0.9272 - val_loss: 0.3416 - val_accuracy: 0.9419\n",
      "Epoch 169/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3358 - accuracy: 0.9223 - val_loss: 0.3439 - val_accuracy: 0.9477\n",
      "Epoch 170/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.3384 - accuracy: 0.9214 - val_loss: 0.3392 - val_accuracy: 0.9390\n",
      "Epoch 171/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.3540 - accuracy: 0.9252 - val_loss: 0.3438 - val_accuracy: 0.9448\n",
      "Epoch 172/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3471 - accuracy: 0.9243 - val_loss: 0.3471 - val_accuracy: 0.9390\n",
      "Epoch 173/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3437 - accuracy: 0.9272 - val_loss: 0.3425 - val_accuracy: 0.9419\n",
      "Epoch 174/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.3409 - accuracy: 0.9262 - val_loss: 0.3420 - val_accuracy: 0.9419\n",
      "Epoch 175/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.3260 - accuracy: 0.9447 - val_loss: 0.3371 - val_accuracy: 0.9448\n",
      "Epoch 176/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3330 - accuracy: 0.9330 - val_loss: 0.3334 - val_accuracy: 0.9506\n",
      "Epoch 177/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.3208 - accuracy: 0.9330 - val_loss: 0.3368 - val_accuracy: 0.9448\n",
      "Epoch 178/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.3243 - accuracy: 0.9388 - val_loss: 0.3396 - val_accuracy: 0.9506\n",
      "Epoch 179/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3217 - accuracy: 0.9330 - val_loss: 0.3321 - val_accuracy: 0.9506\n",
      "Epoch 180/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.3162 - accuracy: 0.9350 - val_loss: 0.3358 - val_accuracy: 0.9477\n",
      "Epoch 181/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.3313 - accuracy: 0.9223 - val_loss: 0.3331 - val_accuracy: 0.9448\n",
      "Epoch 182/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.3223 - accuracy: 0.9350 - val_loss: 0.3310 - val_accuracy: 0.9419\n",
      "Epoch 183/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.3464 - accuracy: 0.9165 - val_loss: 0.3343 - val_accuracy: 0.9419\n",
      "Epoch 184/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.3277 - accuracy: 0.9330 - val_loss: 0.3328 - val_accuracy: 0.9419\n",
      "Epoch 185/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.3237 - accuracy: 0.9340 - val_loss: 0.3317 - val_accuracy: 0.9448\n",
      "Epoch 186/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3225 - accuracy: 0.9369 - val_loss: 0.3388 - val_accuracy: 0.9360\n",
      "Epoch 187/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.3161 - accuracy: 0.9243 - val_loss: 0.3372 - val_accuracy: 0.9360\n",
      "Epoch 188/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3137 - accuracy: 0.9369 - val_loss: 0.3357 - val_accuracy: 0.9390\n",
      "Epoch 189/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3204 - accuracy: 0.9311 - val_loss: 0.3399 - val_accuracy: 0.9448\n",
      "Epoch 190/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.3262 - accuracy: 0.9311 - val_loss: 0.3297 - val_accuracy: 0.9535\n",
      "Epoch 191/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3266 - accuracy: 0.9340 - val_loss: 0.3362 - val_accuracy: 0.9448\n",
      "Epoch 192/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3207 - accuracy: 0.9320 - val_loss: 0.3295 - val_accuracy: 0.9390\n",
      "Epoch 193/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3007 - accuracy: 0.9379 - val_loss: 0.3319 - val_accuracy: 0.9419\n",
      "Epoch 194/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.3057 - accuracy: 0.9369 - val_loss: 0.3287 - val_accuracy: 0.9419\n",
      "Epoch 195/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.3379 - accuracy: 0.9252 - val_loss: 0.3250 - val_accuracy: 0.9477\n",
      "Epoch 196/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.3140 - accuracy: 0.9350 - val_loss: 0.3277 - val_accuracy: 0.9506\n",
      "Epoch 197/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3032 - accuracy: 0.9369 - val_loss: 0.3223 - val_accuracy: 0.9535\n",
      "Epoch 198/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3115 - accuracy: 0.9350 - val_loss: 0.3261 - val_accuracy: 0.9506\n",
      "Epoch 199/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.3258 - accuracy: 0.9291 - val_loss: 0.3281 - val_accuracy: 0.9448\n",
      "Epoch 200/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3160 - accuracy: 0.9359 - val_loss: 0.3269 - val_accuracy: 0.9448\n",
      "Epoch 201/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.3013 - accuracy: 0.9437 - val_loss: 0.3261 - val_accuracy: 0.9564\n",
      "Epoch 202/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.3065 - accuracy: 0.9485 - val_loss: 0.3258 - val_accuracy: 0.9448\n",
      "Epoch 203/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.3144 - accuracy: 0.9398 - val_loss: 0.3319 - val_accuracy: 0.9448\n",
      "Epoch 204/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.3147 - accuracy: 0.9379 - val_loss: 0.3268 - val_accuracy: 0.9419\n",
      "Epoch 205/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.3123 - accuracy: 0.9408 - val_loss: 0.3235 - val_accuracy: 0.9535\n",
      "Epoch 206/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3099 - accuracy: 0.9359 - val_loss: 0.3253 - val_accuracy: 0.9477\n",
      "Epoch 207/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3029 - accuracy: 0.9379 - val_loss: 0.3284 - val_accuracy: 0.9506\n",
      "Epoch 208/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2957 - accuracy: 0.9408 - val_loss: 0.3265 - val_accuracy: 0.9419\n",
      "Epoch 209/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2938 - accuracy: 0.9485 - val_loss: 0.3241 - val_accuracy: 0.9535\n",
      "Epoch 210/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3150 - accuracy: 0.9272 - val_loss: 0.3224 - val_accuracy: 0.9448\n",
      "Epoch 211/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2968 - accuracy: 0.9408 - val_loss: 0.3232 - val_accuracy: 0.9477\n",
      "Epoch 212/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.3122 - accuracy: 0.9330 - val_loss: 0.3211 - val_accuracy: 0.9506\n",
      "Epoch 213/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2975 - accuracy: 0.9379 - val_loss: 0.3185 - val_accuracy: 0.9506\n",
      "Epoch 214/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2888 - accuracy: 0.9437 - val_loss: 0.3200 - val_accuracy: 0.9506\n",
      "Epoch 215/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.3025 - accuracy: 0.9379 - val_loss: 0.3176 - val_accuracy: 0.9535\n",
      "Epoch 216/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2906 - accuracy: 0.9417 - val_loss: 0.3211 - val_accuracy: 0.9360\n",
      "Epoch 217/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.3035 - accuracy: 0.9466 - val_loss: 0.3190 - val_accuracy: 0.9506\n",
      "Epoch 218/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.3049 - accuracy: 0.9252 - val_loss: 0.3188 - val_accuracy: 0.9477\n",
      "Epoch 219/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2976 - accuracy: 0.9340 - val_loss: 0.3262 - val_accuracy: 0.9506\n",
      "Epoch 220/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.2992 - accuracy: 0.9369 - val_loss: 0.3216 - val_accuracy: 0.9477\n",
      "Epoch 221/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2908 - accuracy: 0.9447 - val_loss: 0.3200 - val_accuracy: 0.9448\n",
      "Epoch 222/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2851 - accuracy: 0.9427 - val_loss: 0.3212 - val_accuracy: 0.9535\n",
      "Epoch 223/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2913 - accuracy: 0.9379 - val_loss: 0.3188 - val_accuracy: 0.9477\n",
      "Epoch 224/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2782 - accuracy: 0.9515 - val_loss: 0.3188 - val_accuracy: 0.9477\n",
      "Epoch 225/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2830 - accuracy: 0.9417 - val_loss: 0.3197 - val_accuracy: 0.9419\n",
      "Epoch 226/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2835 - accuracy: 0.9466 - val_loss: 0.3139 - val_accuracy: 0.9506\n",
      "Epoch 227/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2878 - accuracy: 0.9398 - val_loss: 0.3160 - val_accuracy: 0.9535\n",
      "Epoch 228/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2807 - accuracy: 0.9437 - val_loss: 0.3149 - val_accuracy: 0.9506\n",
      "Epoch 229/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2864 - accuracy: 0.9398 - val_loss: 0.3168 - val_accuracy: 0.9448\n",
      "Epoch 230/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2760 - accuracy: 0.9427 - val_loss: 0.3192 - val_accuracy: 0.9477\n",
      "Epoch 231/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2842 - accuracy: 0.9437 - val_loss: 0.3201 - val_accuracy: 0.9448\n",
      "Epoch 232/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2908 - accuracy: 0.9350 - val_loss: 0.3217 - val_accuracy: 0.9477\n",
      "Epoch 233/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2750 - accuracy: 0.9476 - val_loss: 0.3167 - val_accuracy: 0.9535\n",
      "Epoch 234/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2991 - accuracy: 0.9330 - val_loss: 0.3146 - val_accuracy: 0.9477\n",
      "Epoch 235/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2749 - accuracy: 0.9485 - val_loss: 0.3118 - val_accuracy: 0.9535\n",
      "Epoch 236/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.2905 - accuracy: 0.9388 - val_loss: 0.3153 - val_accuracy: 0.9535\n",
      "Epoch 237/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2791 - accuracy: 0.9417 - val_loss: 0.3146 - val_accuracy: 0.9564\n",
      "Epoch 238/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2882 - accuracy: 0.9476 - val_loss: 0.3171 - val_accuracy: 0.9506\n",
      "Epoch 239/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2718 - accuracy: 0.9485 - val_loss: 0.3161 - val_accuracy: 0.9448\n",
      "Epoch 240/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2720 - accuracy: 0.9544 - val_loss: 0.3177 - val_accuracy: 0.9448\n",
      "Epoch 241/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2898 - accuracy: 0.9456 - val_loss: 0.3167 - val_accuracy: 0.9477\n",
      "Epoch 242/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2911 - accuracy: 0.9379 - val_loss: 0.3170 - val_accuracy: 0.9448\n",
      "Epoch 243/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2968 - accuracy: 0.9291 - val_loss: 0.3117 - val_accuracy: 0.9506\n",
      "Epoch 244/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2670 - accuracy: 0.9466 - val_loss: 0.3132 - val_accuracy: 0.9506\n",
      "Epoch 245/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2838 - accuracy: 0.9437 - val_loss: 0.3130 - val_accuracy: 0.9535\n",
      "Epoch 246/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2637 - accuracy: 0.9573 - val_loss: 0.3128 - val_accuracy: 0.9506\n",
      "Epoch 247/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2707 - accuracy: 0.9398 - val_loss: 0.3123 - val_accuracy: 0.9506\n",
      "Epoch 248/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2818 - accuracy: 0.9427 - val_loss: 0.3137 - val_accuracy: 0.9477\n",
      "Epoch 249/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.2645 - accuracy: 0.9485 - val_loss: 0.3152 - val_accuracy: 0.9535\n",
      "Epoch 250/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2893 - accuracy: 0.9447 - val_loss: 0.3113 - val_accuracy: 0.9419\n",
      "Epoch 251/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2696 - accuracy: 0.9476 - val_loss: 0.3129 - val_accuracy: 0.9535\n",
      "Epoch 252/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2740 - accuracy: 0.9476 - val_loss: 0.3147 - val_accuracy: 0.9448\n",
      "Epoch 253/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2703 - accuracy: 0.9447 - val_loss: 0.3159 - val_accuracy: 0.9506\n",
      "Epoch 254/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2740 - accuracy: 0.9447 - val_loss: 0.3143 - val_accuracy: 0.9477\n",
      "Epoch 255/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2816 - accuracy: 0.9369 - val_loss: 0.3101 - val_accuracy: 0.9477\n",
      "Epoch 256/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2596 - accuracy: 0.9495 - val_loss: 0.3082 - val_accuracy: 0.9477\n",
      "Epoch 257/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2625 - accuracy: 0.9505 - val_loss: 0.3104 - val_accuracy: 0.9477\n",
      "Epoch 258/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2686 - accuracy: 0.9447 - val_loss: 0.3132 - val_accuracy: 0.9535\n",
      "Epoch 259/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2611 - accuracy: 0.9485 - val_loss: 0.3090 - val_accuracy: 0.9593\n",
      "Epoch 260/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2644 - accuracy: 0.9485 - val_loss: 0.3110 - val_accuracy: 0.9477\n",
      "Epoch 261/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2762 - accuracy: 0.9359 - val_loss: 0.3061 - val_accuracy: 0.9506\n",
      "Epoch 262/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2729 - accuracy: 0.9447 - val_loss: 0.3104 - val_accuracy: 0.9506\n",
      "Epoch 263/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2601 - accuracy: 0.9495 - val_loss: 0.3054 - val_accuracy: 0.9535\n",
      "Epoch 264/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2516 - accuracy: 0.9505 - val_loss: 0.3110 - val_accuracy: 0.9448\n",
      "Epoch 265/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2479 - accuracy: 0.9534 - val_loss: 0.3060 - val_accuracy: 0.9477\n",
      "Epoch 266/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2449 - accuracy: 0.9534 - val_loss: 0.3061 - val_accuracy: 0.9535\n",
      "Epoch 267/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2641 - accuracy: 0.9495 - val_loss: 0.3048 - val_accuracy: 0.9535\n",
      "Epoch 268/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2791 - accuracy: 0.9379 - val_loss: 0.3064 - val_accuracy: 0.9506\n",
      "Epoch 269/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2483 - accuracy: 0.9447 - val_loss: 0.3072 - val_accuracy: 0.9506\n",
      "Epoch 270/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2567 - accuracy: 0.9417 - val_loss: 0.3090 - val_accuracy: 0.9477\n",
      "Epoch 271/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2702 - accuracy: 0.9476 - val_loss: 0.3095 - val_accuracy: 0.9506\n",
      "Epoch 272/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2507 - accuracy: 0.9524 - val_loss: 0.3046 - val_accuracy: 0.9506\n",
      "Epoch 273/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2508 - accuracy: 0.9534 - val_loss: 0.3043 - val_accuracy: 0.9506\n",
      "Epoch 274/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2459 - accuracy: 0.9621 - val_loss: 0.3109 - val_accuracy: 0.9506\n",
      "Epoch 275/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2415 - accuracy: 0.9573 - val_loss: 0.3057 - val_accuracy: 0.9535\n",
      "Epoch 276/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2482 - accuracy: 0.9602 - val_loss: 0.3031 - val_accuracy: 0.9564\n",
      "Epoch 277/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2543 - accuracy: 0.9476 - val_loss: 0.3045 - val_accuracy: 0.9506\n",
      "Epoch 278/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2657 - accuracy: 0.9515 - val_loss: 0.3111 - val_accuracy: 0.9477\n",
      "Epoch 279/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2723 - accuracy: 0.9456 - val_loss: 0.3043 - val_accuracy: 0.9477\n",
      "Epoch 280/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2387 - accuracy: 0.9583 - val_loss: 0.3030 - val_accuracy: 0.9506\n",
      "Epoch 281/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2607 - accuracy: 0.9466 - val_loss: 0.3074 - val_accuracy: 0.9506\n",
      "Epoch 282/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2360 - accuracy: 0.9524 - val_loss: 0.3050 - val_accuracy: 0.9477\n",
      "Epoch 283/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2597 - accuracy: 0.9485 - val_loss: 0.3042 - val_accuracy: 0.9564\n",
      "Epoch 284/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2656 - accuracy: 0.9456 - val_loss: 0.3050 - val_accuracy: 0.9564\n",
      "Epoch 285/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2352 - accuracy: 0.9602 - val_loss: 0.3041 - val_accuracy: 0.9506\n",
      "Epoch 286/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2328 - accuracy: 0.9621 - val_loss: 0.3075 - val_accuracy: 0.9506\n",
      "Epoch 287/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2483 - accuracy: 0.9447 - val_loss: 0.3059 - val_accuracy: 0.9448\n",
      "Epoch 288/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2419 - accuracy: 0.9524 - val_loss: 0.3070 - val_accuracy: 0.9506\n",
      "Epoch 289/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2410 - accuracy: 0.9563 - val_loss: 0.3059 - val_accuracy: 0.9477\n",
      "Epoch 290/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2481 - accuracy: 0.9563 - val_loss: 0.3053 - val_accuracy: 0.9506\n",
      "Epoch 291/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2531 - accuracy: 0.9466 - val_loss: 0.3052 - val_accuracy: 0.9535\n",
      "Epoch 292/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2389 - accuracy: 0.9534 - val_loss: 0.3033 - val_accuracy: 0.9448\n",
      "Epoch 293/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2533 - accuracy: 0.9466 - val_loss: 0.3045 - val_accuracy: 0.9477\n",
      "Epoch 294/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2479 - accuracy: 0.9515 - val_loss: 0.3065 - val_accuracy: 0.9448\n",
      "Epoch 295/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.2441 - accuracy: 0.9505 - val_loss: 0.3043 - val_accuracy: 0.9506\n",
      "Epoch 296/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2479 - accuracy: 0.9505 - val_loss: 0.3007 - val_accuracy: 0.9506\n",
      "Epoch 297/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2501 - accuracy: 0.9495 - val_loss: 0.3033 - val_accuracy: 0.9506\n",
      "Epoch 298/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2331 - accuracy: 0.9553 - val_loss: 0.3033 - val_accuracy: 0.9477\n",
      "Epoch 299/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2440 - accuracy: 0.9505 - val_loss: 0.3002 - val_accuracy: 0.9477\n",
      "Epoch 300/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2521 - accuracy: 0.9485 - val_loss: 0.3040 - val_accuracy: 0.9506\n",
      "Epoch 301/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2502 - accuracy: 0.9505 - val_loss: 0.3008 - val_accuracy: 0.9506\n",
      "Epoch 302/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2495 - accuracy: 0.9534 - val_loss: 0.3010 - val_accuracy: 0.9506\n",
      "Epoch 303/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2394 - accuracy: 0.9583 - val_loss: 0.3023 - val_accuracy: 0.9506\n",
      "Epoch 304/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2575 - accuracy: 0.9456 - val_loss: 0.3022 - val_accuracy: 0.9448\n",
      "Epoch 305/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2438 - accuracy: 0.9573 - val_loss: 0.3004 - val_accuracy: 0.9477\n",
      "Epoch 306/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2422 - accuracy: 0.9524 - val_loss: 0.2977 - val_accuracy: 0.9564\n",
      "Epoch 307/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2460 - accuracy: 0.9515 - val_loss: 0.2969 - val_accuracy: 0.9535\n",
      "Epoch 308/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2395 - accuracy: 0.9583 - val_loss: 0.2972 - val_accuracy: 0.9564\n",
      "Epoch 309/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2424 - accuracy: 0.9437 - val_loss: 0.3036 - val_accuracy: 0.9448\n",
      "Epoch 310/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2340 - accuracy: 0.9563 - val_loss: 0.3003 - val_accuracy: 0.9506\n",
      "Epoch 311/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2424 - accuracy: 0.9621 - val_loss: 0.3002 - val_accuracy: 0.9448\n",
      "Epoch 312/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2386 - accuracy: 0.9485 - val_loss: 0.3019 - val_accuracy: 0.9477\n",
      "Epoch 313/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2433 - accuracy: 0.9524 - val_loss: 0.2989 - val_accuracy: 0.9477\n",
      "Epoch 314/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2385 - accuracy: 0.9573 - val_loss: 0.3019 - val_accuracy: 0.9535\n",
      "Epoch 315/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2410 - accuracy: 0.9505 - val_loss: 0.3031 - val_accuracy: 0.9477\n",
      "Epoch 316/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2541 - accuracy: 0.9388 - val_loss: 0.3004 - val_accuracy: 0.9477\n",
      "Epoch 317/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2310 - accuracy: 0.9553 - val_loss: 0.3003 - val_accuracy: 0.9506\n",
      "Epoch 318/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2400 - accuracy: 0.9602 - val_loss: 0.2994 - val_accuracy: 0.9506\n",
      "Epoch 319/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2373 - accuracy: 0.9563 - val_loss: 0.2980 - val_accuracy: 0.9477\n",
      "Epoch 320/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2398 - accuracy: 0.9476 - val_loss: 0.3031 - val_accuracy: 0.9506\n",
      "Epoch 321/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2419 - accuracy: 0.9524 - val_loss: 0.3030 - val_accuracy: 0.9506\n",
      "Epoch 322/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2315 - accuracy: 0.9505 - val_loss: 0.2991 - val_accuracy: 0.9506\n",
      "Epoch 323/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2289 - accuracy: 0.9515 - val_loss: 0.3023 - val_accuracy: 0.9477\n",
      "Epoch 324/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2462 - accuracy: 0.9505 - val_loss: 0.2990 - val_accuracy: 0.9564\n",
      "Epoch 325/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2339 - accuracy: 0.9641 - val_loss: 0.3016 - val_accuracy: 0.9477\n",
      "Epoch 326/2000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 0.2381 - accuracy: 0.9476 - val_loss: 0.2983 - val_accuracy: 0.9448\n",
      "Epoch 327/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2354 - accuracy: 0.9621 - val_loss: 0.3016 - val_accuracy: 0.9506\n",
      "Epoch 328/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2442 - accuracy: 0.9524 - val_loss: 0.3015 - val_accuracy: 0.9477\n",
      "Epoch 329/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2292 - accuracy: 0.9563 - val_loss: 0.3008 - val_accuracy: 0.9448\n",
      "Epoch 330/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2334 - accuracy: 0.9524 - val_loss: 0.3002 - val_accuracy: 0.9477\n",
      "Epoch 331/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2276 - accuracy: 0.9602 - val_loss: 0.2950 - val_accuracy: 0.9506\n",
      "Epoch 332/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2423 - accuracy: 0.9524 - val_loss: 0.2992 - val_accuracy: 0.9535\n",
      "Epoch 333/2000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 0.2232 - accuracy: 0.9641 - val_loss: 0.2977 - val_accuracy: 0.9535\n",
      "Epoch 334/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2195 - accuracy: 0.9650 - val_loss: 0.2969 - val_accuracy: 0.9477\n",
      "Epoch 335/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.2372 - accuracy: 0.9583 - val_loss: 0.2960 - val_accuracy: 0.9419\n",
      "Epoch 336/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2385 - accuracy: 0.9534 - val_loss: 0.2968 - val_accuracy: 0.9535\n",
      "Epoch 337/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2275 - accuracy: 0.9573 - val_loss: 0.2983 - val_accuracy: 0.9477\n",
      "Epoch 338/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2289 - accuracy: 0.9592 - val_loss: 0.2957 - val_accuracy: 0.9564\n",
      "Epoch 339/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2387 - accuracy: 0.9524 - val_loss: 0.2979 - val_accuracy: 0.9448\n",
      "Epoch 340/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2199 - accuracy: 0.9621 - val_loss: 0.2963 - val_accuracy: 0.9535\n",
      "Epoch 341/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2360 - accuracy: 0.9544 - val_loss: 0.3013 - val_accuracy: 0.9535\n",
      "Epoch 342/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2406 - accuracy: 0.9437 - val_loss: 0.2984 - val_accuracy: 0.9506\n",
      "Epoch 343/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2364 - accuracy: 0.9495 - val_loss: 0.2974 - val_accuracy: 0.9506\n",
      "Epoch 344/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2410 - accuracy: 0.9456 - val_loss: 0.3029 - val_accuracy: 0.9477\n",
      "Epoch 345/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2304 - accuracy: 0.9612 - val_loss: 0.3008 - val_accuracy: 0.9535\n",
      "Epoch 346/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2221 - accuracy: 0.9602 - val_loss: 0.3032 - val_accuracy: 0.9564\n",
      "Epoch 347/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2412 - accuracy: 0.9515 - val_loss: 0.3027 - val_accuracy: 0.9448\n",
      "Epoch 348/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2318 - accuracy: 0.9495 - val_loss: 0.2978 - val_accuracy: 0.9477\n",
      "Epoch 349/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2394 - accuracy: 0.9447 - val_loss: 0.2973 - val_accuracy: 0.9593\n",
      "Epoch 350/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2232 - accuracy: 0.9641 - val_loss: 0.2971 - val_accuracy: 0.9564\n",
      "Epoch 351/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2268 - accuracy: 0.9534 - val_loss: 0.2934 - val_accuracy: 0.9506\n",
      "Epoch 352/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2315 - accuracy: 0.9495 - val_loss: 0.2982 - val_accuracy: 0.9535\n",
      "Epoch 353/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2281 - accuracy: 0.9515 - val_loss: 0.2950 - val_accuracy: 0.9506\n",
      "Epoch 354/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2094 - accuracy: 0.9641 - val_loss: 0.2986 - val_accuracy: 0.9448\n",
      "Epoch 355/2000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 0.2152 - accuracy: 0.9592 - val_loss: 0.2986 - val_accuracy: 0.9477\n",
      "Epoch 356/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2155 - accuracy: 0.9563 - val_loss: 0.3049 - val_accuracy: 0.9477\n",
      "Epoch 357/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2214 - accuracy: 0.9563 - val_loss: 0.3048 - val_accuracy: 0.9419\n",
      "Epoch 358/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2310 - accuracy: 0.9485 - val_loss: 0.2985 - val_accuracy: 0.9506\n",
      "Epoch 359/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2321 - accuracy: 0.9456 - val_loss: 0.2975 - val_accuracy: 0.9477\n",
      "Epoch 360/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2191 - accuracy: 0.9573 - val_loss: 0.2981 - val_accuracy: 0.9477\n",
      "Epoch 361/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2095 - accuracy: 0.9602 - val_loss: 0.2988 - val_accuracy: 0.9448\n",
      "Epoch 362/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2217 - accuracy: 0.9602 - val_loss: 0.2992 - val_accuracy: 0.9419\n",
      "Epoch 363/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2148 - accuracy: 0.9621 - val_loss: 0.2971 - val_accuracy: 0.9506\n",
      "Epoch 364/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2379 - accuracy: 0.9573 - val_loss: 0.2974 - val_accuracy: 0.9506\n",
      "Epoch 365/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2157 - accuracy: 0.9680 - val_loss: 0.2963 - val_accuracy: 0.9622\n",
      "Epoch 366/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2414 - accuracy: 0.9466 - val_loss: 0.2970 - val_accuracy: 0.9564\n",
      "Epoch 367/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2195 - accuracy: 0.9563 - val_loss: 0.3015 - val_accuracy: 0.9419\n",
      "Epoch 368/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2146 - accuracy: 0.9612 - val_loss: 0.3001 - val_accuracy: 0.9419\n",
      "Epoch 369/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2262 - accuracy: 0.9534 - val_loss: 0.3000 - val_accuracy: 0.9448\n",
      "Epoch 370/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2143 - accuracy: 0.9563 - val_loss: 0.2973 - val_accuracy: 0.9535\n",
      "Epoch 371/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2205 - accuracy: 0.9602 - val_loss: 0.3006 - val_accuracy: 0.9564\n",
      "Epoch 372/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2164 - accuracy: 0.9631 - val_loss: 0.2970 - val_accuracy: 0.9535\n",
      "Epoch 373/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2156 - accuracy: 0.9709 - val_loss: 0.2966 - val_accuracy: 0.9477\n",
      "Epoch 374/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2150 - accuracy: 0.9592 - val_loss: 0.2943 - val_accuracy: 0.9506\n",
      "Epoch 375/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2298 - accuracy: 0.9485 - val_loss: 0.2938 - val_accuracy: 0.9622\n",
      "Epoch 376/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2189 - accuracy: 0.9573 - val_loss: 0.3018 - val_accuracy: 0.9419\n",
      "Epoch 377/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2128 - accuracy: 0.9612 - val_loss: 0.2960 - val_accuracy: 0.9448\n",
      "Epoch 378/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2176 - accuracy: 0.9660 - val_loss: 0.2946 - val_accuracy: 0.9564\n",
      "Epoch 379/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2269 - accuracy: 0.9641 - val_loss: 0.2948 - val_accuracy: 0.9506\n",
      "Epoch 380/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2124 - accuracy: 0.9592 - val_loss: 0.2944 - val_accuracy: 0.9448\n",
      "Epoch 381/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2160 - accuracy: 0.9544 - val_loss: 0.2924 - val_accuracy: 0.9535\n",
      "Epoch 382/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2150 - accuracy: 0.9631 - val_loss: 0.2982 - val_accuracy: 0.9448\n",
      "Epoch 383/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2082 - accuracy: 0.9602 - val_loss: 0.2949 - val_accuracy: 0.9535\n",
      "Epoch 384/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2183 - accuracy: 0.9563 - val_loss: 0.2996 - val_accuracy: 0.9506\n",
      "Epoch 385/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2149 - accuracy: 0.9612 - val_loss: 0.2951 - val_accuracy: 0.9477\n",
      "Epoch 386/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2139 - accuracy: 0.9592 - val_loss: 0.2930 - val_accuracy: 0.9564\n",
      "Epoch 387/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2070 - accuracy: 0.9660 - val_loss: 0.3019 - val_accuracy: 0.9419\n",
      "Epoch 388/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2123 - accuracy: 0.9650 - val_loss: 0.2969 - val_accuracy: 0.9448\n",
      "Epoch 389/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.2169 - accuracy: 0.9602 - val_loss: 0.2957 - val_accuracy: 0.9448\n",
      "Epoch 390/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2139 - accuracy: 0.9563 - val_loss: 0.2937 - val_accuracy: 0.9564\n",
      "Epoch 391/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2110 - accuracy: 0.9563 - val_loss: 0.2969 - val_accuracy: 0.9477\n",
      "Epoch 392/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2126 - accuracy: 0.9670 - val_loss: 0.2963 - val_accuracy: 0.9506\n",
      "Epoch 393/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2195 - accuracy: 0.9515 - val_loss: 0.2925 - val_accuracy: 0.9506\n",
      "Epoch 394/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2166 - accuracy: 0.9544 - val_loss: 0.2924 - val_accuracy: 0.9506\n",
      "Epoch 395/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2064 - accuracy: 0.9699 - val_loss: 0.2942 - val_accuracy: 0.9535\n",
      "Epoch 396/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2114 - accuracy: 0.9583 - val_loss: 0.2949 - val_accuracy: 0.9506\n",
      "Epoch 397/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2076 - accuracy: 0.9621 - val_loss: 0.2943 - val_accuracy: 0.9477\n",
      "Epoch 398/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2027 - accuracy: 0.9612 - val_loss: 0.2929 - val_accuracy: 0.9535\n",
      "Epoch 399/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.2089 - accuracy: 0.9612 - val_loss: 0.2936 - val_accuracy: 0.9477\n",
      "Epoch 400/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2012 - accuracy: 0.9670 - val_loss: 0.2928 - val_accuracy: 0.9593\n",
      "Epoch 401/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2117 - accuracy: 0.9544 - val_loss: 0.2957 - val_accuracy: 0.9477\n",
      "Epoch 402/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2052 - accuracy: 0.9670 - val_loss: 0.2973 - val_accuracy: 0.9477\n",
      "Epoch 403/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2035 - accuracy: 0.9621 - val_loss: 0.2930 - val_accuracy: 0.9477\n",
      "Epoch 404/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.1989 - accuracy: 0.9660 - val_loss: 0.2930 - val_accuracy: 0.9622\n",
      "Epoch 405/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2159 - accuracy: 0.9553 - val_loss: 0.2946 - val_accuracy: 0.9477\n",
      "Epoch 406/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2130 - accuracy: 0.9583 - val_loss: 0.2907 - val_accuracy: 0.9506\n",
      "Epoch 407/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2106 - accuracy: 0.9583 - val_loss: 0.2940 - val_accuracy: 0.9506\n",
      "Epoch 408/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2213 - accuracy: 0.9573 - val_loss: 0.2961 - val_accuracy: 0.9477\n",
      "Epoch 409/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2163 - accuracy: 0.9563 - val_loss: 0.2950 - val_accuracy: 0.9506\n",
      "Epoch 410/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.1996 - accuracy: 0.9631 - val_loss: 0.2952 - val_accuracy: 0.9506\n",
      "Epoch 411/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2055 - accuracy: 0.9631 - val_loss: 0.2940 - val_accuracy: 0.9390\n",
      "Epoch 412/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2036 - accuracy: 0.9621 - val_loss: 0.2890 - val_accuracy: 0.9506\n",
      "Epoch 413/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2119 - accuracy: 0.9592 - val_loss: 0.2944 - val_accuracy: 0.9448\n",
      "Epoch 414/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2011 - accuracy: 0.9641 - val_loss: 0.2957 - val_accuracy: 0.9448\n",
      "Epoch 415/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2025 - accuracy: 0.9592 - val_loss: 0.2960 - val_accuracy: 0.9419\n",
      "Epoch 416/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.1980 - accuracy: 0.9670 - val_loss: 0.2941 - val_accuracy: 0.9535\n",
      "Epoch 417/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2217 - accuracy: 0.9485 - val_loss: 0.2946 - val_accuracy: 0.9448\n",
      "Epoch 418/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2074 - accuracy: 0.9563 - val_loss: 0.2982 - val_accuracy: 0.9448\n",
      "Epoch 419/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2191 - accuracy: 0.9534 - val_loss: 0.2958 - val_accuracy: 0.9564\n",
      "Epoch 420/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2066 - accuracy: 0.9641 - val_loss: 0.2959 - val_accuracy: 0.9477\n",
      "Epoch 421/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.1964 - accuracy: 0.9660 - val_loss: 0.2945 - val_accuracy: 0.9535\n",
      "Epoch 422/2000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 0.1939 - accuracy: 0.9660 - val_loss: 0.2998 - val_accuracy: 0.9448\n",
      "Epoch 423/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2009 - accuracy: 0.9670 - val_loss: 0.2964 - val_accuracy: 0.9477\n",
      "Epoch 424/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.1984 - accuracy: 0.9612 - val_loss: 0.2965 - val_accuracy: 0.9564\n",
      "Epoch 425/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.1914 - accuracy: 0.9689 - val_loss: 0.2923 - val_accuracy: 0.9506\n",
      "Epoch 426/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2104 - accuracy: 0.9563 - val_loss: 0.2918 - val_accuracy: 0.9564\n",
      "Epoch 427/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.2170 - accuracy: 0.9553 - val_loss: 0.2949 - val_accuracy: 0.9506\n",
      "Epoch 428/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2002 - accuracy: 0.9621 - val_loss: 0.2934 - val_accuracy: 0.9477\n",
      "Epoch 429/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.2253 - accuracy: 0.9485 - val_loss: 0.2918 - val_accuracy: 0.9593\n",
      "Epoch 430/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.2061 - accuracy: 0.9650 - val_loss: 0.2900 - val_accuracy: 0.9564\n",
      "Epoch 431/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.1957 - accuracy: 0.9680 - val_loss: 0.2930 - val_accuracy: 0.9593\n",
      "Epoch 432/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2055 - accuracy: 0.9602 - val_loss: 0.2941 - val_accuracy: 0.9535\n",
      "Epoch 433/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2182 - accuracy: 0.9534 - val_loss: 0.2922 - val_accuracy: 0.9477\n",
      "Epoch 434/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2017 - accuracy: 0.9641 - val_loss: 0.2909 - val_accuracy: 0.9622\n",
      "Epoch 435/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2102 - accuracy: 0.9602 - val_loss: 0.2930 - val_accuracy: 0.9535\n",
      "Epoch 436/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.1932 - accuracy: 0.9621 - val_loss: 0.2917 - val_accuracy: 0.9477\n",
      "Epoch 437/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.1956 - accuracy: 0.9718 - val_loss: 0.2938 - val_accuracy: 0.9564\n",
      "Epoch 438/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.1916 - accuracy: 0.9699 - val_loss: 0.2917 - val_accuracy: 0.9506\n",
      "Epoch 439/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.1945 - accuracy: 0.9641 - val_loss: 0.2911 - val_accuracy: 0.9535\n",
      "Epoch 440/2000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 0.2054 - accuracy: 0.9592 - val_loss: 0.2930 - val_accuracy: 0.9535\n",
      "Epoch 441/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.2025 - accuracy: 0.9553 - val_loss: 0.2933 - val_accuracy: 0.9506\n",
      "Epoch 442/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2011 - accuracy: 0.9573 - val_loss: 0.2900 - val_accuracy: 0.9477\n",
      "Epoch 443/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.2041 - accuracy: 0.9573 - val_loss: 0.2955 - val_accuracy: 0.9535\n",
      "Epoch 444/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.1882 - accuracy: 0.9718 - val_loss: 0.2904 - val_accuracy: 0.9535\n",
      "Epoch 445/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.1960 - accuracy: 0.9553 - val_loss: 0.2898 - val_accuracy: 0.9564\n",
      "Epoch 446/2000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 0.2013 - accuracy: 0.9621 - val_loss: 0.2896 - val_accuracy: 0.9535\n",
      "Epoch 447/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.1916 - accuracy: 0.9602 - val_loss: 0.2912 - val_accuracy: 0.9535\n",
      "Epoch 448/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2040 - accuracy: 0.9612 - val_loss: 0.2901 - val_accuracy: 0.9535\n",
      "Epoch 449/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.1953 - accuracy: 0.9660 - val_loss: 0.2901 - val_accuracy: 0.9506\n",
      "Epoch 450/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.2036 - accuracy: 0.9602 - val_loss: 0.2893 - val_accuracy: 0.9535\n",
      "Epoch 451/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.1833 - accuracy: 0.9680 - val_loss: 0.2901 - val_accuracy: 0.9506\n",
      "Epoch 452/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.1963 - accuracy: 0.9621 - val_loss: 0.2922 - val_accuracy: 0.9448\n",
      "Epoch 453/2000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 0.1961 - accuracy: 0.9660 - val_loss: 0.2966 - val_accuracy: 0.9506\n",
      "Epoch 454/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2041 - accuracy: 0.9573 - val_loss: 0.2916 - val_accuracy: 0.9535\n",
      "Epoch 455/2000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 0.1799 - accuracy: 0.9631 - val_loss: 0.2918 - val_accuracy: 0.9535\n",
      "Epoch 456/2000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 0.1941 - accuracy: 0.9621 - val_loss: 0.2901 - val_accuracy: 0.9506\n",
      "Epoch 457/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2017 - accuracy: 0.9631 - val_loss: 0.2919 - val_accuracy: 0.9477\n",
      "Epoch 458/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.2030 - accuracy: 0.9592 - val_loss: 0.2899 - val_accuracy: 0.9419\n",
      "Epoch 459/2000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 0.2025 - accuracy: 0.9621 - val_loss: 0.2928 - val_accuracy: 0.9477\n",
      "Epoch 460/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.1966 - accuracy: 0.9680 - val_loss: 0.2949 - val_accuracy: 0.9506\n",
      "Epoch 461/2000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 0.1930 - accuracy: 0.9612 - val_loss: 0.2940 - val_accuracy: 0.9506\n",
      "Epoch 462/2000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 0.1940 - accuracy: 0.9660 - val_loss: 0.2903 - val_accuracy: 0.9506\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for f in range(1, 11, 1):\n",
    "    frac = f / 10.0\n",
    "    sample = data_grouped.sample(frac=frac, random_state=12345)\n",
    "    sample_grouped = sample.groupby([\"location\", pd.Grouper(key=\"time\", freq=\"1s\")]).mean().reset_index()\n",
    "    train, validation, test = train_validation_test_split(sample_grouped)\n",
    "\n",
    "    train.sort_values(\"time\", inplace=True)\n",
    "    validation.sort_values(\"time\", inplace=True)\n",
    "    test.sort_values(\"time\", inplace=True)\n",
    "\n",
    "    train_imputed = train.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    train_imputed.fillna(0, inplace=True)\n",
    "    train_imputed.reset_index(inplace=True)\n",
    "\n",
    "    validation_imputed = validation.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    validation_imputed.fillna(0, inplace=True)\n",
    "    validation_imputed.reset_index(inplace=True)\n",
    "\n",
    "    test_imputed = test.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    test_imputed.fillna(0, inplace=True)\n",
    "    test_imputed.reset_index(inplace=True)\n",
    "\n",
    "    X_train, y_train = train_imputed[scanners].values, train_imputed[\"location\"].values\n",
    "    X_validation, y_validation = validation_imputed[scanners].values, validation_imputed[\"location\"].values\n",
    "    X_test, y_test = test_imputed[scanners].values, test_imputed[\"location\"].values\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "\n",
    "    y_train = enc.fit_transform(y_train)\n",
    "    y_validation = enc.transform(y_validation)\n",
    "    y_test = enc.transform(y_test)\n",
    "\n",
    "    model = MLPClassifier(size='small')\n",
    "    history = model.fit(X_train, y_train, X_validation, y_validation)\n",
    "\n",
    "    train_loss.append(history.history['loss'][-1])\n",
    "    val_loss.append(history.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deVxVdfrA8c+XTWRXwA1QRHFBZBNNR3MpNbVyyZUypybbpqaZrJmcmabFpvnVtNc0bVO2a5alZpZtlmlpAiLuiisoKiCogOzf3x/nSkjs3Mvhcp/363Vfce8995yHE57nnu/yfJXWGiGEEI7LyewAhBBCmEsSgRBCODhJBEII4eAkEQghhIOTRCCEEA7OxewAGisgIECHhoaaHYYQQtiVpKSkbK11YE3v2V0iCA0NJTEx0ewwhBDCriiljtT2njQNCSGEg5NEIIQQDk4SgRBCODi76yMQQrSs0tJSMjIyKCoqMjsU0QDu7u4EBwfj6ura4M9IIhBC1CkjIwNvb29CQ0NRSpkdjqiD1pqcnBwyMjLo2bNngz8nTUNCiDoVFRXh7+8vScAOKKXw9/dv9N2bJAIhRL0kCdiPpvy/cpxEkJEEXz9kdhRCCNHqOE4iyNwKG56BE9vNjkQI0Qg5OTnExMQQExNDly5dCAoKqnxeUlLSoH3ceOON7N27t85tXnzxRd577z1rhMyIESNISUmxyr5aguN0Fg+4Bj5fCNuWQpeBZkcjhGggf3//yovqQw89hJeXF/fee+9F22it0Vrj5FTzd9vFixfXe5w77rij+cHaKce5I/DoCH0nQOoyKC8zOxohRDOlpaURGRnJbbfdRlxcHJmZmdxyyy3Ex8czYMAAFi1aVLnthW/oZWVl+Pn5sXDhQqKjoxk2bBinTp0C4P777+fZZ5+t3H7hwoUMGTKEvn378uOPPwJQUFDA9OnTiY6OJiEhgfj4+Hq/+b/77rsMHDiQyMhI/va3vwFQVlbG9ddfX/n6888/D8AzzzxDREQE0dHRzJ071+rnrDaOc0cAEJ0Auz+Fg+sgfJzZ0Qhhdx7+dCe7jp+16j4juvnw4NUDmvTZXbt2sXjxYl5++WUAHnvsMTp27EhZWRljxoxhxowZREREXPSZM2fOMGrUKB577DEWLFjAG2+8wcKFC3+1b601P//8M6tWrWLRokV88cUXvPDCC3Tp0oXly5ezbds24uLi6owvIyOD+++/n8TERHx9fRk7diyrV68mMDCQ7Oxstm83mqrz8vIA+Pe//82RI0dwc3OrfK0lOM4dAUDvcdC+I6S8b3YkQggr6NWrF4MHD658vmTJEuLi4oiLi2P37t3s2rXrV59p3749EydOBGDQoEEcPny4xn1fc801v9pmw4YNzJkzB4Do6GgGDKg7gW3evJnLLruMgIAAXF1dufbaa1m/fj29e/dm7969/PGPf2Tt2rX4+voCMGDAAObOnct7773XqAlhzeVYdwQubjBwBiS9BefzoL2f2REJYVea+s3dVjw9PSt/3r9/P8899xw///wzfn5+zJ07t8bx9G5ubpU/Ozs7U1ZWc1Nxu3btfrWN1rpR8dW2vb+/P6mpqXz++ec8//zzLF++nFdffZW1a9fy/fffs3LlSv75z3+yY8cOnJ2dG3XMpnCsOwKA6DlQXgy7VpodiRDCis6ePYu3tzc+Pj5kZmaydu1aqx9jxIgRLFu2DIDt27fXeMdR1dChQ1m3bh05OTmUlZWxdOlSRo0aRVZWFlprZs6cycMPP0xycjLl5eVkZGRw2WWX8cQTT5CVlUVhYaHVf4eaONYdAUC3OAjoY4weGvRbs6MRQlhJXFwcERERREZGEhYWxvDhw61+jD/84Q/MmzePqKgo4uLiiIyMrGzWqUlwcDCLFi1i9OjRaK25+uqrufLKK0lOTuamm25Ca41Siscff5yysjKuvfZazp07R0VFBffddx/e3t5W/x1qohp7q2O2+Ph43eyFaX54Cr5ZBHelQMeG1+MQwhHt3r2b/v37mx1Gq1BWVkZZWRnu7u7s37+f8ePHs3//flxcWtd36pr+nymlkrTW8TVt73hNQwADZwHKGEoqhBANlJ+fz/Dhw4mOjmb69Om88sorrS4JNIXNfgOl1BvAVcAprXVkDe8r4DlgElAI3KC1TrZVPBfxC4Gel8K2JTDqLyB1VIQQDeDn50dSUpLZYVidLe8I3gQm1PH+RCDc8rgFeMmGsfxadALkHoL0n1v0sEII0drYLBFordcDp+vYZArwtjZsAvyUUl1tFc+v9J8Mrh7GXYEQQjgwM/sIgoD0Ks8zLK/9ilLqFqVUolIqMSsryzpHb+dlJIOdH0OprLwkhHBcZiaCmhrmaxzCpLV+VWsdr7WODwwMtF4E0XOg6Azs+8J6+xRCCDtjZiLIAEKqPA8GjrdoBD1Hgnc3aR4SohUbPXr0ryaHPfvss/z+97+v83NeXl4AHD9+nBkzZtS67/qGoz/77LMXTeyaNGmSVeoAPfTQQzz55JPN3o81mJkIVgHzlGEocEZrndmiETg5Q9Qs2P8V5FupyUkIYVUJCQksXbr0oteWLl1KQkJCgz7frVs3PvrooyYfv3oiWLNmDX5+bas8jc0SgVJqCfAT0FcplaGUukkpdZtS6jbLJmuAg0Aa8BpQd3q3leg5oMthR9P/UIQQtjNjxgxWr15NcXExAIcPH+b48eOMGDGC/Px8Lr/8cuLi4hg4cCArV/66dMzhw4eJjDRGsJ8/f545c+YQFRXF7NmzOX/+fOV2t99+e2UJ6wcffBCA559/nuPHjzNmzBjGjBkDQGhoKNnZ2QA8/fTTREZGEhkZWVnC+vDhw/Tv35+bb76ZAQMGMH78+IuOU5OUlBSGDh1KVFQU06ZNIzc3t/L4ERERREVFVRa7+/777ysX5omNjeXcuXNNPrcX2Gwegda6znStjSnN5q8E0ak/dI0xmoeG3m52NEK0bp8vtP4qf10GwsTHan3b39+fIUOG8MUXXzBlyhSWLl3K7NmzUUrh7u7OJ598go+PD9nZ2QwdOpTJkyfXum7vSy+9hIeHB6mpqaSmpl5URvrRRx+lY8eOlJeXc/nll5Oamspdd93F008/zbp16wgICLhoX0lJSSxevJjNmzejteaSSy5h1KhRdOjQgf3797NkyRJee+01Zs2axfLly+tcX2DevHm88MILjBo1igceeICHH36YZ599lscee4xDhw7Rrl27yuaoJ598khdffJHhw4eTn5+Pu7t7Y852jRxzZnF10QmQuQ1O1l1ASghhjqrNQ1WbhbTW/O1vfyMqKoqxY8dy7NgxTp48Wet+1q9fX3lBjoqKIioqqvK9ZcuWERcXR2xsLDt37qy3oNyGDRuYNm0anp6eeHl5cc011/DDDz8A0LNnT2JiYoC6S12DsT5CXl4eo0aNAuC3v/0t69evr4zxuuuu4913362cwTx8+HAWLFjA888/T15enlVmNtv/3GhriJwOX/4dUpfCuEX1by+Eo6rjm7stTZ06lQULFpCcnMz58+crv8m/9957ZGVlkZSUhKurK6GhoTWWnq6qpruFQ4cO8eSTT7JlyxY6dOjADTfcUO9+6qrTdqGENRhlrOtrGqrNZ599xvr161m1ahWPPPIIO3fuZOHChVx55ZWsWbOGoUOH8vXXX9OvX78m7f8CuSMA8Ao0Fq1JXQYV5WZHI4SoxsvLi9GjR/O73/3uok7iM2fO0KlTJ1xdXVm3bh1Hjhypcz8jR46sXKB+x44dpKamAkYJa09PT3x9fTl58iSff/555We8vb1rbIcfOXIkK1asoLCwkIKCAj755BMuvfTSRv9uvr6+dOjQofJu4p133mHUqFFUVFSQnp7OmDFj+Pe//01eXh75+fkcOHCAgQMHct999xEfH8+ePXsafczq5I7ggug5sO9zOPQ99LrM7GiEENUkJCRwzTXXXDSC6LrrruPqq68mPj6emJiYer8Z33777dx4441ERUURExPDkCFDAGO1sdjYWAYMGPCrEta33HILEydOpGvXrqxbt67y9bi4OG644YbKfcyfP5/Y2Ng6m4Fq89Zbb3HbbbdRWFhIWFgYixcvpry8nLlz53LmzBm01tx99934+fnxj3/8g3Xr1uHs7ExERETlamvN4ZhlqGtSWgRP9YE+E+CaV62/fyHslJShtj9ShrqpXN2NvoLdn0Jx84djCSGEvZBEUFV0ApQWGslACCEchCSCqoIHQ8cwSHnf7EiEaFXsrQnZkTXl/5UkgqqUMu4KDv8AeUfNjkaIVsHd3Z2cnBxJBnZAa01OTk6jJ5nJqKHqombBukeNoaQj7zU7GiFMFxwcTEZGBlYrAS9syt3dneDg4EZ9RhJBdR1Cocdw2LYULr1HlrEUDs/V1ZWePXuaHYawIWkaqkn0HMjZD8daZgllIYQwkySCmkRMARd3WadACOEQJBHUxN0X+l1plKYuKzE7GiGEsClJBLWJToDzubD/S7MjEUIIm5JEUJuwMeDZSZqHhBBtniSC2ji7GENJ962FwtNmRyOEEDYjiaAu0XOgohR2LDc7EiGEsBlJBHXpMhA6DzTmFAghRBsliaA+0XPgWCJk7zc7EiGEsAlJBPUZOBOUk3QaCyHaLEkE9fHuDL0uh20fQEWF2dEIIYTVSSJoiOg5cDYDjmwwOxIhhLA6SQQN0e9KaOcjncZCiDZJEkFDuLY36g/tWgklBWZHI4QQViWJoKGiE6AkH/Z8ZnYkQghhVZIIGqr7MPDrLqOHhBBtjiSChnJygqg5cPA7OHvc7GiEEMJqJBE0RvQc0BWw/UOzIxFCCKuRRNAY/r0geAikLAFZyFsI0UZIImismATI2g2Z28yORAghrEISQWMNmAbObjKnQAjRZkgiaKz2HaDvRKOfoLzU7GiEEKLZJBE0RXQCFGZD2jdmRyKEEM0miaApeo8FD3+ZUyCEaBMkETSFs6tRnnrv58YC90IIYcckETRV9BwoL4adK8yORAghmsWmiUApNUEptVcplaaUWljD+92VUuuUUluVUqlKqUm2jMequsZAYD8ZPSSEsHs2SwRKKWfgRWAiEAEkKKUiqm12P7BMax0LzAH+a6t4rE4p464gfROcPmh2NEII0WS2vCMYAqRprQ9qrUuApcCUattowMfysy9gX0V8Bs4ClLF6mRBC2ClbJoIgIL3K8wzLa1U9BMxVSmUAa4A/1LQjpdQtSqlEpVRiVlaWLWJtGt8gCBtljB6SkhNCCDtly0Sganit+tUyAXhTax0MTALeUUr9Kiat9ata63itdXxgYKANQm2G6ATIOwJHfzI7EiGEaBJbJoIMIKTK82B+3fRzE7AMQGv9E+AOBNgwJuvrfzW4esqcAiGE3bJlItgChCuleiql3DA6g1dV2+YocDmAUqo/RiJoRW0/DeDmaSxjuXMFlJ43OxohhGg0myUCrXUZcCewFtiNMTpop1JqkVJqsmWze4CblVLbgCXADVrbYWN79BwoPgt715gdiRBCNJqLLXeutV6D0Qlc9bUHqvy8CxhuyxhaROil4BNszCmInG52NEII0Sgys9ganJwgapZRhO7cSbOjEUKIRpFEYC3Rc0CXw46PzI5ECCEaRRKBtQT2hW5xMnpICGF3JBFYU3QCnNgOJ3aYHYkQQjSYJAJripwOTi6QKoXohBD2QxKBNXn6Q/gVkLoMysvMjkYIIRpEEoG1Rc+B/JNw6DuzIxFCiAaRRGBtfa4Adz9IkU5jIYR9kERgbS7tjL6CPauh6KzZ0QghRL0kEdhCzLVQVgS7VpodiRBC1EsSgS0EDQL/3rKMpRDCLkgisIULy1ge2QC5R8yORggh6iSJwFaiZhv/TV1mbhxCCFEPSQS24tfdqEoqy1gKIVo5SQS2FD0HTh+AjESzIxFCiFpJIrCl/pPBpb0UohNCtGqSCGzJ3Qf6XwU7lkNZsdnRCCFEjSQR2Fr0HCjKg31rzY5ECCFqJInA1nqOBq8u0jwkhGi1JBHYmrMLRM2E/V9CQbbZ0QghxK9IImgJ0QlQUWb0FQghRCvjYnYADqHzAOgSZTQPXXJryx67ogLOpEP2PsjaY3nsM56Hj4epLxl3LUIIhyVXgJYSnQBr/wqn9kCnftbff3kZ5B6G7L2Wi/1e45G9D0oLf9nOMxAC+0HYKNi+DNw84KpnjbIYQgiHJImgpQycAV/ebyxjOfahpu+nrBhyDhgX+8pv+fsgZz+Ul/yynU8QBPaFQTdAQB/j4h/YFzw6/rLN1w/BhmfAJxhG/bnpMQkh7Jokgpbi1Ql6jzVqD132D3Byrnv7kkLLhX6v5Vu+5Zv+6UOgyy0bKegQalzgw8caF/uAvhAQbsxhqM/lD8LZTFj3T/DpBrHXNfe3FELYIUkELSl6Dnx0Ixz+AcJGG68VnTG+0WftufiCn5cOWGoUOblAx17QqT8MmGa54PcxLviu7Zsej1Iw+QXIPwGr/gBenY2EIkRrUHQGdAW072B2JG2e0g0oiKaU6gVkaK2LlVKjgSjgba11no3j+5X4+HidmGintXtKz8OTfcEvBDwDjIv+ucxf3nduZ2nG6Vvl0Q869AQXN9vFVXQW3pwEOQfhxs+gW6ztjiVEQ70xEUry4db10odlBUqpJK11fE3vNfSOYDkQr5TqDbwOrALeByZZJ0QH4doe4m+ELa+DsxuEjYHAKu33fj3qbzKyBXcfuPZDeH08vDcL5n9lNDkJYZaTu+Doj8bPRzdBj2HmxtPGNTQRVGity5RS04BntdYvKKW22jKwNmvcw8ajtfHpCnM/MpLBu9Phd1+Cp7/ZUQlHlfw2OLkaX562/E8SgY01dEJZqVIqAfgtsNrymqttQhKmCewL134AZzJgyWyjw1qIllZaZIyu638VxFxnrP2df8rsqNq0hiaCG4FhwKNa60NKqZ7Au7YLS5im+1CY/j9jDYXl86GivP7PCGFNe1bD+VyI+y0MvgkqSo07BGEzDUoEWutdWuu7tNZLlFIdAG+t9WM2jk2Ypf/VMPHfsPczWPNnWWFNtKzkt4wV/nqOMkbG9RwFiYvlS4kNNSgRKKW+U0r5KKU6AtuAxUqpp20bmjDVJbfA8D9B4uvww1NmRyMcxemDcGg9xM4DJ8vlafB8OJshpdxtqKFNQ75a67PANcBirfUgQAact3WXPwgDZ8G3j0CKlNEWLSD5HVBOF09u7DsJvLsancbCJhqaCFyUUl2BWfzSWSzaOicnmPKicWu+6k5I+8bsiERbVl4KKe8ZxRB9uv3yurMLDLoRDnxjlFcRVtfQRLAIWAsc0FpvUUqFAfttF5ZoNVzcYPa7ENgfls2D4ylmRyTaqv1fQv5Jo5O4urh5xgz7xDdaPi4H0NDO4g+11lFa69stzw9qrafbNjTRarj7wHUfGlP9359lVDkVwtqS3jJW8wsf/+v3fLpCv6tg67vGDH1hVQ3tLA5WSn2ilDqllDqplFqulApuwOcmKKX2KqXSlFILa9lmllJql1Jqp1Lq/cb+AqKF+HSFucuN6qfvzoDC02ZHJNqSM8cg7SuIubb29TEGzzfW/97xccvG5gAa2jS0GKOsRDcgCPjU8lqtlFLOwIvARCACSFBKRVTbJhz4KzBcaz0A+FOjohctK7AvJCyFvKPw/mz5ZiasJ+V9o8Bc3PW1bxM6wqiuK53GVtfQRBCotV6stS6zPN4EAuv5zBAgzdKMVAIsBaZU2+Zm4EWtdS6A1lqmD7Z2PYbB9NcgY4tMOBPWUVEBW9+GniOhY1jt2yll3BUcT4ZjSS0XnwNoaCLIVkrNVUo5Wx5zgZx6PhMEpFd5nmF5rao+QB+l1Eal1Cal1ISadqSUukUplaiUSszKympgyMJmIqbAxMeNGaCf/0UmnInmOfSdcZdZUydxddGzwdUTtkinsTU1NBH8DmPo6AkgE5iBUXaiLjXVja1+xXABwoHRQALwP6WU368+pPWrWut4rXV8YGB9NyKiRVxyK/zmLuM2fcMzZkcj7FnSW8ZAhH5X1b+tuy9EzYIdH0k/lRU1dNTQUa31ZK11oNa6k9Z6KsbksrpkACFVngcDx2vYZqXWulRrfQjYi5EYhD0Y+zBEzoBvHoZtS82ORtijgmzY85mxprere8M+M/gmKCsy+hWEVTT0jqAmC+p5fwsQrpTqqZRyA+ZgdDhXtQIYA6CUCsBoKjrYjJhES3Jygqn/Ndp2V94BB741OyJhb7YtNYrKxdbRSVxdl4EQMtQof1JRYbvYHEhzEkGdSwZprcuAOzEmou0GlmmtdyqlFimlJls2WwvkKKV2AeuAP2ut6+t7EK2JSzvLhLN+8ME8yEw1OyJhL7Q2CswFD4bOEfVvX9Xg+UZdooPrbBObg2lOIqi3h1BrvUZr3Udr3Utr/ajltQe01qssP2ut9QKtdYTWeqDWWtoX7JG7rzHhzN0X3psBuUfMjkjYg/TNkL2vYZ3E1UVMBo8AY7U/0Wx1JgKl1Dml1NkaHucw5hQIYfDpZqxwVlZkJAPpyBP1SXoL3LxgwLTGf9alnVF2Yt/nkJde//aiTnUmAq21t9bap4aHt9a6octcCkfRqT/MWWKUoFiSIBPORO2KzsDOT2DgDGjn1bR9xN9oNC8lvWnV0BxRc5qGhPi10OFwzavGbf/HN8uEM1Gz7R9C2XnjW31T+XWHPhOMfoayEuvF5oAkEQjrGzANJvwf7P4UvlgoE87EryW/DZ0joVtc8/YzeD4UZMHu6gMSRWNIIhC2MfR2GHYn/PwqbHzO7GhEa3I8BTK3GZ3Eqs7Bh/XrdRl0CJVO42aSRCBsZ9wjEDkdvn4QUpeZHY1oLZLfBhd3iJrZ/H05OUH8TXD0Rzi5s/n7c1CSCITtODnB1Jcg9FJY8Xs4+J3ZEQmzlRQa/QMRU4yyEtYQOxec28ldQTNIIhC2dWHCWUA4LJ0LJ7abHZEw064VUHy2eZ3E1Xl0NO48Uz+AorPW268DkUQgbK+9H1z3kbHS2bszjEqTwjElvw0de0GP4dbd7+D5UJJvJAPRaJIIRMvwDTJWOCs9LyucOaqsfXD0J+NuoLmdxNUFxUHXGKMaroxSazRJBKLldOoPCe9D7iFYei2UFpkdkWhJyW8ZC9DHXGv9fV9YtCZrDxzZaP39t3EOkwiyzhXz1o+HzQ5DhI6Aaa8Y3wxlwpnjKCuBbUug70Tw6mSbY0ROB3c/WcqyCRwmEby/+SgPrtrJ0p+lfdp0kdfAFf8yJgGt/ZvcyjuCvZ9BYU7TCsw1lJuHMYJo96dw7oTtjtMGOUwiuGNMLy4ND+AfK3ew5bC0T5tu2B3GhLPNL8NPL5odjbC15LfBJ9iYAGZL8b+DijLjeKLBHCYRuDg78Z+EOII7eHDbO0kcy5OCaKYb9wj0nwxf/QP2rTU7GmEruUfgwDrj27qTs22P5d/LSDaJi6G8zLbHakMcJhEA+Hq48tq8eErKKrj5rUQKS+QPxVROTjDtZWPFqY9uglO7zY5I2MLWd43/xl7XMscbPB/OHTdKVIsGcahEANC7kxfPXxvL7hNn+fOHqWhpnzaXm6dRutrNE96fDQWyQF2bUlFuJILelxvVQltC+BVGM5R0GjeYwyUCgDF9O/HXif34bHsm//k2zexwhG8QzHkf8k/CB3OlpHBbkva18e3cmjOJ6+PsAvE3GCVNsve33HHtmEMmAoCbLw3jmtggnvpqH1/skBEGpgseBFNeNIqHfXa3jCRqK5LfBs9A6DOxZY8bOw+cXCHxjZY9rp1y2ESglOJf1wwkOsSPBctS2HNCapSYbuAMGPkXoylBRhLZv3MnYO/nEJ0ALm4te2zvzsa6xlvfg5KClj22HXLYRADg7urMq9cPwqudC/PfSuR0gTRJmG70X2UkUVuR8j7o8pZtFqpq8HwoPgM7lptzfDvi0IkAoLOPO6/Oi+fUuWJ+/14SpeUVZofk2GQkUdugtdEs1GO4UXnWDN2HQacI+Pk1aWqsh8MnAoCYED8enz6QTQdPs+jTXWaHI2Qkkf07/INRU8qsuwGw1B+6CU6kwrEk8+KwA5IILKbFBnPrqDDe2XSEdzcdMTscISOJ7Fvy29DO11iAxkxRs8HNS4aS1kMSQRV/uaIfY/oG8tCqnWw6KN9CTScjiexT4WnYtQqiZoFre3NjaecN0XNgx8dyZ1kHSQRVODspnkuIpYe/B7e/m0T66UKzQxIyksj+pC6D8mIYZMMCc40Rf5MRT8q7ZkfSakkiqMbH3ShDUV6hufntRAqKpQyF6WQkkf3Q2lh3oFus0eHfGnSOMDqtt7wOFTIYpCaSCGoQFujFf66NY9/JcyxYlkJFhTRJmEpGEtmPY0lwape5ncQ1GXwT5B2BA9+YHUmrJImgFiP7BPL3KyNYu/Mkz30j09RNJyOJ7EPyW+DqAZEzzI7kYv2uBs9O0mlcC0kEdfjd8FBmDgrmuW/2s2Z7ptnhCBlJ1LoVn4Pty2HANeDuY3Y0F3NxM/os9q01ymKLi0giqINSin9OiySuux/3LNvGzuNnzA5JyEii1mvHx1Ba0Ho6iasbdIMxtyBpsdmRtDqSCOrRzsWZl68fhJ+HK7e8nUR2frHZIQkZSdQ6Jb8Fgf0geLDZkdTMNxj6TjLmOJTJv+OqJBE0QCdvd169Pp7s/GJufzeJkjIZeWA6GUnUupzYYXQUx80zvnW3VoNvMtZO3rXS7EhaFUkEDTQw2JcnZkaz5XAuD67aIQvamO3CSKLOkTKSqDXY+g44u0HUHLMjqVvP0dCxl3QaVyOJoBEmR3fjjjG9WPJzOu9IGQrzuXlCwlJw85CRRGYqLYJtS6HfVeDpb3Y0dXNyMu4K0jdDZqrZ0bQakgga6Z5xfRnbvxMPf7qLH9OyzQ5H+AYZw0plJJF5dn8KRXmtt5O4uphrwaU9JL5udiSthk0TgVJqglJqr1IqTSm1sI7tZiiltFIq3pbxWIOTk+KZ2TH0CvTk9+8ncyRHFr0wnYwkMlfyW+DXA0JHmh1Jw7TvAAOnG6UwimQkINgwESilnIEXgYlABJCglIqoYTtv4C5gs61isTZvSxkKgPlvJXKuqNTkiISMJDJJzgGj5HTcPKPZxV4Mng+lhUaTlrDpHcEQIE1rfVBrXVtSnfcAAB0FSURBVAIsBWqqSfsI8G+gyIaxWF0Pf0/+e20cB7MLuPsDKUPRKshIopaX/DYoJ4i5zuxIGqdbLAQNMjqN5Q7SpokgCEiv8jzD8lolpVQsEKK1Xm3DOGzmN70DeOCqCL7efYqnvtprdjhCRhK1rPJSYznK8CvAp6vZ0TTe4PmQvc+4o3FwtkwENQ0mrky9Sikn4Bngnnp3pNQtSqlEpVRiVlaWFUNsvnnDepAwJIQX1x3g023HzQ5HyEiilrNvLRScsp9O4uoGTDP6C2QoqU0TQQYQUuV5MFD1SukNRALfKaUOA0OBVTV1GGutX9Vax2ut4wMDA20YcuMppXh4ciSDQzvw54+2sT1DOp9MJyOJWkbyW+DdFXqPMzuSpnFtD7FzYfdqOOvYtcRsmQi2AOFKqZ5KKTdgDrDqwpta6zNa6wCtdajWOhTYBEzWWifaMCabcHNx4qW5g/D3bMct7yRy6pxddXe0TTKSyLbOZEDa10bfgLOL2dE0XfzvQJcbSc2B2SwRaK3LgDuBtcBuYJnWeqdSapFSarKtjmuWAK92vDpvEHmFpdz2ThLFZeVmhyRkJJHtbH0PdIXxjdqedQyD3mMh6U2jz8NB2XS8l9Z6jda6j9a6l9b6UctrD2itV9Ww7Wh7vBuoakA3X56eFU3y0Tz+/omUoWgVWvtIovIyOPIjfP0wvDwC/q87/PgCVLTiLxIV5UZJiZ6joGNPs6NpvsHz4Vwm7F1jdiSmsaOBv/Zh4sCu3HV5OB8lZfDGxsNmhyNa40iicyeMu5Rlv4UnwmDxRNj4HLTzgaA4+PJ+eH0cnNxldqQ1O/gdnEm3307i6sLHg2+IQ3ca23HjXuv1p8vD2XviLI9+tovwTl6M7NO6OrgdzoWRRK+NMUYS3byuZWvilJfBsUTY/xXs/xJOWGrceHWB/lcbF6Kw0eDua/Rl7FgOn/8FXhkJI++FEQuMhVVai+S3oH1Ho7ZQW+DkDPE3wjeLIGsvBPY1O6IWp+yt+SI+Pl4nJrb+FqSC4jKmv/Qjx/POs/LOEfQM8DQ7JJGRBG9Ogm5xMG+lbS+u+aeMztT9X8GBb41aPMoZQi6B8LHGxb9zZO0lmwuy4YuFsP1D6DQAprxgTIAyW34WPN0fhtwCE/5ldjTWc+H3GnwTTHzc7GhsQimVpLWusYyPJAIbSj9dyJQXN9LBw5VP7hiOj7ur2SGJ7R/B8puMTs7J/7Fe7fyKcqMe//4vjYt/ZorxuldnY3hl+FgIGwPt/Rq3372fw+oFkH8Cht1p9Hm4eVgn5qbY+LzR3/L7TdCpv3lx2MLy+UY/0oLd0M7L7GisThKBiTYdzGHu/zZzaXgA//vtYJydWvGiHY7i23/C+idg/KPwmzubvp/8LDjwjXHxP/AtnM81yi0ED4Hwccaj88Dm1+ApOgNfPWCMbOkYBpNfgNARzdtnU2gN/xlsTMKa/1XLH9/Wjm6CN66Aq541moraGEkEJntv8xH+/skObh0Vxl8ntrFvUfaoogI+/C3sWW30HfS5ooGfK4djyZD2lfGt//hWQINnJ2MIYvg46DXGuFDawqH1sOoPkHvYGP8+9uGWXST+yE+weIIxP8PGw0ZLyip4/Is9FJaUsXBCf3w9WuBuWmtj5BbAbRta90prTVBXIpDO4hZw3SU92J15lle+P0i/Lt5Miw02OyTHdmEk0RsTjJFE87+qvZmjIOeXb/1p38D505Zv/YNhzN+NJp8u0S1TebPnSLj9J1j3KGz6L+z7Eq5+1khALSH5LXDzNkoz2NCpc0Xc/m4ySUdycXZSfLP7FI9NH8hl/Trb9LgoZQwlXf0nSP8Zul9i2+O1InJH0EJKyyu4/vXNJB/NY9mtw4gJaWRbsbC+M8eMkUQu7r+MJKqoML7pp1lG+BxLBjR4BBgX3N5joddl4NHR3NgzEmHlHZC1x1gecsL/2Tam83nwVD+InmMkHxvZlp7Hre8kceZ8KU/MjCLU35N7P9zGnhPnmDkomPuvisC3vQ3vDorzjU7jPhNg+mu2O44JpGmolThdUMLk/2zg5NkixkV0ZlZ8CJeGB0q/gZkujCTqHAn+vYyRPoU5gILgeEtH7zjoGtP66u2XFcP6J2HD00Zz1KQnIGKqbZo0fn4N1txrJMygOOvvH1ielMFfP9lOoFc7XpsXT0Q3o9mruKycF75J46XvD9DJux2PTY9ilC2HZK/5CyQthrt3gVfbGfotiaAVOZZ3ntd/OMQnWzPILSylq687MwYFM3NQCN39TRwN4sgujCTy8De+8fceZ3zrb+3r715wYodxd5CZYoztv/Ip8O5i3WO8fCmg4dYfrJ5oysor+NeaPbyx8RDDwvx58bo4Onr+emjvtvQ87vlwG2mn8kkYEsLfJvXH2xYj8bL2wotD4PIH4dIF1t+/SSQRtEIlZRV8s/skHySms35fFhUahoZ1ZPbgECYM6Ep7N2ezQ3Qs506CZ2Dr+9bfUOVl8NN/4Lv/A5d2cMW/jIJw1rhoH98Kr46GSU/CkJubv78qcgtKuOP9ZH48kMONw0P526T+uDrX/v+gqLScZ77ex2vrD9LVtz2PT49iRHiAVWMC4M2rIPcI/DHFmHDWBkgiaOUyz5xneVIGyxIzOHq6EO92LkyO6cas+BCign1RbWz0grCh7DRjZNHRH415C1c/Bx16NG+fq+82FqC5Z49VR0TtzjzLzW8ncupcMY9OjWRmfEj9H7JIOpLLnz/cxsHsAuYO7c5fJ/bHs50Vx77sXGGMLEv4APpOsN5+TSSJwE5UVGg2HzrNh4nprNmRSVFpBf26eDMzPoRpsUE13i4L8SsVFZD4Onz9kDEkcuyDMPjmpt3tlBQYncR9J8E1r1gtxM9SM7n3w234tHfhlevjmzR4oqi0nCfX7uX1jYcI8mvPEzOiGdbLSs155aXwTCR0GQhzP7LOPk0micAOnS0q5dNtx1mWmMG29DxcnRXjIjozMz6EkdLBLBoiL90YCpn2NYQMNSaiBfZp3D62vgcrfw83rIHQ4c0OqaJC89RXe3lx3QHiuvvx8txBdPJxb9Y+txw+zZ8/3MbhnEJu+E0of5nQFw83K9wdrPs/+P5xuCvZmMhn5yQR2Lk9J87yYWIGn2w9xumCErr4WDqY44Pp4S81jEQdtIZtS426RaXnYfR98Ju7wLmBnayvXwGF2XBnYrP7G84WlfKnpSl8u+cUcwaH8PCUAbRzsU77e2FJGf/+Yi9v/niYHv4ePDEjmiE9mzmc9uxx465g2B0w/hGrxGkmSQRtRG0dzLPiQ5gYKR3Mog75p4zhn7tWQpcomPIf6Bpd92dO7YH/XgLjFsHwPzbr8Aey8rn57USO5hTy4NURzB3awyZ9X5sO5vDnj7aRkXue3w3vyb3j+zbv38UH1xuL2y/YbSxtacckEbRBNXUwXx3TjdnSwSzqsmsVfHaPMVdixJ+MFdxca2maWft32PyycRH06tTkQ3675yR/XJKCm4sT/70ujkvCbDsst6C4jMc+38M7m44QFuDJEzOjGdSjiZ3cB7+HtyfDwFlG4vTwr/LoaDza+dhFOQpJBG1YTR3MfTt7MzM+mGmxQfh7tTM7RNHaFJ42Fr9JeQ8C+hhVWKuXUygrNmbY9hgOs99p0mG01vz3uwM8+eVeBnTz4ZXr4wnya7lv1RvTsvnLR6lknjnPzZeGcfe4Pri7NvLuQGsjERzeaKxtXBMnlxoShL+xZkNNr3t0BDevFk8ekggcRE0dzGP7d2bWYOlgFjVI+xo+/ZOxEP0lt8Jl//il/PKOj+GjG+G65UY9pUYqKC7jzx9tY832E0yO7sbj06NMabo8V1TKv9bsYcnPR+ndyYsnZ0Y3rbyL1kYV2MIco8psYU4Nj9OWh+X5+dPGus41cXarIUFUTx7VEkkzy49LInBAe0+cY1li+kUdzNMHBTErPkQ6mMUvis8Z6yVveQ38uhvzDnpdBm9PhZw0+OO2Rk+oSj9dyM1vJ7Lv5DkWTuzHzZeGmd5UuX5fFvctT+Xk2SJuG9WLP44Nt1pHda0qKowFiQpPG0mhxuRRLamczwVquSa7uBtlROLmNSkcSQQO7EIH87LEdL63dDBf0tOYwfybXgF08HS1/T8I0fod+dGYiJaTBgOugZ0fG4vgjF7YqN1sTMvmjveTqajQvHBtnG1rAjXS2aJS/rl6F8sSM+jb2ZsnZ0YzMNjX7LAuVlFuFPi7cEdRPXH0nwwhQ5q0a0kEAjA6mD9OPsayxHSO5BRWvu7p5kwHTzc6errRwaPqf13x86j2uqcrHTzc6iwDIOxU6Xlj3PzG540mjbt3gG/DSqZrrXlj42H+tWY3YQGevDYvntBWujzruj2nWPhxKtn5Jdwxuhd3XhaOm0vb/3uWRCAuUlGhSTySy/5T58gtKOF0QSm5hSWcLighr7CE04Ul5BaUkl9cVus+vN1d6OjpZiQKD1cjkXi41ZBQjPf82rviIsnDPmSmGmPoG1haoai0nL9/soPlyRmMj+jM07Nj8LJmuQcbOFNYysOrd/Jx8jH6d/XhqZnRldVO2ypJBKJJisvKySss5XRBiZEwCkvILSy1JI+SyuSRa0kcpwtKOF9ay8gKwLe9a2VyqJoshvTsyMg+gQ59l1Feodl8MIeUjDxigv0YFNrBLprsMs+c57Z3ktiWcYY/jQ3nrsvCcbKjQQlf7TrJ3z7ZTm5BCXddHs7to3u12b9DSQSixRSVlv+SIApKLXcXVe82Lk4kOfkllJRX0MHDlUkDuzI1NohB3TvY1cWkqbTW7Dx+lhVbj/Fp6nFOni2ufM/d1YkhPf0Z0dufEb0D6dfFu9Wdk6Qjp7n1nWTOl5TxzOwYxg+wcunrFpJbUMJDn+5kZcpxIoN8eGpmDH27eJsdltVJIhCtVklZBT/sz2JFynG+2nWCotIKgvzaMyWmG1Njg+jTue39gzyaU8jKlGOsSDnGgawCXJ0Vo/t2YmpMEJeEdWRbeh4/7M9mY1o2+0/lA+Dv6cbw3gGM6B3AiPAAurXgePyaLPn5KA+s3EGQX3temxdPeBv4//TFjkz+/skOoxTG2D7cOjKsTTVnSiIQdqGguIwvd51gxdbjbEjLprxC07+rD1NjunF1dDfTL37NkZNfzGfbM1mx9RjJR/MAGNKzI1Njgpg0sAt+HjVXlj1xpogNaUZS2JCWTdY5464hLMCTEeEBDO8dwLBe/vjYYoGWGpSUVbBo9U7e3XSUkX0CeWFObMssLN9CcvKLeWDVTj5LzSQ62JcnZ0a3iSQHkgiEHco6V8xnqcdZkXKclPQ8lIIhoR2ZGhvEpMiudnHxKSwp46tdJ1mx9Rjr9xuJrV8Xb6bEBDE5plujZ9lqrdl3Mp8f9mexIS2bzQdPc760HGcnRXSwr+VuIZCYED+bjILJOlfMHe8l8/Ph09w6Koy/XNGvzU5SXJ16nH+s2EFBSTn3jOvD/EvD7P53lUQg7Nrh7AJWbTvOipRjHMwqwM3ZidF9A5kaG8Rl/To1vmyADZWWV7BhfzYrUo7x5c6TnC8tJ8ivPZNjujE1Jsiqbc8lZRUkH81lY1o2P+zPJjUjjwoNHm7ODA3zZ3jvAC4NDyC8k1ezJ3RtzzjDLe8kkltYwuPTo5gSE2Sl36L1yjpXzP0rtrN250mCO7RndnwIM+KD6eprn3emkghEm6C1Zsexs6xIOcan245z6lwx3u1cuCKyC1NjghjWy9+Ub21aa5KP5rEy5RifpWaSU1CC34XO75gg4nu0TOf3mcJSfjqYw4a0LDam5XAouwCATt7tKvsWhvcOoHMj6/+v2HqM+5anEuDVjleuH0RkUCubhGVDWmu+3HWSt386zMa0HJwUjOnbidmDQxjTr5NdjTCSRCDanPIKzU8HcliRcowvdpwgv7iMTt7tuDra+OYdGeRj87IGaafyWZlyjJUpxzl6upB2Lk6MjejM1JggRvUJNH2SUkZuIRv2Z1f2MeQWlgLQp7NX5d3CkJ7+tY75Lyuv4PEv9vDaD4cY0rMjL10X59BFDI/kFLAsMZ0PEzM4da6YQO92zBwUzKz4kFY7ea4qSQSiTSsqLefbPadYsfUY3+3NoqS8grBAT6bGBDElpptVayudPFvEp5Zmqh3HzuKkYHjvAKbEBHHFgM54t1CnbWNVVGh2ZZ6tTAo/HzpNcVkFLk6KuO4djBFJ4QFEB/vi4uxEXmEJf1iylR/2ZzNvWA/+cVWEXX37taWy8grW7c3igy1H+XbPKSo0DAvzZ86QEK4Y0KVVNVVWJYlAOIwzhaWs2WGMztl86DQAsd39mBLdjauiuxHQhG+0Z4tK+WL7CVZuO8aPB3LQGqKDfZkSE8RV0V3p5N28pRbNUFRaTuLhXDakZbMhLYudx8+iNXi3c2FoL3/2nTxHZl4Rj0wdwOzB3c0Ot9U6caaI5ckZLN1ylPTT5/Ft78q02CDmDAmhX5fWNVNZEoFwSMfzzlu+vR9nd+ZZnJ0UI3oHMDW2G+MjuuBZRxmE4rJy1u3JYmXKMb7Zc4qSsgpC/T2YYrnLCAv0asHfxPZOF5Tw44FsNuw3Op6VgufmxDZ9QRcHU1Gh+elgDku3pLN2xwlKyiuIDvEjYXAIV0V3axUlNyQRCIe37+Q5Vmw12vOP5Z2nvasz4yI6MyWmW2V5iwuL/KxMOcaa7ZmcLSojwMuNq6KMyW3RDrLy24VrgiP8rraQW1DCJ1uPsXTLUfadzMfDzZmro7oxe0gIsSF+pp1XSQRCWFRUaJKO5laO8MktLKWDhysjwgNJPHyazDNFeLo5c8WALkyJDWJ4L/82NbtUtBytNVvT8/jg53Q+TT1OYUk5fTt7M3twCNNig+jgWfMkQluRRCBEDaqWt9iYlk1siB9TYoMY17+zKatpibYrv7iMT7cdZ+mWdLal5+Hm7MQVkV1IGBzC0DD/FhlebFoiUEpNAJ4DnIH/aa0fq/b+AmA+UAZkAb/TWh+pa5+SCIQQ9mx35lk+2GKsHnjmfCndO3owe3AIMwYFN3qOR2OYkgiUUs7APmAckAFsARK01ruqbDMG2Ky1LlRK3Q6M1lrPrmu/kgiEEG1BUWk5a3eeYOnP6fx0MAdnJ8WYvp2YMziE0X0Drd4kWVcisGVX9hAgTWt90BLEUmAKUJkItNbrqmy/CZhrw3iEEKLVcHd1toxCC+JwdgEfJKbzUVIGX+8+SSfvdsyMD2Z2fHe6+zdv0fqGsGUiCALSqzzPAC6pY/ubgM9tGI8QQrRKoQGe3DehHwvG9WHdnlN8sCWdl747wIvrDjC8tz+zB3dnfERnm01Ws2UiqKn3o8Z2KKXUXCAeGFXL+7cAtwB07y6TW4QQbZOrsxPjB3Rh/IAunDhTxIeJ6XyQmM5dS7bi5+HKw5MH2KTgny0TQQYQUuV5MHC8+kZKqbHA34FRWuvi6u8DaK1fBV4Fo4/A+qEKIUTr0sXXnT9cHs4dY3rz44Eclm45SnAH21Q+tWUi2AKEK6V6AseAOcC1VTdQSsUCrwATtNanbBiLEELYJScnxYhwoxaUzY5hqx1rrcuAO4G1wG5gmdZ6p1JqkVJqsmWzJwAv4EOlVIpSapWt4hFCCFEzmxbA0FqvAdZUe+2BKj+PteXxhRBC1E/mzgshhIOTRCCEEA5OEoEQQjg4SQRCCOHgJBEIIYSDk0QghBAOzu7WI1BKZQF1lqq2AwFAttlBtCJyPn4h5+Jicj4u1pzz0UNrHVjTG3aXCNoCpVRibeVgHZGcj1/IubiYnI+L2ep8SNOQEEI4OEkEQgjh4CQRmONVswNoZeR8/ELOxcXkfFzMJudD+giEEMLByR2BEEI4OEkEQgjh4CQR2JBSaoJSaq9SKk0ptbCG9xcopXYppVKVUt8opXqYEWdLqO9cVNluhlJKK6Xa9JDBhpwPpdQsy9/HTqXU+y0dY0tqwL+V7kqpdUqprZZ/L5PMiLMlKKXeUEqdUkrtqOV9pZR63nKuUpVScc0+qNZaHjZ4AM7AASAMcAO2ARHVthkDeFh+vh34wOy4zToXlu28gfXAJiDe7LhN/tsIB7YCHSzPO5kdt8nn41XgdsvPEcBhs+O24fkYCcQBO2p5fxLwOca68EOBzc09ptwR2M4QIE1rfVBrXQIsBaZU3UBrvU5rXWh5ugljXee2qN5zYfEI8G+gqCWDM0FDzsfNwIta61wA3baXcm3I+dCAj+VnX2pY/7yt0FqvB07XsckU4G1t2AT4KaW6NueYkghsJwhIr/I8w/JabW7CyPJtUb3nwrJ+dYjWenVLBmaShvxt9AH6KKU2KqU2KaUmtFh0La8h5+MhYK5SKgNj1cM/tExorVJjry31sulSlQ5O1fBajWN1lVJzgXhglE0jMk+d50Ip5QQ8A9zQUgGZrCF/Gy4YzUOjMe4Uf1BKRWqt82wcmxkacj4SgDe11k8ppYYB71jOR4Xtw2t1GnxtaSi5I7CdDCCkyvNgaridVUqNBf4OTNZaF7dQbC2tvnPhDUQC3ymlDmO0e65qwx3GDfnbyABWaq1LtdaHgL0YiaEtasj5uAlYBqC1/glwxyjA5ogadG1pDEkEtrMFCFdK9VRKuQFzgFVVN7A0h7yCkQTachtwnedCa31Gax2gtQ7VWodi9JdM1lonmhOuzdX7twGswBhMgFIqAKOp6GCLRtlyGnI+jgKXAyil+mMkgqwWjbL1WAXMs4weGgqc0VpnNmeH0jRkI1rrMqXUncBajFERb2itdyqlFgGJWutVwBOAF/ChUgrgqNZ6smlB20gDz4XDaOD5WAuMV0rtAsqBP2utc8yL2nYaeD7uAV5TSt2N0Qxyg7YMoWlrlFJLMJoEAyx9Ig8CrgBa65cx+kgmAWlAIXBjs4/ZRs+lEEKIBpKmISGEcHCSCIQQwsFJIhBCCAcniUAIIRycJAIhhHBwkghEm6SUKldKpVgqd26zVHqt8+9dKRWqlLrWBrH8SSnl0Yjtb1NKzbN2HELURoaPijZJKZWvtfay/NwJeB/YqLV+sI7PjAbu1VpfZeVYDmNUU8225n6FsBa5IxBtnmXW9i3AnZbZmKFKqR+UUsmWx28smz4GXGq5k7i7tu2UUl2VUust2+1QSl1qeX28Uuony7YfKqW8lFJ3Ad2AdUqpddVjU0o9pn5Zk+JJy2sPKaXuVUp1sxzjwqNcKdVDKRWolFqulNpieQxvifMo2i65IxBtUtU7giqv5QL9gHNAhda6SCkVDizRWsdXvyOwNOfUtN09gLvW+lGllDPgAbQDPgYmaq0LlFL3Ae201otquyNQSnUEfgL6aa21UspPa52nlHoIyNdaP1ll2zuAUVrrWcpYpOa/WusNSqnuwFqtdX8rn0LhQKTEhHAkF6o2ugL/UUrFYJRv6FPL9rVttwV4QynlCqzQWqcopUZhLJiy0VIuxA3jIl+XsxhrL/xPKfUZUGMJbss3/vnApZaXxgIRluMA+CilvLXW5+o5nhA1kkQgHIJSKgzjYn4Ko3bLSSAao3m0toVw7q5pO631eqXUSOBKjHLITwC5wFda64SGxmSpsTMEo5jaHOBO4LJqcXcFXscowpdvedkJGKa1Pt/QYwlRF+kjEG2eUioQeBn4j6VQmS+Qaallfz1GoTMwmoy8q3y0xu2Usbb0Ka31axgX6TiMiqnDlVK9Ldt4KKX61LLfC3F5Ab5a6zXAn4CYau+7YpRevk9rva/KW19iJI0L2130OSEaSxKBaKvaXxg+CnyNcfF82PLef4HfKqU2YTT3FFheTwXKLMNN765ju9FAilJqKzAdeE5rnYWxsM4SpVQqRmLoZ9n+VeDzGjqLvYHVlu2/x7gDqeo3wGDg4Sodxt2Au4B4SwfzLuC2Jp4jIQDpLBZCCIcndwRCCOHgJBEIIYSDk0QghBAOThKBEEI4OEkEQgjh4CQRCCGEg5NEIIQQDu7/AZcW9Z2iBLliAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.1, 1.1, 0.1)\n",
    "plt.plot(x, train_loss, label='Training loss')\n",
    "plt.plot(x, val_loss, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Dataset size\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Small_MLP_Classification_GroupBy_FFill_MinMax.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
