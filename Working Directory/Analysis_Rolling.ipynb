{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width: 98% !important }<style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 98% !important }<style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_file = \"../Data/pin.csv\"\n",
    "\n",
    "pin = read_pin(pin_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All beacons: ['0117C55D14E4']\n",
      "Selecting 0117C55D14E4\n"
     ]
    }
   ],
   "source": [
    "filename = \"../Data/rssi4.csv\"\n",
    "B1 = \"0117C55D14E4\"\n",
    "\n",
    "data = read_data(filename, B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[scanners] = minMaxScaling(data[scanners])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C400A2E19293</th>\n",
       "      <th>CD4533FFC0E1</th>\n",
       "      <th>D2B6503554D7</th>\n",
       "      <th>DB8B36A69C56</th>\n",
       "      <th>DD697EA75B68</th>\n",
       "      <th>DF231643E227</th>\n",
       "      <th>E13B805C6CB0</th>\n",
       "      <th>E43355CA8B96</th>\n",
       "      <th>E6D9D20DD197</th>\n",
       "      <th>E8FD0B453DC4</th>\n",
       "      <th>E96AF2C858BA</th>\n",
       "      <th>EC72840D9AD3</th>\n",
       "      <th>F1307ECB3B90</th>\n",
       "      <th>F1EDAF28E08A</th>\n",
       "      <th>F69A86823B96</th>\n",
       "      <th>FB2EE01C18CE</th>\n",
       "      <th>FDAE5980F28C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1264.000000</td>\n",
       "      <td>2194.000000</td>\n",
       "      <td>1506.000000</td>\n",
       "      <td>1643.000000</td>\n",
       "      <td>1736.000000</td>\n",
       "      <td>2635.000000</td>\n",
       "      <td>2792.000000</td>\n",
       "      <td>1299.000000</td>\n",
       "      <td>4569.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>2615.000000</td>\n",
       "      <td>1806.000000</td>\n",
       "      <td>1884.000000</td>\n",
       "      <td>993.000000</td>\n",
       "      <td>2191.000000</td>\n",
       "      <td>1924.000000</td>\n",
       "      <td>1472.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.324855</td>\n",
       "      <td>0.452385</td>\n",
       "      <td>0.389232</td>\n",
       "      <td>0.346166</td>\n",
       "      <td>0.452851</td>\n",
       "      <td>0.479266</td>\n",
       "      <td>0.464518</td>\n",
       "      <td>0.276341</td>\n",
       "      <td>0.440151</td>\n",
       "      <td>0.195326</td>\n",
       "      <td>0.439879</td>\n",
       "      <td>0.479642</td>\n",
       "      <td>0.511748</td>\n",
       "      <td>0.174555</td>\n",
       "      <td>0.458086</td>\n",
       "      <td>0.317897</td>\n",
       "      <td>0.295652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.130288</td>\n",
       "      <td>0.110810</td>\n",
       "      <td>0.111287</td>\n",
       "      <td>0.119266</td>\n",
       "      <td>0.114845</td>\n",
       "      <td>0.126259</td>\n",
       "      <td>0.139811</td>\n",
       "      <td>0.100747</td>\n",
       "      <td>0.188901</td>\n",
       "      <td>0.098163</td>\n",
       "      <td>0.159721</td>\n",
       "      <td>0.146675</td>\n",
       "      <td>0.138114</td>\n",
       "      <td>0.069845</td>\n",
       "      <td>0.142245</td>\n",
       "      <td>0.129125</td>\n",
       "      <td>0.103917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C400A2E19293  CD4533FFC0E1  D2B6503554D7  DB8B36A69C56  DD697EA75B68  \\\n",
       "count   1264.000000   2194.000000   1506.000000   1643.000000   1736.000000   \n",
       "mean       0.324855      0.452385      0.389232      0.346166      0.452851   \n",
       "std        0.130288      0.110810      0.111287      0.119266      0.114845   \n",
       "min        0.050000      0.066667      0.066667      0.033333      0.066667   \n",
       "25%        0.216667      0.383333      0.300000      0.266667      0.383333   \n",
       "50%        0.316667      0.466667      0.400000      0.333333      0.466667   \n",
       "75%        0.416667      0.566667      0.483333      0.433333      0.550000   \n",
       "max        0.600000      0.616667      0.600000      0.583333      0.683333   \n",
       "\n",
       "       DF231643E227  E13B805C6CB0  E43355CA8B96  E6D9D20DD197  E8FD0B453DC4  \\\n",
       "count   2635.000000   2792.000000   1299.000000   4569.000000    649.000000   \n",
       "mean       0.479266      0.464518      0.276341      0.440151      0.195326   \n",
       "std        0.126259      0.139811      0.100747      0.188901      0.098163   \n",
       "min        0.033333      0.050000      0.050000      0.066667      0.033333   \n",
       "25%        0.400000      0.366667      0.216667      0.300000      0.116667   \n",
       "50%        0.483333      0.483333      0.266667      0.416667      0.183333   \n",
       "75%        0.566667      0.583333      0.350000      0.533333      0.283333   \n",
       "max        0.750000      0.783333      0.483333      0.850000      0.433333   \n",
       "\n",
       "       E96AF2C858BA  EC72840D9AD3  F1307ECB3B90  F1EDAF28E08A  F69A86823B96  \\\n",
       "count   2615.000000   1806.000000   1884.000000    993.000000   2191.000000   \n",
       "mean       0.439879      0.479642      0.511748      0.174555      0.458086   \n",
       "std        0.159721      0.146675      0.138114      0.069845      0.142245   \n",
       "min        0.033333      0.066667      0.100000      0.033333      0.050000   \n",
       "25%        0.316667      0.366667      0.416667      0.116667      0.350000   \n",
       "50%        0.450000      0.466667      0.500000      0.183333      0.466667   \n",
       "75%        0.550000      0.583333      0.633333      0.216667      0.550000   \n",
       "max        0.800000      0.750000      0.766667      0.366667      0.733333   \n",
       "\n",
       "       FB2EE01C18CE  FDAE5980F28C  \n",
       "count   1924.000000   1472.000000  \n",
       "mean       0.317897      0.295652  \n",
       "std        0.129125      0.103917  \n",
       "min        0.050000      0.033333  \n",
       "25%        0.216667      0.216667  \n",
       "50%        0.316667      0.300000  \n",
       "75%        0.416667      0.383333  \n",
       "max        0.566667      0.500000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Validation Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = train_validation_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C400A2E19293</th>\n",
       "      <th>CD4533FFC0E1</th>\n",
       "      <th>D2B6503554D7</th>\n",
       "      <th>DB8B36A69C56</th>\n",
       "      <th>DD697EA75B68</th>\n",
       "      <th>DF231643E227</th>\n",
       "      <th>E13B805C6CB0</th>\n",
       "      <th>E43355CA8B96</th>\n",
       "      <th>E6D9D20DD197</th>\n",
       "      <th>E8FD0B453DC4</th>\n",
       "      <th>E96AF2C858BA</th>\n",
       "      <th>EC72840D9AD3</th>\n",
       "      <th>F1307ECB3B90</th>\n",
       "      <th>F1EDAF28E08A</th>\n",
       "      <th>F69A86823B96</th>\n",
       "      <th>FB2EE01C18CE</th>\n",
       "      <th>FDAE5980F28C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1_11</th>\n",
       "      <td>55</td>\n",
       "      <td>71</td>\n",
       "      <td>68</td>\n",
       "      <td>96</td>\n",
       "      <td>126</td>\n",
       "      <td>82</td>\n",
       "      <td>60</td>\n",
       "      <td>105</td>\n",
       "      <td>120</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>130</td>\n",
       "      <td>129</td>\n",
       "      <td>27</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_12</th>\n",
       "      <td>67</td>\n",
       "      <td>76</td>\n",
       "      <td>43</td>\n",
       "      <td>84</td>\n",
       "      <td>79</td>\n",
       "      <td>76</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>153</td>\n",
       "      <td>51</td>\n",
       "      <td>74</td>\n",
       "      <td>151</td>\n",
       "      <td>126</td>\n",
       "      <td>79</td>\n",
       "      <td>106</td>\n",
       "      <td>56</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_13</th>\n",
       "      <td>60</td>\n",
       "      <td>141</td>\n",
       "      <td>47</td>\n",
       "      <td>111</td>\n",
       "      <td>42</td>\n",
       "      <td>86</td>\n",
       "      <td>101</td>\n",
       "      <td>111</td>\n",
       "      <td>229</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>107</td>\n",
       "      <td>80</td>\n",
       "      <td>92</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_14</th>\n",
       "      <td>36</td>\n",
       "      <td>154</td>\n",
       "      <td>45</td>\n",
       "      <td>82</td>\n",
       "      <td>56</td>\n",
       "      <td>89</td>\n",
       "      <td>261</td>\n",
       "      <td>66</td>\n",
       "      <td>210</td>\n",
       "      <td>14</td>\n",
       "      <td>105</td>\n",
       "      <td>50</td>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "      <td>164</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_20</th>\n",
       "      <td>105</td>\n",
       "      <td>92</td>\n",
       "      <td>94</td>\n",
       "      <td>77</td>\n",
       "      <td>124</td>\n",
       "      <td>98</td>\n",
       "      <td>61</td>\n",
       "      <td>82</td>\n",
       "      <td>72</td>\n",
       "      <td>31</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>169</td>\n",
       "      <td>15</td>\n",
       "      <td>74</td>\n",
       "      <td>23</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_21</th>\n",
       "      <td>64</td>\n",
       "      <td>132</td>\n",
       "      <td>78</td>\n",
       "      <td>72</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>52</td>\n",
       "      <td>132</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>78</td>\n",
       "      <td>64</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_22</th>\n",
       "      <td>61</td>\n",
       "      <td>70</td>\n",
       "      <td>58</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>155</td>\n",
       "      <td>205</td>\n",
       "      <td>27</td>\n",
       "      <td>233</td>\n",
       "      <td>27</td>\n",
       "      <td>136</td>\n",
       "      <td>57</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>109</td>\n",
       "      <td>90</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_23</th>\n",
       "      <td>57</td>\n",
       "      <td>86</td>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>202</td>\n",
       "      <td>123</td>\n",
       "      <td>46</td>\n",
       "      <td>290</td>\n",
       "      <td>31</td>\n",
       "      <td>194</td>\n",
       "      <td>58</td>\n",
       "      <td>79</td>\n",
       "      <td>9</td>\n",
       "      <td>107</td>\n",
       "      <td>116</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_24</th>\n",
       "      <td>22</td>\n",
       "      <td>67</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>39</td>\n",
       "      <td>108</td>\n",
       "      <td>95</td>\n",
       "      <td>47</td>\n",
       "      <td>441</td>\n",
       "      <td>17</td>\n",
       "      <td>184</td>\n",
       "      <td>54</td>\n",
       "      <td>64</td>\n",
       "      <td>33</td>\n",
       "      <td>87</td>\n",
       "      <td>135</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_28</th>\n",
       "      <td>99</td>\n",
       "      <td>96</td>\n",
       "      <td>93</td>\n",
       "      <td>52</td>\n",
       "      <td>109</td>\n",
       "      <td>75</td>\n",
       "      <td>96</td>\n",
       "      <td>63</td>\n",
       "      <td>108</td>\n",
       "      <td>70</td>\n",
       "      <td>46</td>\n",
       "      <td>67</td>\n",
       "      <td>57</td>\n",
       "      <td>97</td>\n",
       "      <td>86</td>\n",
       "      <td>27</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_29</th>\n",
       "      <td>60</td>\n",
       "      <td>132</td>\n",
       "      <td>87</td>\n",
       "      <td>57</td>\n",
       "      <td>87</td>\n",
       "      <td>75</td>\n",
       "      <td>145</td>\n",
       "      <td>69</td>\n",
       "      <td>128</td>\n",
       "      <td>25</td>\n",
       "      <td>91</td>\n",
       "      <td>68</td>\n",
       "      <td>87</td>\n",
       "      <td>32</td>\n",
       "      <td>95</td>\n",
       "      <td>108</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_30</th>\n",
       "      <td>34</td>\n",
       "      <td>84</td>\n",
       "      <td>68</td>\n",
       "      <td>27</td>\n",
       "      <td>52</td>\n",
       "      <td>216</td>\n",
       "      <td>182</td>\n",
       "      <td>28</td>\n",
       "      <td>166</td>\n",
       "      <td>17</td>\n",
       "      <td>95</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>12</td>\n",
       "      <td>76</td>\n",
       "      <td>122</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_31</th>\n",
       "      <td>18</td>\n",
       "      <td>56</td>\n",
       "      <td>37</td>\n",
       "      <td>59</td>\n",
       "      <td>45</td>\n",
       "      <td>113</td>\n",
       "      <td>91</td>\n",
       "      <td>25</td>\n",
       "      <td>150</td>\n",
       "      <td>7</td>\n",
       "      <td>174</td>\n",
       "      <td>51</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>152</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_32</th>\n",
       "      <td>30</td>\n",
       "      <td>82</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>129</td>\n",
       "      <td>126</td>\n",
       "      <td>41</td>\n",
       "      <td>311</td>\n",
       "      <td>21</td>\n",
       "      <td>199</td>\n",
       "      <td>62</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>68</td>\n",
       "      <td>138</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          C400A2E19293  CD4533FFC0E1  D2B6503554D7  DB8B36A69C56  \\\n",
       "location                                                           \n",
       "V1_11               55            71            68            96   \n",
       "V1_12               67            76            43            84   \n",
       "V1_13               60           141            47           111   \n",
       "V1_14               36           154            45            82   \n",
       "V1_20              105            92            94            77   \n",
       "V1_21               64           132            78            72   \n",
       "V1_22               61            70            58            62   \n",
       "V1_23               57            86            53            47   \n",
       "V1_24               22            67            53            55   \n",
       "V1_28               99            96            93            52   \n",
       "V1_29               60           132            87            57   \n",
       "V1_30               34            84            68            27   \n",
       "V1_31               18            56            37            59   \n",
       "V1_32               30            82            64            66   \n",
       "\n",
       "          DD697EA75B68  DF231643E227  E13B805C6CB0  E43355CA8B96  \\\n",
       "location                                                           \n",
       "V1_11              126            82            60           105   \n",
       "V1_12               79            76            56            58   \n",
       "V1_13               42            86           101           111   \n",
       "V1_14               56            89           261            66   \n",
       "V1_20              124            98            61            82   \n",
       "V1_21               90            90           120            52   \n",
       "V1_22               68           155           205            27   \n",
       "V1_23               35           202           123            46   \n",
       "V1_24               39           108            95            47   \n",
       "V1_28              109            75            96            63   \n",
       "V1_29               87            75           145            69   \n",
       "V1_30               52           216           182            28   \n",
       "V1_31               45           113            91            25   \n",
       "V1_32               65           129           126            41   \n",
       "\n",
       "          E6D9D20DD197  E8FD0B453DC4  E96AF2C858BA  EC72840D9AD3  \\\n",
       "location                                                           \n",
       "V1_11              120            49            48           130   \n",
       "V1_12              153            51            74           151   \n",
       "V1_13              229            13            33           107   \n",
       "V1_14              210            14           105            50   \n",
       "V1_20               72            31            72            90   \n",
       "V1_21              132            17            86            93   \n",
       "V1_22              233            27           136            57   \n",
       "V1_23              290            31           194            58   \n",
       "V1_24              441            17           184            54   \n",
       "V1_28              108            70            46            67   \n",
       "V1_29              128            25            91            68   \n",
       "V1_30              166            17            95            47   \n",
       "V1_31              150             7           174            51   \n",
       "V1_32              311            21           199            62   \n",
       "\n",
       "          F1307ECB3B90  F1EDAF28E08A  F69A86823B96  FB2EE01C18CE  FDAE5980F28C  \n",
       "location                                                                        \n",
       "V1_11              129            27            45            20            84  \n",
       "V1_12              126            79           106            56            71  \n",
       "V1_13               80            92           150            14            63  \n",
       "V1_14               78            83           164            63            86  \n",
       "V1_20              169            15            74            23            69  \n",
       "V1_21               78            64            85            70            62  \n",
       "V1_22               49            11           109            90            51  \n",
       "V1_23               79             9           107           116            61  \n",
       "V1_24               64            33            87           135            26  \n",
       "V1_28               57            97            86            27            64  \n",
       "V1_29               87            32            95           108            60  \n",
       "V1_30               46            12            76           122            63  \n",
       "V1_31               36             6            46           152            40  \n",
       "V1_32               38            18            68           138            93  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(\"location\")[scanners].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18102, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6034, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(\"time\", inplace=True)\n",
    "validation.sort_values(\"time\", inplace=True)\n",
    "test.sort_values(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rolled = train.groupby(\"location\").rolling(15, min_periods=1).mean().reset_index()\n",
    "validation_rolled = validation.groupby(\"location\").rolling(15, min_periods=1).mean().reset_index()\n",
    "test_rolled = test.groupby(\"location\").rolling(15, min_periods=1).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>level_1</th>\n",
       "      <th>C400A2E19293</th>\n",
       "      <th>CD4533FFC0E1</th>\n",
       "      <th>D2B6503554D7</th>\n",
       "      <th>DB8B36A69C56</th>\n",
       "      <th>DD697EA75B68</th>\n",
       "      <th>DF231643E227</th>\n",
       "      <th>E13B805C6CB0</th>\n",
       "      <th>E43355CA8B96</th>\n",
       "      <th>E6D9D20DD197</th>\n",
       "      <th>E8FD0B453DC4</th>\n",
       "      <th>E96AF2C858BA</th>\n",
       "      <th>EC72840D9AD3</th>\n",
       "      <th>F1307ECB3B90</th>\n",
       "      <th>F1EDAF28E08A</th>\n",
       "      <th>F69A86823B96</th>\n",
       "      <th>FB2EE01C18CE</th>\n",
       "      <th>FDAE5980F28C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1_11</td>\n",
       "      <td>24304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V1_11</td>\n",
       "      <td>24306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1_11</td>\n",
       "      <td>24307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V1_11</td>\n",
       "      <td>24308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V1_11</td>\n",
       "      <td>24310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18097</th>\n",
       "      <td>V1_32</td>\n",
       "      <td>22547</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18098</th>\n",
       "      <td>V1_32</td>\n",
       "      <td>22549</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18099</th>\n",
       "      <td>V1_32</td>\n",
       "      <td>22551</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18100</th>\n",
       "      <td>V1_32</td>\n",
       "      <td>22552</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18101</th>\n",
       "      <td>V1_32</td>\n",
       "      <td>22554</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18102 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      location  level_1  C400A2E19293  CD4533FFC0E1  D2B6503554D7  \\\n",
       "0        V1_11    24304           NaN           NaN           NaN   \n",
       "1        V1_11    24306           NaN           NaN           NaN   \n",
       "2        V1_11    24307           NaN           NaN           NaN   \n",
       "3        V1_11    24308           NaN      0.333333           NaN   \n",
       "4        V1_11    24310           NaN      0.333333           NaN   \n",
       "...        ...      ...           ...           ...           ...   \n",
       "18097    V1_32    22547      0.183333      0.283333      0.333333   \n",
       "18098    V1_32    22549      0.183333      0.283333      0.333333   \n",
       "18099    V1_32    22551      0.183333      0.283333      0.333333   \n",
       "18100    V1_32    22552      0.183333      0.283333      0.333333   \n",
       "18101    V1_32    22554      0.183333      0.283333      0.333333   \n",
       "\n",
       "       DB8B36A69C56  DD697EA75B68  DF231643E227  E13B805C6CB0  E43355CA8B96  \\\n",
       "0              0.55           NaN           NaN           NaN           NaN   \n",
       "1              0.55      0.516667           NaN           NaN           NaN   \n",
       "2              0.55      0.516667           NaN      0.333333           NaN   \n",
       "3              0.55      0.516667           NaN      0.333333           NaN   \n",
       "4              0.55      0.516667          0.15      0.333333           NaN   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "18097           NaN           NaN          0.55      0.433333           NaN   \n",
       "18098           NaN      0.233333          0.55      0.433333           NaN   \n",
       "18099           NaN      0.233333          0.55      0.433333           NaN   \n",
       "18100           NaN      0.233333           NaN      0.433333           NaN   \n",
       "18101           NaN      0.233333           NaN      0.400000           NaN   \n",
       "\n",
       "       E6D9D20DD197  E8FD0B453DC4  E96AF2C858BA  EC72840D9AD3  F1307ECB3B90  \\\n",
       "0               NaN           NaN           NaN           NaN           NaN   \n",
       "1               NaN           NaN           NaN           NaN           NaN   \n",
       "2               NaN           NaN           NaN           NaN           NaN   \n",
       "3               NaN           NaN           NaN           NaN           NaN   \n",
       "4               NaN           NaN      0.100000           NaN           NaN   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "18097      0.516667           NaN      0.700000          0.25           NaN   \n",
       "18098      0.500000           NaN      0.700000          0.25           0.3   \n",
       "18099      0.505556           NaN      0.700000           NaN           0.3   \n",
       "18100      0.505556           NaN      0.679167           NaN           0.3   \n",
       "18101      0.516667           NaN      0.679167           NaN           0.3   \n",
       "\n",
       "       F1EDAF28E08A  F69A86823B96  FB2EE01C18CE  FDAE5980F28C  \n",
       "0               NaN           NaN           NaN           NaN  \n",
       "1               NaN           NaN           NaN           NaN  \n",
       "2               NaN           NaN           NaN           NaN  \n",
       "3               NaN           NaN           NaN           NaN  \n",
       "4               NaN           NaN           NaN           NaN  \n",
       "...             ...           ...           ...           ...  \n",
       "18097           NaN      0.258333           NaN           NaN  \n",
       "18098           NaN      0.258333           NaN           NaN  \n",
       "18099           NaN      0.258333           NaN           NaN  \n",
       "18100           NaN      0.258333           NaN           NaN  \n",
       "18101           NaN      0.258333           NaN           NaN  \n",
       "\n",
       "[18102 rows x 19 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rolled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "1. Forward fill\n",
    "2. Fill NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imputed = train_rolled.set_index(\"location\").groupby(\"location\").ffill()\n",
    "train_imputed.fillna(0, inplace=True)\n",
    "train_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_imputed = validation_rolled.set_index(\"location\").groupby(\"location\").ffill()\n",
    "validation_imputed.fillna(0, inplace=True)\n",
    "validation_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imputed = test_rolled.set_index(\"location\").groupby(\"location\").ffill()\n",
    "test_imputed.fillna(0, inplace=True)\n",
    "test_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Location to Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imputed[\"X\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "train_imputed[\"Y\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_imputed[\"X\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "validation_imputed[\"Y\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imputed[\"X\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "test_imputed[\"Y\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_imputed[scanners].values, train_imputed[[\"X\", \"Y\"]].values\n",
    "X_validation, y_validation = validation_imputed[scanners].values, validation_imputed[[\"X\", \"Y\"]].values\n",
    "X_test, y_test = test_imputed[scanners].values, test_imputed[[\"X\", \"Y\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MLP(size='small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18102 samples, validate on 6034 samples\n",
      "Epoch 1/1000\n",
      "18102/18102 [==============================] - 1s 65us/sample - loss: 105.2131 - mae: 7.2077 - mse: 99.9140 - val_loss: 27.9087 - val_mae: 3.3286 - val_mse: 18.2302\n",
      "Epoch 2/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 18.6432 - mae: 2.2535 - mse: 8.1658 - val_loss: 17.0324 - val_mae: 1.9625 - val_mse: 6.6167\n",
      "Epoch 3/1000\n",
      "18102/18102 [==============================] - 1s 42us/sample - loss: 14.9977 - mae: 1.6252 - mse: 4.2150 - val_loss: 15.4219 - val_mae: 1.6206 - val_mse: 4.7226\n",
      "Epoch 4/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 13.9741 - mae: 1.3618 - mse: 3.0612 - val_loss: 14.7524 - val_mae: 1.4714 - val_mse: 3.9442\n",
      "Epoch 5/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 13.6262 - mae: 1.2636 - mse: 2.6465 - val_loss: 14.3004 - val_mae: 1.3632 - val_mse: 3.3207\n",
      "Epoch 6/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 13.4061 - mae: 1.2004 - mse: 2.3909 - val_loss: 14.0149 - val_mae: 1.3219 - val_mse: 3.0415\n",
      "Epoch 7/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 13.2661 - mae: 1.1566 - mse: 2.2302 - val_loss: 13.8728 - val_mae: 1.2345 - val_mse: 2.6501\n",
      "Epoch 8/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 13.1721 - mae: 1.1285 - mse: 2.1272 - val_loss: 13.7473 - val_mae: 1.2443 - val_mse: 2.6453\n",
      "Epoch 9/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 13.1049 - mae: 1.1079 - mse: 2.0561 - val_loss: 13.7253 - val_mae: 1.3173 - val_mse: 2.9154\n",
      "Epoch 10/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 13.0558 - mae: 1.0943 - mse: 2.0132 - val_loss: 13.6847 - val_mae: 1.1531 - val_mse: 2.3055\n",
      "Epoch 11/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 13.0136 - mae: 1.0824 - mse: 1.9744 - val_loss: 13.5884 - val_mae: 1.2320 - val_mse: 2.5755\n",
      "Epoch 12/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.9744 - mae: 1.0732 - mse: 1.9462 - val_loss: 13.5607 - val_mae: 1.2204 - val_mse: 2.5287\n",
      "Epoch 13/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.9412 - mae: 1.0654 - mse: 1.9207 - val_loss: 13.5323 - val_mae: 1.1655 - val_mse: 2.3345\n",
      "Epoch 14/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.9091 - mae: 1.0558 - mse: 1.8903 - val_loss: 13.5178 - val_mae: 1.2459 - val_mse: 2.6365\n",
      "Epoch 15/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.8830 - mae: 1.0498 - mse: 1.8734 - val_loss: 13.4657 - val_mae: 1.1679 - val_mse: 2.3447\n",
      "Epoch 16/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.8564 - mae: 1.0443 - mse: 1.8538 - val_loss: 13.4459 - val_mae: 1.1784 - val_mse: 2.3889\n",
      "Epoch 17/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.8315 - mae: 1.0384 - mse: 1.8342 - val_loss: 13.4260 - val_mae: 1.1497 - val_mse: 2.3016\n",
      "Epoch 18/1000\n",
      "18102/18102 [==============================] - 1s 39us/sample - loss: 12.8096 - mae: 1.0331 - mse: 1.8200 - val_loss: 13.4150 - val_mae: 1.1365 - val_mse: 2.2587\n",
      "Epoch 19/1000\n",
      "18102/18102 [==============================] - 1s 56us/sample - loss: 12.7891 - mae: 1.0271 - mse: 1.8002 - val_loss: 13.3860 - val_mae: 1.1804 - val_mse: 2.4024\n",
      "Epoch 20/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.7699 - mae: 1.0222 - mse: 1.7860 - val_loss: 13.3639 - val_mae: 1.1518 - val_mse: 2.3068\n",
      "Epoch 21/1000\n",
      "18102/18102 [==============================] - 1s 48us/sample - loss: 12.7496 - mae: 1.0168 - mse: 1.7695 - val_loss: 13.3498 - val_mae: 1.1262 - val_mse: 2.2118\n",
      "Epoch 22/1000\n",
      "18102/18102 [==============================] - 1s 42us/sample - loss: 12.7331 - mae: 1.0133 - mse: 1.7565 - val_loss: 13.3253 - val_mae: 1.1418 - val_mse: 2.2716\n",
      "Epoch 23/1000\n",
      "18102/18102 [==============================] - 1s 42us/sample - loss: 12.7129 - mae: 1.0080 - mse: 1.7408 - val_loss: 13.3083 - val_mae: 1.1371 - val_mse: 2.2565\n",
      "Epoch 24/1000\n",
      "18102/18102 [==============================] - 1s 49us/sample - loss: 12.6953 - mae: 1.0028 - mse: 1.7249 - val_loss: 13.2967 - val_mae: 1.1111 - val_mse: 2.1760\n",
      "Epoch 25/1000\n",
      "18102/18102 [==============================] - 1s 46us/sample - loss: 12.6786 - mae: 1.0001 - mse: 1.7134 - val_loss: 13.2892 - val_mae: 1.1088 - val_mse: 2.1812\n",
      "Epoch 26/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.6625 - mae: 0.9953 - mse: 1.6985 - val_loss: 13.2562 - val_mae: 1.1312 - val_mse: 2.2422\n",
      "Epoch 27/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 12.6478 - mae: 0.9929 - mse: 1.6889 - val_loss: 13.2785 - val_mae: 1.0679 - val_mse: 2.0462\n",
      "Epoch 28/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 12.6347 - mae: 0.9888 - mse: 1.6770 - val_loss: 13.2463 - val_mae: 1.0855 - val_mse: 2.0932\n",
      "Epoch 29/1000\n",
      "18102/18102 [==============================] - 1s 53us/sample - loss: 12.6217 - mae: 0.9853 - mse: 1.6653 - val_loss: 13.2212 - val_mae: 1.1225 - val_mse: 2.2143\n",
      "Epoch 30/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 12.6102 - mae: 0.9830 - mse: 1.6579 - val_loss: 13.2332 - val_mae: 1.0692 - val_mse: 2.0618\n",
      "Epoch 31/1000\n",
      "18102/18102 [==============================] - 1s 51us/sample - loss: 12.5979 - mae: 0.9808 - mse: 1.6483 - val_loss: 13.1966 - val_mae: 1.0958 - val_mse: 2.1372\n",
      "Epoch 32/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.5860 - mae: 0.9783 - mse: 1.6414 - val_loss: 13.2083 - val_mae: 1.0753 - val_mse: 2.0853\n",
      "Epoch 33/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.5754 - mae: 0.9750 - mse: 1.6312 - val_loss: 13.1736 - val_mae: 1.0971 - val_mse: 2.1238\n",
      "Epoch 34/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.5636 - mae: 0.9727 - mse: 1.6223 - val_loss: 13.1899 - val_mae: 1.1399 - val_mse: 2.2901\n",
      "Epoch 35/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.5532 - mae: 0.9705 - mse: 1.6144 - val_loss: 13.2106 - val_mae: 1.0282 - val_mse: 1.9412\n",
      "Epoch 36/1000\n",
      "18102/18102 [==============================] - 1s 39us/sample - loss: 12.5430 - mae: 0.9675 - mse: 1.6063 - val_loss: 13.1558 - val_mae: 1.0666 - val_mse: 2.0407\n",
      "Epoch 37/1000\n",
      "18102/18102 [==============================] - 1s 40us/sample - loss: 12.5317 - mae: 0.9645 - mse: 1.5960 - val_loss: 13.1438 - val_mae: 1.0757 - val_mse: 2.0780\n",
      "Epoch 38/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 12.5220 - mae: 0.9624 - mse: 1.5890 - val_loss: 13.1366 - val_mae: 1.0968 - val_mse: 2.1425\n",
      "Epoch 39/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 12.5133 - mae: 0.9621 - mse: 1.5843 - val_loss: 13.1445 - val_mae: 1.1366 - val_mse: 2.2648\n",
      "Epoch 40/1000\n",
      "18102/18102 [==============================] - 1s 41us/sample - loss: 12.5048 - mae: 0.9585 - mse: 1.5750 - val_loss: 13.1255 - val_mae: 1.1252 - val_mse: 2.2280\n",
      "Epoch 41/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.4966 - mae: 0.9566 - mse: 1.5694 - val_loss: 13.1160 - val_mae: 1.0940 - val_mse: 2.1374\n",
      "Epoch 42/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.4887 - mae: 0.9555 - mse: 1.5652 - val_loss: 13.1173 - val_mae: 1.0580 - val_mse: 2.0355\n",
      "Epoch 43/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.4804 - mae: 0.9535 - mse: 1.5592 - val_loss: 13.1054 - val_mae: 1.0501 - val_mse: 1.9885\n",
      "Epoch 44/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 12.4717 - mae: 0.9513 - mse: 1.5504 - val_loss: 13.0929 - val_mae: 1.0519 - val_mse: 1.9921\n",
      "Epoch 45/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.4644 - mae: 0.9499 - mse: 1.5456 - val_loss: 13.0850 - val_mae: 1.0980 - val_mse: 2.1507\n",
      "Epoch 46/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 12.4574 - mae: 0.9474 - mse: 1.5385 - val_loss: 13.0751 - val_mae: 1.1225 - val_mse: 2.2118\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.4497 - mae: 0.9474 - mse: 1.5362 - val_loss: 13.0780 - val_mae: 1.0350 - val_mse: 1.9571\n",
      "Epoch 48/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.4426 - mae: 0.9450 - mse: 1.5285 - val_loss: 13.0940 - val_mae: 1.1034 - val_mse: 2.1836\n",
      "Epoch 49/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.4371 - mae: 0.9441 - mse: 1.5255 - val_loss: 13.0548 - val_mae: 1.0454 - val_mse: 1.9795\n",
      "Epoch 50/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.4294 - mae: 0.9421 - mse: 1.5186 - val_loss: 13.0463 - val_mae: 1.0719 - val_mse: 2.0501\n",
      "Epoch 51/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.4223 - mae: 0.9411 - mse: 1.5138 - val_loss: 13.0457 - val_mae: 1.1001 - val_mse: 2.1417\n",
      "Epoch 52/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.4160 - mae: 0.9382 - mse: 1.5078 - val_loss: 13.0373 - val_mae: 1.0382 - val_mse: 1.9577\n",
      "Epoch 53/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.4103 - mae: 0.9385 - mse: 1.5042 - val_loss: 13.0278 - val_mae: 1.1002 - val_mse: 2.1320\n",
      "Epoch 54/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.4037 - mae: 0.9369 - mse: 1.5001 - val_loss: 13.0368 - val_mae: 1.0300 - val_mse: 1.9365\n",
      "Epoch 55/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.3982 - mae: 0.9349 - mse: 1.4935 - val_loss: 13.0205 - val_mae: 1.0623 - val_mse: 2.0268\n",
      "Epoch 56/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 12.3924 - mae: 0.9331 - mse: 1.4898 - val_loss: 13.0959 - val_mae: 0.9744 - val_mse: 1.7864\n",
      "Epoch 57/1000\n",
      "18102/18102 [==============================] - 1s 39us/sample - loss: 12.3868 - mae: 0.9319 - mse: 1.4839 - val_loss: 13.0122 - val_mae: 1.0507 - val_mse: 2.0104\n",
      "Epoch 58/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.3799 - mae: 0.9302 - mse: 1.4783 - val_loss: 13.0325 - val_mae: 1.1007 - val_mse: 2.1547\n",
      "Epoch 59/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.3754 - mae: 0.9307 - mse: 1.4773 - val_loss: 13.0055 - val_mae: 1.0589 - val_mse: 2.0293\n",
      "Epoch 60/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.3685 - mae: 0.9268 - mse: 1.4684 - val_loss: 13.0180 - val_mae: 1.1268 - val_mse: 2.2253\n",
      "Epoch 61/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.3641 - mae: 0.9268 - mse: 1.4670 - val_loss: 12.9912 - val_mae: 1.0662 - val_mse: 2.0318\n",
      "Epoch 62/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.3597 - mae: 0.9262 - mse: 1.4632 - val_loss: 12.9930 - val_mae: 1.0554 - val_mse: 2.0114\n",
      "Epoch 63/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.3539 - mae: 0.9243 - mse: 1.4572 - val_loss: 13.0146 - val_mae: 1.0005 - val_mse: 1.8719\n",
      "Epoch 64/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.3489 - mae: 0.9237 - mse: 1.4544 - val_loss: 12.9973 - val_mae: 1.0166 - val_mse: 1.8901\n",
      "Epoch 65/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.3452 - mae: 0.9227 - mse: 1.4519 - val_loss: 12.9912 - val_mae: 1.0761 - val_mse: 2.0809\n",
      "Epoch 66/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.3402 - mae: 0.9217 - mse: 1.4486 - val_loss: 12.9853 - val_mae: 1.0221 - val_mse: 1.9296\n",
      "Epoch 67/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.3360 - mae: 0.9203 - mse: 1.4444 - val_loss: 12.9724 - val_mae: 1.0425 - val_mse: 1.9666\n",
      "Epoch 68/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.3312 - mae: 0.9197 - mse: 1.4415 - val_loss: 12.9547 - val_mae: 1.0424 - val_mse: 1.9692\n",
      "Epoch 69/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.3263 - mae: 0.9189 - mse: 1.4383 - val_loss: 12.9632 - val_mae: 1.0311 - val_mse: 1.9376\n",
      "Epoch 70/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.3226 - mae: 0.9178 - mse: 1.4348 - val_loss: 12.9726 - val_mae: 1.0100 - val_mse: 1.8715\n",
      "Epoch 71/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 12.3172 - mae: 0.9172 - mse: 1.4319 - val_loss: 12.9760 - val_mae: 1.0110 - val_mse: 1.8964\n",
      "Epoch 72/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 12.3154 - mae: 0.9159 - mse: 1.4287 - val_loss: 12.9418 - val_mae: 1.0612 - val_mse: 2.0181\n",
      "Epoch 73/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.3103 - mae: 0.9150 - mse: 1.4256 - val_loss: 12.9463 - val_mae: 1.0518 - val_mse: 1.9856\n",
      "Epoch 74/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 12.3063 - mae: 0.9148 - mse: 1.4236 - val_loss: 12.9528 - val_mae: 1.0124 - val_mse: 1.8903\n",
      "Epoch 75/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.3028 - mae: 0.9144 - mse: 1.4213 - val_loss: 12.9389 - val_mae: 1.0613 - val_mse: 2.0172\n",
      "Epoch 76/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2995 - mae: 0.9135 - mse: 1.4195 - val_loss: 12.9750 - val_mae: 0.9750 - val_mse: 1.7985\n",
      "Epoch 77/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.2957 - mae: 0.9110 - mse: 1.4133 - val_loss: 12.9266 - val_mae: 1.0365 - val_mse: 1.9482\n",
      "Epoch 78/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2898 - mae: 0.9104 - mse: 1.4092 - val_loss: 12.9236 - val_mae: 1.0464 - val_mse: 1.9797\n",
      "Epoch 79/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2882 - mae: 0.9108 - mse: 1.4095 - val_loss: 12.9321 - val_mae: 1.0072 - val_mse: 1.8855\n",
      "Epoch 80/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2841 - mae: 0.9090 - mse: 1.4054 - val_loss: 12.9319 - val_mae: 0.9968 - val_mse: 1.8411\n",
      "Epoch 81/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2809 - mae: 0.9089 - mse: 1.4035 - val_loss: 12.9491 - val_mae: 0.9750 - val_mse: 1.7856\n",
      "Epoch 82/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2782 - mae: 0.9089 - mse: 1.4028 - val_loss: 12.9556 - val_mae: 0.9749 - val_mse: 1.8006\n",
      "Epoch 83/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2744 - mae: 0.9075 - mse: 1.3986 - val_loss: 12.9356 - val_mae: 0.9772 - val_mse: 1.7839\n",
      "Epoch 84/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.2714 - mae: 0.9059 - mse: 1.3952 - val_loss: 12.9119 - val_mae: 1.0044 - val_mse: 1.8528\n",
      "Epoch 85/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2674 - mae: 0.9056 - mse: 1.3922 - val_loss: 12.8957 - val_mae: 1.0315 - val_mse: 1.9306\n",
      "Epoch 86/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2646 - mae: 0.9058 - mse: 1.3920 - val_loss: 12.9081 - val_mae: 1.0205 - val_mse: 1.9084\n",
      "Epoch 87/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2619 - mae: 0.9047 - mse: 1.3889 - val_loss: 12.8917 - val_mae: 1.0230 - val_mse: 1.8947\n",
      "Epoch 88/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2574 - mae: 0.9040 - mse: 1.3851 - val_loss: 12.9152 - val_mae: 1.1267 - val_mse: 2.2020\n",
      "Epoch 89/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2545 - mae: 0.9047 - mse: 1.3868 - val_loss: 12.9197 - val_mae: 0.9703 - val_mse: 1.7752\n",
      "Epoch 90/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.2530 - mae: 0.9030 - mse: 1.3821 - val_loss: 12.8868 - val_mae: 1.0489 - val_mse: 1.9585\n",
      "Epoch 91/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2497 - mae: 0.9034 - mse: 1.3832 - val_loss: 12.9014 - val_mae: 1.0238 - val_mse: 1.9202\n",
      "Epoch 92/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2459 - mae: 0.9014 - mse: 1.3762 - val_loss: 12.9093 - val_mae: 1.1174 - val_mse: 2.1768\n",
      "Epoch 93/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2448 - mae: 0.9026 - mse: 1.3786 - val_loss: 12.9034 - val_mae: 0.9874 - val_mse: 1.8187\n",
      "Epoch 94/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2422 - mae: 0.9007 - mse: 1.3744 - val_loss: 12.8742 - val_mae: 1.0429 - val_mse: 1.9580\n",
      "Epoch 95/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2376 - mae: 0.8999 - mse: 1.3703 - val_loss: 12.8661 - val_mae: 1.0441 - val_mse: 1.9561\n",
      "Epoch 96/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2356 - mae: 0.8999 - mse: 1.3701 - val_loss: 12.8624 - val_mae: 1.0547 - val_mse: 1.9814\n",
      "Epoch 97/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2323 - mae: 0.8996 - mse: 1.3688 - val_loss: 12.8752 - val_mae: 1.0414 - val_mse: 1.9720\n",
      "Epoch 98/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2302 - mae: 0.8985 - mse: 1.3662 - val_loss: 12.8616 - val_mae: 1.0375 - val_mse: 1.9501\n",
      "Epoch 99/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2277 - mae: 0.8975 - mse: 1.3645 - val_loss: 12.8615 - val_mae: 1.0458 - val_mse: 1.9641\n",
      "Epoch 100/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2251 - mae: 0.8975 - mse: 1.3632 - val_loss: 12.8713 - val_mae: 1.0393 - val_mse: 1.9647\n",
      "Epoch 101/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2211 - mae: 0.8965 - mse: 1.3584 - val_loss: 12.9065 - val_mae: 0.9486 - val_mse: 1.6927\n",
      "Epoch 102/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2201 - mae: 0.8962 - mse: 1.3591 - val_loss: 12.8581 - val_mae: 1.0087 - val_mse: 1.8578\n",
      "Epoch 103/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2159 - mae: 0.8947 - mse: 1.3552 - val_loss: 12.8732 - val_mae: 0.9788 - val_mse: 1.7910\n",
      "Epoch 104/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2142 - mae: 0.8945 - mse: 1.3526 - val_loss: 12.8566 - val_mae: 1.0882 - val_mse: 2.0885\n",
      "Epoch 105/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2121 - mae: 0.8944 - mse: 1.3528 - val_loss: 12.8543 - val_mae: 0.9832 - val_mse: 1.7950\n",
      "Epoch 106/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2086 - mae: 0.8937 - mse: 1.3490 - val_loss: 12.8400 - val_mae: 1.0137 - val_mse: 1.8696\n",
      "Epoch 107/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.2072 - mae: 0.8935 - mse: 1.3486 - val_loss: 12.8475 - val_mae: 0.9975 - val_mse: 1.8202\n",
      "Epoch 108/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2045 - mae: 0.8919 - mse: 1.3464 - val_loss: 12.9075 - val_mae: 0.9371 - val_mse: 1.6863\n",
      "Epoch 109/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.2032 - mae: 0.8914 - mse: 1.3435 - val_loss: 12.8366 - val_mae: 0.9819 - val_mse: 1.7889\n",
      "Epoch 110/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1986 - mae: 0.8905 - mse: 1.3392 - val_loss: 12.8269 - val_mae: 1.0117 - val_mse: 1.8546\n",
      "Epoch 111/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1988 - mae: 0.8906 - mse: 1.3424 - val_loss: 12.8244 - val_mae: 1.0398 - val_mse: 1.9284\n",
      "Epoch 112/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1943 - mae: 0.8902 - mse: 1.3396 - val_loss: 12.8345 - val_mae: 0.9905 - val_mse: 1.8146\n",
      "Epoch 113/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1922 - mae: 0.8894 - mse: 1.3378 - val_loss: 12.8435 - val_mae: 1.0200 - val_mse: 1.9086\n",
      "Epoch 114/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1904 - mae: 0.8885 - mse: 1.3352 - val_loss: 12.8319 - val_mae: 0.9990 - val_mse: 1.8412\n",
      "Epoch 115/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1881 - mae: 0.8879 - mse: 1.3330 - val_loss: 12.8194 - val_mae: 1.0358 - val_mse: 1.9251\n",
      "Epoch 116/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1864 - mae: 0.8884 - mse: 1.3331 - val_loss: 12.8254 - val_mae: 0.9777 - val_mse: 1.7632\n",
      "Epoch 117/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1821 - mae: 0.8859 - mse: 1.3278 - val_loss: 12.8161 - val_mae: 1.0274 - val_mse: 1.9204\n",
      "Epoch 118/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1814 - mae: 0.8864 - mse: 1.3267 - val_loss: 12.8236 - val_mae: 0.9836 - val_mse: 1.7956\n",
      "Epoch 119/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1795 - mae: 0.8859 - mse: 1.3262 - val_loss: 12.8057 - val_mae: 1.0162 - val_mse: 1.8781\n",
      "Epoch 120/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1766 - mae: 0.8846 - mse: 1.3224 - val_loss: 12.7999 - val_mae: 1.0231 - val_mse: 1.8822\n",
      "Epoch 121/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1744 - mae: 0.8843 - mse: 1.3229 - val_loss: 12.8134 - val_mae: 0.9748 - val_mse: 1.7584\n",
      "Epoch 122/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1721 - mae: 0.8847 - mse: 1.3209 - val_loss: 12.8006 - val_mae: 1.0141 - val_mse: 1.8719\n",
      "Epoch 123/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1696 - mae: 0.8828 - mse: 1.3172 - val_loss: 12.7883 - val_mae: 1.0072 - val_mse: 1.8470\n",
      "Epoch 124/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1672 - mae: 0.8821 - mse: 1.3147 - val_loss: 12.8064 - val_mae: 0.9821 - val_mse: 1.7983\n",
      "Epoch 125/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1649 - mae: 0.8818 - mse: 1.3126 - val_loss: 12.7949 - val_mae: 1.0720 - val_mse: 2.0142\n",
      "Epoch 126/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1628 - mae: 0.8817 - mse: 1.3125 - val_loss: 12.7863 - val_mae: 1.0232 - val_mse: 1.8857\n",
      "Epoch 127/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1605 - mae: 0.8807 - mse: 1.3106 - val_loss: 12.8006 - val_mae: 0.9724 - val_mse: 1.7489\n",
      "Epoch 128/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1576 - mae: 0.8802 - mse: 1.3057 - val_loss: 12.7939 - val_mae: 1.0566 - val_mse: 1.9862\n",
      "Epoch 129/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1558 - mae: 0.8799 - mse: 1.3061 - val_loss: 12.7965 - val_mae: 0.9880 - val_mse: 1.8100\n",
      "Epoch 130/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1520 - mae: 0.8782 - mse: 1.3011 - val_loss: 12.7903 - val_mae: 0.9690 - val_mse: 1.7592\n",
      "Epoch 131/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1515 - mae: 0.8779 - mse: 1.3015 - val_loss: 12.7803 - val_mae: 0.9867 - val_mse: 1.7897\n",
      "Epoch 132/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1497 - mae: 0.8774 - mse: 1.2994 - val_loss: 12.7952 - val_mae: 0.9725 - val_mse: 1.7599\n",
      "Epoch 133/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1470 - mae: 0.8758 - mse: 1.2959 - val_loss: 12.7759 - val_mae: 1.0298 - val_mse: 1.9056\n",
      "Epoch 134/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1442 - mae: 0.8758 - mse: 1.2945 - val_loss: 12.7938 - val_mae: 1.0029 - val_mse: 1.8530\n",
      "Epoch 135/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1430 - mae: 0.8752 - mse: 1.2937 - val_loss: 12.7902 - val_mae: 0.9523 - val_mse: 1.6902\n",
      "Epoch 136/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1410 - mae: 0.8754 - mse: 1.2925 - val_loss: 12.8123 - val_mae: 0.9690 - val_mse: 1.7711\n",
      "Epoch 137/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1390 - mae: 0.8744 - mse: 1.2904 - val_loss: 12.7894 - val_mae: 1.0082 - val_mse: 1.8736\n",
      "Epoch 138/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1363 - mae: 0.8735 - mse: 1.2874 - val_loss: 12.7834 - val_mae: 0.9449 - val_mse: 1.6789\n",
      "Epoch 139/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1346 - mae: 0.8729 - mse: 1.2856 - val_loss: 12.7713 - val_mae: 0.9686 - val_mse: 1.7270\n",
      "Epoch 140/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1320 - mae: 0.8715 - mse: 1.2817 - val_loss: 12.7691 - val_mae: 1.0825 - val_mse: 2.0346\n",
      "Epoch 141/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1304 - mae: 0.8728 - mse: 1.2829 - val_loss: 12.7482 - val_mae: 0.9961 - val_mse: 1.8177\n",
      "Epoch 142/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1294 - mae: 0.8710 - mse: 1.2817 - val_loss: 12.7590 - val_mae: 1.0139 - val_mse: 1.8679\n",
      "Epoch 143/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1282 - mae: 0.8716 - mse: 1.2799 - val_loss: 12.7645 - val_mae: 0.9943 - val_mse: 1.8221\n",
      "Epoch 144/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1253 - mae: 0.8708 - mse: 1.2770 - val_loss: 12.7521 - val_mae: 0.9705 - val_mse: 1.7411\n",
      "Epoch 145/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1235 - mae: 0.8699 - mse: 1.2754 - val_loss: 12.7444 - val_mae: 1.0103 - val_mse: 1.8528\n",
      "Epoch 146/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1218 - mae: 0.8692 - mse: 1.2740 - val_loss: 12.7659 - val_mae: 0.9460 - val_mse: 1.6874\n",
      "Epoch 147/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1183 - mae: 0.8684 - mse: 1.2711 - val_loss: 12.7415 - val_mae: 1.0083 - val_mse: 1.8423\n",
      "Epoch 148/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1177 - mae: 0.8687 - mse: 1.2705 - val_loss: 12.7498 - val_mae: 1.0373 - val_mse: 1.9260\n",
      "Epoch 149/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1170 - mae: 0.8692 - mse: 1.2719 - val_loss: 12.7470 - val_mae: 0.9603 - val_mse: 1.7193\n",
      "Epoch 150/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1145 - mae: 0.8681 - mse: 1.2691 - val_loss: 12.7396 - val_mae: 0.9869 - val_mse: 1.7849\n",
      "Epoch 151/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1133 - mae: 0.8677 - mse: 1.2663 - val_loss: 12.7286 - val_mae: 1.0328 - val_mse: 1.9052\n",
      "Epoch 152/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1113 - mae: 0.8656 - mse: 1.2641 - val_loss: 12.7352 - val_mae: 1.0362 - val_mse: 1.8875\n",
      "Epoch 153/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1093 - mae: 0.8662 - mse: 1.2645 - val_loss: 12.7278 - val_mae: 0.9981 - val_mse: 1.8151\n",
      "Epoch 154/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1095 - mae: 0.8664 - mse: 1.2641 - val_loss: 12.7256 - val_mae: 1.0091 - val_mse: 1.8433\n",
      "Epoch 155/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1065 - mae: 0.8655 - mse: 1.2615 - val_loss: 12.7308 - val_mae: 1.0010 - val_mse: 1.8289\n",
      "Epoch 156/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.1037 - mae: 0.8645 - mse: 1.2599 - val_loss: 12.8033 - val_mae: 0.8978 - val_mse: 1.5703\n",
      "Epoch 157/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1040 - mae: 0.8644 - mse: 1.2586 - val_loss: 12.7322 - val_mae: 0.9497 - val_mse: 1.6804\n",
      "Epoch 158/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.1014 - mae: 0.8639 - mse: 1.2561 - val_loss: 12.7589 - val_mae: 1.0260 - val_mse: 1.9216\n",
      "Epoch 159/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0995 - mae: 0.8634 - mse: 1.2551 - val_loss: 12.7227 - val_mae: 0.9690 - val_mse: 1.7273\n",
      "Epoch 160/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0994 - mae: 0.8633 - mse: 1.2549 - val_loss: 12.7147 - val_mae: 1.0085 - val_mse: 1.8351\n",
      "Epoch 161/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0962 - mae: 0.8632 - mse: 1.2517 - val_loss: 12.7274 - val_mae: 0.9497 - val_mse: 1.6874\n",
      "Epoch 162/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0947 - mae: 0.8624 - mse: 1.2515 - val_loss: 12.7268 - val_mae: 0.9481 - val_mse: 1.6774\n",
      "Epoch 163/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0929 - mae: 0.8612 - mse: 1.2495 - val_loss: 12.7534 - val_mae: 0.9136 - val_mse: 1.5898\n",
      "Epoch 164/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0915 - mae: 0.8619 - mse: 1.2487 - val_loss: 12.7107 - val_mae: 1.0145 - val_mse: 1.8364\n",
      "Epoch 165/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0901 - mae: 0.8611 - mse: 1.2473 - val_loss: 12.7372 - val_mae: 0.9703 - val_mse: 1.7599\n",
      "Epoch 166/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0890 - mae: 0.8600 - mse: 1.2455 - val_loss: 12.7292 - val_mae: 0.9361 - val_mse: 1.6340\n",
      "Epoch 167/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0872 - mae: 0.8598 - mse: 1.2434 - val_loss: 12.7182 - val_mae: 1.0710 - val_mse: 1.9865\n",
      "Epoch 168/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0870 - mae: 0.8607 - mse: 1.2441 - val_loss: 12.7240 - val_mae: 0.9810 - val_mse: 1.7781\n",
      "Epoch 169/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0843 - mae: 0.8591 - mse: 1.2415 - val_loss: 12.7207 - val_mae: 1.0809 - val_mse: 2.0208\n",
      "Epoch 170/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0823 - mae: 0.8593 - mse: 1.2412 - val_loss: 12.7426 - val_mae: 1.0085 - val_mse: 1.8640\n",
      "Epoch 171/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0818 - mae: 0.8578 - mse: 1.2386 - val_loss: 12.6989 - val_mae: 1.0228 - val_mse: 1.8644\n",
      "Epoch 172/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0805 - mae: 0.8577 - mse: 1.2370 - val_loss: 12.6963 - val_mae: 1.0254 - val_mse: 1.8699\n",
      "Epoch 173/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0786 - mae: 0.8582 - mse: 1.2366 - val_loss: 12.7797 - val_mae: 0.8944 - val_mse: 1.5635\n",
      "Epoch 174/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0776 - mae: 0.8569 - mse: 1.2350 - val_loss: 12.6945 - val_mae: 1.0273 - val_mse: 1.8554\n",
      "Epoch 175/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0755 - mae: 0.8576 - mse: 1.2348 - val_loss: 12.7470 - val_mae: 0.8981 - val_mse: 1.5442\n",
      "Epoch 176/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0742 - mae: 0.8562 - mse: 1.2320 - val_loss: 12.6979 - val_mae: 1.0447 - val_mse: 1.9336\n",
      "Epoch 177/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0728 - mae: 0.8563 - mse: 1.2320 - val_loss: 12.7071 - val_mae: 0.9578 - val_mse: 1.7111\n",
      "Epoch 178/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0703 - mae: 0.8550 - mse: 1.2277 - val_loss: 12.6852 - val_mae: 0.9955 - val_mse: 1.7979\n",
      "Epoch 179/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0703 - mae: 0.8550 - mse: 1.2295 - val_loss: 12.6902 - val_mae: 0.9651 - val_mse: 1.7201\n",
      "Epoch 180/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0693 - mae: 0.8554 - mse: 1.2270 - val_loss: 12.6936 - val_mae: 0.9836 - val_mse: 1.7791\n",
      "Epoch 181/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0683 - mae: 0.8562 - mse: 1.2298 - val_loss: 12.6888 - val_mae: 0.9807 - val_mse: 1.7342\n",
      "Epoch 182/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0669 - mae: 0.8549 - mse: 1.2275 - val_loss: 12.6834 - val_mae: 0.9551 - val_mse: 1.6856\n",
      "Epoch 183/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.0650 - mae: 0.8531 - mse: 1.2234 - val_loss: 12.7097 - val_mae: 1.0717 - val_mse: 1.9934\n",
      "Epoch 184/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.0627 - mae: 0.8535 - mse: 1.2224 - val_loss: 12.6906 - val_mae: 0.9388 - val_mse: 1.6392\n",
      "Epoch 185/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0626 - mae: 0.8535 - mse: 1.2219 - val_loss: 12.6764 - val_mae: 1.0384 - val_mse: 1.9012\n",
      "Epoch 186/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0612 - mae: 0.8528 - mse: 1.2228 - val_loss: 12.6654 - val_mae: 1.0047 - val_mse: 1.8013\n",
      "Epoch 187/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.0602 - mae: 0.8526 - mse: 1.2197 - val_loss: 12.6721 - val_mae: 1.0157 - val_mse: 1.8416\n",
      "Epoch 188/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0583 - mae: 0.8522 - mse: 1.2195 - val_loss: 12.6873 - val_mae: 0.9428 - val_mse: 1.6642\n",
      "Epoch 189/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0583 - mae: 0.8520 - mse: 1.2188 - val_loss: 12.7004 - val_mae: 0.9695 - val_mse: 1.6843\n",
      "Epoch 190/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0565 - mae: 0.8517 - mse: 1.2176 - val_loss: 12.6666 - val_mae: 0.9854 - val_mse: 1.7581\n",
      "Epoch 191/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0556 - mae: 0.8509 - mse: 1.2159 - val_loss: 12.6856 - val_mae: 0.9322 - val_mse: 1.6306\n",
      "Epoch 192/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0540 - mae: 0.8499 - mse: 1.2143 - val_loss: 12.6730 - val_mae: 0.9394 - val_mse: 1.6318\n",
      "Epoch 193/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0511 - mae: 0.8504 - mse: 1.2116 - val_loss: 12.6596 - val_mae: 0.9632 - val_mse: 1.6917\n",
      "Epoch 194/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0504 - mae: 0.8498 - mse: 1.2117 - val_loss: 12.6518 - val_mae: 0.9866 - val_mse: 1.7472\n",
      "Epoch 195/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0497 - mae: 0.8500 - mse: 1.2122 - val_loss: 12.6568 - val_mae: 0.9810 - val_mse: 1.7254\n",
      "Epoch 196/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0490 - mae: 0.8496 - mse: 1.2106 - val_loss: 12.6672 - val_mae: 0.9569 - val_mse: 1.6823\n",
      "Epoch 197/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0463 - mae: 0.8485 - mse: 1.2065 - val_loss: 12.6808 - val_mae: 1.0909 - val_mse: 2.0276\n",
      "Epoch 198/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0459 - mae: 0.8489 - mse: 1.2085 - val_loss: 12.6712 - val_mae: 1.0081 - val_mse: 1.8375\n",
      "Epoch 199/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0453 - mae: 0.8480 - mse: 1.2065 - val_loss: 12.6870 - val_mae: 0.9191 - val_mse: 1.5987\n",
      "Epoch 200/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0436 - mae: 0.8478 - mse: 1.2057 - val_loss: 12.6564 - val_mae: 0.9408 - val_mse: 1.6251\n",
      "Epoch 201/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0428 - mae: 0.8474 - mse: 1.2037 - val_loss: 12.6528 - val_mae: 0.9575 - val_mse: 1.6904\n",
      "Epoch 202/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0420 - mae: 0.8481 - mse: 1.2055 - val_loss: 12.6478 - val_mae: 1.0126 - val_mse: 1.7991\n",
      "Epoch 203/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0399 - mae: 0.8463 - mse: 1.2016 - val_loss: 12.6612 - val_mae: 1.0680 - val_mse: 1.9656\n",
      "Epoch 204/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0398 - mae: 0.8472 - mse: 1.2030 - val_loss: 12.6501 - val_mae: 0.9401 - val_mse: 1.6187\n",
      "Epoch 205/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0387 - mae: 0.8463 - mse: 1.2000 - val_loss: 12.6328 - val_mae: 0.9703 - val_mse: 1.7090\n",
      "Epoch 206/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0364 - mae: 0.8467 - mse: 1.2003 - val_loss: 12.6554 - val_mae: 0.9380 - val_mse: 1.6410\n",
      "Epoch 207/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0342 - mae: 0.8451 - mse: 1.1956 - val_loss: 12.6318 - val_mae: 0.9948 - val_mse: 1.7598\n",
      "Epoch 208/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0345 - mae: 0.8458 - mse: 1.1974 - val_loss: 12.6704 - val_mae: 1.0794 - val_mse: 2.0133\n",
      "Epoch 209/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0327 - mae: 0.8445 - mse: 1.1959 - val_loss: 12.6320 - val_mae: 0.9704 - val_mse: 1.6977\n",
      "Epoch 210/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0327 - mae: 0.8445 - mse: 1.1962 - val_loss: 12.6451 - val_mae: 0.9505 - val_mse: 1.6727\n",
      "Epoch 211/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0313 - mae: 0.8441 - mse: 1.1943 - val_loss: 12.6424 - val_mae: 1.0423 - val_mse: 1.8991\n",
      "Epoch 212/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0302 - mae: 0.8445 - mse: 1.1946 - val_loss: 12.7271 - val_mae: 0.8681 - val_mse: 1.4765\n",
      "Epoch 213/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0287 - mae: 0.8437 - mse: 1.1913 - val_loss: 12.6574 - val_mae: 1.0621 - val_mse: 1.9255\n",
      "Epoch 214/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0275 - mae: 0.8428 - mse: 1.1903 - val_loss: 12.6488 - val_mae: 1.0763 - val_mse: 1.9916\n",
      "Epoch 215/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0274 - mae: 0.8437 - mse: 1.1921 - val_loss: 12.6438 - val_mae: 0.9271 - val_mse: 1.6104\n",
      "Epoch 216/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0254 - mae: 0.8416 - mse: 1.1878 - val_loss: 12.6303 - val_mae: 1.0168 - val_mse: 1.8343\n",
      "Epoch 217/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0252 - mae: 0.8433 - mse: 1.1894 - val_loss: 12.6318 - val_mae: 0.9934 - val_mse: 1.7802\n",
      "Epoch 218/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0245 - mae: 0.8431 - mse: 1.1876 - val_loss: 12.6218 - val_mae: 0.9440 - val_mse: 1.6254\n",
      "Epoch 219/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0218 - mae: 0.8411 - mse: 1.1846 - val_loss: 12.6475 - val_mae: 1.0597 - val_mse: 1.9640\n",
      "Epoch 220/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0230 - mae: 0.8421 - mse: 1.1878 - val_loss: 12.6128 - val_mae: 0.9949 - val_mse: 1.7427\n",
      "Epoch 221/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.0213 - mae: 0.8420 - mse: 1.1868 - val_loss: 12.6194 - val_mae: 0.9496 - val_mse: 1.6500\n",
      "Epoch 222/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 12.0197 - mae: 0.8411 - mse: 1.1832 - val_loss: 12.6204 - val_mae: 0.9613 - val_mse: 1.6850\n",
      "Epoch 223/1000\n",
      "18102/18102 [==============================] - 1s 43us/sample - loss: 12.0194 - mae: 0.8408 - mse: 1.1828 - val_loss: 12.6105 - val_mae: 0.9956 - val_mse: 1.7716\n",
      "Epoch 224/1000\n",
      "18102/18102 [==============================] - 1s 42us/sample - loss: 12.0184 - mae: 0.8413 - mse: 1.1834 - val_loss: 12.6252 - val_mae: 0.9617 - val_mse: 1.6933\n",
      "Epoch 225/1000\n",
      "18102/18102 [==============================] - 1s 42us/sample - loss: 12.0176 - mae: 0.8404 - mse: 1.1807 - val_loss: 12.6118 - val_mae: 1.0198 - val_mse: 1.8144\n",
      "Epoch 226/1000\n",
      "18102/18102 [==============================] - 1s 40us/sample - loss: 12.0160 - mae: 0.8399 - mse: 1.1801 - val_loss: 12.6180 - val_mae: 1.0320 - val_mse: 1.8437\n",
      "Epoch 227/1000\n",
      "18102/18102 [==============================] - 1s 41us/sample - loss: 12.0149 - mae: 0.8402 - mse: 1.1803 - val_loss: 12.6140 - val_mae: 0.9549 - val_mse: 1.6389\n",
      "Epoch 228/1000\n",
      "18102/18102 [==============================] - 1s 41us/sample - loss: 12.0134 - mae: 0.8388 - mse: 1.1777 - val_loss: 12.6272 - val_mae: 0.9992 - val_mse: 1.7883\n",
      "Epoch 229/1000\n",
      "18102/18102 [==============================] - 1s 39us/sample - loss: 12.0127 - mae: 0.8393 - mse: 1.1769 - val_loss: 12.6173 - val_mae: 0.9945 - val_mse: 1.7855\n",
      "Epoch 230/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 12.0107 - mae: 0.8389 - mse: 1.1758 - val_loss: 12.6085 - val_mae: 0.9548 - val_mse: 1.6603\n",
      "Epoch 231/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0118 - mae: 0.8390 - mse: 1.1769 - val_loss: 12.6029 - val_mae: 1.0112 - val_mse: 1.7831\n",
      "Epoch 232/1000\n",
      "18102/18102 [==============================] - 1s 40us/sample - loss: 12.0091 - mae: 0.8384 - mse: 1.1746 - val_loss: 12.5959 - val_mae: 0.9879 - val_mse: 1.7383\n",
      "Epoch 233/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 12.0092 - mae: 0.8385 - mse: 1.1749 - val_loss: 12.6435 - val_mae: 0.9419 - val_mse: 1.6601\n",
      "Epoch 234/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 12.0083 - mae: 0.8373 - mse: 1.1737 - val_loss: 12.6093 - val_mae: 0.9346 - val_mse: 1.6125\n",
      "Epoch 235/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 12.0071 - mae: 0.8381 - mse: 1.1726 - val_loss: 12.6648 - val_mae: 0.8741 - val_mse: 1.4696\n",
      "Epoch 236/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 12.0064 - mae: 0.8371 - mse: 1.1708 - val_loss: 12.5912 - val_mae: 0.9754 - val_mse: 1.7053\n",
      "Epoch 237/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 12.0051 - mae: 0.8371 - mse: 1.1717 - val_loss: 12.6068 - val_mae: 0.9833 - val_mse: 1.7444\n",
      "Epoch 238/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 12.0041 - mae: 0.8370 - mse: 1.1712 - val_loss: 12.6074 - val_mae: 0.9247 - val_mse: 1.5732\n",
      "Epoch 239/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 12.0035 - mae: 0.8366 - mse: 1.1706 - val_loss: 12.6057 - val_mae: 0.9742 - val_mse: 1.7227\n",
      "Epoch 240/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.0023 - mae: 0.8368 - mse: 1.1693 - val_loss: 12.5935 - val_mae: 0.9582 - val_mse: 1.6620\n",
      "Epoch 241/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.0014 - mae: 0.8363 - mse: 1.1674 - val_loss: 12.6237 - val_mae: 0.8938 - val_mse: 1.5012\n",
      "Epoch 242/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 12.0012 - mae: 0.8365 - mse: 1.1670 - val_loss: 12.6015 - val_mae: 0.9453 - val_mse: 1.6122\n",
      "Epoch 243/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9995 - mae: 0.8349 - mse: 1.1652 - val_loss: 12.6224 - val_mae: 1.0628 - val_mse: 1.9516\n",
      "Epoch 244/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9990 - mae: 0.8359 - mse: 1.1660 - val_loss: 12.5921 - val_mae: 0.9521 - val_mse: 1.6470\n",
      "Epoch 245/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9980 - mae: 0.8343 - mse: 1.1633 - val_loss: 12.5901 - val_mae: 0.9740 - val_mse: 1.7141\n",
      "Epoch 246/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9982 - mae: 0.8350 - mse: 1.1648 - val_loss: 12.5855 - val_mae: 0.9846 - val_mse: 1.7127\n",
      "Epoch 247/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9955 - mae: 0.8342 - mse: 1.1624 - val_loss: 12.5885 - val_mae: 0.9342 - val_mse: 1.5911\n",
      "Epoch 248/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9958 - mae: 0.8348 - mse: 1.1632 - val_loss: 12.5844 - val_mae: 0.9948 - val_mse: 1.7456\n",
      "Epoch 249/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9944 - mae: 0.8335 - mse: 1.1610 - val_loss: 12.5793 - val_mae: 0.9701 - val_mse: 1.6908\n",
      "Epoch 250/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9939 - mae: 0.8345 - mse: 1.1625 - val_loss: 12.6151 - val_mae: 0.8958 - val_mse: 1.5158\n",
      "Epoch 251/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9924 - mae: 0.8331 - mse: 1.1593 - val_loss: 12.5962 - val_mae: 0.9681 - val_mse: 1.7048\n",
      "Epoch 252/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9929 - mae: 0.8330 - mse: 1.1590 - val_loss: 12.5804 - val_mae: 1.0056 - val_mse: 1.7596\n",
      "Epoch 253/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9905 - mae: 0.8324 - mse: 1.1578 - val_loss: 12.5837 - val_mae: 1.0114 - val_mse: 1.7682\n",
      "Epoch 254/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9901 - mae: 0.8332 - mse: 1.1576 - val_loss: 12.5913 - val_mae: 1.0547 - val_mse: 1.8833\n",
      "Epoch 255/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9896 - mae: 0.8322 - mse: 1.1562 - val_loss: 12.6152 - val_mae: 1.0599 - val_mse: 1.8744\n",
      "Epoch 256/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9891 - mae: 0.8327 - mse: 1.1567 - val_loss: 12.6069 - val_mae: 1.0220 - val_mse: 1.8541\n",
      "Epoch 257/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9878 - mae: 0.8318 - mse: 1.1550 - val_loss: 12.5922 - val_mae: 1.0382 - val_mse: 1.8354\n",
      "Epoch 258/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9876 - mae: 0.8323 - mse: 1.1558 - val_loss: 12.5786 - val_mae: 1.0231 - val_mse: 1.8054\n",
      "Epoch 259/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9860 - mae: 0.8317 - mse: 1.1546 - val_loss: 12.5727 - val_mae: 0.9898 - val_mse: 1.7219\n",
      "Epoch 260/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9851 - mae: 0.8318 - mse: 1.1546 - val_loss: 12.5769 - val_mae: 0.9711 - val_mse: 1.7010\n",
      "Epoch 261/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9849 - mae: 0.8318 - mse: 1.1538 - val_loss: 12.5695 - val_mae: 0.9504 - val_mse: 1.6242\n",
      "Epoch 262/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9836 - mae: 0.8304 - mse: 1.1511 - val_loss: 12.5927 - val_mae: 0.9378 - val_mse: 1.6204\n",
      "Epoch 263/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9812 - mae: 0.8308 - mse: 1.1504 - val_loss: 12.5650 - val_mae: 1.0110 - val_mse: 1.7777\n",
      "Epoch 264/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9816 - mae: 0.8308 - mse: 1.1503 - val_loss: 12.5607 - val_mae: 0.9517 - val_mse: 1.6290\n",
      "Epoch 265/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9803 - mae: 0.8302 - mse: 1.1475 - val_loss: 12.5690 - val_mae: 1.0204 - val_mse: 1.7942\n",
      "Epoch 266/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9796 - mae: 0.8296 - mse: 1.1491 - val_loss: 12.5900 - val_mae: 0.9017 - val_mse: 1.5132\n",
      "Epoch 267/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9796 - mae: 0.8305 - mse: 1.1494 - val_loss: 12.5640 - val_mae: 0.9476 - val_mse: 1.6166\n",
      "Epoch 268/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9798 - mae: 0.8300 - mse: 1.1493 - val_loss: 12.5635 - val_mae: 0.9693 - val_mse: 1.6824\n",
      "Epoch 269/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9793 - mae: 0.8303 - mse: 1.1481 - val_loss: 12.5741 - val_mae: 1.0331 - val_mse: 1.8289\n",
      "Epoch 270/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9770 - mae: 0.8290 - mse: 1.1460 - val_loss: 12.5579 - val_mae: 0.9810 - val_mse: 1.7059\n",
      "Epoch 271/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9770 - mae: 0.8291 - mse: 1.1465 - val_loss: 12.5756 - val_mae: 1.0200 - val_mse: 1.7820\n",
      "Epoch 272/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9760 - mae: 0.8287 - mse: 1.1469 - val_loss: 12.5584 - val_mae: 0.9936 - val_mse: 1.7488\n",
      "Epoch 273/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9751 - mae: 0.8284 - mse: 1.1447 - val_loss: 12.5818 - val_mae: 0.9679 - val_mse: 1.7043\n",
      "Epoch 274/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9745 - mae: 0.8287 - mse: 1.1441 - val_loss: 12.5589 - val_mae: 1.0117 - val_mse: 1.7700\n",
      "Epoch 275/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9728 - mae: 0.8275 - mse: 1.1415 - val_loss: 12.5534 - val_mae: 0.9836 - val_mse: 1.7120\n",
      "Epoch 276/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9720 - mae: 0.8275 - mse: 1.1419 - val_loss: 12.5612 - val_mae: 0.9613 - val_mse: 1.6741\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9715 - mae: 0.8281 - mse: 1.1414 - val_loss: 12.5518 - val_mae: 0.9613 - val_mse: 1.6667\n",
      "Epoch 278/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9704 - mae: 0.8277 - mse: 1.1410 - val_loss: 12.5503 - val_mae: 0.9560 - val_mse: 1.6268\n",
      "Epoch 279/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9708 - mae: 0.8271 - mse: 1.1408 - val_loss: 12.5610 - val_mae: 0.9656 - val_mse: 1.6428\n",
      "Epoch 280/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9696 - mae: 0.8274 - mse: 1.1411 - val_loss: 12.5510 - val_mae: 0.9308 - val_mse: 1.5797\n",
      "Epoch 281/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9672 - mae: 0.8262 - mse: 1.1370 - val_loss: 12.5655 - val_mae: 1.0157 - val_mse: 1.7668\n",
      "Epoch 282/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9680 - mae: 0.8275 - mse: 1.1386 - val_loss: 12.5665 - val_mae: 0.9452 - val_mse: 1.6388\n",
      "Epoch 283/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9670 - mae: 0.8266 - mse: 1.1378 - val_loss: 12.5477 - val_mae: 1.0047 - val_mse: 1.7443\n",
      "Epoch 284/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9658 - mae: 0.8258 - mse: 1.1361 - val_loss: 12.5548 - val_mae: 1.0224 - val_mse: 1.8064\n",
      "Epoch 285/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9650 - mae: 0.8259 - mse: 1.1360 - val_loss: 12.5753 - val_mae: 1.0712 - val_mse: 1.9261\n",
      "Epoch 286/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9662 - mae: 0.8265 - mse: 1.1374 - val_loss: 12.5644 - val_mae: 0.9659 - val_mse: 1.6957\n",
      "Epoch 287/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9646 - mae: 0.8259 - mse: 1.1350 - val_loss: 12.5438 - val_mae: 1.0052 - val_mse: 1.7643\n",
      "Epoch 288/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9628 - mae: 0.8251 - mse: 1.1324 - val_loss: 12.5372 - val_mae: 0.9867 - val_mse: 1.7149\n",
      "Epoch 289/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9631 - mae: 0.8251 - mse: 1.1325 - val_loss: 12.5660 - val_mae: 1.0599 - val_mse: 1.9061\n",
      "Epoch 290/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9614 - mae: 0.8252 - mse: 1.1334 - val_loss: 12.5439 - val_mae: 0.9400 - val_mse: 1.5820\n",
      "Epoch 291/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9607 - mae: 0.8254 - mse: 1.1317 - val_loss: 12.5346 - val_mae: 0.9933 - val_mse: 1.7345\n",
      "Epoch 292/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9612 - mae: 0.8251 - mse: 1.1330 - val_loss: 12.5424 - val_mae: 0.9821 - val_mse: 1.7108\n",
      "Epoch 293/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9600 - mae: 0.8248 - mse: 1.1317 - val_loss: 12.5465 - val_mae: 0.9499 - val_mse: 1.6373\n",
      "Epoch 294/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9585 - mae: 0.8238 - mse: 1.1302 - val_loss: 12.5620 - val_mae: 0.8937 - val_mse: 1.4739\n",
      "Epoch 295/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9593 - mae: 0.8245 - mse: 1.1299 - val_loss: 12.5509 - val_mae: 1.0091 - val_mse: 1.7944\n",
      "Epoch 296/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9580 - mae: 0.8239 - mse: 1.1293 - val_loss: 12.5600 - val_mae: 1.0348 - val_mse: 1.8562\n",
      "Epoch 297/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9572 - mae: 0.8245 - mse: 1.1290 - val_loss: 12.5342 - val_mae: 0.9598 - val_mse: 1.6582\n",
      "Epoch 298/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9568 - mae: 0.8234 - mse: 1.1290 - val_loss: 12.5355 - val_mae: 0.9929 - val_mse: 1.7355\n",
      "Epoch 299/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9571 - mae: 0.8236 - mse: 1.1284 - val_loss: 12.5940 - val_mae: 1.0596 - val_mse: 1.9405\n",
      "Epoch 300/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9549 - mae: 0.8230 - mse: 1.1278 - val_loss: 12.5641 - val_mae: 0.9064 - val_mse: 1.5323\n",
      "Epoch 301/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9546 - mae: 0.8232 - mse: 1.1265 - val_loss: 12.5307 - val_mae: 0.9686 - val_mse: 1.6728\n",
      "Epoch 302/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9536 - mae: 0.8232 - mse: 1.1246 - val_loss: 12.5334 - val_mae: 0.9263 - val_mse: 1.5653\n",
      "Epoch 303/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9532 - mae: 0.8228 - mse: 1.1256 - val_loss: 12.5258 - val_mae: 0.9664 - val_mse: 1.6535\n",
      "Epoch 304/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9543 - mae: 0.8237 - mse: 1.1264 - val_loss: 12.5568 - val_mae: 0.9791 - val_mse: 1.7238\n",
      "Epoch 305/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9516 - mae: 0.8223 - mse: 1.1241 - val_loss: 12.5673 - val_mae: 1.0461 - val_mse: 1.9044\n",
      "Epoch 306/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9513 - mae: 0.8226 - mse: 1.1236 - val_loss: 12.5656 - val_mae: 1.0618 - val_mse: 1.9342\n",
      "Epoch 307/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9497 - mae: 0.8218 - mse: 1.1233 - val_loss: 12.5223 - val_mae: 0.9782 - val_mse: 1.6759\n",
      "Epoch 308/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9485 - mae: 0.8217 - mse: 1.1217 - val_loss: 12.5201 - val_mae: 0.9665 - val_mse: 1.6455\n",
      "Epoch 309/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9488 - mae: 0.8226 - mse: 1.1224 - val_loss: 12.5524 - val_mae: 0.8860 - val_mse: 1.4635\n",
      "Epoch 310/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9485 - mae: 0.8211 - mse: 1.1198 - val_loss: 12.5270 - val_mae: 0.9963 - val_mse: 1.7206\n",
      "Epoch 311/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9484 - mae: 0.8218 - mse: 1.1217 - val_loss: 12.5489 - val_mae: 0.8944 - val_mse: 1.4923\n",
      "Epoch 312/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9474 - mae: 0.8215 - mse: 1.1198 - val_loss: 12.5461 - val_mae: 0.8998 - val_mse: 1.5025\n",
      "Epoch 313/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9461 - mae: 0.8212 - mse: 1.1185 - val_loss: 12.5197 - val_mae: 0.9630 - val_mse: 1.6596\n",
      "Epoch 314/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9454 - mae: 0.8213 - mse: 1.1200 - val_loss: 12.5554 - val_mae: 0.8780 - val_mse: 1.4345\n",
      "Epoch 315/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9454 - mae: 0.8204 - mse: 1.1176 - val_loss: 12.5370 - val_mae: 0.9857 - val_mse: 1.7331\n",
      "Epoch 316/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9446 - mae: 0.8207 - mse: 1.1191 - val_loss: 12.5115 - val_mae: 0.9595 - val_mse: 1.6333\n",
      "Epoch 317/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9437 - mae: 0.8203 - mse: 1.1181 - val_loss: 12.5323 - val_mae: 0.9272 - val_mse: 1.5798\n",
      "Epoch 318/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9443 - mae: 0.8208 - mse: 1.1166 - val_loss: 12.5342 - val_mae: 0.9646 - val_mse: 1.6782\n",
      "Epoch 319/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9421 - mae: 0.8204 - mse: 1.1172 - val_loss: 12.6118 - val_mae: 0.8335 - val_mse: 1.3505\n",
      "Epoch 320/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9421 - mae: 0.8198 - mse: 1.1154 - val_loss: 12.5129 - val_mae: 0.9413 - val_mse: 1.5981\n",
      "Epoch 321/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9409 - mae: 0.8191 - mse: 1.1141 - val_loss: 12.5095 - val_mae: 0.9458 - val_mse: 1.5897\n",
      "Epoch 322/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9413 - mae: 0.8201 - mse: 1.1155 - val_loss: 12.5389 - val_mae: 0.9447 - val_mse: 1.6288\n",
      "Epoch 323/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9401 - mae: 0.8197 - mse: 1.1144 - val_loss: 12.5539 - val_mae: 0.8888 - val_mse: 1.4829\n",
      "Epoch 324/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9395 - mae: 0.8190 - mse: 1.1126 - val_loss: 12.5348 - val_mae: 1.0188 - val_mse: 1.8144\n",
      "Epoch 325/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9391 - mae: 0.8190 - mse: 1.1144 - val_loss: 12.5174 - val_mae: 0.9416 - val_mse: 1.5810\n",
      "Epoch 326/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9387 - mae: 0.8195 - mse: 1.1130 - val_loss: 12.5259 - val_mae: 0.8942 - val_mse: 1.4751\n",
      "Epoch 327/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9387 - mae: 0.8187 - mse: 1.1118 - val_loss: 12.5228 - val_mae: 0.9543 - val_mse: 1.6477\n",
      "Epoch 328/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9370 - mae: 0.8191 - mse: 1.1122 - val_loss: 12.5261 - val_mae: 0.9711 - val_mse: 1.6896\n",
      "Epoch 329/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9371 - mae: 0.8180 - mse: 1.1112 - val_loss: 12.5044 - val_mae: 0.9842 - val_mse: 1.7089\n",
      "Epoch 330/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9347 - mae: 0.8178 - mse: 1.1096 - val_loss: 12.5145 - val_mae: 0.9499 - val_mse: 1.6238\n",
      "Epoch 331/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9361 - mae: 0.8190 - mse: 1.1120 - val_loss: 12.5264 - val_mae: 0.8962 - val_mse: 1.4924\n",
      "Epoch 332/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9346 - mae: 0.8176 - mse: 1.1085 - val_loss: 12.5292 - val_mae: 1.0444 - val_mse: 1.8325\n",
      "Epoch 333/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9346 - mae: 0.8185 - mse: 1.1099 - val_loss: 12.5086 - val_mae: 0.9535 - val_mse: 1.6116\n",
      "Epoch 334/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9340 - mae: 0.8176 - mse: 1.1082 - val_loss: 12.5379 - val_mae: 1.0041 - val_mse: 1.7845\n",
      "Epoch 335/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9340 - mae: 0.8185 - mse: 1.1104 - val_loss: 12.5059 - val_mae: 0.9302 - val_mse: 1.5631\n",
      "Epoch 336/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9328 - mae: 0.8171 - mse: 1.1075 - val_loss: 12.6108 - val_mae: 1.1544 - val_mse: 2.1283\n",
      "Epoch 337/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9322 - mae: 0.8185 - mse: 1.1093 - val_loss: 12.5292 - val_mae: 0.8897 - val_mse: 1.4534\n",
      "Epoch 338/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9311 - mae: 0.8174 - mse: 1.1065 - val_loss: 12.5345 - val_mae: 0.8748 - val_mse: 1.4315\n",
      "Epoch 339/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9312 - mae: 0.8177 - mse: 1.1067 - val_loss: 12.5167 - val_mae: 0.9119 - val_mse: 1.5295\n",
      "Epoch 340/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9293 - mae: 0.8171 - mse: 1.1050 - val_loss: 12.5132 - val_mae: 1.0115 - val_mse: 1.7682\n",
      "Epoch 341/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9301 - mae: 0.8168 - mse: 1.1061 - val_loss: 12.5436 - val_mae: 0.9078 - val_mse: 1.5361\n",
      "Epoch 342/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9295 - mae: 0.8166 - mse: 1.1051 - val_loss: 12.5188 - val_mae: 0.9445 - val_mse: 1.6226\n",
      "Epoch 343/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9282 - mae: 0.8166 - mse: 1.1047 - val_loss: 12.5221 - val_mae: 0.8818 - val_mse: 1.4480\n",
      "Epoch 344/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9283 - mae: 0.8157 - mse: 1.1029 - val_loss: 12.5071 - val_mae: 1.0012 - val_mse: 1.7418\n",
      "Epoch 345/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9265 - mae: 0.8171 - mse: 1.1032 - val_loss: 12.4971 - val_mae: 0.9961 - val_mse: 1.7281\n",
      "Epoch 346/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9262 - mae: 0.8160 - mse: 1.1032 - val_loss: 12.5006 - val_mae: 0.9429 - val_mse: 1.5804\n",
      "Epoch 347/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9265 - mae: 0.8160 - mse: 1.1023 - val_loss: 12.5126 - val_mae: 0.9945 - val_mse: 1.7336\n",
      "Epoch 348/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9259 - mae: 0.8161 - mse: 1.1024 - val_loss: 12.5158 - val_mae: 1.0045 - val_mse: 1.7762\n",
      "Epoch 349/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9258 - mae: 0.8162 - mse: 1.1027 - val_loss: 12.5073 - val_mae: 0.9138 - val_mse: 1.5376\n",
      "Epoch 350/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9249 - mae: 0.8152 - mse: 1.1018 - val_loss: 12.4940 - val_mae: 0.9946 - val_mse: 1.7118\n",
      "Epoch 351/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9252 - mae: 0.8163 - mse: 1.1031 - val_loss: 12.4959 - val_mae: 0.9137 - val_mse: 1.5061\n",
      "Epoch 352/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9238 - mae: 0.8150 - mse: 1.1003 - val_loss: 12.5079 - val_mae: 0.8971 - val_mse: 1.4831\n",
      "Epoch 353/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9229 - mae: 0.8149 - mse: 1.0986 - val_loss: 12.5052 - val_mae: 1.0091 - val_mse: 1.7407\n",
      "Epoch 354/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9231 - mae: 0.8156 - mse: 1.1003 - val_loss: 12.4983 - val_mae: 0.9943 - val_mse: 1.7308\n",
      "Epoch 355/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9214 - mae: 0.8151 - mse: 1.0987 - val_loss: 12.4861 - val_mae: 0.9677 - val_mse: 1.6499\n",
      "Epoch 356/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9207 - mae: 0.8147 - mse: 1.0979 - val_loss: 12.5136 - val_mae: 0.8770 - val_mse: 1.4305\n",
      "Epoch 357/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9208 - mae: 0.8139 - mse: 1.0979 - val_loss: 12.4952 - val_mae: 0.9360 - val_mse: 1.5577\n",
      "Epoch 358/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9191 - mae: 0.8144 - mse: 1.0964 - val_loss: 12.4884 - val_mae: 0.9334 - val_mse: 1.5629\n",
      "Epoch 359/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9203 - mae: 0.8138 - mse: 1.0970 - val_loss: 12.5074 - val_mae: 0.9206 - val_mse: 1.5476\n",
      "Epoch 360/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9199 - mae: 0.8146 - mse: 1.0976 - val_loss: 12.4827 - val_mae: 0.9626 - val_mse: 1.6353\n",
      "Epoch 361/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9178 - mae: 0.8136 - mse: 1.0951 - val_loss: 12.5072 - val_mae: 1.0082 - val_mse: 1.7722\n",
      "Epoch 362/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9186 - mae: 0.8133 - mse: 1.0958 - val_loss: 12.5270 - val_mae: 1.0135 - val_mse: 1.8029\n",
      "Epoch 363/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9169 - mae: 0.8134 - mse: 1.0943 - val_loss: 12.5102 - val_mae: 1.0018 - val_mse: 1.7609\n",
      "Epoch 364/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9164 - mae: 0.8144 - mse: 1.0949 - val_loss: 12.5318 - val_mae: 0.8611 - val_mse: 1.3837\n",
      "Epoch 365/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9161 - mae: 0.8129 - mse: 1.0926 - val_loss: 12.4799 - val_mae: 0.9770 - val_mse: 1.6721\n",
      "Epoch 366/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9155 - mae: 0.8124 - mse: 1.0936 - val_loss: 12.4955 - val_mae: 0.9755 - val_mse: 1.6539\n",
      "Epoch 367/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9148 - mae: 0.8137 - mse: 1.0942 - val_loss: 12.4961 - val_mae: 0.9225 - val_mse: 1.5519\n",
      "Epoch 368/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9132 - mae: 0.8119 - mse: 1.0898 - val_loss: 12.4817 - val_mae: 0.9623 - val_mse: 1.6451\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9136 - mae: 0.8130 - mse: 1.0923 - val_loss: 12.4997 - val_mae: 1.0161 - val_mse: 1.7529\n",
      "Epoch 370/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9137 - mae: 0.8130 - mse: 1.0924 - val_loss: 12.5234 - val_mae: 1.0476 - val_mse: 1.8792\n",
      "Epoch 371/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9133 - mae: 0.8125 - mse: 1.0915 - val_loss: 12.5339 - val_mae: 0.9081 - val_mse: 1.5379\n",
      "Epoch 372/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9132 - mae: 0.8125 - mse: 1.0916 - val_loss: 12.4882 - val_mae: 1.0021 - val_mse: 1.7177\n",
      "Epoch 373/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9130 - mae: 0.8125 - mse: 1.0919 - val_loss: 12.4914 - val_mae: 0.9252 - val_mse: 1.5475\n",
      "Epoch 374/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9100 - mae: 0.8115 - mse: 1.0876 - val_loss: 12.4796 - val_mae: 0.9772 - val_mse: 1.6626\n",
      "Epoch 375/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9118 - mae: 0.8127 - mse: 1.0918 - val_loss: 12.4860 - val_mae: 0.9721 - val_mse: 1.6343\n",
      "Epoch 376/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9111 - mae: 0.8122 - mse: 1.0892 - val_loss: 12.4958 - val_mae: 0.8947 - val_mse: 1.4719\n",
      "Epoch 377/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9100 - mae: 0.8132 - mse: 1.0899 - val_loss: 12.5459 - val_mae: 0.8517 - val_mse: 1.3922\n",
      "Epoch 378/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9093 - mae: 0.8108 - mse: 1.0866 - val_loss: 12.4925 - val_mae: 0.9908 - val_mse: 1.7292\n",
      "Epoch 379/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9089 - mae: 0.8118 - mse: 1.0881 - val_loss: 12.4934 - val_mae: 0.9742 - val_mse: 1.6822\n",
      "Epoch 380/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9097 - mae: 0.8123 - mse: 1.0905 - val_loss: 12.4751 - val_mae: 0.9151 - val_mse: 1.5106\n",
      "Epoch 381/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9085 - mae: 0.8111 - mse: 1.0863 - val_loss: 12.4698 - val_mae: 0.9858 - val_mse: 1.6999\n",
      "Epoch 382/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9077 - mae: 0.8110 - mse: 1.0864 - val_loss: 12.4904 - val_mae: 0.9385 - val_mse: 1.5992\n",
      "Epoch 383/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9065 - mae: 0.8107 - mse: 1.0855 - val_loss: 12.4865 - val_mae: 0.9154 - val_mse: 1.5002\n",
      "Epoch 384/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9068 - mae: 0.8108 - mse: 1.0854 - val_loss: 12.4721 - val_mae: 0.9392 - val_mse: 1.5737\n",
      "Epoch 385/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9062 - mae: 0.8103 - mse: 1.0845 - val_loss: 12.5255 - val_mae: 1.0825 - val_mse: 1.9302\n",
      "Epoch 386/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9061 - mae: 0.8111 - mse: 1.0849 - val_loss: 12.5098 - val_mae: 1.0653 - val_mse: 1.9109\n",
      "Epoch 387/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9052 - mae: 0.8109 - mse: 1.0854 - val_loss: 12.4800 - val_mae: 0.9883 - val_mse: 1.6786\n",
      "Epoch 388/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9053 - mae: 0.8114 - mse: 1.0852 - val_loss: 12.4814 - val_mae: 1.0050 - val_mse: 1.7568\n",
      "Epoch 389/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9032 - mae: 0.8103 - mse: 1.0826 - val_loss: 12.4992 - val_mae: 0.9101 - val_mse: 1.4787\n",
      "Epoch 390/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9042 - mae: 0.8100 - mse: 1.0825 - val_loss: 12.4810 - val_mae: 0.8934 - val_mse: 1.4570\n",
      "Epoch 391/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.9041 - mae: 0.8105 - mse: 1.0826 - val_loss: 12.4835 - val_mae: 0.9018 - val_mse: 1.4988\n",
      "Epoch 392/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.9015 - mae: 0.8096 - mse: 1.0810 - val_loss: 12.4691 - val_mae: 0.9217 - val_mse: 1.5317\n",
      "Epoch 393/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9018 - mae: 0.8098 - mse: 1.0806 - val_loss: 12.4653 - val_mae: 0.9573 - val_mse: 1.6216\n",
      "Epoch 394/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9019 - mae: 0.8091 - mse: 1.0818 - val_loss: 12.4899 - val_mae: 0.9492 - val_mse: 1.5716\n",
      "Epoch 395/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.9005 - mae: 0.8090 - mse: 1.0806 - val_loss: 12.4729 - val_mae: 0.9974 - val_mse: 1.7143\n",
      "Epoch 396/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.9020 - mae: 0.8104 - mse: 1.0826 - val_loss: 12.4644 - val_mae: 0.9413 - val_mse: 1.5816\n",
      "Epoch 397/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8995 - mae: 0.8084 - mse: 1.0795 - val_loss: 12.4805 - val_mae: 0.8818 - val_mse: 1.4265\n",
      "Epoch 398/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8998 - mae: 0.8092 - mse: 1.0784 - val_loss: 12.4680 - val_mae: 0.9628 - val_mse: 1.6531\n",
      "Epoch 399/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8998 - mae: 0.8087 - mse: 1.0803 - val_loss: 12.4765 - val_mae: 0.9464 - val_mse: 1.5661\n",
      "Epoch 400/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8979 - mae: 0.8087 - mse: 1.0773 - val_loss: 12.4875 - val_mae: 1.0257 - val_mse: 1.7785\n",
      "Epoch 401/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8978 - mae: 0.8081 - mse: 1.0782 - val_loss: 12.4667 - val_mae: 0.9139 - val_mse: 1.4985\n",
      "Epoch 402/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8990 - mae: 0.8078 - mse: 1.0776 - val_loss: 12.4809 - val_mae: 1.0241 - val_mse: 1.8052\n",
      "Epoch 403/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8975 - mae: 0.8088 - mse: 1.0778 - val_loss: 12.4641 - val_mae: 0.9113 - val_mse: 1.5110\n",
      "Epoch 404/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8965 - mae: 0.8082 - mse: 1.0773 - val_loss: 12.4917 - val_mae: 0.8674 - val_mse: 1.3982\n",
      "Epoch 405/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8953 - mae: 0.8065 - mse: 1.0754 - val_loss: 12.4599 - val_mae: 0.9813 - val_mse: 1.6749\n",
      "Epoch 406/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8954 - mae: 0.8083 - mse: 1.0761 - val_loss: 12.4713 - val_mae: 0.8915 - val_mse: 1.4645\n",
      "Epoch 407/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8957 - mae: 0.8078 - mse: 1.0754 - val_loss: 12.5126 - val_mae: 1.0711 - val_mse: 1.9410\n",
      "Epoch 408/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8951 - mae: 0.8077 - mse: 1.0764 - val_loss: 12.4700 - val_mae: 0.9907 - val_mse: 1.7135\n",
      "Epoch 409/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8945 - mae: 0.8079 - mse: 1.0759 - val_loss: 12.4610 - val_mae: 0.9987 - val_mse: 1.7047\n",
      "Epoch 410/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8940 - mae: 0.8078 - mse: 1.0749 - val_loss: 12.4584 - val_mae: 0.9907 - val_mse: 1.7040\n",
      "Epoch 411/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8940 - mae: 0.8071 - mse: 1.0745 - val_loss: 12.4588 - val_mae: 0.9542 - val_mse: 1.5992\n",
      "Epoch 412/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8930 - mae: 0.8071 - mse: 1.0734 - val_loss: 12.5156 - val_mae: 1.0192 - val_mse: 1.8208\n",
      "Epoch 413/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8933 - mae: 0.8077 - mse: 1.0737 - val_loss: 12.4571 - val_mae: 0.9226 - val_mse: 1.5390\n",
      "Epoch 414/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8910 - mae: 0.8068 - mse: 1.0730 - val_loss: 12.4666 - val_mae: 0.8953 - val_mse: 1.4668\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8912 - mae: 0.8065 - mse: 1.0723 - val_loss: 12.4565 - val_mae: 0.9204 - val_mse: 1.5110\n",
      "Epoch 416/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8913 - mae: 0.8076 - mse: 1.0729 - val_loss: 12.4699 - val_mae: 0.9065 - val_mse: 1.5017\n",
      "Epoch 417/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8890 - mae: 0.8059 - mse: 1.0704 - val_loss: 12.4658 - val_mae: 0.9624 - val_mse: 1.6047\n",
      "Epoch 418/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8906 - mae: 0.8062 - mse: 1.0714 - val_loss: 12.4516 - val_mae: 0.9615 - val_mse: 1.6122\n",
      "Epoch 419/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8910 - mae: 0.8062 - mse: 1.0718 - val_loss: 12.4474 - val_mae: 0.9453 - val_mse: 1.5871\n",
      "Epoch 420/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8900 - mae: 0.8062 - mse: 1.0718 - val_loss: 12.4850 - val_mae: 1.0596 - val_mse: 1.8627\n",
      "Epoch 421/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8875 - mae: 0.8063 - mse: 1.0703 - val_loss: 12.4565 - val_mae: 0.9508 - val_mse: 1.5759\n",
      "Epoch 422/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8890 - mae: 0.8064 - mse: 1.0708 - val_loss: 12.4496 - val_mae: 0.9830 - val_mse: 1.6754\n",
      "Epoch 423/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8866 - mae: 0.8056 - mse: 1.0684 - val_loss: 12.4494 - val_mae: 0.9859 - val_mse: 1.6877\n",
      "Epoch 424/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8875 - mae: 0.8055 - mse: 1.0688 - val_loss: 12.4684 - val_mae: 1.0256 - val_mse: 1.7984\n",
      "Epoch 425/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8869 - mae: 0.8046 - mse: 1.0681 - val_loss: 12.4683 - val_mae: 0.9879 - val_mse: 1.7216\n",
      "Epoch 426/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8882 - mae: 0.8058 - mse: 1.0700 - val_loss: 12.4554 - val_mae: 1.0091 - val_mse: 1.7445\n",
      "Epoch 427/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8876 - mae: 0.8056 - mse: 1.0691 - val_loss: 12.4669 - val_mae: 0.9058 - val_mse: 1.4964\n",
      "Epoch 428/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8851 - mae: 0.8047 - mse: 1.0667 - val_loss: 12.4615 - val_mae: 0.9758 - val_mse: 1.6298\n",
      "Epoch 429/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8856 - mae: 0.8049 - mse: 1.0664 - val_loss: 12.4529 - val_mae: 1.0105 - val_mse: 1.7433\n",
      "Epoch 430/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8856 - mae: 0.8060 - mse: 1.0685 - val_loss: 12.4439 - val_mae: 0.9762 - val_mse: 1.6449\n",
      "Epoch 431/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8843 - mae: 0.8044 - mse: 1.0664 - val_loss: 12.4550 - val_mae: 0.9958 - val_mse: 1.7214\n",
      "Epoch 432/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8844 - mae: 0.8048 - mse: 1.0679 - val_loss: 12.4485 - val_mae: 0.9379 - val_mse: 1.5383\n",
      "Epoch 433/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8826 - mae: 0.8039 - mse: 1.0636 - val_loss: 12.4846 - val_mae: 0.8693 - val_mse: 1.4180\n",
      "Epoch 434/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8831 - mae: 0.8041 - mse: 1.0639 - val_loss: 12.4486 - val_mae: 0.9990 - val_mse: 1.7040\n",
      "Epoch 435/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8833 - mae: 0.8046 - mse: 1.0651 - val_loss: 12.4802 - val_mae: 1.0621 - val_mse: 1.8699\n",
      "Epoch 436/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8825 - mae: 0.8038 - mse: 1.0651 - val_loss: 12.4652 - val_mae: 1.0243 - val_mse: 1.7944\n",
      "Epoch 437/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8819 - mae: 0.8043 - mse: 1.0646 - val_loss: 12.4413 - val_mae: 0.9262 - val_mse: 1.5430\n",
      "Epoch 438/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8800 - mae: 0.8037 - mse: 1.0621 - val_loss: 12.4486 - val_mae: 0.9581 - val_mse: 1.5890\n",
      "Epoch 439/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8811 - mae: 0.8047 - mse: 1.0638 - val_loss: 12.4441 - val_mae: 0.9351 - val_mse: 1.5366\n",
      "Epoch 440/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8814 - mae: 0.8039 - mse: 1.0630 - val_loss: 12.4511 - val_mae: 1.0128 - val_mse: 1.7543\n",
      "Epoch 441/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8804 - mae: 0.8040 - mse: 1.0639 - val_loss: 12.4583 - val_mae: 1.0161 - val_mse: 1.7465\n",
      "Epoch 442/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8799 - mae: 0.8031 - mse: 1.0633 - val_loss: 12.4442 - val_mae: 0.9028 - val_mse: 1.4674\n",
      "Epoch 443/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8784 - mae: 0.8026 - mse: 1.0613 - val_loss: 12.4513 - val_mae: 1.0060 - val_mse: 1.7128\n",
      "Epoch 444/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8794 - mae: 0.8040 - mse: 1.0639 - val_loss: 12.4341 - val_mae: 0.9363 - val_mse: 1.5454\n",
      "Epoch 445/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8773 - mae: 0.8023 - mse: 1.0602 - val_loss: 12.4998 - val_mae: 1.0534 - val_mse: 1.9021\n",
      "Epoch 446/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8783 - mae: 0.8030 - mse: 1.0621 - val_loss: 12.4331 - val_mae: 0.9354 - val_mse: 1.5420\n",
      "Epoch 447/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8780 - mae: 0.8031 - mse: 1.0620 - val_loss: 12.4869 - val_mae: 0.8426 - val_mse: 1.3421\n",
      "Epoch 448/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8774 - mae: 0.8017 - mse: 1.0593 - val_loss: 12.4588 - val_mae: 1.0316 - val_mse: 1.8056\n",
      "Epoch 449/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8771 - mae: 0.8029 - mse: 1.0622 - val_loss: 12.4753 - val_mae: 0.8490 - val_mse: 1.3460\n",
      "Epoch 450/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8770 - mae: 0.8022 - mse: 1.0602 - val_loss: 12.4418 - val_mae: 0.9346 - val_mse: 1.5616\n",
      "Epoch 451/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8757 - mae: 0.8022 - mse: 1.0596 - val_loss: 12.4491 - val_mae: 0.8896 - val_mse: 1.4536\n",
      "Epoch 452/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8758 - mae: 0.8029 - mse: 1.0597 - val_loss: 12.4506 - val_mae: 0.8952 - val_mse: 1.4620\n",
      "Epoch 453/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8748 - mae: 0.8023 - mse: 1.0583 - val_loss: 12.4403 - val_mae: 0.9315 - val_mse: 1.5578\n",
      "Epoch 454/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8756 - mae: 0.8012 - mse: 1.0584 - val_loss: 12.4292 - val_mae: 0.9547 - val_mse: 1.6033\n",
      "Epoch 455/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8758 - mae: 0.8030 - mse: 1.0609 - val_loss: 12.4267 - val_mae: 0.9359 - val_mse: 1.5482\n",
      "Epoch 456/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8740 - mae: 0.8017 - mse: 1.0586 - val_loss: 12.4398 - val_mae: 0.8885 - val_mse: 1.4409\n",
      "Epoch 457/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8734 - mae: 0.8013 - mse: 1.0580 - val_loss: 12.4323 - val_mae: 0.9119 - val_mse: 1.4909\n",
      "Epoch 458/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8734 - mae: 0.8025 - mse: 1.0581 - val_loss: 12.4353 - val_mae: 0.9458 - val_mse: 1.5977\n",
      "Epoch 459/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8740 - mae: 0.8013 - mse: 1.0574 - val_loss: 12.4296 - val_mae: 0.9495 - val_mse: 1.5743\n",
      "Epoch 460/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8721 - mae: 0.8015 - mse: 1.0559 - val_loss: 12.4369 - val_mae: 0.9027 - val_mse: 1.4806\n",
      "Epoch 461/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8724 - mae: 0.8004 - mse: 1.0558 - val_loss: 12.4397 - val_mae: 0.8931 - val_mse: 1.4583\n",
      "Epoch 462/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8716 - mae: 0.8006 - mse: 1.0549 - val_loss: 12.4587 - val_mae: 1.0408 - val_mse: 1.8356\n",
      "Epoch 463/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8703 - mae: 0.8002 - mse: 1.0547 - val_loss: 12.4286 - val_mae: 0.9469 - val_mse: 1.5770\n",
      "Epoch 464/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8711 - mae: 0.8007 - mse: 1.0555 - val_loss: 12.4259 - val_mae: 0.9356 - val_mse: 1.5387\n",
      "Epoch 465/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8693 - mae: 0.8009 - mse: 1.0542 - val_loss: 12.4420 - val_mae: 0.8897 - val_mse: 1.4380\n",
      "Epoch 466/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8709 - mae: 0.8015 - mse: 1.0560 - val_loss: 12.4339 - val_mae: 0.8918 - val_mse: 1.4335\n",
      "Epoch 467/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8696 - mae: 0.8002 - mse: 1.0533 - val_loss: 12.4287 - val_mae: 0.9120 - val_mse: 1.4793\n",
      "Epoch 468/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8688 - mae: 0.8002 - mse: 1.0522 - val_loss: 12.4535 - val_mae: 0.8597 - val_mse: 1.3701\n",
      "Epoch 469/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8687 - mae: 0.8005 - mse: 1.0541 - val_loss: 12.4286 - val_mae: 0.8932 - val_mse: 1.4488\n",
      "Epoch 470/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8696 - mae: 0.7999 - mse: 1.0542 - val_loss: 12.4228 - val_mae: 0.9791 - val_mse: 1.6423\n",
      "Epoch 471/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8672 - mae: 0.7998 - mse: 1.0520 - val_loss: 12.4201 - val_mae: 0.9275 - val_mse: 1.5223\n",
      "Epoch 472/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8682 - mae: 0.8003 - mse: 1.0529 - val_loss: 12.4227 - val_mae: 0.9232 - val_mse: 1.5333\n",
      "Epoch 473/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8682 - mae: 0.8006 - mse: 1.0537 - val_loss: 12.4575 - val_mae: 1.0534 - val_mse: 1.8504\n",
      "Epoch 474/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8676 - mae: 0.8000 - mse: 1.0524 - val_loss: 12.4547 - val_mae: 1.0312 - val_mse: 1.8138\n",
      "Epoch 475/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8670 - mae: 0.8005 - mse: 1.0534 - val_loss: 12.4419 - val_mae: 1.0277 - val_mse: 1.7658\n",
      "Epoch 476/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8652 - mae: 0.8000 - mse: 1.0507 - val_loss: 12.4253 - val_mae: 0.9917 - val_mse: 1.6894\n",
      "Epoch 477/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8673 - mae: 0.8000 - mse: 1.0529 - val_loss: 12.4226 - val_mae: 0.9864 - val_mse: 1.6608\n",
      "Epoch 478/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8647 - mae: 0.7995 - mse: 1.0503 - val_loss: 12.4245 - val_mae: 0.9121 - val_mse: 1.5046\n",
      "Epoch 479/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8649 - mae: 0.7988 - mse: 1.0487 - val_loss: 12.4333 - val_mae: 1.0265 - val_mse: 1.7764\n",
      "Epoch 480/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8639 - mae: 0.7992 - mse: 1.0509 - val_loss: 12.4309 - val_mae: 0.8830 - val_mse: 1.4176\n",
      "Epoch 481/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8648 - mae: 0.7993 - mse: 1.0498 - val_loss: 12.4152 - val_mae: 0.9500 - val_mse: 1.5701\n",
      "Epoch 482/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8638 - mae: 0.7993 - mse: 1.0495 - val_loss: 12.4644 - val_mae: 1.0746 - val_mse: 1.9029\n",
      "Epoch 483/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8631 - mae: 0.8001 - mse: 1.0509 - val_loss: 12.4280 - val_mae: 0.9726 - val_mse: 1.6579\n",
      "Epoch 484/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8632 - mae: 0.7983 - mse: 1.0483 - val_loss: 12.4277 - val_mae: 0.9192 - val_mse: 1.5228\n",
      "Epoch 485/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8619 - mae: 0.7981 - mse: 1.0467 - val_loss: 12.4332 - val_mae: 1.0173 - val_mse: 1.7547\n",
      "Epoch 486/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8625 - mae: 0.7987 - mse: 1.0491 - val_loss: 12.4458 - val_mae: 1.0002 - val_mse: 1.7483\n",
      "Epoch 487/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8619 - mae: 0.7986 - mse: 1.0486 - val_loss: 12.4342 - val_mae: 1.0295 - val_mse: 1.7848\n",
      "Epoch 488/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8618 - mae: 0.7991 - mse: 1.0489 - val_loss: 12.4446 - val_mae: 1.0369 - val_mse: 1.7893\n",
      "Epoch 489/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8624 - mae: 0.7986 - mse: 1.0494 - val_loss: 12.4128 - val_mae: 0.9521 - val_mse: 1.5838\n",
      "Epoch 490/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8616 - mae: 0.7979 - mse: 1.0483 - val_loss: 12.4089 - val_mae: 0.9619 - val_mse: 1.6107\n",
      "Epoch 491/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8610 - mae: 0.7992 - mse: 1.0482 - val_loss: 12.4215 - val_mae: 0.9580 - val_mse: 1.6198\n",
      "Epoch 492/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8601 - mae: 0.7980 - mse: 1.0471 - val_loss: 12.4203 - val_mae: 0.9848 - val_mse: 1.6535\n",
      "Epoch 493/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8598 - mae: 0.7978 - mse: 1.0467 - val_loss: 12.4160 - val_mae: 0.9332 - val_mse: 1.5566\n",
      "Epoch 494/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8598 - mae: 0.7987 - mse: 1.0463 - val_loss: 12.4642 - val_mae: 1.0179 - val_mse: 1.8015\n",
      "Epoch 495/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8596 - mae: 0.7985 - mse: 1.0480 - val_loss: 12.4145 - val_mae: 0.9417 - val_mse: 1.5634\n",
      "Epoch 496/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8591 - mae: 0.7973 - mse: 1.0458 - val_loss: 12.4059 - val_mae: 0.9192 - val_mse: 1.5013\n",
      "Epoch 497/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8578 - mae: 0.7976 - mse: 1.0446 - val_loss: 12.4052 - val_mae: 0.9188 - val_mse: 1.4922\n",
      "Epoch 498/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8570 - mae: 0.7970 - mse: 1.0435 - val_loss: 12.4029 - val_mae: 0.9411 - val_mse: 1.5587\n",
      "Epoch 499/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8577 - mae: 0.7968 - mse: 1.0447 - val_loss: 12.4119 - val_mae: 0.9891 - val_mse: 1.6715\n",
      "Epoch 500/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8563 - mae: 0.7972 - mse: 1.0440 - val_loss: 12.4287 - val_mae: 0.9170 - val_mse: 1.5276\n",
      "Epoch 501/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8567 - mae: 0.7969 - mse: 1.0440 - val_loss: 12.4090 - val_mae: 0.9407 - val_mse: 1.5443\n",
      "Epoch 502/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8555 - mae: 0.7974 - mse: 1.0423 - val_loss: 12.4130 - val_mae: 0.9032 - val_mse: 1.4786\n",
      "Epoch 503/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8561 - mae: 0.7971 - mse: 1.0439 - val_loss: 12.4186 - val_mae: 0.9555 - val_mse: 1.6088\n",
      "Epoch 504/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8544 - mae: 0.7962 - mse: 1.0423 - val_loss: 12.4157 - val_mae: 0.9106 - val_mse: 1.4959\n",
      "Epoch 505/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8550 - mae: 0.7971 - mse: 1.0434 - val_loss: 12.4149 - val_mae: 0.8895 - val_mse: 1.4404\n",
      "Epoch 506/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8546 - mae: 0.7963 - mse: 1.0419 - val_loss: 12.4026 - val_mae: 0.9489 - val_mse: 1.5699\n",
      "Epoch 507/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8546 - mae: 0.7960 - mse: 1.0418 - val_loss: 12.4136 - val_mae: 0.9766 - val_mse: 1.6607\n",
      "Epoch 508/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8541 - mae: 0.7965 - mse: 1.0413 - val_loss: 12.4490 - val_mae: 0.9743 - val_mse: 1.6928\n",
      "Epoch 509/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8542 - mae: 0.7960 - mse: 1.0424 - val_loss: 12.3993 - val_mae: 0.9344 - val_mse: 1.5426\n",
      "Epoch 510/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8537 - mae: 0.7965 - mse: 1.0410 - val_loss: 12.4344 - val_mae: 1.0199 - val_mse: 1.7847\n",
      "Epoch 511/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8533 - mae: 0.7969 - mse: 1.0419 - val_loss: 12.4302 - val_mae: 0.9837 - val_mse: 1.6957\n",
      "Epoch 512/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8536 - mae: 0.7962 - mse: 1.0420 - val_loss: 12.4221 - val_mae: 0.9018 - val_mse: 1.4845\n",
      "Epoch 513/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8522 - mae: 0.7953 - mse: 1.0396 - val_loss: 12.4069 - val_mae: 0.9180 - val_mse: 1.5092\n",
      "Epoch 514/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8531 - mae: 0.7969 - mse: 1.0403 - val_loss: 12.4049 - val_mae: 0.9067 - val_mse: 1.4650\n",
      "Epoch 515/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8521 - mae: 0.7965 - mse: 1.0406 - val_loss: 12.4056 - val_mae: 0.9064 - val_mse: 1.4748\n",
      "Epoch 516/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8500 - mae: 0.7950 - mse: 1.0374 - val_loss: 12.4051 - val_mae: 0.9628 - val_mse: 1.6250\n",
      "Epoch 517/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8518 - mae: 0.7955 - mse: 1.0399 - val_loss: 12.4018 - val_mae: 0.9624 - val_mse: 1.6037\n",
      "Epoch 518/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8506 - mae: 0.7955 - mse: 1.0392 - val_loss: 12.4443 - val_mae: 0.9133 - val_mse: 1.5254\n",
      "Epoch 519/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8508 - mae: 0.7946 - mse: 1.0382 - val_loss: 12.4495 - val_mae: 1.0568 - val_mse: 1.8348\n",
      "Epoch 520/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8511 - mae: 0.7955 - mse: 1.0399 - val_loss: 12.3954 - val_mae: 0.9206 - val_mse: 1.5065\n",
      "Epoch 521/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8505 - mae: 0.7958 - mse: 1.0390 - val_loss: 12.4194 - val_mae: 0.9598 - val_mse: 1.6306\n",
      "Epoch 522/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8494 - mae: 0.7945 - mse: 1.0368 - val_loss: 12.4003 - val_mae: 0.9086 - val_mse: 1.4809\n",
      "Epoch 523/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8491 - mae: 0.7950 - mse: 1.0376 - val_loss: 12.4038 - val_mae: 0.9585 - val_mse: 1.6071\n",
      "Epoch 524/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8480 - mae: 0.7940 - mse: 1.0359 - val_loss: 12.4630 - val_mae: 1.0665 - val_mse: 1.9222\n",
      "Epoch 525/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8503 - mae: 0.7961 - mse: 1.0405 - val_loss: 12.4133 - val_mae: 0.8851 - val_mse: 1.4358\n",
      "Epoch 526/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8490 - mae: 0.7950 - mse: 1.0376 - val_loss: 12.4149 - val_mae: 1.0062 - val_mse: 1.7051\n",
      "Epoch 527/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8484 - mae: 0.7943 - mse: 1.0379 - val_loss: 12.4232 - val_mae: 1.0143 - val_mse: 1.7216\n",
      "Epoch 528/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8474 - mae: 0.7947 - mse: 1.0373 - val_loss: 12.3934 - val_mae: 0.9624 - val_mse: 1.6000\n",
      "Epoch 529/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8470 - mae: 0.7940 - mse: 1.0358 - val_loss: 12.3907 - val_mae: 0.9541 - val_mse: 1.5904\n",
      "Epoch 530/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8468 - mae: 0.7937 - mse: 1.0355 - val_loss: 12.4080 - val_mae: 1.0128 - val_mse: 1.7299\n",
      "Epoch 531/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8464 - mae: 0.7945 - mse: 1.0349 - val_loss: 12.4126 - val_mae: 1.0125 - val_mse: 1.7450\n",
      "Epoch 532/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8466 - mae: 0.7944 - mse: 1.0368 - val_loss: 12.4043 - val_mae: 0.8748 - val_mse: 1.3976\n",
      "Epoch 533/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8454 - mae: 0.7938 - mse: 1.0343 - val_loss: 12.3995 - val_mae: 0.9689 - val_mse: 1.6081\n",
      "Epoch 534/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.8467 - mae: 0.7943 - mse: 1.0364 - val_loss: 12.4007 - val_mae: 0.9730 - val_mse: 1.6117\n",
      "Epoch 535/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8456 - mae: 0.7943 - mse: 1.0353 - val_loss: 12.4193 - val_mae: 0.9710 - val_mse: 1.6640\n",
      "Epoch 536/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.8447 - mae: 0.7937 - mse: 1.0338 - val_loss: 12.3954 - val_mae: 0.9714 - val_mse: 1.6273\n",
      "Epoch 537/1000\n",
      "18102/18102 [==============================] - 1s 43us/sample - loss: 11.8446 - mae: 0.7939 - mse: 1.0341 - val_loss: 12.4159 - val_mae: 0.9645 - val_mse: 1.5893\n",
      "Epoch 538/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.8447 - mae: 0.7943 - mse: 1.0348 - val_loss: 12.4291 - val_mae: 1.0453 - val_mse: 1.8034\n",
      "Epoch 539/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.8443 - mae: 0.7939 - mse: 1.0352 - val_loss: 12.4038 - val_mae: 0.9560 - val_mse: 1.6178\n",
      "Epoch 540/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.8447 - mae: 0.7941 - mse: 1.0361 - val_loss: 12.3907 - val_mae: 0.9221 - val_mse: 1.5021\n",
      "Epoch 541/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.8430 - mae: 0.7931 - mse: 1.0324 - val_loss: 12.4174 - val_mae: 1.0161 - val_mse: 1.7555\n",
      "Epoch 542/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.8426 - mae: 0.7935 - mse: 1.0334 - val_loss: 12.4601 - val_mae: 0.8175 - val_mse: 1.2821\n",
      "Epoch 543/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.8440 - mae: 0.7934 - mse: 1.0337 - val_loss: 12.3992 - val_mae: 0.9664 - val_mse: 1.6455\n",
      "Epoch 544/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.8425 - mae: 0.7927 - mse: 1.0327 - val_loss: 12.3958 - val_mae: 0.9241 - val_mse: 1.5272\n",
      "Epoch 545/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 11.8435 - mae: 0.7941 - mse: 1.0347 - val_loss: 12.3808 - val_mae: 0.9272 - val_mse: 1.5153\n",
      "Epoch 546/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.8425 - mae: 0.7927 - mse: 1.0329 - val_loss: 12.4276 - val_mae: 1.0057 - val_mse: 1.7519\n",
      "Epoch 547/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.8415 - mae: 0.7923 - mse: 1.0316 - val_loss: 12.3857 - val_mae: 0.9454 - val_mse: 1.5694\n",
      "Epoch 548/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.8418 - mae: 0.7930 - mse: 1.0331 - val_loss: 12.4042 - val_mae: 0.9449 - val_mse: 1.5771\n",
      "Epoch 549/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.8407 - mae: 0.7928 - mse: 1.0307 - val_loss: 12.4187 - val_mae: 0.8654 - val_mse: 1.3909\n",
      "Epoch 550/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 11.8423 - mae: 0.7928 - mse: 1.0322 - val_loss: 12.4235 - val_mae: 0.9776 - val_mse: 1.6865\n",
      "Epoch 551/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 11.8406 - mae: 0.7932 - mse: 1.0320 - val_loss: 12.3911 - val_mae: 0.9916 - val_mse: 1.6782\n",
      "Epoch 552/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.8410 - mae: 0.7934 - mse: 1.0325 - val_loss: 12.3880 - val_mae: 0.8988 - val_mse: 1.4556\n",
      "Epoch 553/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.8397 - mae: 0.7921 - mse: 1.0305 - val_loss: 12.3993 - val_mae: 0.8756 - val_mse: 1.4028\n",
      "Epoch 554/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8407 - mae: 0.7919 - mse: 1.0297 - val_loss: 12.4007 - val_mae: 0.9582 - val_mse: 1.6251\n",
      "Epoch 555/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8406 - mae: 0.7927 - mse: 1.0320 - val_loss: 12.3942 - val_mae: 0.8797 - val_mse: 1.4088\n",
      "Epoch 556/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8389 - mae: 0.7924 - mse: 1.0310 - val_loss: 12.3966 - val_mae: 0.8740 - val_mse: 1.3980\n",
      "Epoch 557/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8389 - mae: 0.7923 - mse: 1.0290 - val_loss: 12.3845 - val_mae: 0.9508 - val_mse: 1.5708\n",
      "Epoch 558/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8376 - mae: 0.7918 - mse: 1.0289 - val_loss: 12.4023 - val_mae: 0.8628 - val_mse: 1.3698\n",
      "Epoch 559/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8384 - mae: 0.7927 - mse: 1.0300 - val_loss: 12.4133 - val_mae: 0.8711 - val_mse: 1.4060\n",
      "Epoch 560/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8390 - mae: 0.7926 - mse: 1.0299 - val_loss: 12.3982 - val_mae: 0.9891 - val_mse: 1.6477\n",
      "Epoch 561/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8381 - mae: 0.7926 - mse: 1.0300 - val_loss: 12.4045 - val_mae: 0.8551 - val_mse: 1.3507\n",
      "Epoch 562/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8370 - mae: 0.7914 - mse: 1.0279 - val_loss: 12.4302 - val_mae: 1.0559 - val_mse: 1.8340\n",
      "Epoch 563/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8374 - mae: 0.7923 - mse: 1.0293 - val_loss: 12.3874 - val_mae: 0.9687 - val_mse: 1.6121\n",
      "Epoch 564/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8371 - mae: 0.7922 - mse: 1.0293 - val_loss: 12.4350 - val_mae: 0.9780 - val_mse: 1.6939\n",
      "Epoch 565/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8376 - mae: 0.7920 - mse: 1.0303 - val_loss: 12.3825 - val_mae: 0.9711 - val_mse: 1.6243\n",
      "Epoch 566/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8349 - mae: 0.7913 - mse: 1.0265 - val_loss: 12.4240 - val_mae: 0.9127 - val_mse: 1.5215\n",
      "Epoch 567/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8364 - mae: 0.7917 - mse: 1.0287 - val_loss: 12.3959 - val_mae: 0.8696 - val_mse: 1.3865\n",
      "Epoch 568/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8361 - mae: 0.7911 - mse: 1.0282 - val_loss: 12.3879 - val_mae: 0.8910 - val_mse: 1.4357\n",
      "Epoch 569/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8350 - mae: 0.7907 - mse: 1.0262 - val_loss: 12.4022 - val_mae: 0.8984 - val_mse: 1.4315\n",
      "Epoch 570/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8362 - mae: 0.7913 - mse: 1.0275 - val_loss: 12.4095 - val_mae: 1.0165 - val_mse: 1.7655\n",
      "Epoch 571/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8349 - mae: 0.7910 - mse: 1.0271 - val_loss: 12.3961 - val_mae: 0.9580 - val_mse: 1.6296\n",
      "Epoch 572/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8362 - mae: 0.7920 - mse: 1.0284 - val_loss: 12.3801 - val_mae: 0.9425 - val_mse: 1.5689\n",
      "Epoch 573/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8346 - mae: 0.7907 - mse: 1.0255 - val_loss: 12.3823 - val_mae: 0.9775 - val_mse: 1.6364\n",
      "Epoch 574/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8343 - mae: 0.7910 - mse: 1.0268 - val_loss: 12.4112 - val_mae: 0.8499 - val_mse: 1.3432\n",
      "Epoch 575/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8348 - mae: 0.7913 - mse: 1.0273 - val_loss: 12.3978 - val_mae: 0.9405 - val_mse: 1.5760\n",
      "Epoch 576/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8336 - mae: 0.7906 - mse: 1.0257 - val_loss: 12.3784 - val_mae: 0.9500 - val_mse: 1.5624\n",
      "Epoch 577/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8359 - mae: 0.7916 - mse: 1.0283 - val_loss: 12.3898 - val_mae: 1.0069 - val_mse: 1.7077\n",
      "Epoch 578/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8337 - mae: 0.7912 - mse: 1.0269 - val_loss: 12.4051 - val_mae: 0.8458 - val_mse: 1.3354\n",
      "Epoch 579/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8341 - mae: 0.7910 - mse: 1.0256 - val_loss: 12.3706 - val_mae: 0.9385 - val_mse: 1.5495\n",
      "Epoch 580/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8321 - mae: 0.7900 - mse: 1.0230 - val_loss: 12.3996 - val_mae: 1.0059 - val_mse: 1.7323\n",
      "Epoch 581/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8330 - mae: 0.7906 - mse: 1.0254 - val_loss: 12.4239 - val_mae: 0.8793 - val_mse: 1.4325\n",
      "Epoch 582/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8330 - mae: 0.7905 - mse: 1.0249 - val_loss: 12.3882 - val_mae: 0.9267 - val_mse: 1.5450\n",
      "Epoch 583/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8316 - mae: 0.7903 - mse: 1.0235 - val_loss: 12.4028 - val_mae: 0.9268 - val_mse: 1.5567\n",
      "Epoch 584/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8326 - mae: 0.7906 - mse: 1.0248 - val_loss: 12.3791 - val_mae: 0.8918 - val_mse: 1.4252\n",
      "Epoch 585/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8319 - mae: 0.7909 - mse: 1.0237 - val_loss: 12.4525 - val_mae: 1.0145 - val_mse: 1.8004\n",
      "Epoch 586/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8321 - mae: 0.7908 - mse: 1.0255 - val_loss: 12.3991 - val_mae: 0.9428 - val_mse: 1.5924\n",
      "Epoch 587/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8320 - mae: 0.7905 - mse: 1.0254 - val_loss: 12.3846 - val_mae: 0.9198 - val_mse: 1.4828\n",
      "Epoch 588/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8311 - mae: 0.7899 - mse: 1.0231 - val_loss: 12.3996 - val_mae: 1.0257 - val_mse: 1.7814\n",
      "Epoch 589/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8317 - mae: 0.7903 - mse: 1.0242 - val_loss: 12.4396 - val_mae: 1.0621 - val_mse: 1.8986\n",
      "Epoch 590/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8311 - mae: 0.7900 - mse: 1.0245 - val_loss: 12.3763 - val_mae: 0.9829 - val_mse: 1.6440\n",
      "Epoch 591/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8306 - mae: 0.7907 - mse: 1.0250 - val_loss: 12.3952 - val_mae: 0.9167 - val_mse: 1.5160\n",
      "Epoch 592/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8301 - mae: 0.7906 - mse: 1.0230 - val_loss: 12.3743 - val_mae: 0.9535 - val_mse: 1.5772\n",
      "Epoch 593/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8296 - mae: 0.7898 - mse: 1.0229 - val_loss: 12.3786 - val_mae: 0.9694 - val_mse: 1.6324\n",
      "Epoch 594/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8296 - mae: 0.7898 - mse: 1.0223 - val_loss: 12.3801 - val_mae: 0.9910 - val_mse: 1.6840\n",
      "Epoch 595/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8291 - mae: 0.7896 - mse: 1.0238 - val_loss: 12.3804 - val_mae: 0.9566 - val_mse: 1.6007\n",
      "Epoch 596/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8287 - mae: 0.7905 - mse: 1.0223 - val_loss: 12.3794 - val_mae: 0.9548 - val_mse: 1.5673\n",
      "Epoch 597/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8284 - mae: 0.7900 - mse: 1.0225 - val_loss: 12.3778 - val_mae: 0.8860 - val_mse: 1.4159\n",
      "Epoch 598/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8273 - mae: 0.7901 - mse: 1.0209 - val_loss: 12.3791 - val_mae: 0.8854 - val_mse: 1.4113\n",
      "Epoch 599/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8294 - mae: 0.7895 - mse: 1.0226 - val_loss: 12.4287 - val_mae: 0.9006 - val_mse: 1.4897\n",
      "Epoch 600/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8285 - mae: 0.7893 - mse: 1.0225 - val_loss: 12.3758 - val_mae: 0.9291 - val_mse: 1.5400\n",
      "Epoch 601/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8270 - mae: 0.7894 - mse: 1.0207 - val_loss: 12.3797 - val_mae: 0.9942 - val_mse: 1.6907\n",
      "Epoch 602/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.8269 - mae: 0.7903 - mse: 1.0222 - val_loss: 12.3722 - val_mae: 0.9425 - val_mse: 1.5475\n",
      "Epoch 603/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.8274 - mae: 0.7896 - mse: 1.0226 - val_loss: 12.3730 - val_mae: 0.9401 - val_mse: 1.5453\n",
      "Epoch 604/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8272 - mae: 0.7890 - mse: 1.0215 - val_loss: 12.3781 - val_mae: 0.9535 - val_mse: 1.5577\n",
      "Epoch 605/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8260 - mae: 0.7890 - mse: 1.0194 - val_loss: 12.4378 - val_mae: 1.0740 - val_mse: 1.9218\n",
      "Epoch 606/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.8267 - mae: 0.7902 - mse: 1.0215 - val_loss: 12.3712 - val_mae: 0.9576 - val_mse: 1.5938\n",
      "Epoch 607/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8256 - mae: 0.7897 - mse: 1.0198 - val_loss: 12.3818 - val_mae: 0.9591 - val_mse: 1.6239\n",
      "Epoch 608/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8256 - mae: 0.7878 - mse: 1.0190 - val_loss: 12.3794 - val_mae: 0.9455 - val_mse: 1.5878\n",
      "Epoch 609/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8238 - mae: 0.7878 - mse: 1.0179 - val_loss: 12.4032 - val_mae: 0.9596 - val_mse: 1.6284\n",
      "Epoch 610/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8254 - mae: 0.7890 - mse: 1.0215 - val_loss: 12.3885 - val_mae: 0.9579 - val_mse: 1.6223\n",
      "Epoch 611/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8247 - mae: 0.7885 - mse: 1.0190 - val_loss: 12.3732 - val_mae: 0.9565 - val_mse: 1.6006\n",
      "Epoch 612/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8251 - mae: 0.7888 - mse: 1.0205 - val_loss: 12.3662 - val_mae: 0.9374 - val_mse: 1.5377\n",
      "Epoch 613/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8250 - mae: 0.7896 - mse: 1.0203 - val_loss: 12.4118 - val_mae: 0.9700 - val_mse: 1.6673\n",
      "Epoch 614/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8244 - mae: 0.7885 - mse: 1.0189 - val_loss: 12.3877 - val_mae: 0.9581 - val_mse: 1.6162\n",
      "Epoch 615/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8243 - mae: 0.7887 - mse: 1.0196 - val_loss: 12.3715 - val_mae: 0.9885 - val_mse: 1.6610\n",
      "Epoch 616/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8251 - mae: 0.7893 - mse: 1.0208 - val_loss: 12.3766 - val_mae: 0.9213 - val_mse: 1.5275\n",
      "Epoch 617/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8241 - mae: 0.7881 - mse: 1.0175 - val_loss: 12.3697 - val_mae: 0.9752 - val_mse: 1.6363\n",
      "Epoch 618/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8243 - mae: 0.7889 - mse: 1.0189 - val_loss: 12.3842 - val_mae: 0.9114 - val_mse: 1.5055\n",
      "Epoch 619/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8234 - mae: 0.7881 - mse: 1.0187 - val_loss: 12.4227 - val_mae: 1.0046 - val_mse: 1.7602\n",
      "Epoch 620/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8223 - mae: 0.7882 - mse: 1.0172 - val_loss: 12.3637 - val_mae: 0.9208 - val_mse: 1.4878\n",
      "Epoch 621/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8229 - mae: 0.7879 - mse: 1.0170 - val_loss: 12.3924 - val_mae: 1.0039 - val_mse: 1.6814\n",
      "Epoch 622/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8218 - mae: 0.7882 - mse: 1.0179 - val_loss: 12.3652 - val_mae: 0.9445 - val_mse: 1.5607\n",
      "Epoch 623/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8210 - mae: 0.7884 - mse: 1.0158 - val_loss: 12.3708 - val_mae: 0.9302 - val_mse: 1.5433\n",
      "Epoch 624/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8223 - mae: 0.7885 - mse: 1.0182 - val_loss: 12.3662 - val_mae: 0.8981 - val_mse: 1.4392\n",
      "Epoch 625/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8219 - mae: 0.7880 - mse: 1.0168 - val_loss: 12.4069 - val_mae: 1.0432 - val_mse: 1.7762\n",
      "Epoch 626/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8213 - mae: 0.7886 - mse: 1.0172 - val_loss: 12.3646 - val_mae: 0.9010 - val_mse: 1.4663\n",
      "Epoch 627/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8225 - mae: 0.7882 - mse: 1.0179 - val_loss: 12.4353 - val_mae: 1.0049 - val_mse: 1.7692\n",
      "Epoch 628/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8218 - mae: 0.7877 - mse: 1.0175 - val_loss: 12.3891 - val_mae: 1.0208 - val_mse: 1.7575\n",
      "Epoch 629/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8219 - mae: 0.7881 - mse: 1.0180 - val_loss: 12.3720 - val_mae: 0.9771 - val_mse: 1.6519\n",
      "Epoch 630/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8211 - mae: 0.7878 - mse: 1.0170 - val_loss: 12.3710 - val_mae: 0.8721 - val_mse: 1.3886\n",
      "Epoch 631/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8212 - mae: 0.7876 - mse: 1.0163 - val_loss: 12.3739 - val_mae: 0.9413 - val_mse: 1.5673\n",
      "Epoch 632/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8208 - mae: 0.7886 - mse: 1.0174 - val_loss: 12.3689 - val_mae: 0.9835 - val_mse: 1.6465\n",
      "Epoch 633/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8199 - mae: 0.7869 - mse: 1.0151 - val_loss: 12.3867 - val_mae: 0.9457 - val_mse: 1.5370\n",
      "Epoch 634/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8211 - mae: 0.7878 - mse: 1.0183 - val_loss: 12.3782 - val_mae: 0.8694 - val_mse: 1.3746\n",
      "Epoch 635/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8195 - mae: 0.7874 - mse: 1.0155 - val_loss: 12.3756 - val_mae: 0.9947 - val_mse: 1.6907\n",
      "Epoch 636/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8187 - mae: 0.7875 - mse: 1.0148 - val_loss: 12.3706 - val_mae: 0.8889 - val_mse: 1.4336\n",
      "Epoch 637/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8200 - mae: 0.7876 - mse: 1.0152 - val_loss: 12.3596 - val_mae: 0.9345 - val_mse: 1.5373\n",
      "Epoch 638/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8190 - mae: 0.7875 - mse: 1.0157 - val_loss: 12.3728 - val_mae: 0.8752 - val_mse: 1.3890\n",
      "Epoch 639/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8191 - mae: 0.7865 - mse: 1.0155 - val_loss: 12.3792 - val_mae: 0.9110 - val_mse: 1.5015\n",
      "Epoch 640/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8182 - mae: 0.7871 - mse: 1.0139 - val_loss: 12.3646 - val_mae: 0.9506 - val_mse: 1.5855\n",
      "Epoch 641/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.8192 - mae: 0.7875 - mse: 1.0152 - val_loss: 12.4404 - val_mae: 0.9624 - val_mse: 1.6632\n",
      "Epoch 642/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 11.8164 - mae: 0.7870 - mse: 1.0134 - val_loss: 12.3679 - val_mae: 0.9736 - val_mse: 1.6176\n",
      "Epoch 643/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8182 - mae: 0.7870 - mse: 1.0138 - val_loss: 12.3601 - val_mae: 0.9504 - val_mse: 1.5789\n",
      "Epoch 644/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.8176 - mae: 0.7863 - mse: 1.0138 - val_loss: 12.3657 - val_mae: 0.9073 - val_mse: 1.4601\n",
      "Epoch 645/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.8175 - mae: 0.7870 - mse: 1.0140 - val_loss: 12.3901 - val_mae: 0.9882 - val_mse: 1.6912\n",
      "Epoch 646/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8170 - mae: 0.7870 - mse: 1.0135 - val_loss: 12.3677 - val_mae: 0.8857 - val_mse: 1.4191\n",
      "Epoch 647/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.8160 - mae: 0.7866 - mse: 1.0126 - val_loss: 12.3620 - val_mae: 0.9672 - val_mse: 1.6108\n",
      "Epoch 648/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8170 - mae: 0.7860 - mse: 1.0135 - val_loss: 12.3933 - val_mae: 0.9190 - val_mse: 1.4638\n",
      "Epoch 649/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.8160 - mae: 0.7862 - mse: 1.0121 - val_loss: 12.3648 - val_mae: 0.8784 - val_mse: 1.4078\n",
      "Epoch 650/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.8164 - mae: 0.7871 - mse: 1.0128 - val_loss: 12.3592 - val_mae: 0.9547 - val_mse: 1.5912\n",
      "Epoch 651/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.8153 - mae: 0.7851 - mse: 1.0109 - val_loss: 12.3681 - val_mae: 0.9973 - val_mse: 1.6767\n",
      "Epoch 652/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.8158 - mae: 0.7870 - mse: 1.0127 - val_loss: 12.3748 - val_mae: 0.9399 - val_mse: 1.5677\n",
      "Epoch 653/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.8156 - mae: 0.7862 - mse: 1.0126 - val_loss: 12.3574 - val_mae: 0.9347 - val_mse: 1.5204\n",
      "Epoch 654/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.8161 - mae: 0.7865 - mse: 1.0124 - val_loss: 12.3544 - val_mae: 0.9479 - val_mse: 1.5718\n",
      "Epoch 655/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8166 - mae: 0.7868 - mse: 1.0143 - val_loss: 12.3510 - val_mae: 0.9180 - val_mse: 1.4948\n",
      "Epoch 656/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8158 - mae: 0.7868 - mse: 1.0132 - val_loss: 12.3632 - val_mae: 0.9671 - val_mse: 1.5933\n",
      "Epoch 657/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.8155 - mae: 0.7858 - mse: 1.0120 - val_loss: 12.3996 - val_mae: 1.0173 - val_mse: 1.7676\n",
      "Epoch 658/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.8157 - mae: 0.7863 - mse: 1.0126 - val_loss: 12.3649 - val_mae: 0.9313 - val_mse: 1.5442\n",
      "Epoch 659/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.8149 - mae: 0.7855 - mse: 1.0114 - val_loss: 12.3607 - val_mae: 0.9641 - val_mse: 1.6115\n",
      "Epoch 660/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.8137 - mae: 0.7856 - mse: 1.0104 - val_loss: 12.4003 - val_mae: 1.0519 - val_mse: 1.8323\n",
      "Epoch 661/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.8145 - mae: 0.7868 - mse: 1.0136 - val_loss: 12.3807 - val_mae: 0.8733 - val_mse: 1.3760\n",
      "Epoch 662/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8137 - mae: 0.7858 - mse: 1.0103 - val_loss: 12.3641 - val_mae: 0.9751 - val_mse: 1.6496\n",
      "Epoch 663/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8139 - mae: 0.7866 - mse: 1.0119 - val_loss: 12.3606 - val_mae: 0.9274 - val_mse: 1.5392\n",
      "Epoch 664/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8134 - mae: 0.7858 - mse: 1.0107 - val_loss: 12.3604 - val_mae: 0.9548 - val_mse: 1.5939\n",
      "Epoch 665/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.8132 - mae: 0.7858 - mse: 1.0106 - val_loss: 12.3673 - val_mae: 0.9742 - val_mse: 1.6077\n",
      "Epoch 666/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.8122 - mae: 0.7849 - mse: 1.0091 - val_loss: 12.3694 - val_mae: 0.9948 - val_mse: 1.6807\n",
      "Epoch 667/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8132 - mae: 0.7858 - mse: 1.0110 - val_loss: 12.3529 - val_mae: 0.8926 - val_mse: 1.4300\n",
      "Epoch 668/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.8125 - mae: 0.7852 - mse: 1.0093 - val_loss: 12.3686 - val_mae: 0.9778 - val_mse: 1.6589\n",
      "Epoch 669/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.8124 - mae: 0.7859 - mse: 1.0097 - val_loss: 12.3613 - val_mae: 0.9162 - val_mse: 1.5018\n",
      "Epoch 670/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.8127 - mae: 0.7856 - mse: 1.0100 - val_loss: 12.4212 - val_mae: 1.0398 - val_mse: 1.8436\n",
      "Epoch 671/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 11.8128 - mae: 0.7858 - mse: 1.0109 - val_loss: 12.3532 - val_mae: 0.9483 - val_mse: 1.5674\n",
      "Epoch 672/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 11.8119 - mae: 0.7850 - mse: 1.0099 - val_loss: 12.3662 - val_mae: 0.8937 - val_mse: 1.4547\n",
      "Epoch 673/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 11.8118 - mae: 0.7854 - mse: 1.0101 - val_loss: 12.3783 - val_mae: 0.8569 - val_mse: 1.3453\n",
      "Epoch 674/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.8118 - mae: 0.7855 - mse: 1.0093 - val_loss: 12.3907 - val_mae: 1.0410 - val_mse: 1.7936\n",
      "Epoch 675/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.8119 - mae: 0.7856 - mse: 1.0098 - val_loss: 12.3626 - val_mae: 0.9459 - val_mse: 1.5787\n",
      "Epoch 676/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.8111 - mae: 0.7841 - mse: 1.0084 - val_loss: 12.3726 - val_mae: 0.9658 - val_mse: 1.6389\n",
      "Epoch 677/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8117 - mae: 0.7852 - mse: 1.0099 - val_loss: 12.3629 - val_mae: 0.9642 - val_mse: 1.6222\n",
      "Epoch 678/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8092 - mae: 0.7844 - mse: 1.0072 - val_loss: 12.3626 - val_mae: 0.9191 - val_mse: 1.5152\n",
      "Epoch 679/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8106 - mae: 0.7850 - mse: 1.0088 - val_loss: 12.3940 - val_mae: 0.9056 - val_mse: 1.4339\n",
      "Epoch 680/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8095 - mae: 0.7840 - mse: 1.0074 - val_loss: 12.3503 - val_mae: 0.9129 - val_mse: 1.4868\n",
      "Epoch 681/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8117 - mae: 0.7854 - mse: 1.0097 - val_loss: 12.3463 - val_mae: 0.9426 - val_mse: 1.5406\n",
      "Epoch 682/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8105 - mae: 0.7845 - mse: 1.0072 - val_loss: 12.3747 - val_mae: 1.0172 - val_mse: 1.7427\n",
      "Epoch 683/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8094 - mae: 0.7844 - mse: 1.0074 - val_loss: 12.3572 - val_mae: 0.9819 - val_mse: 1.6546\n",
      "Epoch 684/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8092 - mae: 0.7854 - mse: 1.0089 - val_loss: 12.3643 - val_mae: 0.9528 - val_mse: 1.5511\n",
      "Epoch 685/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8097 - mae: 0.7846 - mse: 1.0075 - val_loss: 12.3839 - val_mae: 0.9575 - val_mse: 1.6228\n",
      "Epoch 686/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8090 - mae: 0.7851 - mse: 1.0079 - val_loss: 12.3491 - val_mae: 0.9317 - val_mse: 1.5215\n",
      "Epoch 687/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8087 - mae: 0.7841 - mse: 1.0067 - val_loss: 12.3483 - val_mae: 0.9029 - val_mse: 1.4517\n",
      "Epoch 688/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8084 - mae: 0.7842 - mse: 1.0064 - val_loss: 12.3670 - val_mae: 0.8960 - val_mse: 1.4568\n",
      "Epoch 689/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8086 - mae: 0.7834 - mse: 1.0067 - val_loss: 12.3481 - val_mae: 0.9067 - val_mse: 1.4778\n",
      "Epoch 690/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8080 - mae: 0.7840 - mse: 1.0058 - val_loss: 12.3975 - val_mae: 1.0508 - val_mse: 1.8280\n",
      "Epoch 691/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8090 - mae: 0.7844 - mse: 1.0084 - val_loss: 12.3621 - val_mae: 1.0018 - val_mse: 1.6838\n",
      "Epoch 692/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8087 - mae: 0.7842 - mse: 1.0063 - val_loss: 12.4036 - val_mae: 1.0162 - val_mse: 1.7771\n",
      "Epoch 693/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.8076 - mae: 0.7842 - mse: 1.0055 - val_loss: 12.3622 - val_mae: 0.9698 - val_mse: 1.6342\n",
      "Epoch 694/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.8086 - mae: 0.7844 - mse: 1.0079 - val_loss: 12.3507 - val_mae: 0.8764 - val_mse: 1.3956\n",
      "Epoch 695/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.8071 - mae: 0.7836 - mse: 1.0043 - val_loss: 12.3573 - val_mae: 0.9260 - val_mse: 1.5177\n",
      "Epoch 696/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8067 - mae: 0.7839 - mse: 1.0051 - val_loss: 12.3597 - val_mae: 0.9719 - val_mse: 1.6381\n",
      "Epoch 697/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8059 - mae: 0.7829 - mse: 1.0034 - val_loss: 12.3828 - val_mae: 0.9326 - val_mse: 1.5699\n",
      "Epoch 698/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8077 - mae: 0.7840 - mse: 1.0067 - val_loss: 12.3475 - val_mae: 0.9290 - val_mse: 1.5315\n",
      "Epoch 699/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8059 - mae: 0.7835 - mse: 1.0046 - val_loss: 12.3622 - val_mae: 0.9967 - val_mse: 1.6858\n",
      "Epoch 700/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8071 - mae: 0.7838 - mse: 1.0065 - val_loss: 12.3512 - val_mae: 0.9420 - val_mse: 1.5646\n",
      "Epoch 701/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.8058 - mae: 0.7833 - mse: 1.0037 - val_loss: 12.3863 - val_mae: 0.8719 - val_mse: 1.4125\n",
      "Epoch 702/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8058 - mae: 0.7831 - mse: 1.0051 - val_loss: 12.3602 - val_mae: 0.8820 - val_mse: 1.3965\n",
      "Epoch 703/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8058 - mae: 0.7837 - mse: 1.0053 - val_loss: 12.3532 - val_mae: 0.9012 - val_mse: 1.4661\n",
      "Epoch 704/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8071 - mae: 0.7849 - mse: 1.0073 - val_loss: 12.3477 - val_mae: 0.9086 - val_mse: 1.4745\n",
      "Epoch 705/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8054 - mae: 0.7833 - mse: 1.0050 - val_loss: 12.3446 - val_mae: 0.9176 - val_mse: 1.4886\n",
      "Epoch 706/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.8045 - mae: 0.7832 - mse: 1.0034 - val_loss: 12.3458 - val_mae: 0.9081 - val_mse: 1.4820\n",
      "Epoch 707/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8051 - mae: 0.7843 - mse: 1.0040 - val_loss: 12.3431 - val_mae: 0.9028 - val_mse: 1.4634\n",
      "Epoch 708/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8057 - mae: 0.7828 - mse: 1.0044 - val_loss: 12.3706 - val_mae: 0.8461 - val_mse: 1.3311\n",
      "Epoch 709/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8057 - mae: 0.7832 - mse: 1.0036 - val_loss: 12.3794 - val_mae: 1.0083 - val_mse: 1.7437\n",
      "Epoch 710/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8046 - mae: 0.7838 - mse: 1.0037 - val_loss: 12.3678 - val_mae: 0.8942 - val_mse: 1.4586\n",
      "Epoch 711/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.8042 - mae: 0.7830 - mse: 1.0038 - val_loss: 12.3393 - val_mae: 0.9216 - val_mse: 1.4977\n",
      "Epoch 712/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8047 - mae: 0.7825 - mse: 1.0027 - val_loss: 12.3564 - val_mae: 0.9341 - val_mse: 1.5536\n",
      "Epoch 713/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8041 - mae: 0.7829 - mse: 1.0034 - val_loss: 12.3540 - val_mae: 0.8778 - val_mse: 1.4048\n",
      "Epoch 714/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.8043 - mae: 0.7835 - mse: 1.0040 - val_loss: 12.4372 - val_mae: 1.0537 - val_mse: 1.8951\n",
      "Epoch 715/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.8043 - mae: 0.7833 - mse: 1.0050 - val_loss: 12.3425 - val_mae: 0.9126 - val_mse: 1.4847\n",
      "Epoch 716/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8038 - mae: 0.7834 - mse: 1.0030 - val_loss: 12.3642 - val_mae: 0.9534 - val_mse: 1.6066\n",
      "Epoch 717/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8036 - mae: 0.7834 - mse: 1.0031 - val_loss: 12.3668 - val_mae: 0.9485 - val_mse: 1.5987\n",
      "Epoch 718/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8039 - mae: 0.7822 - mse: 1.0035 - val_loss: 12.3674 - val_mae: 0.8641 - val_mse: 1.3748\n",
      "Epoch 719/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8039 - mae: 0.7826 - mse: 1.0026 - val_loss: 12.3503 - val_mae: 0.9571 - val_mse: 1.5980\n",
      "Epoch 720/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8040 - mae: 0.7835 - mse: 1.0041 - val_loss: 12.3507 - val_mae: 0.9343 - val_mse: 1.5469\n",
      "Epoch 721/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8029 - mae: 0.7826 - mse: 1.0008 - val_loss: 12.3512 - val_mae: 0.8847 - val_mse: 1.4132\n",
      "Epoch 722/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8026 - mae: 0.7828 - mse: 1.0022 - val_loss: 12.3470 - val_mae: 0.9689 - val_mse: 1.6185\n",
      "Epoch 723/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8028 - mae: 0.7831 - mse: 1.0030 - val_loss: 12.3422 - val_mae: 0.8779 - val_mse: 1.3981\n",
      "Epoch 724/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8020 - mae: 0.7825 - mse: 1.0014 - val_loss: 12.3480 - val_mae: 0.8985 - val_mse: 1.4568\n",
      "Epoch 725/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8030 - mae: 0.7829 - mse: 1.0033 - val_loss: 12.3437 - val_mae: 0.9040 - val_mse: 1.4586\n",
      "Epoch 726/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8028 - mae: 0.7829 - mse: 1.0029 - val_loss: 12.3560 - val_mae: 0.9992 - val_mse: 1.6873\n",
      "Epoch 727/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.8019 - mae: 0.7835 - mse: 1.0025 - val_loss: 12.3380 - val_mae: 0.9231 - val_mse: 1.5005\n",
      "Epoch 728/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.8016 - mae: 0.7827 - mse: 1.0017 - val_loss: 12.3393 - val_mae: 0.9423 - val_mse: 1.5535\n",
      "Epoch 729/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.8019 - mae: 0.7823 - mse: 1.0024 - val_loss: 12.3469 - val_mae: 0.9775 - val_mse: 1.6297\n",
      "Epoch 730/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.8010 - mae: 0.7829 - mse: 1.0021 - val_loss: 12.3720 - val_mae: 0.8502 - val_mse: 1.3445\n",
      "Epoch 731/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.8008 - mae: 0.7821 - mse: 1.0005 - val_loss: 12.3849 - val_mae: 0.8304 - val_mse: 1.3015\n",
      "Epoch 732/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8002 - mae: 0.7822 - mse: 1.0001 - val_loss: 12.3544 - val_mae: 0.9571 - val_mse: 1.5744\n",
      "Epoch 733/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.8015 - mae: 0.7827 - mse: 1.0029 - val_loss: 12.3546 - val_mae: 0.9846 - val_mse: 1.6529\n",
      "Epoch 734/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8010 - mae: 0.7828 - mse: 1.0021 - val_loss: 12.3586 - val_mae: 0.9989 - val_mse: 1.6792\n",
      "Epoch 735/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8001 - mae: 0.7819 - mse: 0.9990 - val_loss: 12.3814 - val_mae: 1.0222 - val_mse: 1.7830\n",
      "Epoch 736/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.8014 - mae: 0.7827 - mse: 1.0037 - val_loss: 12.3543 - val_mae: 0.8697 - val_mse: 1.3848\n",
      "Epoch 737/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.8009 - mae: 0.7832 - mse: 1.0019 - val_loss: 12.3378 - val_mae: 0.9280 - val_mse: 1.5206\n",
      "Epoch 738/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8001 - mae: 0.7818 - mse: 0.9994 - val_loss: 12.3869 - val_mae: 1.0370 - val_mse: 1.8156\n",
      "Epoch 739/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8004 - mae: 0.7824 - mse: 1.0025 - val_loss: 12.3419 - val_mae: 0.9116 - val_mse: 1.4797\n",
      "Epoch 740/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7999 - mae: 0.7811 - mse: 0.9995 - val_loss: 12.3493 - val_mae: 0.9762 - val_mse: 1.6481\n",
      "Epoch 741/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7993 - mae: 0.7821 - mse: 1.0008 - val_loss: 12.3556 - val_mae: 0.8818 - val_mse: 1.4191\n",
      "Epoch 742/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7993 - mae: 0.7813 - mse: 0.9991 - val_loss: 12.3446 - val_mae: 0.9688 - val_mse: 1.6212\n",
      "Epoch 743/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7991 - mae: 0.7818 - mse: 1.0002 - val_loss: 12.3601 - val_mae: 0.9409 - val_mse: 1.5843\n",
      "Epoch 744/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.8000 - mae: 0.7823 - mse: 1.0018 - val_loss: 12.3478 - val_mae: 0.8878 - val_mse: 1.4336\n",
      "Epoch 745/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7991 - mae: 0.7814 - mse: 0.9991 - val_loss: 12.3392 - val_mae: 0.9724 - val_mse: 1.6129\n",
      "Epoch 746/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7975 - mae: 0.7814 - mse: 0.9982 - val_loss: 12.3998 - val_mae: 1.0552 - val_mse: 1.7997\n",
      "Epoch 747/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7976 - mae: 0.7816 - mse: 0.9982 - val_loss: 12.3769 - val_mae: 0.9466 - val_mse: 1.5936\n",
      "Epoch 748/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7978 - mae: 0.7822 - mse: 0.9990 - val_loss: 12.3409 - val_mae: 0.8780 - val_mse: 1.3949\n",
      "Epoch 749/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7978 - mae: 0.7816 - mse: 0.9992 - val_loss: 12.4151 - val_mae: 1.0011 - val_mse: 1.7469\n",
      "Epoch 750/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7983 - mae: 0.7827 - mse: 1.0017 - val_loss: 12.3401 - val_mae: 0.9031 - val_mse: 1.4659\n",
      "Epoch 751/1000\n",
      "18102/18102 [==============================] - 1s 40us/sample - loss: 11.7973 - mae: 0.7819 - mse: 0.9971 - val_loss: 12.3511 - val_mae: 0.9107 - val_mse: 1.4927\n",
      "Epoch 752/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7963 - mae: 0.7810 - mse: 0.9975 - val_loss: 12.3361 - val_mae: 0.9507 - val_mse: 1.5660\n",
      "Epoch 753/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7963 - mae: 0.7813 - mse: 0.9974 - val_loss: 12.3648 - val_mae: 1.0198 - val_mse: 1.7503\n",
      "Epoch 754/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.7970 - mae: 0.7806 - mse: 0.9990 - val_loss: 12.3596 - val_mae: 0.9996 - val_mse: 1.6893\n",
      "Epoch 755/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7968 - mae: 0.7820 - mse: 0.9990 - val_loss: 12.3527 - val_mae: 0.9301 - val_mse: 1.4997\n",
      "Epoch 756/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7967 - mae: 0.7822 - mse: 0.9989 - val_loss: 12.3385 - val_mae: 0.8960 - val_mse: 1.4346\n",
      "Epoch 757/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.7963 - mae: 0.7808 - mse: 0.9977 - val_loss: 12.3332 - val_mae: 0.9327 - val_mse: 1.5230\n",
      "Epoch 758/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7952 - mae: 0.7805 - mse: 0.9961 - val_loss: 12.3633 - val_mae: 0.9703 - val_mse: 1.6531\n",
      "Epoch 759/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7966 - mae: 0.7816 - mse: 0.9987 - val_loss: 12.3336 - val_mae: 0.9303 - val_mse: 1.5041\n",
      "Epoch 760/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7962 - mae: 0.7811 - mse: 0.9971 - val_loss: 12.3362 - val_mae: 0.9677 - val_mse: 1.6179\n",
      "Epoch 761/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7967 - mae: 0.7816 - mse: 0.9981 - val_loss: 12.3507 - val_mae: 0.9840 - val_mse: 1.6710\n",
      "Epoch 762/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7964 - mae: 0.7816 - mse: 0.9985 - val_loss: 12.3333 - val_mae: 0.9483 - val_mse: 1.5739\n",
      "Epoch 763/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7950 - mae: 0.7807 - mse: 0.9980 - val_loss: 12.3745 - val_mae: 0.9442 - val_mse: 1.5866\n",
      "Epoch 764/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7968 - mae: 0.7816 - mse: 0.9998 - val_loss: 12.3399 - val_mae: 0.9045 - val_mse: 1.4649\n",
      "Epoch 765/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7955 - mae: 0.7814 - mse: 0.9975 - val_loss: 12.3392 - val_mae: 0.9152 - val_mse: 1.4992\n",
      "Epoch 766/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7944 - mae: 0.7804 - mse: 0.9967 - val_loss: 12.3431 - val_mae: 0.8855 - val_mse: 1.3975\n",
      "Epoch 767/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7952 - mae: 0.7802 - mse: 0.9974 - val_loss: 12.3590 - val_mae: 1.0119 - val_mse: 1.7021\n",
      "Epoch 768/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.7945 - mae: 0.7811 - mse: 0.9963 - val_loss: 12.3472 - val_mae: 0.9961 - val_mse: 1.6779\n",
      "Epoch 769/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7938 - mae: 0.7814 - mse: 0.9961 - val_loss: 12.3649 - val_mae: 0.9875 - val_mse: 1.6273\n",
      "Epoch 770/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7953 - mae: 0.7814 - mse: 0.9970 - val_loss: 12.3364 - val_mae: 0.9456 - val_mse: 1.5584\n",
      "Epoch 771/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7954 - mae: 0.7805 - mse: 0.9959 - val_loss: 12.3720 - val_mae: 1.0290 - val_mse: 1.7904\n",
      "Epoch 772/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7948 - mae: 0.7816 - mse: 0.9979 - val_loss: 12.3638 - val_mae: 0.9387 - val_mse: 1.5039\n",
      "Epoch 773/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7937 - mae: 0.7807 - mse: 0.9967 - val_loss: 12.3374 - val_mae: 0.9521 - val_mse: 1.5864\n",
      "Epoch 774/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7940 - mae: 0.7800 - mse: 0.9960 - val_loss: 12.3320 - val_mae: 0.9255 - val_mse: 1.4977\n",
      "Epoch 775/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7939 - mae: 0.7813 - mse: 0.9961 - val_loss: 12.3466 - val_mae: 0.9421 - val_mse: 1.5710\n",
      "Epoch 776/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7943 - mae: 0.7809 - mse: 0.9970 - val_loss: 12.3308 - val_mae: 0.9302 - val_mse: 1.5074\n",
      "Epoch 777/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7929 - mae: 0.7807 - mse: 0.9962 - val_loss: 12.3523 - val_mae: 0.9705 - val_mse: 1.6474\n",
      "Epoch 778/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7935 - mae: 0.7804 - mse: 0.9955 - val_loss: 12.3404 - val_mae: 0.8936 - val_mse: 1.4454\n",
      "Epoch 779/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 11.7931 - mae: 0.7804 - mse: 0.9950 - val_loss: 12.3514 - val_mae: 1.0132 - val_mse: 1.7249\n",
      "Epoch 780/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7930 - mae: 0.7808 - mse: 0.9960 - val_loss: 12.3293 - val_mae: 0.9085 - val_mse: 1.4617\n",
      "Epoch 781/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7926 - mae: 0.7806 - mse: 0.9957 - val_loss: 12.3345 - val_mae: 0.9021 - val_mse: 1.4490\n",
      "Epoch 782/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7928 - mae: 0.7805 - mse: 0.9955 - val_loss: 12.3545 - val_mae: 0.9946 - val_mse: 1.6505\n",
      "Epoch 783/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7921 - mae: 0.7810 - mse: 0.9952 - val_loss: 12.3272 - val_mae: 0.9190 - val_mse: 1.4944\n",
      "Epoch 784/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7932 - mae: 0.7805 - mse: 0.9961 - val_loss: 12.4038 - val_mae: 0.9719 - val_mse: 1.6784\n",
      "Epoch 785/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7921 - mae: 0.7808 - mse: 0.9953 - val_loss: 12.3300 - val_mae: 0.9349 - val_mse: 1.5250\n",
      "Epoch 786/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7916 - mae: 0.7798 - mse: 0.9948 - val_loss: 12.3450 - val_mae: 0.9010 - val_mse: 1.4660\n",
      "Epoch 787/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7919 - mae: 0.7807 - mse: 0.9946 - val_loss: 12.3899 - val_mae: 0.9443 - val_mse: 1.5960\n",
      "Epoch 788/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7918 - mae: 0.7800 - mse: 0.9951 - val_loss: 12.3667 - val_mae: 0.8322 - val_mse: 1.2853\n",
      "Epoch 789/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.7906 - mae: 0.7804 - mse: 0.9929 - val_loss: 12.3435 - val_mae: 0.9880 - val_mse: 1.6758\n",
      "Epoch 790/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7917 - mae: 0.7802 - mse: 0.9961 - val_loss: 12.3297 - val_mae: 0.9516 - val_mse: 1.5641\n",
      "Epoch 791/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7910 - mae: 0.7802 - mse: 0.9928 - val_loss: 12.3518 - val_mae: 0.9290 - val_mse: 1.4885\n",
      "Epoch 792/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7898 - mae: 0.7790 - mse: 0.9918 - val_loss: 12.3248 - val_mae: 0.9057 - val_mse: 1.4548\n",
      "Epoch 793/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7906 - mae: 0.7797 - mse: 0.9938 - val_loss: 12.3276 - val_mae: 0.9373 - val_mse: 1.5396\n",
      "Epoch 794/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7903 - mae: 0.7796 - mse: 0.9925 - val_loss: 12.3465 - val_mae: 0.9786 - val_mse: 1.6571\n",
      "Epoch 795/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7901 - mae: 0.7799 - mse: 0.9935 - val_loss: 12.3539 - val_mae: 0.9905 - val_mse: 1.6854\n",
      "Epoch 796/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7893 - mae: 0.7797 - mse: 0.9930 - val_loss: 12.3265 - val_mae: 0.9368 - val_mse: 1.5415\n",
      "Epoch 797/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7902 - mae: 0.7803 - mse: 0.9935 - val_loss: 12.3389 - val_mae: 0.9831 - val_mse: 1.6543\n",
      "Epoch 798/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7905 - mae: 0.7806 - mse: 0.9944 - val_loss: 12.3448 - val_mae: 0.8867 - val_mse: 1.4294\n",
      "Epoch 799/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7901 - mae: 0.7798 - mse: 0.9922 - val_loss: 12.3292 - val_mae: 0.9720 - val_mse: 1.6270\n",
      "Epoch 800/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7883 - mae: 0.7794 - mse: 0.9926 - val_loss: 12.3713 - val_mae: 0.8569 - val_mse: 1.3725\n",
      "Epoch 801/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7892 - mae: 0.7787 - mse: 0.9922 - val_loss: 12.3308 - val_mae: 0.9510 - val_mse: 1.5781\n",
      "Epoch 802/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7893 - mae: 0.7791 - mse: 0.9929 - val_loss: 12.3781 - val_mae: 1.0152 - val_mse: 1.6890\n",
      "Epoch 803/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7895 - mae: 0.7804 - mse: 0.9935 - val_loss: 12.3341 - val_mae: 0.8847 - val_mse: 1.4237\n",
      "Epoch 804/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 11.7889 - mae: 0.7792 - mse: 0.9926 - val_loss: 12.3596 - val_mae: 1.0040 - val_mse: 1.7273\n",
      "Epoch 805/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.7895 - mae: 0.7795 - mse: 0.9926 - val_loss: 12.3469 - val_mae: 1.0007 - val_mse: 1.6964\n",
      "Epoch 806/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7894 - mae: 0.7800 - mse: 0.9936 - val_loss: 12.3397 - val_mae: 0.9545 - val_mse: 1.5913\n",
      "Epoch 807/1000\n",
      "18102/18102 [==============================] - 1s 39us/sample - loss: 11.7884 - mae: 0.7796 - mse: 0.9923 - val_loss: 12.3412 - val_mae: 0.9894 - val_mse: 1.6594\n",
      "Epoch 808/1000\n",
      "18102/18102 [==============================] - 1s 39us/sample - loss: 11.7889 - mae: 0.7803 - mse: 0.9932 - val_loss: 12.3424 - val_mae: 0.8866 - val_mse: 1.4360\n",
      "Epoch 809/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7881 - mae: 0.7788 - mse: 0.9906 - val_loss: 12.3644 - val_mae: 0.9284 - val_mse: 1.5504\n",
      "Epoch 810/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7892 - mae: 0.7798 - mse: 0.9926 - val_loss: 12.3326 - val_mae: 0.8990 - val_mse: 1.4548\n",
      "Epoch 811/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7870 - mae: 0.7791 - mse: 0.9913 - val_loss: 12.3437 - val_mae: 0.8478 - val_mse: 1.3205\n",
      "Epoch 812/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7886 - mae: 0.7784 - mse: 0.9902 - val_loss: 12.3584 - val_mae: 0.8500 - val_mse: 1.3213\n",
      "Epoch 813/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7882 - mae: 0.7793 - mse: 0.9917 - val_loss: 12.3251 - val_mae: 0.9116 - val_mse: 1.4611\n",
      "Epoch 814/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7885 - mae: 0.7792 - mse: 0.9923 - val_loss: 12.3951 - val_mae: 0.9944 - val_mse: 1.7337\n",
      "Epoch 815/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7888 - mae: 0.7798 - mse: 0.9924 - val_loss: 12.3563 - val_mae: 0.9348 - val_mse: 1.5584\n",
      "Epoch 816/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7886 - mae: 0.7794 - mse: 0.9931 - val_loss: 12.4326 - val_mae: 0.7887 - val_mse: 1.2199\n",
      "Epoch 817/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7874 - mae: 0.7780 - mse: 0.9894 - val_loss: 12.3318 - val_mae: 0.9351 - val_mse: 1.5109\n",
      "Epoch 818/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7871 - mae: 0.7800 - mse: 0.9916 - val_loss: 12.3738 - val_mae: 0.9466 - val_mse: 1.6008\n",
      "Epoch 819/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7873 - mae: 0.7788 - mse: 0.9907 - val_loss: 12.3876 - val_mae: 0.9820 - val_mse: 1.6898\n",
      "Epoch 820/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7869 - mae: 0.7788 - mse: 0.9913 - val_loss: 12.3270 - val_mae: 0.9241 - val_mse: 1.5177\n",
      "Epoch 821/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.7871 - mae: 0.7795 - mse: 0.9912 - val_loss: 12.3248 - val_mae: 0.9440 - val_mse: 1.5500\n",
      "Epoch 822/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7857 - mae: 0.7787 - mse: 0.9898 - val_loss: 12.3841 - val_mae: 0.9204 - val_mse: 1.5384\n",
      "Epoch 823/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 11.7857 - mae: 0.7784 - mse: 0.9902 - val_loss: 12.3256 - val_mae: 0.8941 - val_mse: 1.4285\n",
      "Epoch 824/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.7860 - mae: 0.7784 - mse: 0.9886 - val_loss: 12.3388 - val_mae: 0.9889 - val_mse: 1.6648\n",
      "Epoch 825/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.7852 - mae: 0.7788 - mse: 0.9901 - val_loss: 12.3475 - val_mae: 0.8990 - val_mse: 1.4677\n",
      "Epoch 826/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7862 - mae: 0.7786 - mse: 0.9900 - val_loss: 12.3280 - val_mae: 0.9528 - val_mse: 1.5732\n",
      "Epoch 827/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7857 - mae: 0.7789 - mse: 0.9900 - val_loss: 12.3371 - val_mae: 0.9828 - val_mse: 1.6499\n",
      "Epoch 828/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7861 - mae: 0.7795 - mse: 0.9908 - val_loss: 12.3263 - val_mae: 0.8948 - val_mse: 1.4358\n",
      "Epoch 829/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7864 - mae: 0.7784 - mse: 0.9900 - val_loss: 12.3204 - val_mae: 0.9032 - val_mse: 1.4541\n",
      "Epoch 830/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7840 - mae: 0.7786 - mse: 0.9887 - val_loss: 12.3197 - val_mae: 0.8947 - val_mse: 1.4312\n",
      "Epoch 831/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7858 - mae: 0.7789 - mse: 0.9908 - val_loss: 12.3288 - val_mae: 0.9397 - val_mse: 1.5234\n",
      "Epoch 832/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 11.7846 - mae: 0.7786 - mse: 0.9886 - val_loss: 12.3242 - val_mae: 0.9499 - val_mse: 1.5782\n",
      "Epoch 833/1000\n",
      "18102/18102 [==============================] - 1s 44us/sample - loss: 11.7844 - mae: 0.7787 - mse: 0.9895 - val_loss: 12.3703 - val_mae: 1.0512 - val_mse: 1.8149\n",
      "Epoch 834/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7851 - mae: 0.7791 - mse: 0.9905 - val_loss: 12.3301 - val_mae: 0.8586 - val_mse: 1.3464\n",
      "Epoch 835/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7842 - mae: 0.7777 - mse: 0.9882 - val_loss: 12.3460 - val_mae: 1.0176 - val_mse: 1.7402\n",
      "Epoch 836/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7843 - mae: 0.7777 - mse: 0.9893 - val_loss: 12.3324 - val_mae: 0.9796 - val_mse: 1.6301\n",
      "Epoch 837/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7839 - mae: 0.7775 - mse: 0.9870 - val_loss: 12.3606 - val_mae: 1.0044 - val_mse: 1.7325\n",
      "Epoch 838/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7847 - mae: 0.7775 - mse: 0.9900 - val_loss: 12.3259 - val_mae: 0.9045 - val_mse: 1.4408\n",
      "Epoch 839/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.7839 - mae: 0.7780 - mse: 0.9877 - val_loss: 12.3284 - val_mae: 0.9361 - val_mse: 1.5465\n",
      "Epoch 840/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7838 - mae: 0.7772 - mse: 0.9879 - val_loss: 12.3546 - val_mae: 0.9406 - val_mse: 1.5784\n",
      "Epoch 841/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.7831 - mae: 0.7778 - mse: 0.9881 - val_loss: 12.3432 - val_mae: 0.8945 - val_mse: 1.4630\n",
      "Epoch 842/1000\n",
      "18102/18102 [==============================] - 1s 41us/sample - loss: 11.7837 - mae: 0.7778 - mse: 0.9882 - val_loss: 12.3580 - val_mae: 0.9975 - val_mse: 1.6486\n",
      "Epoch 843/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.7840 - mae: 0.7772 - mse: 0.9886 - val_loss: 12.3273 - val_mae: 0.9511 - val_mse: 1.5456\n",
      "Epoch 844/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.7834 - mae: 0.7781 - mse: 0.9879 - val_loss: 12.3257 - val_mae: 0.9256 - val_mse: 1.4883\n",
      "Epoch 845/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7839 - mae: 0.7780 - mse: 0.9885 - val_loss: 12.3680 - val_mae: 1.0492 - val_mse: 1.8149\n",
      "Epoch 846/1000\n",
      "18102/18102 [==============================] - 1s 40us/sample - loss: 11.7820 - mae: 0.7777 - mse: 0.9877 - val_loss: 12.3236 - val_mae: 0.9082 - val_mse: 1.4702\n",
      "Epoch 847/1000\n",
      "18102/18102 [==============================] - 1s 39us/sample - loss: 11.7834 - mae: 0.7782 - mse: 0.9877 - val_loss: 12.3207 - val_mae: 0.9155 - val_mse: 1.4726\n",
      "Epoch 848/1000\n",
      "18102/18102 [==============================] - 1s 40us/sample - loss: 11.7819 - mae: 0.7768 - mse: 0.9861 - val_loss: 12.3308 - val_mae: 0.9497 - val_mse: 1.5850\n",
      "Epoch 849/1000\n",
      "18102/18102 [==============================] - 1s 41us/sample - loss: 11.7822 - mae: 0.7781 - mse: 0.9880 - val_loss: 12.3488 - val_mae: 0.9984 - val_mse: 1.6508\n",
      "Epoch 850/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 11.7822 - mae: 0.7772 - mse: 0.9865 - val_loss: 12.3239 - val_mae: 0.9738 - val_mse: 1.6199\n",
      "Epoch 851/1000\n",
      "18102/18102 [==============================] - 1s 42us/sample - loss: 11.7813 - mae: 0.7779 - mse: 0.9871 - val_loss: 12.3319 - val_mae: 0.8986 - val_mse: 1.4539\n",
      "Epoch 852/1000\n",
      "18102/18102 [==============================] - 1s 40us/sample - loss: 11.7827 - mae: 0.7783 - mse: 0.9874 - val_loss: 12.3202 - val_mae: 0.9502 - val_mse: 1.5739\n",
      "Epoch 853/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.7821 - mae: 0.7777 - mse: 0.9874 - val_loss: 12.3262 - val_mae: 0.9338 - val_mse: 1.5093\n",
      "Epoch 854/1000\n",
      "18102/18102 [==============================] - 1s 41us/sample - loss: 11.7814 - mae: 0.7779 - mse: 0.9864 - val_loss: 12.3115 - val_mae: 0.9003 - val_mse: 1.4478\n",
      "Epoch 855/1000\n",
      "18102/18102 [==============================] - 1s 43us/sample - loss: 11.7807 - mae: 0.7776 - mse: 0.9872 - val_loss: 12.3392 - val_mae: 0.8667 - val_mse: 1.3506\n",
      "Epoch 856/1000\n",
      "18102/18102 [==============================] - 1s 51us/sample - loss: 11.7816 - mae: 0.7771 - mse: 0.9869 - val_loss: 12.3239 - val_mae: 0.9455 - val_mse: 1.5586\n",
      "Epoch 857/1000\n",
      "18102/18102 [==============================] - 1s 53us/sample - loss: 11.7822 - mae: 0.7781 - mse: 0.9881 - val_loss: 12.3391 - val_mae: 0.8493 - val_mse: 1.3342\n",
      "Epoch 858/1000\n",
      "18102/18102 [==============================] - 1s 51us/sample - loss: 11.7819 - mae: 0.7777 - mse: 0.9877 - val_loss: 12.3156 - val_mae: 0.9269 - val_mse: 1.5076\n",
      "Epoch 859/1000\n",
      "18102/18102 [==============================] - 1s 51us/sample - loss: 11.7817 - mae: 0.7779 - mse: 0.9876 - val_loss: 12.3423 - val_mae: 0.9900 - val_mse: 1.6833\n",
      "Epoch 860/1000\n",
      "18102/18102 [==============================] - 1s 52us/sample - loss: 11.7818 - mae: 0.7782 - mse: 0.9881 - val_loss: 12.3632 - val_mae: 0.8463 - val_mse: 1.3429\n",
      "Epoch 861/1000\n",
      "18102/18102 [==============================] - 1s 51us/sample - loss: 11.7815 - mae: 0.7777 - mse: 0.9868 - val_loss: 12.3247 - val_mae: 0.9243 - val_mse: 1.5130\n",
      "Epoch 862/1000\n",
      "18102/18102 [==============================] - 1s 51us/sample - loss: 11.7815 - mae: 0.7771 - mse: 0.9875 - val_loss: 12.3445 - val_mae: 1.0005 - val_mse: 1.7088\n",
      "Epoch 863/1000\n",
      "18102/18102 [==============================] - 1s 51us/sample - loss: 11.7809 - mae: 0.7777 - mse: 0.9878 - val_loss: 12.3168 - val_mae: 0.8816 - val_mse: 1.4062\n",
      "Epoch 864/1000\n",
      "18102/18102 [==============================] - 1s 52us/sample - loss: 11.7811 - mae: 0.7768 - mse: 0.9862 - val_loss: 12.3289 - val_mae: 0.9626 - val_mse: 1.6092\n",
      "Epoch 865/1000\n",
      "18102/18102 [==============================] - 1s 52us/sample - loss: 11.7814 - mae: 0.7774 - mse: 0.9875 - val_loss: 12.3240 - val_mae: 0.9376 - val_mse: 1.5529\n",
      "Epoch 866/1000\n",
      "18102/18102 [==============================] - 1s 50us/sample - loss: 11.7808 - mae: 0.7775 - mse: 0.9877 - val_loss: 12.3281 - val_mae: 0.8593 - val_mse: 1.3482\n",
      "Epoch 867/1000\n",
      "18102/18102 [==============================] - 1s 46us/sample - loss: 11.7797 - mae: 0.7766 - mse: 0.9842 - val_loss: 12.3332 - val_mae: 0.8702 - val_mse: 1.3851\n",
      "Epoch 868/1000\n",
      "18102/18102 [==============================] - 1s 41us/sample - loss: 11.7792 - mae: 0.7768 - mse: 0.9851 - val_loss: 12.3223 - val_mae: 0.8880 - val_mse: 1.4114\n",
      "Epoch 869/1000\n",
      "18102/18102 [==============================] - 1s 39us/sample - loss: 11.7799 - mae: 0.7771 - mse: 0.9853 - val_loss: 12.3518 - val_mae: 1.0289 - val_mse: 1.7549\n",
      "Epoch 870/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.7803 - mae: 0.7769 - mse: 0.9866 - val_loss: 12.3287 - val_mae: 0.9324 - val_mse: 1.5358\n",
      "Epoch 871/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.7798 - mae: 0.7771 - mse: 0.9863 - val_loss: 12.3129 - val_mae: 0.9206 - val_mse: 1.5024\n",
      "Epoch 872/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 11.7798 - mae: 0.7767 - mse: 0.9855 - val_loss: 12.3438 - val_mae: 0.9885 - val_mse: 1.6335\n",
      "Epoch 873/1000\n",
      "18102/18102 [==============================] - 1s 39us/sample - loss: 11.7798 - mae: 0.7777 - mse: 0.9870 - val_loss: 12.3503 - val_mae: 0.8788 - val_mse: 1.4218\n",
      "Epoch 874/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 11.7793 - mae: 0.7765 - mse: 0.9852 - val_loss: 12.3212 - val_mae: 0.9612 - val_mse: 1.6006\n",
      "Epoch 875/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 40us/sample - loss: 11.7791 - mae: 0.7771 - mse: 0.9846 - val_loss: 12.3410 - val_mae: 0.8856 - val_mse: 1.3888\n",
      "Epoch 876/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.7790 - mae: 0.7763 - mse: 0.9856 - val_loss: 12.3530 - val_mae: 1.0268 - val_mse: 1.7539\n",
      "Epoch 877/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.7792 - mae: 0.7766 - mse: 0.9846 - val_loss: 12.3166 - val_mae: 0.9052 - val_mse: 1.4673\n",
      "Epoch 878/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.7789 - mae: 0.7768 - mse: 0.9852 - val_loss: 12.3307 - val_mae: 0.8897 - val_mse: 1.4434\n",
      "Epoch 879/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7798 - mae: 0.7768 - mse: 0.9866 - val_loss: 12.3351 - val_mae: 0.9987 - val_mse: 1.6919\n",
      "Epoch 880/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7787 - mae: 0.7769 - mse: 0.9852 - val_loss: 12.3230 - val_mae: 0.9703 - val_mse: 1.6140\n",
      "Epoch 881/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.7778 - mae: 0.7772 - mse: 0.9841 - val_loss: 12.3270 - val_mae: 0.9444 - val_mse: 1.5735\n",
      "Epoch 882/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.7779 - mae: 0.7758 - mse: 0.9837 - val_loss: 12.3233 - val_mae: 0.9721 - val_mse: 1.6288\n",
      "Epoch 883/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7784 - mae: 0.7767 - mse: 0.9856 - val_loss: 12.3587 - val_mae: 0.9248 - val_mse: 1.5456\n",
      "Epoch 884/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7779 - mae: 0.7762 - mse: 0.9833 - val_loss: 12.3300 - val_mae: 0.9788 - val_mse: 1.6194\n",
      "Epoch 885/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7777 - mae: 0.7769 - mse: 0.9837 - val_loss: 12.3300 - val_mae: 0.9448 - val_mse: 1.5762\n",
      "Epoch 886/1000\n",
      "18102/18102 [==============================] - 1s 40us/sample - loss: 11.7778 - mae: 0.7767 - mse: 0.9843 - val_loss: 12.3233 - val_mae: 0.9626 - val_mse: 1.6118\n",
      "Epoch 887/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.7768 - mae: 0.7757 - mse: 0.9825 - val_loss: 12.3152 - val_mae: 0.9409 - val_mse: 1.5478\n",
      "Epoch 888/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7784 - mae: 0.7762 - mse: 0.9842 - val_loss: 12.3426 - val_mae: 1.0160 - val_mse: 1.7301\n",
      "Epoch 889/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.7778 - mae: 0.7763 - mse: 0.9843 - val_loss: 12.3263 - val_mae: 0.8522 - val_mse: 1.3333\n",
      "Epoch 890/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7774 - mae: 0.7762 - mse: 0.9829 - val_loss: 12.3188 - val_mae: 0.9575 - val_mse: 1.5789\n",
      "Epoch 891/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.7767 - mae: 0.7763 - mse: 0.9838 - val_loss: 12.3480 - val_mae: 0.9394 - val_mse: 1.5800\n",
      "Epoch 892/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7761 - mae: 0.7761 - mse: 0.9835 - val_loss: 12.3308 - val_mae: 1.0018 - val_mse: 1.6786\n",
      "Epoch 893/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7767 - mae: 0.7762 - mse: 0.9842 - val_loss: 12.3220 - val_mae: 0.9100 - val_mse: 1.4510\n",
      "Epoch 894/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.7769 - mae: 0.7761 - mse: 0.9833 - val_loss: 12.3120 - val_mae: 0.9048 - val_mse: 1.4553\n",
      "Epoch 895/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 11.7770 - mae: 0.7761 - mse: 0.9834 - val_loss: 12.3569 - val_mae: 1.0002 - val_mse: 1.7177\n",
      "Epoch 896/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 11.7756 - mae: 0.7755 - mse: 0.9830 - val_loss: 12.3254 - val_mae: 0.9702 - val_mse: 1.5868\n",
      "Epoch 897/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7779 - mae: 0.7775 - mse: 0.9858 - val_loss: 12.3091 - val_mae: 0.9090 - val_mse: 1.4710\n",
      "Epoch 898/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 11.7763 - mae: 0.7758 - mse: 0.9822 - val_loss: 12.3226 - val_mae: 0.8544 - val_mse: 1.3390\n",
      "Epoch 899/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.7759 - mae: 0.7759 - mse: 0.9817 - val_loss: 12.3240 - val_mae: 0.8905 - val_mse: 1.4360\n",
      "Epoch 900/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.7764 - mae: 0.7762 - mse: 0.9836 - val_loss: 12.3081 - val_mae: 0.9326 - val_mse: 1.5224\n",
      "Epoch 901/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.7761 - mae: 0.7755 - mse: 0.9822 - val_loss: 12.3356 - val_mae: 0.9838 - val_mse: 1.6744\n",
      "Epoch 902/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.7755 - mae: 0.7762 - mse: 0.9834 - val_loss: 12.3942 - val_mae: 0.8118 - val_mse: 1.2703\n",
      "Epoch 903/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.7755 - mae: 0.7760 - mse: 0.9819 - val_loss: 12.3465 - val_mae: 1.0232 - val_mse: 1.7485\n",
      "Epoch 904/1000\n",
      "18102/18102 [==============================] - 1s 40us/sample - loss: 11.7748 - mae: 0.7757 - mse: 0.9818 - val_loss: 12.3577 - val_mae: 0.8570 - val_mse: 1.3673\n",
      "Epoch 905/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7756 - mae: 0.7756 - mse: 0.9821 - val_loss: 12.3510 - val_mae: 0.8763 - val_mse: 1.4169\n",
      "Epoch 906/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 11.7752 - mae: 0.7756 - mse: 0.9819 - val_loss: 12.3205 - val_mae: 0.9449 - val_mse: 1.5728\n",
      "Epoch 907/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7753 - mae: 0.7745 - mse: 0.9816 - val_loss: 12.3798 - val_mae: 0.9859 - val_mse: 1.6985\n",
      "Epoch 908/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7751 - mae: 0.7763 - mse: 0.9824 - val_loss: 12.3157 - val_mae: 0.9115 - val_mse: 1.4725\n",
      "Epoch 909/1000\n",
      "18102/18102 [==============================] - 1s 33us/sample - loss: 11.7738 - mae: 0.7754 - mse: 0.9814 - val_loss: 12.3172 - val_mae: 0.8768 - val_mse: 1.3912\n",
      "Epoch 910/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.7740 - mae: 0.7757 - mse: 0.9813 - val_loss: 12.3074 - val_mae: 0.9360 - val_mse: 1.5328\n",
      "Epoch 911/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.7739 - mae: 0.7754 - mse: 0.9817 - val_loss: 12.3282 - val_mae: 0.8805 - val_mse: 1.4183\n",
      "Epoch 912/1000\n",
      "18102/18102 [==============================] - 1s 40us/sample - loss: 11.7740 - mae: 0.7754 - mse: 0.9813 - val_loss: 12.3648 - val_mae: 0.8802 - val_mse: 1.3679\n",
      "Epoch 913/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7753 - mae: 0.7761 - mse: 0.9832 - val_loss: 12.3235 - val_mae: 0.8680 - val_mse: 1.3753\n",
      "Epoch 914/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7742 - mae: 0.7749 - mse: 0.9809 - val_loss: 12.3165 - val_mae: 0.9309 - val_mse: 1.5067\n",
      "Epoch 915/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7734 - mae: 0.7752 - mse: 0.9808 - val_loss: 12.3078 - val_mae: 0.8972 - val_mse: 1.4337\n",
      "Epoch 916/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7728 - mae: 0.7758 - mse: 0.9804 - val_loss: 12.3354 - val_mae: 0.9889 - val_mse: 1.6769\n",
      "Epoch 917/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.7734 - mae: 0.7744 - mse: 0.9804 - val_loss: 12.3108 - val_mae: 0.9132 - val_mse: 1.4850\n",
      "Epoch 918/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7720 - mae: 0.7738 - mse: 0.9779 - val_loss: 12.3131 - val_mae: 0.8815 - val_mse: 1.4096\n",
      "Epoch 919/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7731 - mae: 0.7750 - mse: 0.9805 - val_loss: 12.3269 - val_mae: 0.8688 - val_mse: 1.3590\n",
      "Epoch 920/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7731 - mae: 0.7749 - mse: 0.9803 - val_loss: 12.3180 - val_mae: 0.8683 - val_mse: 1.3692\n",
      "Epoch 921/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 40us/sample - loss: 11.7734 - mae: 0.7754 - mse: 0.9802 - val_loss: 12.3162 - val_mae: 0.9443 - val_mse: 1.5605\n",
      "Epoch 922/1000\n",
      "18102/18102 [==============================] - 1s 37us/sample - loss: 11.7729 - mae: 0.7749 - mse: 0.9809 - val_loss: 12.3061 - val_mae: 0.9315 - val_mse: 1.5182\n",
      "Epoch 923/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7717 - mae: 0.7745 - mse: 0.9797 - val_loss: 12.3171 - val_mae: 0.9746 - val_mse: 1.6084\n",
      "Epoch 924/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7719 - mae: 0.7746 - mse: 0.9797 - val_loss: 12.3088 - val_mae: 0.8970 - val_mse: 1.4443\n",
      "Epoch 925/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7735 - mae: 0.7751 - mse: 0.9817 - val_loss: 12.3186 - val_mae: 0.8820 - val_mse: 1.3891\n",
      "Epoch 926/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.7728 - mae: 0.7745 - mse: 0.9802 - val_loss: 12.3142 - val_mae: 0.9093 - val_mse: 1.4856\n",
      "Epoch 927/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.7725 - mae: 0.7753 - mse: 0.9804 - val_loss: 12.3160 - val_mae: 0.9616 - val_mse: 1.5786\n",
      "Epoch 928/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7717 - mae: 0.7742 - mse: 0.9797 - val_loss: 12.3200 - val_mae: 0.8837 - val_mse: 1.3968\n",
      "Epoch 929/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7722 - mae: 0.7747 - mse: 0.9803 - val_loss: 12.3206 - val_mae: 0.9332 - val_mse: 1.5421\n",
      "Epoch 930/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.7732 - mae: 0.7752 - mse: 0.9816 - val_loss: 12.3098 - val_mae: 0.8932 - val_mse: 1.4137\n",
      "Epoch 931/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7714 - mae: 0.7739 - mse: 0.9790 - val_loss: 12.3098 - val_mae: 0.8908 - val_mse: 1.4250\n",
      "Epoch 932/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7709 - mae: 0.7747 - mse: 0.9787 - val_loss: 12.3277 - val_mae: 0.9075 - val_mse: 1.4356\n",
      "Epoch 933/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.7706 - mae: 0.7748 - mse: 0.9781 - val_loss: 12.3480 - val_mae: 1.0304 - val_mse: 1.7740\n",
      "Epoch 934/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.7714 - mae: 0.7743 - mse: 0.9796 - val_loss: 12.3025 - val_mae: 0.9395 - val_mse: 1.5358\n",
      "Epoch 935/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7714 - mae: 0.7741 - mse: 0.9792 - val_loss: 12.3232 - val_mae: 0.9497 - val_mse: 1.5408\n",
      "Epoch 936/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7709 - mae: 0.7750 - mse: 0.9791 - val_loss: 12.3190 - val_mae: 0.8944 - val_mse: 1.4467\n",
      "Epoch 937/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.7716 - mae: 0.7750 - mse: 0.9804 - val_loss: 12.3507 - val_mae: 0.8811 - val_mse: 1.4266\n",
      "Epoch 938/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.7717 - mae: 0.7744 - mse: 0.9791 - val_loss: 12.3403 - val_mae: 0.9936 - val_mse: 1.7032\n",
      "Epoch 939/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7702 - mae: 0.7743 - mse: 0.9788 - val_loss: 12.3559 - val_mae: 0.9999 - val_mse: 1.7255\n",
      "Epoch 940/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7706 - mae: 0.7742 - mse: 0.9791 - val_loss: 12.3284 - val_mae: 0.8703 - val_mse: 1.3954\n",
      "Epoch 941/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7703 - mae: 0.7739 - mse: 0.9786 - val_loss: 12.3151 - val_mae: 0.9207 - val_mse: 1.5048\n",
      "Epoch 942/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7706 - mae: 0.7740 - mse: 0.9787 - val_loss: 12.3244 - val_mae: 0.9876 - val_mse: 1.6697\n",
      "Epoch 943/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7696 - mae: 0.7744 - mse: 0.9781 - val_loss: 12.3441 - val_mae: 0.9696 - val_mse: 1.6504\n",
      "Epoch 944/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7696 - mae: 0.7737 - mse: 0.9772 - val_loss: 12.3248 - val_mae: 0.9990 - val_mse: 1.6938\n",
      "Epoch 945/1000\n",
      "18102/18102 [==============================] - 1s 42us/sample - loss: 11.7691 - mae: 0.7743 - mse: 0.9778 - val_loss: 12.3076 - val_mae: 0.9509 - val_mse: 1.5607\n",
      "Epoch 946/1000\n",
      "18102/18102 [==============================] - 1s 40us/sample - loss: 11.7703 - mae: 0.7739 - mse: 0.9787 - val_loss: 12.3220 - val_mae: 0.9604 - val_mse: 1.6052\n",
      "Epoch 947/1000\n",
      "18102/18102 [==============================] - 1s 41us/sample - loss: 11.7693 - mae: 0.7748 - mse: 0.9787 - val_loss: 12.3378 - val_mae: 0.9730 - val_mse: 1.6584\n",
      "Epoch 948/1000\n",
      "18102/18102 [==============================] - 1s 41us/sample - loss: 11.7700 - mae: 0.7739 - mse: 0.9780 - val_loss: 12.3032 - val_mae: 0.8869 - val_mse: 1.4166\n",
      "Epoch 949/1000\n",
      "18102/18102 [==============================] - 1s 42us/sample - loss: 11.7694 - mae: 0.7737 - mse: 0.9782 - val_loss: 12.3311 - val_mae: 0.9501 - val_mse: 1.5329\n",
      "Epoch 950/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 11.7697 - mae: 0.7740 - mse: 0.9778 - val_loss: 12.3235 - val_mae: 0.8566 - val_mse: 1.3318\n",
      "Epoch 951/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.7688 - mae: 0.7738 - mse: 0.9770 - val_loss: 12.3152 - val_mae: 0.8897 - val_mse: 1.4398\n",
      "Epoch 952/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 11.7697 - mae: 0.7739 - mse: 0.9779 - val_loss: 12.3467 - val_mae: 1.0355 - val_mse: 1.7691\n",
      "Epoch 953/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.7691 - mae: 0.7739 - mse: 0.9776 - val_loss: 12.3052 - val_mae: 0.8970 - val_mse: 1.4418\n",
      "Epoch 954/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7689 - mae: 0.7741 - mse: 0.9779 - val_loss: 12.3103 - val_mae: 0.8822 - val_mse: 1.3918\n",
      "Epoch 955/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 11.7689 - mae: 0.7737 - mse: 0.9768 - val_loss: 12.3020 - val_mae: 0.9199 - val_mse: 1.4848\n",
      "Epoch 956/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.7676 - mae: 0.7739 - mse: 0.9762 - val_loss: 12.3023 - val_mae: 0.9037 - val_mse: 1.4541\n",
      "Epoch 957/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.7692 - mae: 0.7735 - mse: 0.9776 - val_loss: 12.3432 - val_mae: 0.9674 - val_mse: 1.6417\n",
      "Epoch 958/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.7685 - mae: 0.7740 - mse: 0.9776 - val_loss: 12.3046 - val_mae: 0.8946 - val_mse: 1.4367\n",
      "Epoch 959/1000\n",
      "18102/18102 [==============================] - 1s 34us/sample - loss: 11.7675 - mae: 0.7738 - mse: 0.9763 - val_loss: 12.3051 - val_mae: 0.8915 - val_mse: 1.4194\n",
      "Epoch 960/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7682 - mae: 0.7743 - mse: 0.9764 - val_loss: 12.3090 - val_mae: 0.9383 - val_mse: 1.5533\n",
      "Epoch 961/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7672 - mae: 0.7725 - mse: 0.9760 - val_loss: 12.3116 - val_mae: 0.9313 - val_mse: 1.4978\n",
      "Epoch 962/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7679 - mae: 0.7738 - mse: 0.9765 - val_loss: 12.3169 - val_mae: 0.8820 - val_mse: 1.4105\n",
      "Epoch 963/1000\n",
      "18102/18102 [==============================] - 1s 40us/sample - loss: 11.7685 - mae: 0.7733 - mse: 0.9764 - val_loss: 12.3108 - val_mae: 0.9314 - val_mse: 1.5341\n",
      "Epoch 964/1000\n",
      "18102/18102 [==============================] - 1s 40us/sample - loss: 11.7679 - mae: 0.7736 - mse: 0.9755 - val_loss: 12.3530 - val_mae: 1.0389 - val_mse: 1.7943\n",
      "Epoch 965/1000\n",
      "18102/18102 [==============================] - 1s 43us/sample - loss: 11.7671 - mae: 0.7731 - mse: 0.9763 - val_loss: 12.3665 - val_mae: 1.0692 - val_mse: 1.8572\n",
      "Epoch 966/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7682 - mae: 0.7733 - mse: 0.9772 - val_loss: 12.3062 - val_mae: 0.9418 - val_mse: 1.5354\n",
      "Epoch 967/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18102/18102 [==============================] - 1s 38us/sample - loss: 11.7658 - mae: 0.7730 - mse: 0.9744 - val_loss: 12.3144 - val_mae: 0.8759 - val_mse: 1.3924\n",
      "Epoch 968/1000\n",
      "18102/18102 [==============================] - 1s 41us/sample - loss: 11.7670 - mae: 0.7727 - mse: 0.9740 - val_loss: 12.3589 - val_mae: 0.9803 - val_mse: 1.6826\n",
      "Epoch 969/1000\n",
      "18102/18102 [==============================] - 1s 38us/sample - loss: 11.7667 - mae: 0.7732 - mse: 0.9754 - val_loss: 12.3267 - val_mae: 0.9271 - val_mse: 1.5384\n",
      "Epoch 970/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7671 - mae: 0.7730 - mse: 0.9764 - val_loss: 12.3250 - val_mae: 1.0039 - val_mse: 1.6939\n",
      "Epoch 971/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.7680 - mae: 0.7737 - mse: 0.9776 - val_loss: 12.3176 - val_mae: 0.9929 - val_mse: 1.6652\n",
      "Epoch 972/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7667 - mae: 0.7731 - mse: 0.9760 - val_loss: 12.3134 - val_mae: 0.8988 - val_mse: 1.4522\n",
      "Epoch 973/1000\n",
      "18102/18102 [==============================] - 1s 43us/sample - loss: 11.7670 - mae: 0.7734 - mse: 0.9754 - val_loss: 12.3249 - val_mae: 0.9041 - val_mse: 1.4756\n",
      "Epoch 974/1000\n",
      "18102/18102 [==============================] - 1s 45us/sample - loss: 11.7652 - mae: 0.7720 - mse: 0.9733 - val_loss: 12.3398 - val_mae: 0.9864 - val_mse: 1.6875\n",
      "Epoch 975/1000\n",
      "18102/18102 [==============================] - 1s 35us/sample - loss: 11.7655 - mae: 0.7732 - mse: 0.9743 - val_loss: 12.3092 - val_mae: 0.8902 - val_mse: 1.4397\n",
      "Epoch 976/1000\n",
      "18102/18102 [==============================] - 1s 31us/sample - loss: 11.7668 - mae: 0.7724 - mse: 0.9752 - val_loss: 12.3940 - val_mae: 1.0922 - val_mse: 1.9517\n",
      "Epoch 977/1000\n",
      "18102/18102 [==============================] - 1s 43us/sample - loss: 11.7654 - mae: 0.7732 - mse: 0.9753 - val_loss: 12.3656 - val_mae: 1.0608 - val_mse: 1.8322\n",
      "Epoch 978/1000\n",
      "18102/18102 [==============================] - 1s 39us/sample - loss: 11.7649 - mae: 0.7729 - mse: 0.9746 - val_loss: 12.3474 - val_mae: 0.8733 - val_mse: 1.4136\n",
      "Epoch 979/1000\n",
      "18102/18102 [==============================] - 1s 40us/sample - loss: 11.7669 - mae: 0.7740 - mse: 0.9762 - val_loss: 12.3153 - val_mae: 0.9609 - val_mse: 1.6061\n",
      "Epoch 980/1000\n",
      "18102/18102 [==============================] - 1s 36us/sample - loss: 11.7652 - mae: 0.7735 - mse: 0.9746 - val_loss: 12.3054 - val_mae: 0.8862 - val_mse: 1.4226\n",
      "Epoch 981/1000\n",
      "18102/18102 [==============================] - 1s 44us/sample - loss: 11.7652 - mae: 0.7721 - mse: 0.9733 - val_loss: 12.3079 - val_mae: 0.9587 - val_mse: 1.5723\n",
      "Epoch 982/1000\n",
      "18102/18102 [==============================] - 1s 39us/sample - loss: 11.7651 - mae: 0.7725 - mse: 0.9747 - val_loss: 12.2948 - val_mae: 0.9268 - val_mse: 1.5095\n",
      "Epoch 983/1000\n",
      "18102/18102 [==============================] - 1s 29us/sample - loss: 11.7649 - mae: 0.7725 - mse: 0.9736 - val_loss: 12.3251 - val_mae: 0.9584 - val_mse: 1.5750\n",
      "Epoch 984/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7652 - mae: 0.7726 - mse: 0.9747 - val_loss: 12.3132 - val_mae: 0.8574 - val_mse: 1.3574\n",
      "Epoch 985/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7653 - mae: 0.7726 - mse: 0.9746 - val_loss: 12.3122 - val_mae: 0.9522 - val_mse: 1.5788\n",
      "Epoch 986/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7645 - mae: 0.7731 - mse: 0.9731 - val_loss: 12.2984 - val_mae: 0.9249 - val_mse: 1.4889\n",
      "Epoch 987/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7644 - mae: 0.7724 - mse: 0.9733 - val_loss: 12.3790 - val_mae: 1.0649 - val_mse: 1.8118\n",
      "Epoch 988/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7642 - mae: 0.7721 - mse: 0.9734 - val_loss: 12.3303 - val_mae: 0.8492 - val_mse: 1.3431\n",
      "Epoch 989/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.7648 - mae: 0.7723 - mse: 0.9735 - val_loss: 12.3391 - val_mae: 0.9818 - val_mse: 1.6695\n",
      "Epoch 990/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.7631 - mae: 0.7721 - mse: 0.9719 - val_loss: 12.3068 - val_mae: 0.9528 - val_mse: 1.5771\n",
      "Epoch 991/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7645 - mae: 0.7724 - mse: 0.9741 - val_loss: 12.2955 - val_mae: 0.9001 - val_mse: 1.4489\n",
      "Epoch 992/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7636 - mae: 0.7712 - mse: 0.9725 - val_loss: 12.3228 - val_mae: 0.9244 - val_mse: 1.5260\n",
      "Epoch 993/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.7634 - mae: 0.7725 - mse: 0.9727 - val_loss: 12.3363 - val_mae: 0.9811 - val_mse: 1.6584\n",
      "Epoch 994/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7644 - mae: 0.7724 - mse: 0.9738 - val_loss: 12.3447 - val_mae: 1.0345 - val_mse: 1.7493\n",
      "Epoch 995/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7643 - mae: 0.7726 - mse: 0.9747 - val_loss: 12.3255 - val_mae: 0.8793 - val_mse: 1.4180\n",
      "Epoch 996/1000\n",
      "18102/18102 [==============================] - 1s 28us/sample - loss: 11.7629 - mae: 0.7714 - mse: 0.9712 - val_loss: 12.3105 - val_mae: 0.9530 - val_mse: 1.5506\n",
      "Epoch 997/1000\n",
      "18102/18102 [==============================] - 1s 30us/sample - loss: 11.7627 - mae: 0.7725 - mse: 0.9723 - val_loss: 12.3037 - val_mae: 0.9485 - val_mse: 1.5674\n",
      "Epoch 998/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7633 - mae: 0.7721 - mse: 0.9729 - val_loss: 12.2913 - val_mae: 0.9179 - val_mse: 1.4794\n",
      "Epoch 999/1000\n",
      "18102/18102 [==============================] - 1s 32us/sample - loss: 11.7630 - mae: 0.7718 - mse: 0.9734 - val_loss: 12.3047 - val_mae: 0.8593 - val_mse: 1.3442\n",
      "Epoch 1000/1000\n",
      "18102/18102 [==============================] - 1s 44us/sample - loss: 11.7629 - mae: 0.7715 - mse: 0.9719 - val_loss: 12.3122 - val_mae: 0.8772 - val_mse: 1.3750\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model_validation(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6035/1 - 0s - loss: 16.2625 - mae: 0.8929 - mse: 1.5117\n",
      "Test loss: 12.577598065468726\n",
      "Mean absolute error: 0.8928766\n",
      "Mean squared error: 1.5117496\n"
     ]
    }
   ],
   "source": [
    "model.model_testing(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,442\n",
      "Trainable params: 5,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1810 samples, validate on 603 samples\n",
      "Epoch 1/1000\n",
      "1810/1810 [==============================] - 1s 300us/sample - loss: 175.6457 - mae: 10.8118 - mse: 174.1802 - val_loss: 88.1896 - val_mae: 6.8443 - val_mse: 84.3382\n",
      "Epoch 2/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 41.0364 - mae: 4.3075 - mse: 32.2252 - val_loss: 45.1540 - val_mae: 4.6355 - val_mse: 38.2469\n",
      "Epoch 3/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 25.3880 - mae: 2.9982 - mse: 15.3256 - val_loss: 28.8359 - val_mae: 3.1792 - val_mse: 20.7300\n",
      "Epoch 4/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 18.9861 - mae: 2.2348 - mse: 8.5713 - val_loss: 22.8313 - val_mae: 2.5808 - val_mse: 13.6989\n",
      "Epoch 5/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 17.1827 - mae: 1.9938 - mse: 6.6409 - val_loss: 20.1371 - val_mae: 2.2755 - val_mse: 10.4039\n",
      "Epoch 6/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 16.1880 - mae: 1.8743 - mse: 5.5783 - val_loss: 19.0740 - val_mae: 2.1859 - val_mse: 9.4701\n",
      "Epoch 7/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 15.4795 - mae: 1.7450 - mse: 4.8437 - val_loss: 17.8817 - val_mae: 1.9369 - val_mse: 7.6153\n",
      "Epoch 8/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 14.9328 - mae: 1.6327 - mse: 4.2558 - val_loss: 17.4428 - val_mae: 1.8690 - val_mse: 7.0906\n",
      "Epoch 9/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 14.4912 - mae: 1.5223 - mse: 3.7800 - val_loss: 17.3713 - val_mae: 1.9335 - val_mse: 7.4496\n",
      "Epoch 10/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 14.2374 - mae: 1.4539 - mse: 3.5155 - val_loss: 17.2699 - val_mae: 1.8805 - val_mse: 6.9860\n",
      "Epoch 11/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 14.0872 - mae: 1.4008 - mse: 3.3433 - val_loss: 17.2534 - val_mae: 1.8835 - val_mse: 6.8129\n",
      "Epoch 12/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 13.9390 - mae: 1.3627 - mse: 3.1785 - val_loss: 17.1906 - val_mae: 1.8897 - val_mse: 6.6134\n",
      "Epoch 13/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 13.8521 - mae: 1.3339 - mse: 3.0796 - val_loss: 17.2850 - val_mae: 1.8878 - val_mse: 6.5928\n",
      "Epoch 14/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 13.7694 - mae: 1.3183 - mse: 3.0033 - val_loss: 17.4599 - val_mae: 1.8726 - val_mse: 6.3657\n",
      "Epoch 15/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 13.6953 - mae: 1.2934 - mse: 2.9124 - val_loss: 17.3115 - val_mae: 1.9161 - val_mse: 6.5969\n",
      "Epoch 16/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 13.6180 - mae: 1.2760 - mse: 2.8351 - val_loss: 17.5589 - val_mae: 1.8975 - val_mse: 6.5159\n",
      "Epoch 17/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 13.5492 - mae: 1.2574 - mse: 2.7627 - val_loss: 17.6479 - val_mae: 1.8854 - val_mse: 6.4134\n",
      "Epoch 18/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 13.5089 - mae: 1.2482 - mse: 2.7194 - val_loss: 17.4876 - val_mae: 1.9088 - val_mse: 6.4599\n",
      "Epoch 19/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 13.4306 - mae: 1.2229 - mse: 2.6301 - val_loss: 17.4534 - val_mae: 1.9661 - val_mse: 6.9645\n",
      "Epoch 20/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 13.3780 - mae: 1.2181 - mse: 2.5860 - val_loss: 17.4654 - val_mae: 1.9158 - val_mse: 6.5057\n",
      "Epoch 21/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 13.3382 - mae: 1.2037 - mse: 2.5337 - val_loss: 17.3689 - val_mae: 1.9444 - val_mse: 6.6805\n",
      "Epoch 22/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 13.2723 - mae: 1.1828 - mse: 2.4727 - val_loss: 18.0283 - val_mae: 1.9170 - val_mse: 6.4161\n",
      "Epoch 23/1000\n",
      "1810/1810 [==============================] - 0s 43us/sample - loss: 13.2112 - mae: 1.1642 - mse: 2.3868 - val_loss: 17.4562 - val_mae: 1.9162 - val_mse: 6.6199\n",
      "Epoch 24/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 13.1768 - mae: 1.1565 - mse: 2.3632 - val_loss: 17.7585 - val_mae: 1.8968 - val_mse: 6.5109\n",
      "Epoch 25/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 13.1428 - mae: 1.1419 - mse: 2.3253 - val_loss: 17.8408 - val_mae: 1.9008 - val_mse: 6.5192\n",
      "Epoch 26/1000\n",
      "1810/1810 [==============================] - 0s 38us/sample - loss: 13.0952 - mae: 1.1237 - mse: 2.2663 - val_loss: 17.4867 - val_mae: 1.9877 - val_mse: 7.0272\n",
      "Epoch 27/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 13.0511 - mae: 1.1091 - mse: 2.2351 - val_loss: 17.3297 - val_mae: 1.9373 - val_mse: 6.7098\n",
      "Epoch 28/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 13.0204 - mae: 1.1052 - mse: 2.1907 - val_loss: 17.5511 - val_mae: 1.8972 - val_mse: 6.4557\n",
      "Epoch 29/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.9919 - mae: 1.1021 - mse: 2.1663 - val_loss: 17.8547 - val_mae: 1.8810 - val_mse: 6.2714\n",
      "Epoch 30/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 12.9298 - mae: 1.0748 - mse: 2.0878 - val_loss: 17.2454 - val_mae: 1.9127 - val_mse: 6.5127\n",
      "Epoch 31/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.8955 - mae: 1.0676 - mse: 2.0608 - val_loss: 17.6932 - val_mae: 1.8744 - val_mse: 6.2428\n",
      "Epoch 32/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.8938 - mae: 1.0629 - mse: 2.0507 - val_loss: 17.2834 - val_mae: 1.9001 - val_mse: 6.4620\n",
      "Epoch 33/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.8632 - mae: 1.0528 - mse: 2.0256 - val_loss: 17.3054 - val_mae: 1.9687 - val_mse: 6.7963\n",
      "Epoch 34/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.8244 - mae: 1.0436 - mse: 1.9837 - val_loss: 17.1454 - val_mae: 1.8981 - val_mse: 6.4164\n",
      "Epoch 35/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.7959 - mae: 1.0349 - mse: 1.9552 - val_loss: 18.0568 - val_mae: 1.8713 - val_mse: 6.2212\n",
      "Epoch 36/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.7938 - mae: 1.0293 - mse: 1.9371 - val_loss: 17.0827 - val_mae: 1.8804 - val_mse: 6.2766\n",
      "Epoch 37/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.7569 - mae: 1.0256 - mse: 1.9144 - val_loss: 17.2401 - val_mae: 1.8281 - val_mse: 6.0052\n",
      "Epoch 38/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 12.7527 - mae: 1.0160 - mse: 1.9034 - val_loss: 17.3344 - val_mae: 1.8279 - val_mse: 5.9577\n",
      "Epoch 39/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.7449 - mae: 1.0146 - mse: 1.8940 - val_loss: 17.9106 - val_mae: 1.8416 - val_mse: 6.0488\n",
      "Epoch 40/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 12.7021 - mae: 0.9976 - mse: 1.8353 - val_loss: 17.1295 - val_mae: 1.8545 - val_mse: 5.9106\n",
      "Epoch 41/1000\n",
      "1810/1810 [==============================] - 0s 37us/sample - loss: 12.6828 - mae: 0.9947 - mse: 1.8189 - val_loss: 16.8923 - val_mae: 1.9342 - val_mse: 6.4721\n",
      "Epoch 42/1000\n",
      "1810/1810 [==============================] - 0s 37us/sample - loss: 12.6542 - mae: 0.9871 - mse: 1.8088 - val_loss: 17.3363 - val_mae: 1.8158 - val_mse: 5.8659\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.6604 - mae: 0.9817 - mse: 1.8022 - val_loss: 17.1253 - val_mae: 1.8269 - val_mse: 5.9484\n",
      "Epoch 44/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 12.6366 - mae: 0.9772 - mse: 1.7666 - val_loss: 16.9513 - val_mae: 1.9191 - val_mse: 6.4285\n",
      "Epoch 45/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 12.6243 - mae: 0.9787 - mse: 1.7796 - val_loss: 16.8639 - val_mae: 1.8204 - val_mse: 5.7673\n",
      "Epoch 46/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.5951 - mae: 0.9662 - mse: 1.7356 - val_loss: 16.6988 - val_mae: 1.8268 - val_mse: 5.8181\n",
      "Epoch 47/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 12.5957 - mae: 0.9655 - mse: 1.7308 - val_loss: 16.5982 - val_mae: 1.8648 - val_mse: 5.9438\n",
      "Epoch 48/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.5710 - mae: 0.9613 - mse: 1.7158 - val_loss: 16.7259 - val_mae: 1.7991 - val_mse: 5.6955\n",
      "Epoch 49/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 12.5630 - mae: 0.9646 - mse: 1.7042 - val_loss: 17.0525 - val_mae: 1.7771 - val_mse: 5.5166\n",
      "Epoch 50/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.5233 - mae: 0.9458 - mse: 1.6536 - val_loss: 17.1247 - val_mae: 1.7602 - val_mse: 5.5915\n",
      "Epoch 51/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.5435 - mae: 0.9558 - mse: 1.6763 - val_loss: 17.1042 - val_mae: 1.7762 - val_mse: 5.4776\n",
      "Epoch 52/1000\n",
      "1810/1810 [==============================] - 0s 37us/sample - loss: 12.5173 - mae: 0.9434 - mse: 1.6431 - val_loss: 16.5373 - val_mae: 1.7973 - val_mse: 5.5956\n",
      "Epoch 53/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.4971 - mae: 0.9395 - mse: 1.6310 - val_loss: 16.9321 - val_mae: 1.7551 - val_mse: 5.4631\n",
      "Epoch 54/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 12.4839 - mae: 0.9318 - mse: 1.6169 - val_loss: 17.3383 - val_mae: 1.7612 - val_mse: 5.4785\n",
      "Epoch 55/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.4816 - mae: 0.9291 - mse: 1.6037 - val_loss: 16.7003 - val_mae: 1.7423 - val_mse: 5.3452\n",
      "Epoch 56/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.4655 - mae: 0.9222 - mse: 1.5933 - val_loss: 16.5649 - val_mae: 1.7390 - val_mse: 5.3130\n",
      "Epoch 57/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.4446 - mae: 0.9249 - mse: 1.5682 - val_loss: 16.5830 - val_mae: 1.7663 - val_mse: 5.4596\n",
      "Epoch 58/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.4518 - mae: 0.9217 - mse: 1.5802 - val_loss: 16.4605 - val_mae: 1.7631 - val_mse: 5.3816\n",
      "Epoch 59/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 12.4317 - mae: 0.9147 - mse: 1.5597 - val_loss: 16.8819 - val_mae: 1.7309 - val_mse: 5.2885\n",
      "Epoch 60/1000\n",
      "1810/1810 [==============================] - 0s 38us/sample - loss: 12.4268 - mae: 0.9114 - mse: 1.5473 - val_loss: 16.4156 - val_mae: 1.7612 - val_mse: 5.2869\n",
      "Epoch 61/1000\n",
      "1810/1810 [==============================] - 0s 45us/sample - loss: 12.4144 - mae: 0.9121 - mse: 1.5504 - val_loss: 16.9083 - val_mae: 1.7207 - val_mse: 5.2676\n",
      "Epoch 62/1000\n",
      "1810/1810 [==============================] - 0s 43us/sample - loss: 12.3947 - mae: 0.9002 - mse: 1.5189 - val_loss: 16.8180 - val_mae: 1.7305 - val_mse: 5.2996\n",
      "Epoch 63/1000\n",
      "1810/1810 [==============================] - 0s 50us/sample - loss: 12.4035 - mae: 0.9077 - mse: 1.5292 - val_loss: 17.3129 - val_mae: 1.7451 - val_mse: 5.3785\n",
      "Epoch 64/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.3799 - mae: 0.9016 - mse: 1.4958 - val_loss: 16.5907 - val_mae: 1.7217 - val_mse: 5.1811\n",
      "Epoch 65/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 12.3801 - mae: 0.8978 - mse: 1.4940 - val_loss: 16.3789 - val_mae: 1.8386 - val_mse: 5.7301\n",
      "Epoch 66/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.3460 - mae: 0.8997 - mse: 1.4805 - val_loss: 16.2561 - val_mae: 1.7660 - val_mse: 5.3256\n",
      "Epoch 67/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.3377 - mae: 0.8904 - mse: 1.4627 - val_loss: 16.4642 - val_mae: 1.7122 - val_mse: 5.1351\n",
      "Epoch 68/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 12.3565 - mae: 0.8970 - mse: 1.4812 - val_loss: 17.0355 - val_mae: 1.7281 - val_mse: 5.2662\n",
      "Epoch 69/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.3265 - mae: 0.8823 - mse: 1.4424 - val_loss: 16.1575 - val_mae: 1.8156 - val_mse: 5.6002\n",
      "Epoch 70/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 12.3475 - mae: 0.8950 - mse: 1.4736 - val_loss: 16.4282 - val_mae: 1.7086 - val_mse: 5.0680\n",
      "Epoch 71/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 12.3195 - mae: 0.8809 - mse: 1.4427 - val_loss: 16.6944 - val_mae: 1.6977 - val_mse: 5.1011\n",
      "Epoch 72/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.3003 - mae: 0.8703 - mse: 1.4173 - val_loss: 16.2003 - val_mae: 1.7448 - val_mse: 5.2681\n",
      "Epoch 73/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 12.3198 - mae: 0.8857 - mse: 1.4411 - val_loss: 16.3220 - val_mae: 1.7157 - val_mse: 5.1313\n",
      "Epoch 74/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.2963 - mae: 0.8737 - mse: 1.4205 - val_loss: 16.8193 - val_mae: 1.7108 - val_mse: 5.1084\n",
      "Epoch 75/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.2797 - mae: 0.8685 - mse: 1.3913 - val_loss: 16.3604 - val_mae: 1.7023 - val_mse: 5.0476\n",
      "Epoch 76/1000\n",
      "1810/1810 [==============================] - 0s 37us/sample - loss: 12.2904 - mae: 0.8720 - mse: 1.4115 - val_loss: 16.3323 - val_mae: 1.7151 - val_mse: 5.1198\n",
      "Epoch 77/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.2680 - mae: 0.8642 - mse: 1.3914 - val_loss: 16.1505 - val_mae: 1.8009 - val_mse: 5.5407\n",
      "Epoch 78/1000\n",
      "1810/1810 [==============================] - 0s 40us/sample - loss: 12.2918 - mae: 0.8757 - mse: 1.4250 - val_loss: 16.8174 - val_mae: 1.7165 - val_mse: 5.2964\n",
      "Epoch 79/1000\n",
      "1810/1810 [==============================] - 0s 46us/sample - loss: 12.2606 - mae: 0.8621 - mse: 1.3725 - val_loss: 16.1576 - val_mae: 1.7607 - val_mse: 5.2347\n",
      "Epoch 80/1000\n",
      "1810/1810 [==============================] - 0s 38us/sample - loss: 12.2533 - mae: 0.8634 - mse: 1.3768 - val_loss: 16.4270 - val_mae: 1.7090 - val_mse: 5.0519\n",
      "Epoch 81/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.2459 - mae: 0.8667 - mse: 1.3718 - val_loss: 16.4708 - val_mae: 1.6915 - val_mse: 5.0432\n",
      "Epoch 82/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.2324 - mae: 0.8577 - mse: 1.3531 - val_loss: 16.1593 - val_mae: 1.7477 - val_mse: 5.1505\n",
      "Epoch 83/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.2325 - mae: 0.8648 - mse: 1.3536 - val_loss: 16.3667 - val_mae: 1.6934 - val_mse: 5.0864\n",
      "Epoch 84/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.2256 - mae: 0.8483 - mse: 1.3440 - val_loss: 16.1449 - val_mae: 1.7193 - val_mse: 5.1096\n",
      "Epoch 85/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.2240 - mae: 0.8568 - mse: 1.3479 - val_loss: 16.5407 - val_mae: 1.6820 - val_mse: 5.1121\n",
      "Epoch 86/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.2240 - mae: 0.8530 - mse: 1.3486 - val_loss: 16.2383 - val_mae: 1.6875 - val_mse: 4.9898\n",
      "Epoch 87/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.2057 - mae: 0.8478 - mse: 1.3292 - val_loss: 16.2386 - val_mae: 1.7026 - val_mse: 4.9632\n",
      "Epoch 88/1000\n",
      "1810/1810 [==============================] - 0s 37us/sample - loss: 12.2074 - mae: 0.8449 - mse: 1.3336 - val_loss: 16.0838 - val_mae: 1.7304 - val_mse: 5.1626\n",
      "Epoch 89/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.1970 - mae: 0.8417 - mse: 1.3229 - val_loss: 16.6100 - val_mae: 1.6958 - val_mse: 5.0887\n",
      "Epoch 90/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.1826 - mae: 0.8362 - mse: 1.3005 - val_loss: 16.6033 - val_mae: 1.6670 - val_mse: 4.9411\n",
      "Epoch 91/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.1994 - mae: 0.8472 - mse: 1.3244 - val_loss: 17.0299 - val_mae: 1.6879 - val_mse: 5.0961\n",
      "Epoch 92/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.1893 - mae: 0.8350 - mse: 1.2993 - val_loss: 16.3989 - val_mae: 1.6701 - val_mse: 4.9363\n",
      "Epoch 93/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.1870 - mae: 0.8403 - mse: 1.3107 - val_loss: 16.2942 - val_mae: 1.7198 - val_mse: 5.1463\n",
      "Epoch 94/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.1883 - mae: 0.8437 - mse: 1.3088 - val_loss: 16.5135 - val_mae: 1.7158 - val_mse: 5.1647\n",
      "Epoch 95/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.1560 - mae: 0.8296 - mse: 1.2731 - val_loss: 16.3541 - val_mae: 1.6877 - val_mse: 4.9635\n",
      "Epoch 96/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 12.1782 - mae: 0.8379 - mse: 1.2973 - val_loss: 16.1241 - val_mae: 1.7149 - val_mse: 5.0002\n",
      "Epoch 97/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.1533 - mae: 0.8332 - mse: 1.2814 - val_loss: 16.3765 - val_mae: 1.6824 - val_mse: 5.0052\n",
      "Epoch 98/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.1321 - mae: 0.8242 - mse: 1.2516 - val_loss: 16.0030 - val_mae: 1.6879 - val_mse: 4.9445\n",
      "Epoch 99/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 12.1440 - mae: 0.8235 - mse: 1.2690 - val_loss: 16.1082 - val_mae: 1.7215 - val_mse: 5.1128\n",
      "Epoch 100/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.1548 - mae: 0.8321 - mse: 1.2850 - val_loss: 16.4573 - val_mae: 1.6590 - val_mse: 4.8788\n",
      "Epoch 101/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.1359 - mae: 0.8271 - mse: 1.2465 - val_loss: 16.0886 - val_mae: 1.6994 - val_mse: 4.9896\n",
      "Epoch 102/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.1163 - mae: 0.8192 - mse: 1.2407 - val_loss: 16.5271 - val_mae: 1.6588 - val_mse: 4.8903\n",
      "Epoch 103/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.1276 - mae: 0.8185 - mse: 1.2452 - val_loss: 16.1330 - val_mae: 1.7629 - val_mse: 5.3146\n",
      "Epoch 104/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 12.1145 - mae: 0.8221 - mse: 1.2441 - val_loss: 16.5818 - val_mae: 1.6926 - val_mse: 5.0311\n",
      "Epoch 105/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.1355 - mae: 0.8283 - mse: 1.2617 - val_loss: 16.1689 - val_mae: 1.7150 - val_mse: 5.1279\n",
      "Epoch 106/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.1028 - mae: 0.8229 - mse: 1.2324 - val_loss: 16.4221 - val_mae: 1.6788 - val_mse: 4.8882\n",
      "Epoch 107/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.1110 - mae: 0.8181 - mse: 1.2320 - val_loss: 16.2258 - val_mae: 1.6982 - val_mse: 4.9454\n",
      "Epoch 108/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.1029 - mae: 0.8200 - mse: 1.2270 - val_loss: 16.1956 - val_mae: 1.7005 - val_mse: 5.0371\n",
      "Epoch 109/1000\n",
      "1810/1810 [==============================] - 0s 38us/sample - loss: 12.1100 - mae: 0.8206 - mse: 1.2371 - val_loss: 16.6346 - val_mae: 1.6641 - val_mse: 4.9258\n",
      "Epoch 110/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 12.0937 - mae: 0.8128 - mse: 1.2121 - val_loss: 16.2301 - val_mae: 1.6810 - val_mse: 4.9154\n",
      "Epoch 111/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.1079 - mae: 0.8186 - mse: 1.2357 - val_loss: 16.2452 - val_mae: 1.6913 - val_mse: 4.9409\n",
      "Epoch 112/1000\n",
      "1810/1810 [==============================] - 0s 37us/sample - loss: 12.0910 - mae: 0.8135 - mse: 1.2199 - val_loss: 16.7490 - val_mae: 1.6834 - val_mse: 4.9828\n",
      "Epoch 113/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.0866 - mae: 0.8038 - mse: 1.2066 - val_loss: 16.2414 - val_mae: 1.6945 - val_mse: 5.0174\n",
      "Epoch 114/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 12.0742 - mae: 0.8098 - mse: 1.1982 - val_loss: 16.7194 - val_mae: 1.6640 - val_mse: 4.9463\n",
      "Epoch 115/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.0734 - mae: 0.8055 - mse: 1.1942 - val_loss: 16.4551 - val_mae: 1.6727 - val_mse: 4.9284\n",
      "Epoch 116/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.0651 - mae: 0.8025 - mse: 1.1863 - val_loss: 16.0619 - val_mae: 1.7292 - val_mse: 5.1129\n",
      "Epoch 117/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.0754 - mae: 0.8073 - mse: 1.2003 - val_loss: 16.0849 - val_mae: 1.7163 - val_mse: 5.1064\n",
      "Epoch 118/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.0824 - mae: 0.8091 - mse: 1.2109 - val_loss: 16.3785 - val_mae: 1.6815 - val_mse: 4.9612\n",
      "Epoch 119/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.0556 - mae: 0.8036 - mse: 1.1821 - val_loss: 16.3710 - val_mae: 1.6869 - val_mse: 5.0162\n",
      "Epoch 120/1000\n",
      "1810/1810 [==============================] - 0s 37us/sample - loss: 12.0634 - mae: 0.7997 - mse: 1.1844 - val_loss: 16.0543 - val_mae: 1.8010 - val_mse: 5.4681\n",
      "Epoch 121/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.0686 - mae: 0.8132 - mse: 1.2032 - val_loss: 16.1102 - val_mae: 1.7027 - val_mse: 4.9963\n",
      "Epoch 122/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 12.0479 - mae: 0.8013 - mse: 1.1783 - val_loss: 16.6752 - val_mae: 1.6792 - val_mse: 4.9579\n",
      "Epoch 123/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.0393 - mae: 0.7908 - mse: 1.1623 - val_loss: 16.2235 - val_mae: 1.6899 - val_mse: 4.9388\n",
      "Epoch 124/1000\n",
      "1810/1810 [==============================] - 0s 37us/sample - loss: 12.0440 - mae: 0.8042 - mse: 1.1634 - val_loss: 16.4861 - val_mae: 1.6628 - val_mse: 4.8924\n",
      "Epoch 125/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 12.0386 - mae: 0.7926 - mse: 1.1603 - val_loss: 16.1999 - val_mae: 1.7366 - val_mse: 5.2170\n",
      "Epoch 126/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 12.0376 - mae: 0.7976 - mse: 1.1659 - val_loss: 16.7998 - val_mae: 1.6695 - val_mse: 4.9728\n",
      "Epoch 127/1000\n",
      "1810/1810 [==============================] - 0s 37us/sample - loss: 12.0425 - mae: 0.7925 - mse: 1.1605 - val_loss: 16.2278 - val_mae: 1.6925 - val_mse: 5.0234\n",
      "Epoch 128/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.0212 - mae: 0.7952 - mse: 1.1480 - val_loss: 16.4525 - val_mae: 1.6847 - val_mse: 4.9769\n",
      "Epoch 129/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.0239 - mae: 0.7917 - mse: 1.1480 - val_loss: 16.0817 - val_mae: 1.7068 - val_mse: 5.0274\n",
      "Epoch 130/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.0268 - mae: 0.7918 - mse: 1.1592 - val_loss: 16.2956 - val_mae: 1.7041 - val_mse: 4.9714\n",
      "Epoch 131/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.0197 - mae: 0.7925 - mse: 1.1434 - val_loss: 16.3254 - val_mae: 1.6859 - val_mse: 4.9929\n",
      "Epoch 132/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.0096 - mae: 0.7881 - mse: 1.1348 - val_loss: 15.9805 - val_mae: 1.7439 - val_mse: 5.2173\n",
      "Epoch 133/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.0206 - mae: 0.7941 - mse: 1.1558 - val_loss: 15.9855 - val_mae: 1.7402 - val_mse: 5.1598\n",
      "Epoch 134/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.0092 - mae: 0.7922 - mse: 1.1366 - val_loss: 16.0638 - val_mae: 1.7353 - val_mse: 5.1297\n",
      "Epoch 135/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 11.9993 - mae: 0.7914 - mse: 1.1320 - val_loss: 16.5511 - val_mae: 1.6879 - val_mse: 4.9851\n",
      "Epoch 136/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.0138 - mae: 0.7860 - mse: 1.1376 - val_loss: 16.1192 - val_mae: 1.7459 - val_mse: 5.1690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9888 - mae: 0.7835 - mse: 1.1193 - val_loss: 16.2293 - val_mae: 1.7197 - val_mse: 5.0755\n",
      "Epoch 138/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.0022 - mae: 0.7846 - mse: 1.1283 - val_loss: 16.1143 - val_mae: 1.7267 - val_mse: 5.0837\n",
      "Epoch 139/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9900 - mae: 0.7802 - mse: 1.1213 - val_loss: 16.0009 - val_mae: 1.7552 - val_mse: 5.2062\n",
      "Epoch 140/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 12.0016 - mae: 0.7921 - mse: 1.1357 - val_loss: 16.1016 - val_mae: 1.7299 - val_mse: 5.1093\n",
      "Epoch 141/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9895 - mae: 0.7836 - mse: 1.1212 - val_loss: 16.3238 - val_mae: 1.6744 - val_mse: 4.9414\n",
      "Epoch 142/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 11.9848 - mae: 0.7814 - mse: 1.1111 - val_loss: 16.0666 - val_mae: 1.7250 - val_mse: 5.0947\n",
      "Epoch 143/1000\n",
      "1810/1810 [==============================] - 0s 40us/sample - loss: 11.9996 - mae: 0.7869 - mse: 1.1350 - val_loss: 16.7666 - val_mae: 1.6846 - val_mse: 4.9959\n",
      "Epoch 144/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9821 - mae: 0.7743 - mse: 1.1055 - val_loss: 16.2437 - val_mae: 1.7234 - val_mse: 5.1449\n",
      "Epoch 145/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 11.9771 - mae: 0.7827 - mse: 1.1076 - val_loss: 16.1006 - val_mae: 1.7465 - val_mse: 5.1779\n",
      "Epoch 146/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9784 - mae: 0.7802 - mse: 1.1106 - val_loss: 16.0475 - val_mae: 1.7892 - val_mse: 5.3586\n",
      "Epoch 147/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.9687 - mae: 0.7737 - mse: 1.1040 - val_loss: 16.1684 - val_mae: 1.7028 - val_mse: 4.9987\n",
      "Epoch 148/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9702 - mae: 0.7763 - mse: 1.1000 - val_loss: 16.0394 - val_mae: 1.7582 - val_mse: 5.2164\n",
      "Epoch 149/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.9674 - mae: 0.7776 - mse: 1.1030 - val_loss: 16.0182 - val_mae: 1.7476 - val_mse: 5.1765\n",
      "Epoch 150/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9631 - mae: 0.7731 - mse: 1.0908 - val_loss: 16.0279 - val_mae: 1.7543 - val_mse: 5.2256\n",
      "Epoch 151/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9548 - mae: 0.7763 - mse: 1.0942 - val_loss: 16.0839 - val_mae: 1.7558 - val_mse: 5.1932\n",
      "Epoch 152/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9621 - mae: 0.7747 - mse: 1.0900 - val_loss: 16.5117 - val_mae: 1.6958 - val_mse: 5.0645\n",
      "Epoch 153/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9696 - mae: 0.7728 - mse: 1.0981 - val_loss: 16.2565 - val_mae: 1.7313 - val_mse: 5.1825\n",
      "Epoch 154/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9480 - mae: 0.7672 - mse: 1.0807 - val_loss: 16.4749 - val_mae: 1.6811 - val_mse: 4.9410\n",
      "Epoch 155/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 11.9518 - mae: 0.7702 - mse: 1.0785 - val_loss: 16.7489 - val_mae: 1.6913 - val_mse: 5.0592\n",
      "Epoch 156/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9536 - mae: 0.7717 - mse: 1.0792 - val_loss: 16.2292 - val_mae: 1.6938 - val_mse: 4.9806\n",
      "Epoch 157/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9405 - mae: 0.7630 - mse: 1.0684 - val_loss: 16.0447 - val_mae: 1.7241 - val_mse: 5.0445\n",
      "Epoch 158/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9427 - mae: 0.7665 - mse: 1.0792 - val_loss: 16.6340 - val_mae: 1.6806 - val_mse: 5.0103\n",
      "Epoch 159/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9425 - mae: 0.7629 - mse: 1.0700 - val_loss: 16.2868 - val_mae: 1.6985 - val_mse: 5.0443\n",
      "Epoch 160/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9558 - mae: 0.7731 - mse: 1.0911 - val_loss: 16.7106 - val_mae: 1.6838 - val_mse: 5.0280\n",
      "Epoch 161/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.9227 - mae: 0.7570 - mse: 1.0440 - val_loss: 16.0323 - val_mae: 1.7603 - val_mse: 5.2760\n",
      "Epoch 162/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9394 - mae: 0.7634 - mse: 1.0767 - val_loss: 16.0665 - val_mae: 1.6971 - val_mse: 4.9770\n",
      "Epoch 163/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.9372 - mae: 0.7657 - mse: 1.0741 - val_loss: 16.2655 - val_mae: 1.6747 - val_mse: 4.9175\n",
      "Epoch 164/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9264 - mae: 0.7619 - mse: 1.0584 - val_loss: 16.4438 - val_mae: 1.6944 - val_mse: 5.0501\n",
      "Epoch 165/1000\n",
      "1810/1810 [==============================] - 0s 37us/sample - loss: 11.9183 - mae: 0.7539 - mse: 1.0438 - val_loss: 15.9869 - val_mae: 1.7446 - val_mse: 5.2188\n",
      "Epoch 166/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 11.9344 - mae: 0.7677 - mse: 1.0770 - val_loss: 16.4947 - val_mae: 1.6718 - val_mse: 4.9403\n",
      "Epoch 167/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9032 - mae: 0.7527 - mse: 1.0337 - val_loss: 16.2592 - val_mae: 1.7078 - val_mse: 5.0901\n",
      "Epoch 168/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9094 - mae: 0.7575 - mse: 1.0453 - val_loss: 16.1241 - val_mae: 1.6767 - val_mse: 4.8885\n",
      "Epoch 169/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 11.9181 - mae: 0.7605 - mse: 1.0521 - val_loss: 16.0357 - val_mae: 1.7081 - val_mse: 5.0077\n",
      "Epoch 170/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9053 - mae: 0.7594 - mse: 1.0421 - val_loss: 16.4843 - val_mae: 1.6746 - val_mse: 4.9709\n",
      "Epoch 171/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9016 - mae: 0.7499 - mse: 1.0297 - val_loss: 16.4226 - val_mae: 1.6980 - val_mse: 5.0377\n",
      "Epoch 172/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9103 - mae: 0.7577 - mse: 1.0435 - val_loss: 16.0286 - val_mae: 1.7027 - val_mse: 4.9784\n",
      "Epoch 173/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9103 - mae: 0.7569 - mse: 1.0467 - val_loss: 16.6726 - val_mae: 1.6668 - val_mse: 4.9789\n",
      "Epoch 174/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9031 - mae: 0.7511 - mse: 1.0322 - val_loss: 16.0975 - val_mae: 1.7318 - val_mse: 5.1508\n",
      "Epoch 175/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 11.8940 - mae: 0.7546 - mse: 1.0307 - val_loss: 16.1860 - val_mae: 1.7387 - val_mse: 5.1788\n",
      "Epoch 176/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.9176 - mae: 0.7586 - mse: 1.0591 - val_loss: 16.1840 - val_mae: 1.6993 - val_mse: 5.0068\n",
      "Epoch 177/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.8750 - mae: 0.7439 - mse: 1.0103 - val_loss: 16.1904 - val_mae: 1.7029 - val_mse: 5.0319\n",
      "Epoch 178/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8891 - mae: 0.7487 - mse: 1.0262 - val_loss: 16.3990 - val_mae: 1.6836 - val_mse: 4.9442\n",
      "Epoch 179/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8949 - mae: 0.7504 - mse: 1.0265 - val_loss: 15.9612 - val_mae: 1.7747 - val_mse: 5.2803\n",
      "Epoch 180/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8798 - mae: 0.7464 - mse: 1.0197 - val_loss: 16.2387 - val_mae: 1.6981 - val_mse: 4.9974\n",
      "Epoch 181/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8880 - mae: 0.7477 - mse: 1.0269 - val_loss: 16.3820 - val_mae: 1.6652 - val_mse: 4.8934\n",
      "Epoch 182/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8928 - mae: 0.7465 - mse: 1.0267 - val_loss: 15.9680 - val_mae: 1.7429 - val_mse: 5.1664\n",
      "Epoch 183/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8812 - mae: 0.7506 - mse: 1.0175 - val_loss: 15.9230 - val_mae: 1.8009 - val_mse: 5.4614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8967 - mae: 0.7564 - mse: 1.0425 - val_loss: 16.0548 - val_mae: 1.7125 - val_mse: 5.0128\n",
      "Epoch 185/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 11.8621 - mae: 0.7438 - mse: 0.9987 - val_loss: 15.9960 - val_mae: 1.7969 - val_mse: 5.4309\n",
      "Epoch 186/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8747 - mae: 0.7481 - mse: 1.0185 - val_loss: 16.3036 - val_mae: 1.6937 - val_mse: 4.9796\n",
      "Epoch 187/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.8816 - mae: 0.7491 - mse: 1.0181 - val_loss: 16.6712 - val_mae: 1.6627 - val_mse: 4.9416\n",
      "Epoch 188/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8737 - mae: 0.7445 - mse: 1.0065 - val_loss: 16.0385 - val_mae: 1.7147 - val_mse: 5.0169\n",
      "Epoch 189/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8650 - mae: 0.7456 - mse: 1.0004 - val_loss: 16.0526 - val_mae: 1.7160 - val_mse: 5.0503\n",
      "Epoch 190/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8635 - mae: 0.7423 - mse: 0.9994 - val_loss: 16.1885 - val_mae: 1.6934 - val_mse: 4.9989\n",
      "Epoch 191/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8772 - mae: 0.7485 - mse: 1.0197 - val_loss: 16.1586 - val_mae: 1.6827 - val_mse: 4.9220\n",
      "Epoch 192/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8606 - mae: 0.7388 - mse: 0.9975 - val_loss: 15.9445 - val_mae: 1.7144 - val_mse: 5.0166\n",
      "Epoch 193/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8623 - mae: 0.7436 - mse: 0.9998 - val_loss: 16.0556 - val_mae: 1.6829 - val_mse: 4.9084\n",
      "Epoch 194/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 11.8650 - mae: 0.7440 - mse: 1.0056 - val_loss: 16.0139 - val_mae: 1.7159 - val_mse: 5.0091\n",
      "Epoch 195/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 11.8526 - mae: 0.7388 - mse: 0.9917 - val_loss: 15.9353 - val_mae: 1.7955 - val_mse: 5.4067\n",
      "Epoch 196/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.8508 - mae: 0.7423 - mse: 0.9958 - val_loss: 16.0912 - val_mae: 1.7210 - val_mse: 5.0538\n",
      "Epoch 197/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8753 - mae: 0.7470 - mse: 1.0160 - val_loss: 15.9711 - val_mae: 1.7668 - val_mse: 5.2478\n",
      "Epoch 198/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.8356 - mae: 0.7349 - mse: 0.9831 - val_loss: 16.0723 - val_mae: 1.7222 - val_mse: 5.0431\n",
      "Epoch 199/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8415 - mae: 0.7378 - mse: 0.9793 - val_loss: 16.0807 - val_mae: 1.7177 - val_mse: 5.0389\n",
      "Epoch 200/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.8549 - mae: 0.7399 - mse: 0.9988 - val_loss: 16.1014 - val_mae: 1.7264 - val_mse: 5.0727\n",
      "Epoch 201/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.8448 - mae: 0.7402 - mse: 0.9888 - val_loss: 16.2892 - val_mae: 1.6869 - val_mse: 4.9224\n",
      "Epoch 202/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8353 - mae: 0.7334 - mse: 0.9738 - val_loss: 16.3206 - val_mae: 1.6754 - val_mse: 4.9130\n",
      "Epoch 203/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 11.8473 - mae: 0.7334 - mse: 0.9821 - val_loss: 15.9840 - val_mae: 1.7064 - val_mse: 5.0314\n",
      "Epoch 204/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 11.8229 - mae: 0.7311 - mse: 0.9691 - val_loss: 16.3735 - val_mae: 1.6730 - val_mse: 4.9255\n",
      "Epoch 205/1000\n",
      "1810/1810 [==============================] - 0s 35us/sample - loss: 11.8344 - mae: 0.7273 - mse: 0.9684 - val_loss: 15.9139 - val_mae: 1.7797 - val_mse: 5.3389\n",
      "Epoch 206/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8488 - mae: 0.7410 - mse: 0.9982 - val_loss: 16.4234 - val_mae: 1.6828 - val_mse: 4.9468\n",
      "Epoch 207/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8174 - mae: 0.7272 - mse: 0.9552 - val_loss: 16.1433 - val_mae: 1.7064 - val_mse: 4.9764\n",
      "Epoch 208/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8331 - mae: 0.7290 - mse: 0.9762 - val_loss: 16.0888 - val_mae: 1.7200 - val_mse: 5.0676\n",
      "Epoch 209/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8331 - mae: 0.7337 - mse: 0.9710 - val_loss: 16.1949 - val_mae: 1.7158 - val_mse: 5.0776\n",
      "Epoch 210/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.8212 - mae: 0.7295 - mse: 0.9644 - val_loss: 16.0168 - val_mae: 1.7261 - val_mse: 5.0695\n",
      "Epoch 211/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.8269 - mae: 0.7278 - mse: 0.9668 - val_loss: 16.1400 - val_mae: 1.8853 - val_mse: 5.9124\n",
      "Epoch 212/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8178 - mae: 0.7352 - mse: 0.9692 - val_loss: 15.9978 - val_mae: 1.7806 - val_mse: 5.3360\n",
      "Epoch 213/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8224 - mae: 0.7305 - mse: 0.9716 - val_loss: 15.9411 - val_mae: 1.7636 - val_mse: 5.1994\n",
      "Epoch 214/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 11.8263 - mae: 0.7382 - mse: 0.9743 - val_loss: 16.2064 - val_mae: 1.6873 - val_mse: 4.9146\n",
      "Epoch 215/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 11.8077 - mae: 0.7251 - mse: 0.9476 - val_loss: 16.3219 - val_mae: 1.7001 - val_mse: 5.0272\n",
      "Epoch 216/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 11.8275 - mae: 0.7292 - mse: 0.9640 - val_loss: 16.1271 - val_mae: 1.7121 - val_mse: 5.0387\n",
      "Epoch 217/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8080 - mae: 0.7219 - mse: 0.9511 - val_loss: 16.1356 - val_mae: 1.7230 - val_mse: 5.0724\n",
      "Epoch 218/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8215 - mae: 0.7286 - mse: 0.9630 - val_loss: 16.0370 - val_mae: 1.8139 - val_mse: 5.5033\n",
      "Epoch 219/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8089 - mae: 0.7328 - mse: 0.9580 - val_loss: 16.6702 - val_mae: 1.6726 - val_mse: 4.9778\n",
      "Epoch 220/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8019 - mae: 0.7211 - mse: 0.9366 - val_loss: 16.2979 - val_mae: 1.6825 - val_mse: 4.9178\n",
      "Epoch 221/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8017 - mae: 0.7218 - mse: 0.9408 - val_loss: 16.5216 - val_mae: 1.6747 - val_mse: 4.9614\n",
      "Epoch 222/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.8099 - mae: 0.7247 - mse: 0.9524 - val_loss: 16.1385 - val_mae: 1.7178 - val_mse: 5.0500\n",
      "Epoch 223/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7999 - mae: 0.7229 - mse: 0.9443 - val_loss: 16.3757 - val_mae: 1.6982 - val_mse: 4.9912\n",
      "Epoch 224/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 11.8050 - mae: 0.7218 - mse: 0.9454 - val_loss: 15.9656 - val_mae: 1.8023 - val_mse: 5.4108\n",
      "Epoch 225/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7935 - mae: 0.7222 - mse: 0.9443 - val_loss: 16.5246 - val_mae: 1.6791 - val_mse: 5.0032\n",
      "Epoch 226/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7910 - mae: 0.7173 - mse: 0.9318 - val_loss: 16.2409 - val_mae: 1.7156 - val_mse: 5.0531\n",
      "Epoch 227/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.8072 - mae: 0.7234 - mse: 0.9469 - val_loss: 16.0710 - val_mae: 1.8365 - val_mse: 5.5989\n",
      "Epoch 228/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7949 - mae: 0.7284 - mse: 0.9506 - val_loss: 16.0451 - val_mae: 1.7349 - val_mse: 5.0937\n",
      "Epoch 229/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7931 - mae: 0.7214 - mse: 0.9404 - val_loss: 16.3651 - val_mae: 1.7063 - val_mse: 5.0199\n",
      "Epoch 230/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 11.7989 - mae: 0.7252 - mse: 0.9398 - val_loss: 16.0778 - val_mae: 1.7563 - val_mse: 5.2209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7844 - mae: 0.7180 - mse: 0.9320 - val_loss: 16.0059 - val_mae: 1.7261 - val_mse: 5.1067\n",
      "Epoch 232/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7819 - mae: 0.7181 - mse: 0.9294 - val_loss: 16.2731 - val_mae: 1.7290 - val_mse: 5.1159\n",
      "Epoch 233/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 11.8116 - mae: 0.7248 - mse: 0.9576 - val_loss: 16.1147 - val_mae: 1.7513 - val_mse: 5.2027\n",
      "Epoch 234/1000\n",
      "1810/1810 [==============================] - 0s 42us/sample - loss: 11.7772 - mae: 0.7163 - mse: 0.9212 - val_loss: 16.0627 - val_mae: 1.7814 - val_mse: 5.3713\n",
      "Epoch 235/1000\n",
      "1810/1810 [==============================] - 0s 37us/sample - loss: 11.7870 - mae: 0.7160 - mse: 0.9353 - val_loss: 16.0614 - val_mae: 1.7515 - val_mse: 5.2233\n",
      "Epoch 236/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 11.7844 - mae: 0.7221 - mse: 0.9360 - val_loss: 16.4665 - val_mae: 1.6770 - val_mse: 4.9519\n",
      "Epoch 237/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 11.7805 - mae: 0.7113 - mse: 0.9196 - val_loss: 16.1442 - val_mae: 1.8718 - val_mse: 5.8322\n",
      "Epoch 238/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7815 - mae: 0.7236 - mse: 0.9395 - val_loss: 16.3054 - val_mae: 1.7057 - val_mse: 5.0190\n",
      "Epoch 239/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 11.7857 - mae: 0.7154 - mse: 0.9265 - val_loss: 16.2386 - val_mae: 1.8924 - val_mse: 5.9172\n",
      "Epoch 240/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7892 - mae: 0.7217 - mse: 0.9470 - val_loss: 16.4534 - val_mae: 1.6685 - val_mse: 4.9193\n",
      "Epoch 241/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7788 - mae: 0.7184 - mse: 0.9209 - val_loss: 16.0554 - val_mae: 1.7714 - val_mse: 5.2948\n",
      "Epoch 242/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7729 - mae: 0.7207 - mse: 0.9254 - val_loss: 16.0832 - val_mae: 1.7818 - val_mse: 5.3501\n",
      "Epoch 243/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 11.7713 - mae: 0.7154 - mse: 0.9187 - val_loss: 16.1884 - val_mae: 1.7583 - val_mse: 5.2487\n",
      "Epoch 244/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7751 - mae: 0.7131 - mse: 0.9195 - val_loss: 16.3274 - val_mae: 1.7145 - val_mse: 5.0920\n",
      "Epoch 245/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.7629 - mae: 0.7142 - mse: 0.9150 - val_loss: 16.5775 - val_mae: 1.7039 - val_mse: 5.0684\n",
      "Epoch 246/1000\n",
      "1810/1810 [==============================] - 0s 32us/sample - loss: 11.7766 - mae: 0.7165 - mse: 0.9164 - val_loss: 16.0549 - val_mae: 1.8033 - val_mse: 5.4550\n",
      "Epoch 247/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7754 - mae: 0.7127 - mse: 0.9286 - val_loss: 16.1262 - val_mae: 1.7701 - val_mse: 5.2781\n",
      "Epoch 248/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 11.7645 - mae: 0.7145 - mse: 0.9148 - val_loss: 16.1947 - val_mae: 1.7325 - val_mse: 5.1323\n",
      "Epoch 249/1000\n",
      "1810/1810 [==============================] - 0s 34us/sample - loss: 11.7752 - mae: 0.7174 - mse: 0.9217 - val_loss: 16.1125 - val_mae: 1.7522 - val_mse: 5.2212\n",
      "Epoch 250/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 11.7675 - mae: 0.7120 - mse: 0.9162 - val_loss: 16.1681 - val_mae: 1.8129 - val_mse: 5.5313\n",
      "Epoch 251/1000\n",
      "1810/1810 [==============================] - 0s 36us/sample - loss: 11.7562 - mae: 0.7122 - mse: 0.9070 - val_loss: 16.2175 - val_mae: 1.7164 - val_mse: 5.0607\n",
      "Epoch 252/1000\n",
      "1810/1810 [==============================] - 0s 37us/sample - loss: 11.7622 - mae: 0.7099 - mse: 0.9109 - val_loss: 16.2698 - val_mae: 1.7539 - val_mse: 5.2450\n",
      "Epoch 253/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7559 - mae: 0.7095 - mse: 0.9053 - val_loss: 16.1203 - val_mae: 1.7710 - val_mse: 5.2807\n",
      "Epoch 254/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7568 - mae: 0.7124 - mse: 0.9056 - val_loss: 16.2982 - val_mae: 1.7256 - val_mse: 5.1360\n",
      "Epoch 255/1000\n",
      "1810/1810 [==============================] - 0s 33us/sample - loss: 11.7608 - mae: 0.7097 - mse: 0.9071 - val_loss: 16.1248 - val_mae: 1.7949 - val_mse: 5.4585\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,442\n",
      "Trainable params: 5,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3620 samples, validate on 1207 samples\n",
      "Epoch 1/1000\n",
      "3620/3620 [==============================] - 1s 169us/sample - loss: 112.7599 - mae: 7.7200 - mse: 107.8872 - val_loss: 38.3049 - val_mae: 4.1452 - val_mse: 30.6387\n",
      "Epoch 2/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 21.9294 - mae: 2.6325 - mse: 11.6967 - val_loss: 22.7940 - val_mae: 2.5336 - val_mse: 12.6003\n",
      "Epoch 3/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 16.3005 - mae: 1.8501 - mse: 5.7213 - val_loss: 21.6126 - val_mae: 2.6856 - val_mse: 12.9153\n",
      "Epoch 4/1000\n",
      "3620/3620 [==============================] - 0s 30us/sample - loss: 14.5656 - mae: 1.5246 - mse: 3.9291 - val_loss: 18.1797 - val_mae: 2.1193 - val_mse: 8.4545\n",
      "Epoch 5/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 13.6963 - mae: 1.3328 - mse: 2.9893 - val_loss: 17.8001 - val_mae: 2.1666 - val_mse: 8.3570\n",
      "Epoch 6/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 13.4099 - mae: 1.2658 - mse: 2.6652 - val_loss: 18.3655 - val_mae: 2.3453 - val_mse: 9.3875\n",
      "Epoch 7/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 13.3010 - mae: 1.2404 - mse: 2.5606 - val_loss: 17.3982 - val_mae: 1.7430 - val_mse: 5.7237\n",
      "Epoch 8/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 13.2566 - mae: 1.2196 - mse: 2.4765 - val_loss: 16.7361 - val_mae: 1.8050 - val_mse: 6.1645\n",
      "Epoch 9/1000\n",
      "3620/3620 [==============================] - 0s 38us/sample - loss: 13.1791 - mae: 1.2014 - mse: 2.4048 - val_loss: 16.6356 - val_mae: 1.8342 - val_mse: 6.3568\n",
      "Epoch 10/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 13.1417 - mae: 1.1881 - mse: 2.3697 - val_loss: 16.5781 - val_mae: 1.7445 - val_mse: 5.9338\n",
      "Epoch 11/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 13.0993 - mae: 1.1752 - mse: 2.3215 - val_loss: 16.7734 - val_mae: 1.7520 - val_mse: 5.8261\n",
      "Epoch 12/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 13.0661 - mae: 1.1669 - mse: 2.2792 - val_loss: 17.0687 - val_mae: 1.7180 - val_mse: 5.7628\n",
      "Epoch 13/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 13.0266 - mae: 1.1523 - mse: 2.2364 - val_loss: 17.1169 - val_mae: 1.9586 - val_mse: 7.0049\n",
      "Epoch 14/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 12.9890 - mae: 1.1439 - mse: 2.2059 - val_loss: 17.0362 - val_mae: 1.7033 - val_mse: 5.6536\n",
      "Epoch 15/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.9715 - mae: 1.1330 - mse: 2.1821 - val_loss: 17.2042 - val_mae: 1.8127 - val_mse: 6.2629\n",
      "Epoch 16/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.9289 - mae: 1.1207 - mse: 2.1359 - val_loss: 17.0393 - val_mae: 1.7293 - val_mse: 5.7550\n",
      "Epoch 17/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.9174 - mae: 1.1141 - mse: 2.1159 - val_loss: 18.0435 - val_mae: 2.2854 - val_mse: 8.8641\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3620/3620 [==============================] - 0s 33us/sample - loss: 12.8713 - mae: 1.1065 - mse: 2.0849 - val_loss: 16.7447 - val_mae: 1.8202 - val_mse: 6.4212\n",
      "Epoch 19/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 12.8629 - mae: 1.0995 - mse: 2.0695 - val_loss: 16.9307 - val_mae: 1.8610 - val_mse: 6.6623\n",
      "Epoch 20/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 12.8179 - mae: 1.0864 - mse: 2.0204 - val_loss: 17.5626 - val_mae: 2.0484 - val_mse: 7.5670\n",
      "Epoch 21/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 12.7875 - mae: 1.0807 - mse: 1.9894 - val_loss: 16.8652 - val_mae: 1.8363 - val_mse: 6.4316\n",
      "Epoch 22/1000\n",
      "3620/3620 [==============================] - 0s 43us/sample - loss: 12.7797 - mae: 1.0751 - mse: 1.9800 - val_loss: 17.6710 - val_mae: 2.1910 - val_mse: 8.3148\n",
      "Epoch 23/1000\n",
      "3620/3620 [==============================] - 0s 37us/sample - loss: 12.7508 - mae: 1.0672 - mse: 1.9647 - val_loss: 16.8118 - val_mae: 1.8740 - val_mse: 6.7388\n",
      "Epoch 24/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.7212 - mae: 1.0540 - mse: 1.9167 - val_loss: 17.1457 - val_mae: 2.0124 - val_mse: 7.4276\n",
      "Epoch 25/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.7028 - mae: 1.0511 - mse: 1.9003 - val_loss: 17.2769 - val_mae: 1.9794 - val_mse: 7.2480\n",
      "Epoch 26/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.6702 - mae: 1.0403 - mse: 1.8637 - val_loss: 17.4469 - val_mae: 1.7010 - val_mse: 5.8203\n",
      "Epoch 27/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.6520 - mae: 1.0306 - mse: 1.8265 - val_loss: 17.3701 - val_mae: 2.0918 - val_mse: 7.8326\n",
      "Epoch 28/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 12.6325 - mae: 1.0296 - mse: 1.8333 - val_loss: 17.3316 - val_mae: 1.6899 - val_mse: 5.6801\n",
      "Epoch 29/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.6006 - mae: 1.0144 - mse: 1.7714 - val_loss: 17.6988 - val_mae: 2.2030 - val_mse: 8.3774\n",
      "Epoch 30/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.5865 - mae: 1.0153 - mse: 1.7885 - val_loss: 17.1818 - val_mae: 1.7438 - val_mse: 6.1345\n",
      "Epoch 31/1000\n",
      "3620/3620 [==============================] - 0s 30us/sample - loss: 12.5689 - mae: 1.0026 - mse: 1.7442 - val_loss: 16.5464 - val_mae: 1.7386 - val_mse: 6.1281\n",
      "Epoch 32/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 12.5302 - mae: 0.9914 - mse: 1.7098 - val_loss: 16.5245 - val_mae: 1.6881 - val_mse: 5.8062\n",
      "Epoch 33/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 12.5061 - mae: 0.9838 - mse: 1.6812 - val_loss: 17.1409 - val_mae: 1.6735 - val_mse: 5.7871\n",
      "Epoch 34/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.4988 - mae: 0.9795 - mse: 1.6643 - val_loss: 18.0469 - val_mae: 2.2806 - val_mse: 8.6999\n",
      "Epoch 35/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.4676 - mae: 0.9756 - mse: 1.6540 - val_loss: 16.6745 - val_mae: 1.6637 - val_mse: 5.6930\n",
      "Epoch 36/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.4381 - mae: 0.9621 - mse: 1.6096 - val_loss: 16.8130 - val_mae: 1.6905 - val_mse: 5.6313\n",
      "Epoch 37/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.4342 - mae: 0.9578 - mse: 1.5977 - val_loss: 16.5124 - val_mae: 1.7322 - val_mse: 6.1115\n",
      "Epoch 38/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.4202 - mae: 0.9512 - mse: 1.5901 - val_loss: 16.5442 - val_mae: 1.7368 - val_mse: 6.1013\n",
      "Epoch 39/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 12.3866 - mae: 0.9451 - mse: 1.5562 - val_loss: 16.5483 - val_mae: 1.6412 - val_mse: 5.6259\n",
      "Epoch 40/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.3803 - mae: 0.9392 - mse: 1.5462 - val_loss: 16.8892 - val_mae: 1.9747 - val_mse: 7.2012\n",
      "Epoch 41/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.3631 - mae: 0.9346 - mse: 1.5345 - val_loss: 16.5400 - val_mae: 1.7835 - val_mse: 6.3700\n",
      "Epoch 42/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.3593 - mae: 0.9344 - mse: 1.5337 - val_loss: 16.5666 - val_mae: 1.7843 - val_mse: 6.3990\n",
      "Epoch 43/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.3440 - mae: 0.9250 - mse: 1.5075 - val_loss: 17.3259 - val_mae: 2.1180 - val_mse: 7.8583\n",
      "Epoch 44/1000\n",
      "3620/3620 [==============================] - 0s 37us/sample - loss: 12.3217 - mae: 0.9237 - mse: 1.4963 - val_loss: 16.9962 - val_mae: 2.0061 - val_mse: 7.4041\n",
      "Epoch 45/1000\n",
      "3620/3620 [==============================] - 0s 37us/sample - loss: 12.3167 - mae: 0.9217 - mse: 1.4871 - val_loss: 17.3754 - val_mae: 2.1205 - val_mse: 7.9805\n",
      "Epoch 46/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 12.2923 - mae: 0.9134 - mse: 1.4686 - val_loss: 16.9022 - val_mae: 1.9524 - val_mse: 7.1528\n",
      "Epoch 47/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.2795 - mae: 0.9084 - mse: 1.4510 - val_loss: 16.5067 - val_mae: 1.6603 - val_mse: 5.8108\n",
      "Epoch 48/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.2637 - mae: 0.8994 - mse: 1.4226 - val_loss: 16.6987 - val_mae: 1.7834 - val_mse: 6.4467\n",
      "Epoch 49/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.2493 - mae: 0.9003 - mse: 1.4135 - val_loss: 16.5187 - val_mae: 1.7363 - val_mse: 6.1763\n",
      "Epoch 50/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.2439 - mae: 0.8933 - mse: 1.4029 - val_loss: 16.7758 - val_mae: 1.9599 - val_mse: 7.0457\n",
      "Epoch 51/1000\n",
      "3620/3620 [==============================] - 0s 30us/sample - loss: 12.2379 - mae: 0.8944 - mse: 1.4028 - val_loss: 16.3233 - val_mae: 1.6847 - val_mse: 5.8261\n",
      "Epoch 52/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.2262 - mae: 0.8861 - mse: 1.3883 - val_loss: 17.0244 - val_mae: 2.0265 - val_mse: 7.4454\n",
      "Epoch 53/1000\n",
      "3620/3620 [==============================] - 0s 30us/sample - loss: 12.2015 - mae: 0.8843 - mse: 1.3724 - val_loss: 16.7300 - val_mae: 1.8801 - val_mse: 6.7730\n",
      "Epoch 54/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 12.1935 - mae: 0.8817 - mse: 1.3577 - val_loss: 16.3079 - val_mae: 1.6684 - val_mse: 5.7330\n",
      "Epoch 55/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.1832 - mae: 0.8780 - mse: 1.3401 - val_loss: 16.7648 - val_mae: 1.9501 - val_mse: 6.9093\n",
      "Epoch 56/1000\n",
      "3620/3620 [==============================] - 0s 30us/sample - loss: 12.1829 - mae: 0.8792 - mse: 1.3491 - val_loss: 17.0819 - val_mae: 2.0524 - val_mse: 7.5936\n",
      "Epoch 57/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.1625 - mae: 0.8697 - mse: 1.3283 - val_loss: 17.2248 - val_mae: 2.0851 - val_mse: 7.7610\n",
      "Epoch 58/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.1537 - mae: 0.8692 - mse: 1.3202 - val_loss: 16.6060 - val_mae: 1.8591 - val_mse: 6.6628\n",
      "Epoch 59/1000\n",
      "3620/3620 [==============================] - 0s 30us/sample - loss: 12.1346 - mae: 0.8552 - mse: 1.2943 - val_loss: 16.7207 - val_mae: 1.9126 - val_mse: 6.8978\n",
      "Epoch 60/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 12.1347 - mae: 0.8579 - mse: 1.2984 - val_loss: 16.6452 - val_mae: 1.8285 - val_mse: 6.5619\n",
      "Epoch 61/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 12.1351 - mae: 0.8617 - mse: 1.2940 - val_loss: 16.9902 - val_mae: 2.0474 - val_mse: 7.5099\n",
      "Epoch 62/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 12.1127 - mae: 0.8527 - mse: 1.2802 - val_loss: 16.2383 - val_mae: 1.6377 - val_mse: 5.6715\n",
      "Epoch 63/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 12.1108 - mae: 0.8488 - mse: 1.2696 - val_loss: 16.4305 - val_mae: 1.6001 - val_mse: 5.2730\n",
      "Epoch 64/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.0916 - mae: 0.8401 - mse: 1.2415 - val_loss: 17.0612 - val_mae: 2.0606 - val_mse: 7.5246\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3620/3620 [==============================] - 0s 35us/sample - loss: 12.0889 - mae: 0.8469 - mse: 1.2547 - val_loss: 16.2063 - val_mae: 1.6988 - val_mse: 5.8152\n",
      "Epoch 66/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 12.0735 - mae: 0.8386 - mse: 1.2317 - val_loss: 16.1660 - val_mae: 1.6159 - val_mse: 5.4352\n",
      "Epoch 67/1000\n",
      "3620/3620 [==============================] - 0s 36us/sample - loss: 12.0732 - mae: 0.8384 - mse: 1.2330 - val_loss: 16.6506 - val_mae: 1.8988 - val_mse: 6.8023\n",
      "Epoch 68/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 12.0511 - mae: 0.8346 - mse: 1.2120 - val_loss: 16.5456 - val_mae: 1.7811 - val_mse: 6.3423\n",
      "Epoch 69/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 12.0606 - mae: 0.8336 - mse: 1.2239 - val_loss: 16.2280 - val_mae: 1.7048 - val_mse: 5.8948\n",
      "Epoch 70/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 12.0412 - mae: 0.8272 - mse: 1.2036 - val_loss: 16.4318 - val_mae: 1.7488 - val_mse: 6.1633\n",
      "Epoch 71/1000\n",
      "3620/3620 [==============================] - 0s 36us/sample - loss: 12.0386 - mae: 0.8272 - mse: 1.1994 - val_loss: 16.9989 - val_mae: 2.0471 - val_mse: 7.5294\n",
      "Epoch 72/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.0226 - mae: 0.8234 - mse: 1.1877 - val_loss: 16.2417 - val_mae: 1.6120 - val_mse: 5.3433\n",
      "Epoch 73/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 12.0305 - mae: 0.8184 - mse: 1.1857 - val_loss: 16.3115 - val_mae: 1.7728 - val_mse: 6.1368\n",
      "Epoch 74/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 12.0295 - mae: 0.8209 - mse: 1.1863 - val_loss: 16.1982 - val_mae: 1.6566 - val_mse: 5.5339\n",
      "Epoch 75/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 12.0116 - mae: 0.8169 - mse: 1.1694 - val_loss: 16.3434 - val_mae: 1.5708 - val_mse: 5.0947\n",
      "Epoch 76/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 12.0119 - mae: 0.8120 - mse: 1.1597 - val_loss: 16.2160 - val_mae: 1.7898 - val_mse: 6.0921\n",
      "Epoch 77/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 11.9967 - mae: 0.8142 - mse: 1.1594 - val_loss: 16.1683 - val_mae: 1.7130 - val_mse: 5.8427\n",
      "Epoch 78/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.9949 - mae: 0.8086 - mse: 1.1527 - val_loss: 16.2689 - val_mae: 1.7846 - val_mse: 6.1461\n",
      "Epoch 79/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.9867 - mae: 0.8085 - mse: 1.1469 - val_loss: 16.1277 - val_mae: 1.6722 - val_mse: 5.6751\n",
      "Epoch 80/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.9905 - mae: 0.8139 - mse: 1.1533 - val_loss: 16.5838 - val_mae: 1.6018 - val_mse: 5.2200\n",
      "Epoch 81/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.9680 - mae: 0.8005 - mse: 1.1212 - val_loss: 16.1029 - val_mae: 1.6171 - val_mse: 5.4110\n",
      "Epoch 82/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.9881 - mae: 0.8078 - mse: 1.1465 - val_loss: 16.1461 - val_mae: 1.7461 - val_mse: 5.9070\n",
      "Epoch 83/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.9726 - mae: 0.8055 - mse: 1.1346 - val_loss: 16.7698 - val_mae: 1.9914 - val_mse: 7.1692\n",
      "Epoch 84/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.9606 - mae: 0.8020 - mse: 1.1307 - val_loss: 16.6400 - val_mae: 1.9413 - val_mse: 6.9065\n",
      "Epoch 85/1000\n",
      "3620/3620 [==============================] - 0s 35us/sample - loss: 11.9405 - mae: 0.7970 - mse: 1.1076 - val_loss: 16.9624 - val_mae: 2.0554 - val_mse: 7.4960\n",
      "Epoch 86/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.9527 - mae: 0.8039 - mse: 1.1224 - val_loss: 16.2543 - val_mae: 1.8053 - val_mse: 6.1791\n",
      "Epoch 87/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 11.9466 - mae: 0.7966 - mse: 1.1100 - val_loss: 16.1481 - val_mae: 1.7674 - val_mse: 5.9872\n",
      "Epoch 88/1000\n",
      "3620/3620 [==============================] - 0s 35us/sample - loss: 11.9394 - mae: 0.7922 - mse: 1.1007 - val_loss: 16.6973 - val_mae: 1.9910 - val_mse: 7.1196\n",
      "Epoch 89/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.9308 - mae: 0.7912 - mse: 1.0964 - val_loss: 16.0689 - val_mae: 1.6720 - val_mse: 5.4627\n",
      "Epoch 90/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.9389 - mae: 0.7922 - mse: 1.0974 - val_loss: 17.5413 - val_mae: 2.2370 - val_mse: 8.4313\n",
      "Epoch 91/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.9206 - mae: 0.7936 - mse: 1.0954 - val_loss: 16.5040 - val_mae: 1.9306 - val_mse: 6.7885\n",
      "Epoch 92/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.9174 - mae: 0.7889 - mse: 1.0864 - val_loss: 16.6704 - val_mae: 1.9710 - val_mse: 7.0299\n",
      "Epoch 93/1000\n",
      "3620/3620 [==============================] - 0s 30us/sample - loss: 11.9249 - mae: 0.7891 - mse: 1.0876 - val_loss: 16.3800 - val_mae: 1.8725 - val_mse: 6.5240\n",
      "Epoch 94/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.9026 - mae: 0.7828 - mse: 1.0642 - val_loss: 17.1822 - val_mae: 2.1207 - val_mse: 7.8078\n",
      "Epoch 95/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.9038 - mae: 0.7850 - mse: 1.0822 - val_loss: 16.3208 - val_mae: 1.8357 - val_mse: 6.3704\n",
      "Epoch 96/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8953 - mae: 0.7763 - mse: 1.0618 - val_loss: 16.1835 - val_mae: 1.7643 - val_mse: 6.0435\n",
      "Epoch 97/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.9088 - mae: 0.7819 - mse: 1.0719 - val_loss: 18.0044 - val_mae: 2.3751 - val_mse: 9.1034\n",
      "Epoch 98/1000\n",
      "3620/3620 [==============================] - 0s 30us/sample - loss: 11.9047 - mae: 0.7881 - mse: 1.0838 - val_loss: 16.9449 - val_mae: 2.0655 - val_mse: 7.5019\n",
      "Epoch 99/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.8885 - mae: 0.7777 - mse: 1.0566 - val_loss: 16.0820 - val_mae: 1.6139 - val_mse: 5.4245\n",
      "Epoch 100/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8791 - mae: 0.7726 - mse: 1.0400 - val_loss: 16.1631 - val_mae: 1.6873 - val_mse: 5.7866\n",
      "Epoch 101/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8867 - mae: 0.7763 - mse: 1.0551 - val_loss: 16.8727 - val_mae: 2.0503 - val_mse: 7.3996\n",
      "Epoch 102/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8722 - mae: 0.7753 - mse: 1.0450 - val_loss: 16.5321 - val_mae: 1.9146 - val_mse: 6.7191\n",
      "Epoch 103/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8704 - mae: 0.7740 - mse: 1.0375 - val_loss: 16.3838 - val_mae: 1.8489 - val_mse: 6.4493\n",
      "Epoch 104/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.8771 - mae: 0.7740 - mse: 1.0430 - val_loss: 16.1708 - val_mae: 1.6836 - val_mse: 5.7059\n",
      "Epoch 105/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.8607 - mae: 0.7707 - mse: 1.0262 - val_loss: 15.9854 - val_mae: 1.6660 - val_mse: 5.4434\n",
      "Epoch 106/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8620 - mae: 0.7672 - mse: 1.0247 - val_loss: 16.1614 - val_mae: 1.6622 - val_mse: 5.6493\n",
      "Epoch 107/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8580 - mae: 0.7686 - mse: 1.0234 - val_loss: 16.8643 - val_mae: 2.0431 - val_mse: 7.3429\n",
      "Epoch 108/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8545 - mae: 0.7693 - mse: 1.0273 - val_loss: 16.0767 - val_mae: 1.7259 - val_mse: 5.7919\n",
      "Epoch 109/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8534 - mae: 0.7692 - mse: 1.0227 - val_loss: 16.3215 - val_mae: 1.8594 - val_mse: 6.4338\n",
      "Epoch 110/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.8459 - mae: 0.7641 - mse: 1.0143 - val_loss: 16.4212 - val_mae: 1.8797 - val_mse: 6.5608\n",
      "Epoch 111/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8428 - mae: 0.7648 - mse: 1.0138 - val_loss: 16.9819 - val_mae: 2.0799 - val_mse: 7.5890\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8407 - mae: 0.7652 - mse: 1.0188 - val_loss: 16.0620 - val_mae: 1.6942 - val_mse: 5.6747\n",
      "Epoch 113/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8406 - mae: 0.7627 - mse: 1.0088 - val_loss: 16.0485 - val_mae: 1.6794 - val_mse: 5.6146\n",
      "Epoch 114/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8385 - mae: 0.7580 - mse: 1.0043 - val_loss: 16.0903 - val_mae: 1.6083 - val_mse: 5.2070\n",
      "Epoch 115/1000\n",
      "3620/3620 [==============================] - 0s 40us/sample - loss: 11.8246 - mae: 0.7565 - mse: 0.9893 - val_loss: 16.8300 - val_mae: 2.0420 - val_mse: 7.2930\n",
      "Epoch 116/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.8205 - mae: 0.7587 - mse: 0.9877 - val_loss: 16.7460 - val_mae: 1.9954 - val_mse: 7.0684\n",
      "Epoch 117/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.8198 - mae: 0.7574 - mse: 0.9926 - val_loss: 16.2230 - val_mae: 1.8301 - val_mse: 6.2154\n",
      "Epoch 118/1000\n",
      "3620/3620 [==============================] - 0s 45us/sample - loss: 11.8170 - mae: 0.7580 - mse: 0.9871 - val_loss: 16.3963 - val_mae: 1.5352 - val_mse: 5.0784\n",
      "Epoch 119/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8208 - mae: 0.7562 - mse: 0.9826 - val_loss: 16.7742 - val_mae: 2.0419 - val_mse: 7.2827\n",
      "Epoch 120/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.8080 - mae: 0.7556 - mse: 0.9822 - val_loss: 16.0942 - val_mae: 1.5678 - val_mse: 5.2706\n",
      "Epoch 121/1000\n",
      "3620/3620 [==============================] - 0s 30us/sample - loss: 11.8089 - mae: 0.7539 - mse: 0.9767 - val_loss: 16.1141 - val_mae: 1.7792 - val_mse: 6.0320\n",
      "Epoch 122/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.8113 - mae: 0.7541 - mse: 0.9804 - val_loss: 16.1237 - val_mae: 1.5561 - val_mse: 5.0777\n",
      "Epoch 123/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.8006 - mae: 0.7450 - mse: 0.9588 - val_loss: 16.3593 - val_mae: 1.8704 - val_mse: 6.5054\n",
      "Epoch 124/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 11.8186 - mae: 0.7567 - mse: 0.9925 - val_loss: 16.2117 - val_mae: 1.8226 - val_mse: 6.2430\n",
      "Epoch 125/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.7936 - mae: 0.7498 - mse: 0.9642 - val_loss: 16.1020 - val_mae: 1.6076 - val_mse: 5.2338\n",
      "Epoch 126/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7948 - mae: 0.7469 - mse: 0.9593 - val_loss: 16.1798 - val_mae: 1.8142 - val_mse: 6.2119\n",
      "Epoch 127/1000\n",
      "3620/3620 [==============================] - 0s 30us/sample - loss: 11.7930 - mae: 0.7493 - mse: 0.9689 - val_loss: 16.4169 - val_mae: 1.9116 - val_mse: 6.6671\n",
      "Epoch 128/1000\n",
      "3620/3620 [==============================] - 0s 30us/sample - loss: 11.7835 - mae: 0.7472 - mse: 0.9591 - val_loss: 15.8903 - val_mae: 1.5719 - val_mse: 5.1565\n",
      "Epoch 129/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.7779 - mae: 0.7413 - mse: 0.9456 - val_loss: 17.0494 - val_mae: 2.1331 - val_mse: 7.7143\n",
      "Epoch 130/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7766 - mae: 0.7450 - mse: 0.9547 - val_loss: 16.4869 - val_mae: 1.9428 - val_mse: 6.7613\n",
      "Epoch 131/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7796 - mae: 0.7439 - mse: 0.9561 - val_loss: 16.2605 - val_mae: 1.8618 - val_mse: 6.3990\n",
      "Epoch 132/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7782 - mae: 0.7469 - mse: 0.9503 - val_loss: 15.9648 - val_mae: 1.5279 - val_mse: 4.9128\n",
      "Epoch 133/1000\n",
      "3620/3620 [==============================] - 0s 42us/sample - loss: 11.7702 - mae: 0.7372 - mse: 0.9347 - val_loss: 15.9427 - val_mae: 1.7085 - val_mse: 5.6866\n",
      "Epoch 134/1000\n",
      "3620/3620 [==============================] - 0s 38us/sample - loss: 11.7694 - mae: 0.7407 - mse: 0.9426 - val_loss: 16.0935 - val_mae: 1.7533 - val_mse: 5.8752\n",
      "Epoch 135/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7702 - mae: 0.7387 - mse: 0.9423 - val_loss: 15.9102 - val_mae: 1.6704 - val_mse: 5.5388\n",
      "Epoch 136/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7730 - mae: 0.7414 - mse: 0.9427 - val_loss: 15.9559 - val_mae: 1.6529 - val_mse: 5.4758\n",
      "Epoch 137/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7658 - mae: 0.7361 - mse: 0.9376 - val_loss: 16.1536 - val_mae: 1.5652 - val_mse: 5.0988\n",
      "Epoch 138/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7576 - mae: 0.7385 - mse: 0.9256 - val_loss: 16.2432 - val_mae: 1.8559 - val_mse: 6.3569\n",
      "Epoch 139/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.7614 - mae: 0.7385 - mse: 0.9357 - val_loss: 15.9032 - val_mae: 1.6691 - val_mse: 5.5446\n",
      "Epoch 140/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7487 - mae: 0.7312 - mse: 0.9208 - val_loss: 16.8483 - val_mae: 2.0951 - val_mse: 7.4456\n",
      "Epoch 141/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7540 - mae: 0.7383 - mse: 0.9333 - val_loss: 16.5283 - val_mae: 2.0003 - val_mse: 7.0010\n",
      "Epoch 142/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7426 - mae: 0.7338 - mse: 0.9210 - val_loss: 17.0229 - val_mae: 2.1506 - val_mse: 7.7608\n",
      "Epoch 143/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7467 - mae: 0.7357 - mse: 0.9242 - val_loss: 15.9009 - val_mae: 1.6882 - val_mse: 5.5641\n",
      "Epoch 144/1000\n",
      "3620/3620 [==============================] - 0s 36us/sample - loss: 11.7469 - mae: 0.7327 - mse: 0.9205 - val_loss: 16.1862 - val_mae: 1.8268 - val_mse: 6.1026\n",
      "Epoch 145/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 11.7405 - mae: 0.7296 - mse: 0.9167 - val_loss: 16.4133 - val_mae: 1.9426 - val_mse: 6.7204\n",
      "Epoch 146/1000\n",
      "3620/3620 [==============================] - 0s 38us/sample - loss: 11.7355 - mae: 0.7320 - mse: 0.9117 - val_loss: 16.5834 - val_mae: 2.0008 - val_mse: 7.0464\n",
      "Epoch 147/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 11.7340 - mae: 0.7347 - mse: 0.9164 - val_loss: 16.4238 - val_mae: 1.9567 - val_mse: 6.7732\n",
      "Epoch 148/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.7312 - mae: 0.7303 - mse: 0.9092 - val_loss: 16.1386 - val_mae: 1.7809 - val_mse: 5.8619\n",
      "Epoch 149/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7279 - mae: 0.7293 - mse: 0.9027 - val_loss: 15.8493 - val_mae: 1.6102 - val_mse: 5.3451\n",
      "Epoch 150/1000\n",
      "3620/3620 [==============================] - 0s 30us/sample - loss: 11.7290 - mae: 0.7268 - mse: 0.9005 - val_loss: 16.0553 - val_mae: 1.7598 - val_mse: 5.9413\n",
      "Epoch 151/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7201 - mae: 0.7260 - mse: 0.8970 - val_loss: 16.3568 - val_mae: 1.9242 - val_mse: 6.6468\n",
      "Epoch 152/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7199 - mae: 0.7278 - mse: 0.8995 - val_loss: 16.5763 - val_mae: 2.0069 - val_mse: 7.0788\n",
      "Epoch 153/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7143 - mae: 0.7260 - mse: 0.8973 - val_loss: 16.1026 - val_mae: 1.7631 - val_mse: 5.9990\n",
      "Epoch 154/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.7195 - mae: 0.7252 - mse: 0.8980 - val_loss: 16.6835 - val_mae: 2.0228 - val_mse: 7.1886\n",
      "Epoch 155/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7237 - mae: 0.7276 - mse: 0.9069 - val_loss: 15.8023 - val_mae: 1.6115 - val_mse: 5.3342\n",
      "Epoch 156/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7084 - mae: 0.7230 - mse: 0.8879 - val_loss: 16.7787 - val_mae: 2.0663 - val_mse: 7.3822\n",
      "Epoch 157/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7152 - mae: 0.7245 - mse: 0.8975 - val_loss: 15.8178 - val_mae: 1.6754 - val_mse: 5.5544\n",
      "Epoch 158/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.7092 - mae: 0.7196 - mse: 0.8860 - val_loss: 16.3258 - val_mae: 1.9022 - val_mse: 6.5609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.7070 - mae: 0.7190 - mse: 0.8843 - val_loss: 16.0104 - val_mae: 1.7960 - val_mse: 6.0173\n",
      "Epoch 160/1000\n",
      "3620/3620 [==============================] - 0s 35us/sample - loss: 11.7044 - mae: 0.7196 - mse: 0.8827 - val_loss: 16.0837 - val_mae: 1.8178 - val_mse: 6.1782\n",
      "Epoch 161/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.6992 - mae: 0.7191 - mse: 0.8807 - val_loss: 15.8181 - val_mae: 1.5374 - val_mse: 4.9496\n",
      "Epoch 162/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6974 - mae: 0.7157 - mse: 0.8710 - val_loss: 16.2295 - val_mae: 1.8631 - val_mse: 6.3444\n",
      "Epoch 163/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6988 - mae: 0.7186 - mse: 0.8795 - val_loss: 16.3603 - val_mae: 1.9342 - val_mse: 6.7530\n",
      "Epoch 164/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.6997 - mae: 0.7201 - mse: 0.8823 - val_loss: 15.7508 - val_mae: 1.6093 - val_mse: 5.2997\n",
      "Epoch 165/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6985 - mae: 0.7184 - mse: 0.8768 - val_loss: 15.8789 - val_mae: 1.7500 - val_mse: 5.8465\n",
      "Epoch 166/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.6858 - mae: 0.7124 - mse: 0.8652 - val_loss: 15.7872 - val_mae: 1.5691 - val_mse: 5.1666\n",
      "Epoch 167/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6914 - mae: 0.7089 - mse: 0.8667 - val_loss: 17.4285 - val_mae: 2.2787 - val_mse: 8.4117\n",
      "Epoch 168/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 11.6938 - mae: 0.7196 - mse: 0.8813 - val_loss: 15.8523 - val_mae: 1.5266 - val_mse: 4.8179\n",
      "Epoch 169/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6900 - mae: 0.7127 - mse: 0.8626 - val_loss: 15.9217 - val_mae: 1.7818 - val_mse: 5.9801\n",
      "Epoch 170/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6812 - mae: 0.7141 - mse: 0.8660 - val_loss: 16.2157 - val_mae: 1.9037 - val_mse: 6.5185\n",
      "Epoch 171/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 11.6867 - mae: 0.7158 - mse: 0.8710 - val_loss: 15.8060 - val_mae: 1.5358 - val_mse: 5.0038\n",
      "Epoch 172/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.6728 - mae: 0.7097 - mse: 0.8507 - val_loss: 16.5156 - val_mae: 1.9937 - val_mse: 6.9672\n",
      "Epoch 173/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6805 - mae: 0.7140 - mse: 0.8658 - val_loss: 16.5570 - val_mae: 2.0253 - val_mse: 7.1038\n",
      "Epoch 174/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6779 - mae: 0.7137 - mse: 0.8656 - val_loss: 16.0640 - val_mae: 1.8179 - val_mse: 6.1176\n",
      "Epoch 175/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6822 - mae: 0.7136 - mse: 0.8673 - val_loss: 16.0027 - val_mae: 1.8167 - val_mse: 6.1405\n",
      "Epoch 176/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6746 - mae: 0.7117 - mse: 0.8575 - val_loss: 16.4336 - val_mae: 1.9687 - val_mse: 6.8353\n",
      "Epoch 177/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6762 - mae: 0.7091 - mse: 0.8615 - val_loss: 15.7843 - val_mae: 1.5369 - val_mse: 5.0290\n",
      "Epoch 178/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6711 - mae: 0.7088 - mse: 0.8497 - val_loss: 15.7655 - val_mae: 1.6229 - val_mse: 5.3638\n",
      "Epoch 179/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6698 - mae: 0.7077 - mse: 0.8499 - val_loss: 15.9036 - val_mae: 1.7832 - val_mse: 5.9406\n",
      "Epoch 180/1000\n",
      "3620/3620 [==============================] - 0s 35us/sample - loss: 11.6698 - mae: 0.7107 - mse: 0.8536 - val_loss: 15.9029 - val_mae: 1.7657 - val_mse: 5.8962\n",
      "Epoch 181/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6628 - mae: 0.7069 - mse: 0.8465 - val_loss: 15.8063 - val_mae: 1.4907 - val_mse: 4.7963\n",
      "Epoch 182/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6703 - mae: 0.7070 - mse: 0.8496 - val_loss: 15.7922 - val_mae: 1.6304 - val_mse: 5.4197\n",
      "Epoch 183/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6592 - mae: 0.7067 - mse: 0.8427 - val_loss: 16.0744 - val_mae: 1.8098 - val_mse: 6.1176\n",
      "Epoch 184/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6681 - mae: 0.7075 - mse: 0.8539 - val_loss: 16.2882 - val_mae: 1.9438 - val_mse: 6.6950\n",
      "Epoch 185/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6596 - mae: 0.7067 - mse: 0.8470 - val_loss: 17.2412 - val_mae: 2.2354 - val_mse: 8.1644\n",
      "Epoch 186/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.6577 - mae: 0.7098 - mse: 0.8518 - val_loss: 16.6100 - val_mae: 2.0291 - val_mse: 7.1683\n",
      "Epoch 187/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6578 - mae: 0.7083 - mse: 0.8469 - val_loss: 15.8666 - val_mae: 1.6650 - val_mse: 5.5310\n",
      "Epoch 188/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6580 - mae: 0.7042 - mse: 0.8424 - val_loss: 15.6806 - val_mae: 1.5669 - val_mse: 5.1161\n",
      "Epoch 189/1000\n",
      "3620/3620 [==============================] - 0s 37us/sample - loss: 11.6458 - mae: 0.7015 - mse: 0.8271 - val_loss: 16.5169 - val_mae: 1.9869 - val_mse: 7.0053\n",
      "Epoch 190/1000\n",
      "3620/3620 [==============================] - 0s 41us/sample - loss: 11.6455 - mae: 0.7030 - mse: 0.8348 - val_loss: 15.9511 - val_mae: 1.7883 - val_mse: 5.9304\n",
      "Epoch 191/1000\n",
      "3620/3620 [==============================] - 0s 42us/sample - loss: 11.6586 - mae: 0.7074 - mse: 0.8441 - val_loss: 15.7033 - val_mae: 1.6498 - val_mse: 5.4294\n",
      "Epoch 192/1000\n",
      "3620/3620 [==============================] - 0s 47us/sample - loss: 11.6414 - mae: 0.6969 - mse: 0.8226 - val_loss: 15.8506 - val_mae: 1.7474 - val_mse: 5.8119\n",
      "Epoch 193/1000\n",
      "3620/3620 [==============================] - 0s 49us/sample - loss: 11.6504 - mae: 0.7015 - mse: 0.8345 - val_loss: 16.0672 - val_mae: 1.8419 - val_mse: 6.2410\n",
      "Epoch 194/1000\n",
      "3620/3620 [==============================] - 0s 66us/sample - loss: 11.6513 - mae: 0.7048 - mse: 0.8387 - val_loss: 15.6966 - val_mae: 1.5165 - val_mse: 4.9191\n",
      "Epoch 195/1000\n",
      "3620/3620 [==============================] - 0s 52us/sample - loss: 11.6490 - mae: 0.6992 - mse: 0.8311 - val_loss: 15.9317 - val_mae: 1.7591 - val_mse: 5.8926\n",
      "Epoch 196/1000\n",
      "3620/3620 [==============================] - 0s 38us/sample - loss: 11.6437 - mae: 0.6996 - mse: 0.8343 - val_loss: 16.2200 - val_mae: 1.9174 - val_mse: 6.5597\n",
      "Epoch 197/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6417 - mae: 0.7032 - mse: 0.8313 - val_loss: 15.9507 - val_mae: 1.7997 - val_mse: 6.0489\n",
      "Epoch 198/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6408 - mae: 0.6986 - mse: 0.8272 - val_loss: 16.1552 - val_mae: 1.8667 - val_mse: 6.3742\n",
      "Epoch 199/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6416 - mae: 0.7001 - mse: 0.8309 - val_loss: 15.6600 - val_mae: 1.5647 - val_mse: 5.0913\n",
      "Epoch 200/1000\n",
      "3620/3620 [==============================] - 0s 49us/sample - loss: 11.6413 - mae: 0.6962 - mse: 0.8250 - val_loss: 17.1401 - val_mae: 2.1933 - val_mse: 8.0463\n",
      "Epoch 201/1000\n",
      "3620/3620 [==============================] - 0s 39us/sample - loss: 11.6460 - mae: 0.7062 - mse: 0.8411 - val_loss: 15.7118 - val_mae: 1.6068 - val_mse: 5.2113\n",
      "Epoch 202/1000\n",
      "3620/3620 [==============================] - 0s 37us/sample - loss: 11.6453 - mae: 0.6982 - mse: 0.8305 - val_loss: 15.7952 - val_mae: 1.7207 - val_mse: 5.6859\n",
      "Epoch 203/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6274 - mae: 0.6939 - mse: 0.8141 - val_loss: 15.9007 - val_mae: 1.7803 - val_mse: 5.9498\n",
      "Epoch 204/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 11.6347 - mae: 0.6996 - mse: 0.8232 - val_loss: 15.7595 - val_mae: 1.6573 - val_mse: 5.4505\n",
      "Epoch 205/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6357 - mae: 0.6985 - mse: 0.8225 - val_loss: 15.8786 - val_mae: 1.7657 - val_mse: 5.8499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6325 - mae: 0.6982 - mse: 0.8215 - val_loss: 15.8861 - val_mae: 1.7651 - val_mse: 5.8764\n",
      "Epoch 207/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.6265 - mae: 0.6963 - mse: 0.8162 - val_loss: 16.3280 - val_mae: 1.9520 - val_mse: 6.7614\n",
      "Epoch 208/1000\n",
      "3620/3620 [==============================] - 0s 35us/sample - loss: 11.6309 - mae: 0.6953 - mse: 0.8195 - val_loss: 15.7443 - val_mae: 1.6141 - val_mse: 5.3071\n",
      "Epoch 209/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6283 - mae: 0.6931 - mse: 0.8164 - val_loss: 15.7469 - val_mae: 1.7003 - val_mse: 5.6031\n",
      "Epoch 210/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6273 - mae: 0.6938 - mse: 0.8169 - val_loss: 15.7502 - val_mae: 1.6017 - val_mse: 5.1278\n",
      "Epoch 211/1000\n",
      "3620/3620 [==============================] - 0s 30us/sample - loss: 11.6284 - mae: 0.6927 - mse: 0.8128 - val_loss: 15.7964 - val_mae: 1.7196 - val_mse: 5.7007\n",
      "Epoch 212/1000\n",
      "3620/3620 [==============================] - 0s 37us/sample - loss: 11.6321 - mae: 0.6957 - mse: 0.8195 - val_loss: 15.6586 - val_mae: 1.6206 - val_mse: 5.1433\n",
      "Epoch 213/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6230 - mae: 0.6947 - mse: 0.8117 - val_loss: 16.3178 - val_mae: 1.9493 - val_mse: 6.7744\n",
      "Epoch 214/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6191 - mae: 0.6948 - mse: 0.8149 - val_loss: 15.7644 - val_mae: 1.5550 - val_mse: 4.9293\n",
      "Epoch 215/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6231 - mae: 0.6943 - mse: 0.8098 - val_loss: 16.5040 - val_mae: 2.0284 - val_mse: 7.0719\n",
      "Epoch 216/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6233 - mae: 0.6948 - mse: 0.8180 - val_loss: 15.6812 - val_mae: 1.5267 - val_mse: 4.9086\n",
      "Epoch 217/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6246 - mae: 0.6917 - mse: 0.8101 - val_loss: 15.7108 - val_mae: 1.5916 - val_mse: 5.2132\n",
      "Epoch 218/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6220 - mae: 0.6955 - mse: 0.8138 - val_loss: 15.7366 - val_mae: 1.6907 - val_mse: 5.5874\n",
      "Epoch 219/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 11.6170 - mae: 0.6934 - mse: 0.8105 - val_loss: 15.7724 - val_mae: 1.7033 - val_mse: 5.6399\n",
      "Epoch 220/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6205 - mae: 0.6930 - mse: 0.8112 - val_loss: 15.7752 - val_mae: 1.7317 - val_mse: 5.7355\n",
      "Epoch 221/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6169 - mae: 0.6938 - mse: 0.8096 - val_loss: 15.7642 - val_mae: 1.7537 - val_mse: 5.8114\n",
      "Epoch 222/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 11.6077 - mae: 0.6908 - mse: 0.7972 - val_loss: 15.6558 - val_mae: 1.5931 - val_mse: 5.2069\n",
      "Epoch 223/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 11.6129 - mae: 0.6860 - mse: 0.8044 - val_loss: 15.8191 - val_mae: 1.7324 - val_mse: 5.7689\n",
      "Epoch 224/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6076 - mae: 0.6906 - mse: 0.7994 - val_loss: 15.8363 - val_mae: 1.5110 - val_mse: 4.9595\n",
      "Epoch 225/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6151 - mae: 0.6894 - mse: 0.8001 - val_loss: 15.7187 - val_mae: 1.6574 - val_mse: 5.4821\n",
      "Epoch 226/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.6081 - mae: 0.6882 - mse: 0.8009 - val_loss: 15.9316 - val_mae: 1.7972 - val_mse: 6.0146\n",
      "Epoch 227/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6126 - mae: 0.6912 - mse: 0.8054 - val_loss: 15.7072 - val_mae: 1.5711 - val_mse: 5.1565\n",
      "Epoch 228/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.6064 - mae: 0.6871 - mse: 0.7940 - val_loss: 15.9784 - val_mae: 1.8170 - val_mse: 6.1276\n",
      "Epoch 229/1000\n",
      "3620/3620 [==============================] - 0s 34us/sample - loss: 11.6049 - mae: 0.6903 - mse: 0.7987 - val_loss: 15.6634 - val_mae: 1.5919 - val_mse: 5.2043\n",
      "Epoch 230/1000\n",
      "3620/3620 [==============================] - 0s 36us/sample - loss: 11.6104 - mae: 0.6888 - mse: 0.8010 - val_loss: 15.7497 - val_mae: 1.6964 - val_mse: 5.6136\n",
      "Epoch 231/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6017 - mae: 0.6889 - mse: 0.7955 - val_loss: 15.7834 - val_mae: 1.7006 - val_mse: 5.6282\n",
      "Epoch 232/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6027 - mae: 0.6870 - mse: 0.7959 - val_loss: 16.0708 - val_mae: 1.8588 - val_mse: 6.3150\n",
      "Epoch 233/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6010 - mae: 0.6853 - mse: 0.7919 - val_loss: 15.6324 - val_mae: 1.6029 - val_mse: 5.1925\n",
      "Epoch 234/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.5979 - mae: 0.6875 - mse: 0.7897 - val_loss: 16.5092 - val_mae: 2.0353 - val_mse: 7.0682\n",
      "Epoch 235/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5971 - mae: 0.6884 - mse: 0.7940 - val_loss: 15.7436 - val_mae: 1.6053 - val_mse: 5.2762\n",
      "Epoch 236/1000\n",
      "3620/3620 [==============================] - 0s 35us/sample - loss: 11.6002 - mae: 0.6870 - mse: 0.7951 - val_loss: 16.5973 - val_mae: 2.0480 - val_mse: 7.2192\n",
      "Epoch 237/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.5914 - mae: 0.6861 - mse: 0.7904 - val_loss: 16.8746 - val_mae: 2.1058 - val_mse: 7.6350\n",
      "Epoch 238/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.6044 - mae: 0.6902 - mse: 0.8045 - val_loss: 16.0819 - val_mae: 1.8804 - val_mse: 6.3713\n",
      "Epoch 239/1000\n",
      "3620/3620 [==============================] - 0s 37us/sample - loss: 11.5963 - mae: 0.6884 - mse: 0.7924 - val_loss: 15.8028 - val_mae: 1.7034 - val_mse: 5.6311\n",
      "Epoch 240/1000\n",
      "3620/3620 [==============================] - 0s 35us/sample - loss: 11.5951 - mae: 0.6856 - mse: 0.7844 - val_loss: 15.7088 - val_mae: 1.6804 - val_mse: 5.4547\n",
      "Epoch 241/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5872 - mae: 0.6814 - mse: 0.7774 - val_loss: 15.5894 - val_mae: 1.6114 - val_mse: 5.2063\n",
      "Epoch 242/1000\n",
      "3620/3620 [==============================] - 0s 35us/sample - loss: 11.5908 - mae: 0.6821 - mse: 0.7825 - val_loss: 16.0212 - val_mae: 1.8381 - val_mse: 6.1635\n",
      "Epoch 243/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.5915 - mae: 0.6871 - mse: 0.7852 - val_loss: 15.8331 - val_mae: 1.7667 - val_mse: 5.8698\n",
      "Epoch 244/1000\n",
      "3620/3620 [==============================] - 0s 48us/sample - loss: 11.5894 - mae: 0.6839 - mse: 0.7851 - val_loss: 15.7356 - val_mae: 1.7041 - val_mse: 5.5797\n",
      "Epoch 245/1000\n",
      "3620/3620 [==============================] - 0s 44us/sample - loss: 11.5895 - mae: 0.6820 - mse: 0.7809 - val_loss: 15.6564 - val_mae: 1.6616 - val_mse: 5.3193\n",
      "Epoch 246/1000\n",
      "3620/3620 [==============================] - 0s 37us/sample - loss: 11.5929 - mae: 0.6844 - mse: 0.7861 - val_loss: 16.4747 - val_mae: 1.9900 - val_mse: 6.9848\n",
      "Epoch 247/1000\n",
      "3620/3620 [==============================] - 0s 53us/sample - loss: 11.5869 - mae: 0.6843 - mse: 0.7874 - val_loss: 15.9027 - val_mae: 1.7975 - val_mse: 5.9644\n",
      "Epoch 248/1000\n",
      "3620/3620 [==============================] - 0s 41us/sample - loss: 11.5881 - mae: 0.6845 - mse: 0.7810 - val_loss: 15.8466 - val_mae: 1.7349 - val_mse: 5.7194\n",
      "Epoch 249/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5808 - mae: 0.6799 - mse: 0.7745 - val_loss: 15.6226 - val_mae: 1.6571 - val_mse: 5.3934\n",
      "Epoch 250/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5851 - mae: 0.6819 - mse: 0.7803 - val_loss: 15.7895 - val_mae: 1.7465 - val_mse: 5.7575\n",
      "Epoch 251/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5823 - mae: 0.6828 - mse: 0.7793 - val_loss: 16.1241 - val_mae: 1.8990 - val_mse: 6.4608\n",
      "Epoch 252/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5881 - mae: 0.6820 - mse: 0.7875 - val_loss: 15.9844 - val_mae: 1.8391 - val_mse: 6.1732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5791 - mae: 0.6826 - mse: 0.7758 - val_loss: 15.6685 - val_mae: 1.5286 - val_mse: 4.9564\n",
      "Epoch 254/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5874 - mae: 0.6801 - mse: 0.7794 - val_loss: 15.6913 - val_mae: 1.6047 - val_mse: 5.2654\n",
      "Epoch 255/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5839 - mae: 0.6829 - mse: 0.7773 - val_loss: 16.4787 - val_mae: 1.9987 - val_mse: 7.0458\n",
      "Epoch 256/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5711 - mae: 0.6823 - mse: 0.7736 - val_loss: 16.0428 - val_mae: 1.8426 - val_mse: 6.1913\n",
      "Epoch 257/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5860 - mae: 0.6847 - mse: 0.7847 - val_loss: 16.0463 - val_mae: 1.8704 - val_mse: 6.3191\n",
      "Epoch 258/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5757 - mae: 0.6808 - mse: 0.7728 - val_loss: 15.7363 - val_mae: 1.6932 - val_mse: 5.5541\n",
      "Epoch 259/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5751 - mae: 0.6770 - mse: 0.7698 - val_loss: 15.6760 - val_mae: 1.6385 - val_mse: 5.2747\n",
      "Epoch 260/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5785 - mae: 0.6836 - mse: 0.7741 - val_loss: 15.6057 - val_mae: 1.5782 - val_mse: 5.0908\n",
      "Epoch 261/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5753 - mae: 0.6783 - mse: 0.7706 - val_loss: 16.1595 - val_mae: 1.8962 - val_mse: 6.4853\n",
      "Epoch 262/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5790 - mae: 0.6830 - mse: 0.7790 - val_loss: 15.9120 - val_mae: 1.7900 - val_mse: 5.9625\n",
      "Epoch 263/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5715 - mae: 0.6781 - mse: 0.7694 - val_loss: 15.6466 - val_mae: 1.5883 - val_mse: 5.1059\n",
      "Epoch 264/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5762 - mae: 0.6775 - mse: 0.7680 - val_loss: 15.6329 - val_mae: 1.5714 - val_mse: 5.0934\n",
      "Epoch 265/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5744 - mae: 0.6783 - mse: 0.7697 - val_loss: 16.2255 - val_mae: 1.9070 - val_mse: 6.5246\n",
      "Epoch 266/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5712 - mae: 0.6789 - mse: 0.7714 - val_loss: 15.7073 - val_mae: 1.6733 - val_mse: 5.4867\n",
      "Epoch 267/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5733 - mae: 0.6784 - mse: 0.7682 - val_loss: 15.6921 - val_mae: 1.5621 - val_mse: 4.9256\n",
      "Epoch 268/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5682 - mae: 0.6746 - mse: 0.7620 - val_loss: 15.7019 - val_mae: 1.6426 - val_mse: 5.1955\n",
      "Epoch 269/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5747 - mae: 0.6778 - mse: 0.7717 - val_loss: 15.6649 - val_mae: 1.6671 - val_mse: 5.4236\n",
      "Epoch 270/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5661 - mae: 0.6800 - mse: 0.7645 - val_loss: 15.6862 - val_mae: 1.6769 - val_mse: 5.4781\n",
      "Epoch 271/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5644 - mae: 0.6763 - mse: 0.7608 - val_loss: 15.6901 - val_mae: 1.6491 - val_mse: 5.2196\n",
      "Epoch 272/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5725 - mae: 0.6751 - mse: 0.7671 - val_loss: 15.7648 - val_mae: 1.7389 - val_mse: 5.7579\n",
      "Epoch 273/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5671 - mae: 0.6749 - mse: 0.7669 - val_loss: 15.7050 - val_mae: 1.6010 - val_mse: 5.1794\n",
      "Epoch 274/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5711 - mae: 0.6779 - mse: 0.7689 - val_loss: 15.9281 - val_mae: 1.8039 - val_mse: 6.0601\n",
      "Epoch 275/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5634 - mae: 0.6772 - mse: 0.7623 - val_loss: 15.6195 - val_mae: 1.5688 - val_mse: 5.0435\n",
      "Epoch 276/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5568 - mae: 0.6706 - mse: 0.7523 - val_loss: 15.6197 - val_mae: 1.5867 - val_mse: 5.0464\n",
      "Epoch 277/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5690 - mae: 0.6737 - mse: 0.7628 - val_loss: 15.7351 - val_mae: 1.6860 - val_mse: 5.5082\n",
      "Epoch 278/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5595 - mae: 0.6744 - mse: 0.7567 - val_loss: 15.6705 - val_mae: 1.5101 - val_mse: 4.8596\n",
      "Epoch 279/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.5589 - mae: 0.6722 - mse: 0.7542 - val_loss: 16.0612 - val_mae: 1.8781 - val_mse: 6.3559\n",
      "Epoch 280/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5621 - mae: 0.6751 - mse: 0.7621 - val_loss: 15.6923 - val_mae: 1.5821 - val_mse: 5.1363\n",
      "Epoch 281/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5578 - mae: 0.6714 - mse: 0.7499 - val_loss: 15.8619 - val_mae: 1.7779 - val_mse: 5.9305\n",
      "Epoch 282/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5586 - mae: 0.6742 - mse: 0.7594 - val_loss: 15.7961 - val_mae: 1.7152 - val_mse: 5.6591\n",
      "Epoch 283/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5568 - mae: 0.6733 - mse: 0.7582 - val_loss: 16.2012 - val_mae: 1.9149 - val_mse: 6.5031\n",
      "Epoch 284/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.5570 - mae: 0.6759 - mse: 0.7618 - val_loss: 16.5547 - val_mae: 2.0198 - val_mse: 7.1215\n",
      "Epoch 285/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5578 - mae: 0.6795 - mse: 0.7602 - val_loss: 15.6472 - val_mae: 1.5636 - val_mse: 5.0286\n",
      "Epoch 286/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5592 - mae: 0.6724 - mse: 0.7549 - val_loss: 15.9811 - val_mae: 1.7747 - val_mse: 5.9076\n",
      "Epoch 287/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5486 - mae: 0.6724 - mse: 0.7471 - val_loss: 15.7680 - val_mae: 1.6243 - val_mse: 5.1498\n",
      "Epoch 288/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5573 - mae: 0.6709 - mse: 0.7531 - val_loss: 15.7132 - val_mae: 1.6297 - val_mse: 5.3001\n",
      "Epoch 289/1000\n",
      "3620/3620 [==============================] - 0s 31us/sample - loss: 11.5509 - mae: 0.6730 - mse: 0.7510 - val_loss: 16.1368 - val_mae: 1.9023 - val_mse: 6.4533\n",
      "Epoch 290/1000\n",
      "3620/3620 [==============================] - 0s 32us/sample - loss: 11.5491 - mae: 0.6751 - mse: 0.7534 - val_loss: 15.8099 - val_mae: 1.7046 - val_mse: 5.6485\n",
      "Epoch 291/1000\n",
      "3620/3620 [==============================] - 0s 33us/sample - loss: 11.5554 - mae: 0.6751 - mse: 0.7588 - val_loss: 15.7013 - val_mae: 1.6773 - val_mse: 5.4860\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,442\n",
      "Trainable params: 5,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5430 samples, validate on 1810 samples\n",
      "Epoch 1/1000\n",
      "5430/5430 [==============================] - 1s 124us/sample - loss: 82.7417 - mae: 6.2777 - mse: 76.2891 - val_loss: 23.6848 - val_mae: 2.7229 - val_mse: 14.2548\n",
      "Epoch 2/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 17.7113 - mae: 2.0999 - mse: 7.1808 - val_loss: 19.6278 - val_mae: 2.3314 - val_mse: 9.9397\n",
      "Epoch 3/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 15.4625 - mae: 1.7580 - mse: 4.8200 - val_loss: 17.1959 - val_mae: 1.9112 - val_mse: 6.4762\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5430/5430 [==============================] - 0s 32us/sample - loss: 13.9641 - mae: 1.4481 - mse: 3.2434 - val_loss: 16.0052 - val_mae: 1.7092 - val_mse: 5.4381\n",
      "Epoch 5/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 13.2680 - mae: 1.2531 - mse: 2.4885 - val_loss: 15.6084 - val_mae: 1.5910 - val_mse: 4.8398\n",
      "Epoch 6/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 13.0930 - mae: 1.1921 - mse: 2.2816 - val_loss: 15.7356 - val_mae: 1.7570 - val_mse: 5.6210\n",
      "Epoch 7/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 13.0096 - mae: 1.1639 - mse: 2.1958 - val_loss: 15.5746 - val_mae: 1.6314 - val_mse: 5.0598\n",
      "Epoch 8/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.9420 - mae: 1.1380 - mse: 2.1214 - val_loss: 15.3293 - val_mae: 1.5349 - val_mse: 4.5701\n",
      "Epoch 9/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.8939 - mae: 1.1224 - mse: 2.0663 - val_loss: 15.1094 - val_mae: 1.5210 - val_mse: 4.4758\n",
      "Epoch 10/1000\n",
      "5430/5430 [==============================] - 0s 32us/sample - loss: 12.8394 - mae: 1.1028 - mse: 2.0119 - val_loss: 15.0668 - val_mae: 1.4431 - val_mse: 4.1061\n",
      "Epoch 11/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 12.7849 - mae: 1.0854 - mse: 1.9514 - val_loss: 14.9014 - val_mae: 1.4612 - val_mse: 4.1018\n",
      "Epoch 12/1000\n",
      "5430/5430 [==============================] - 0s 34us/sample - loss: 12.7347 - mae: 1.0657 - mse: 1.8939 - val_loss: 15.0730 - val_mae: 1.6862 - val_mse: 5.0371\n",
      "Epoch 13/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.7032 - mae: 1.0545 - mse: 1.8678 - val_loss: 15.2339 - val_mae: 1.4748 - val_mse: 4.2545\n",
      "Epoch 14/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.6380 - mae: 1.0305 - mse: 1.7942 - val_loss: 15.0614 - val_mae: 1.5586 - val_mse: 4.6051\n",
      "Epoch 15/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.5999 - mae: 1.0165 - mse: 1.7546 - val_loss: 15.0386 - val_mae: 1.5315 - val_mse: 4.4707\n",
      "Epoch 16/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.5513 - mae: 1.0007 - mse: 1.7013 - val_loss: 14.7525 - val_mae: 1.5444 - val_mse: 4.3769\n",
      "Epoch 17/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.5186 - mae: 0.9846 - mse: 1.6635 - val_loss: 14.6135 - val_mae: 1.4364 - val_mse: 3.9362\n",
      "Epoch 18/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.4779 - mae: 0.9724 - mse: 1.6216 - val_loss: 14.7119 - val_mae: 1.5351 - val_mse: 4.3427\n",
      "Epoch 19/1000\n",
      "5430/5430 [==============================] - 0s 48us/sample - loss: 12.4438 - mae: 0.9605 - mse: 1.5862 - val_loss: 14.5200 - val_mae: 1.3514 - val_mse: 3.5437\n",
      "Epoch 20/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.4086 - mae: 0.9453 - mse: 1.5455 - val_loss: 14.6207 - val_mae: 1.3329 - val_mse: 3.5186\n",
      "Epoch 21/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.3870 - mae: 0.9382 - mse: 1.5210 - val_loss: 14.4120 - val_mae: 1.4063 - val_mse: 3.7280\n",
      "Epoch 22/1000\n",
      "5430/5430 [==============================] - 0s 32us/sample - loss: 12.3455 - mae: 0.9267 - mse: 1.4828 - val_loss: 14.4765 - val_mae: 1.3565 - val_mse: 3.5693\n",
      "Epoch 23/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 12.3207 - mae: 0.9188 - mse: 1.4564 - val_loss: 14.3904 - val_mae: 1.3401 - val_mse: 3.4878\n",
      "Epoch 24/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 12.3010 - mae: 0.9130 - mse: 1.4319 - val_loss: 14.4298 - val_mae: 1.4862 - val_mse: 4.0835\n",
      "Epoch 25/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 12.2729 - mae: 0.9036 - mse: 1.4054 - val_loss: 14.4448 - val_mae: 1.3462 - val_mse: 3.5285\n",
      "Epoch 26/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.2483 - mae: 0.8951 - mse: 1.3732 - val_loss: 14.4136 - val_mae: 1.4989 - val_mse: 4.1454\n",
      "Epoch 27/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.2335 - mae: 0.8891 - mse: 1.3687 - val_loss: 14.5935 - val_mae: 1.2725 - val_mse: 3.3081\n",
      "Epoch 28/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.2156 - mae: 0.8800 - mse: 1.3398 - val_loss: 14.3063 - val_mae: 1.4492 - val_mse: 3.9312\n",
      "Epoch 29/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 12.1888 - mae: 0.8758 - mse: 1.3183 - val_loss: 14.2164 - val_mae: 1.2860 - val_mse: 3.2712\n",
      "Epoch 30/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.1881 - mae: 0.8746 - mse: 1.3141 - val_loss: 14.2502 - val_mae: 1.3958 - val_mse: 3.6641\n",
      "Epoch 31/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.1806 - mae: 0.8721 - mse: 1.3095 - val_loss: 14.1780 - val_mae: 1.3675 - val_mse: 3.5267\n",
      "Epoch 32/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.1597 - mae: 0.8638 - mse: 1.2845 - val_loss: 14.3913 - val_mae: 1.4671 - val_mse: 4.0271\n",
      "Epoch 33/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 12.1392 - mae: 0.8582 - mse: 1.2679 - val_loss: 14.1536 - val_mae: 1.3939 - val_mse: 3.6500\n",
      "Epoch 34/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 12.1309 - mae: 0.8568 - mse: 1.2586 - val_loss: 14.1098 - val_mae: 1.3672 - val_mse: 3.5588\n",
      "Epoch 35/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.1034 - mae: 0.8453 - mse: 1.2349 - val_loss: 14.7025 - val_mae: 1.1993 - val_mse: 3.0829\n",
      "Epoch 36/1000\n",
      "5430/5430 [==============================] - 0s 32us/sample - loss: 12.1026 - mae: 0.8464 - mse: 1.2242 - val_loss: 14.3479 - val_mae: 1.4076 - val_mse: 3.7995\n",
      "Epoch 37/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 12.0952 - mae: 0.8410 - mse: 1.2227 - val_loss: 14.1291 - val_mae: 1.3872 - val_mse: 3.6373\n",
      "Epoch 38/1000\n",
      "5430/5430 [==============================] - 0s 39us/sample - loss: 12.0822 - mae: 0.8394 - mse: 1.2119 - val_loss: 14.0780 - val_mae: 1.3470 - val_mse: 3.4655\n",
      "Epoch 39/1000\n",
      "5430/5430 [==============================] - 0s 32us/sample - loss: 12.0750 - mae: 0.8340 - mse: 1.2018 - val_loss: 14.3598 - val_mae: 1.3422 - val_mse: 3.5206\n",
      "Epoch 40/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 12.0549 - mae: 0.8295 - mse: 1.1831 - val_loss: 14.0685 - val_mae: 1.2276 - val_mse: 3.0739\n",
      "Epoch 41/1000\n",
      "5430/5430 [==============================] - 0s 41us/sample - loss: 12.0441 - mae: 0.8246 - mse: 1.1710 - val_loss: 14.1242 - val_mae: 1.3247 - val_mse: 3.4365\n",
      "Epoch 42/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.0330 - mae: 0.8219 - mse: 1.1637 - val_loss: 14.0894 - val_mae: 1.2103 - val_mse: 3.0536\n",
      "Epoch 43/1000\n",
      "5430/5430 [==============================] - 0s 32us/sample - loss: 12.0320 - mae: 0.8220 - mse: 1.1593 - val_loss: 14.2129 - val_mae: 1.2400 - val_mse: 3.1910\n",
      "Epoch 44/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.0118 - mae: 0.8156 - mse: 1.1386 - val_loss: 14.1677 - val_mae: 1.3117 - val_mse: 3.4105\n",
      "Epoch 45/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 12.0095 - mae: 0.8145 - mse: 1.1396 - val_loss: 14.2281 - val_mae: 1.1592 - val_mse: 2.9217\n",
      "Epoch 46/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 11.9989 - mae: 0.8082 - mse: 1.1247 - val_loss: 14.3735 - val_mae: 1.2374 - val_mse: 3.1856\n",
      "Epoch 47/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.9925 - mae: 0.8070 - mse: 1.1198 - val_loss: 14.2931 - val_mae: 1.1937 - val_mse: 3.0458\n",
      "Epoch 48/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 11.9882 - mae: 0.8056 - mse: 1.1168 - val_loss: 14.3718 - val_mae: 1.1969 - val_mse: 3.0464\n",
      "Epoch 49/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.9856 - mae: 0.8031 - mse: 1.1143 - val_loss: 14.0740 - val_mae: 1.2725 - val_mse: 3.2874\n",
      "Epoch 50/1000\n",
      "5430/5430 [==============================] - 0s 33us/sample - loss: 11.9714 - mae: 0.7994 - mse: 1.0979 - val_loss: 13.9598 - val_mae: 1.2680 - val_mse: 3.2253\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.9579 - mae: 0.7939 - mse: 1.0851 - val_loss: 14.0517 - val_mae: 1.4087 - val_mse: 3.7192\n",
      "Epoch 52/1000\n",
      "5430/5430 [==============================] - 0s 32us/sample - loss: 11.9490 - mae: 0.7939 - mse: 1.0801 - val_loss: 14.0031 - val_mae: 1.3473 - val_mse: 3.5028\n",
      "Epoch 53/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 11.9407 - mae: 0.7912 - mse: 1.0682 - val_loss: 14.1254 - val_mae: 1.3974 - val_mse: 3.7234\n",
      "Epoch 54/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 11.9397 - mae: 0.7882 - mse: 1.0708 - val_loss: 14.1704 - val_mae: 1.1792 - val_mse: 2.9834\n",
      "Epoch 55/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.9286 - mae: 0.7870 - mse: 1.0538 - val_loss: 14.2448 - val_mae: 1.2331 - val_mse: 3.1741\n",
      "Epoch 56/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.9206 - mae: 0.7836 - mse: 1.0493 - val_loss: 14.1347 - val_mae: 1.2648 - val_mse: 3.2609\n",
      "Epoch 57/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 11.9163 - mae: 0.7776 - mse: 1.0430 - val_loss: 14.1328 - val_mae: 1.3849 - val_mse: 3.6850\n",
      "Epoch 58/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.9084 - mae: 0.7808 - mse: 1.0381 - val_loss: 14.0210 - val_mae: 1.2023 - val_mse: 3.0464\n",
      "Epoch 59/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.9000 - mae: 0.7749 - mse: 1.0289 - val_loss: 14.1409 - val_mae: 1.1823 - val_mse: 2.9977\n",
      "Epoch 60/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 11.8929 - mae: 0.7767 - mse: 1.0209 - val_loss: 14.3433 - val_mae: 1.2631 - val_mse: 3.2693\n",
      "Epoch 61/1000\n",
      "5430/5430 [==============================] - 0s 33us/sample - loss: 11.8838 - mae: 0.7667 - mse: 1.0116 - val_loss: 14.1600 - val_mae: 1.3392 - val_mse: 3.5156\n",
      "Epoch 62/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.8803 - mae: 0.7709 - mse: 1.0106 - val_loss: 14.4727 - val_mae: 1.1393 - val_mse: 2.9279\n",
      "Epoch 63/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 11.8796 - mae: 0.7682 - mse: 1.0043 - val_loss: 14.0006 - val_mae: 1.2899 - val_mse: 3.3308\n",
      "Epoch 64/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 11.8560 - mae: 0.7605 - mse: 0.9852 - val_loss: 14.3269 - val_mae: 1.3128 - val_mse: 3.4800\n",
      "Epoch 65/1000\n",
      "5430/5430 [==============================] - 0s 38us/sample - loss: 11.8652 - mae: 0.7638 - mse: 0.9944 - val_loss: 14.0501 - val_mae: 1.2105 - val_mse: 3.0735\n",
      "Epoch 66/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.8565 - mae: 0.7618 - mse: 0.9839 - val_loss: 14.0053 - val_mae: 1.2658 - val_mse: 3.2834\n",
      "Epoch 67/1000\n",
      "5430/5430 [==============================] - 0s 43us/sample - loss: 11.8504 - mae: 0.7592 - mse: 0.9800 - val_loss: 14.1945 - val_mae: 1.2276 - val_mse: 3.1671\n",
      "Epoch 68/1000\n",
      "5430/5430 [==============================] - 0s 33us/sample - loss: 11.8488 - mae: 0.7571 - mse: 0.9754 - val_loss: 14.1369 - val_mae: 1.3710 - val_mse: 3.6373\n",
      "Epoch 69/1000\n",
      "5430/5430 [==============================] - 0s 33us/sample - loss: 11.8321 - mae: 0.7532 - mse: 0.9601 - val_loss: 14.0726 - val_mae: 1.2654 - val_mse: 3.2896\n",
      "Epoch 70/1000\n",
      "5430/5430 [==============================] - 0s 38us/sample - loss: 11.8376 - mae: 0.7550 - mse: 0.9653 - val_loss: 14.0311 - val_mae: 1.2759 - val_mse: 3.3044\n",
      "Epoch 71/1000\n",
      "5430/5430 [==============================] - 0s 43us/sample - loss: 11.8349 - mae: 0.7537 - mse: 0.9642 - val_loss: 14.0830 - val_mae: 1.2524 - val_mse: 3.2523\n",
      "Epoch 72/1000\n",
      "5430/5430 [==============================] - 0s 46us/sample - loss: 11.8312 - mae: 0.7539 - mse: 0.9603 - val_loss: 14.2021 - val_mae: 1.1942 - val_mse: 3.0879\n",
      "Epoch 73/1000\n",
      "5430/5430 [==============================] - 0s 47us/sample - loss: 11.8277 - mae: 0.7507 - mse: 0.9579 - val_loss: 14.0651 - val_mae: 1.2451 - val_mse: 3.2095\n",
      "Epoch 74/1000\n",
      "5430/5430 [==============================] - 0s 46us/sample - loss: 11.8227 - mae: 0.7500 - mse: 0.9515 - val_loss: 14.2586 - val_mae: 1.1746 - val_mse: 3.0338\n",
      "Epoch 75/1000\n",
      "5430/5430 [==============================] - 0s 46us/sample - loss: 11.8130 - mae: 0.7457 - mse: 0.9404 - val_loss: 14.1230 - val_mae: 1.2570 - val_mse: 3.2775\n",
      "Epoch 76/1000\n",
      "5430/5430 [==============================] - 0s 46us/sample - loss: 11.8130 - mae: 0.7472 - mse: 0.9414 - val_loss: 14.0934 - val_mae: 1.3049 - val_mse: 3.4062\n",
      "Epoch 77/1000\n",
      "5430/5430 [==============================] - 0s 43us/sample - loss: 11.7946 - mae: 0.7433 - mse: 0.9250 - val_loss: 14.0688 - val_mae: 1.2968 - val_mse: 3.3506\n",
      "Epoch 78/1000\n",
      "5430/5430 [==============================] - 0s 48us/sample - loss: 11.8018 - mae: 0.7437 - mse: 0.9314 - val_loss: 14.0428 - val_mae: 1.2757 - val_mse: 3.2927\n",
      "Epoch 79/1000\n",
      "5430/5430 [==============================] - 0s 32us/sample - loss: 11.7933 - mae: 0.7396 - mse: 0.9227 - val_loss: 14.3706 - val_mae: 1.5315 - val_mse: 4.2438\n",
      "Epoch 80/1000\n",
      "5430/5430 [==============================] - 0s 33us/sample - loss: 11.7933 - mae: 0.7430 - mse: 0.9269 - val_loss: 14.2284 - val_mae: 1.4566 - val_mse: 3.9252\n",
      "Epoch 81/1000\n",
      "5430/5430 [==============================] - 0s 32us/sample - loss: 11.7896 - mae: 0.7405 - mse: 0.9231 - val_loss: 14.4764 - val_mae: 1.1902 - val_mse: 3.1161\n",
      "Epoch 82/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 11.7847 - mae: 0.7368 - mse: 0.9128 - val_loss: 14.0907 - val_mae: 1.2257 - val_mse: 3.1784\n",
      "Epoch 83/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 11.7801 - mae: 0.7372 - mse: 0.9106 - val_loss: 14.2144 - val_mae: 1.3820 - val_mse: 3.7116\n",
      "Epoch 84/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7729 - mae: 0.7345 - mse: 0.9044 - val_loss: 14.1497 - val_mae: 1.3005 - val_mse: 3.4800\n",
      "Epoch 85/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 11.7738 - mae: 0.7354 - mse: 0.9067 - val_loss: 14.2176 - val_mae: 1.3123 - val_mse: 3.5112\n",
      "Epoch 86/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7681 - mae: 0.7340 - mse: 0.9005 - val_loss: 14.3573 - val_mae: 1.2788 - val_mse: 3.4115\n",
      "Epoch 87/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7636 - mae: 0.7320 - mse: 0.8972 - val_loss: 14.4261 - val_mae: 1.1969 - val_mse: 3.1707\n",
      "Epoch 88/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7627 - mae: 0.7321 - mse: 0.8950 - val_loss: 14.1462 - val_mae: 1.2221 - val_mse: 3.1951\n",
      "Epoch 89/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7600 - mae: 0.7311 - mse: 0.8917 - val_loss: 14.1427 - val_mae: 1.2740 - val_mse: 3.3530\n",
      "Epoch 90/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7535 - mae: 0.7279 - mse: 0.8882 - val_loss: 14.3033 - val_mae: 1.2481 - val_mse: 3.3086\n",
      "Epoch 91/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7520 - mae: 0.7287 - mse: 0.8853 - val_loss: 14.3831 - val_mae: 1.2327 - val_mse: 3.2683\n",
      "Epoch 92/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7479 - mae: 0.7250 - mse: 0.8790 - val_loss: 14.2950 - val_mae: 1.4718 - val_mse: 4.0209\n",
      "Epoch 93/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7451 - mae: 0.7291 - mse: 0.8805 - val_loss: 14.2073 - val_mae: 1.2171 - val_mse: 3.1865\n",
      "Epoch 94/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7398 - mae: 0.7251 - mse: 0.8718 - val_loss: 14.1381 - val_mae: 1.3285 - val_mse: 3.5206\n",
      "Epoch 95/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7355 - mae: 0.7222 - mse: 0.8702 - val_loss: 14.3961 - val_mae: 1.1864 - val_mse: 3.1304\n",
      "Epoch 96/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7314 - mae: 0.7204 - mse: 0.8649 - val_loss: 14.3960 - val_mae: 1.1874 - val_mse: 3.1329\n",
      "Epoch 97/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7366 - mae: 0.7233 - mse: 0.8699 - val_loss: 14.2402 - val_mae: 1.3618 - val_mse: 3.6921\n",
      "Epoch 98/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7308 - mae: 0.7223 - mse: 0.8667 - val_loss: 14.2335 - val_mae: 1.3378 - val_mse: 3.6053\n",
      "Epoch 99/1000\n",
      "5430/5430 [==============================] - 0s 30us/sample - loss: 11.7246 - mae: 0.7209 - mse: 0.8584 - val_loss: 14.2815 - val_mae: 1.4915 - val_mse: 4.0860\n",
      "Epoch 100/1000\n",
      "5430/5430 [==============================] - 0s 31us/sample - loss: 11.7185 - mae: 0.7201 - mse: 0.8556 - val_loss: 14.1921 - val_mae: 1.3723 - val_mse: 3.7015\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,442\n",
      "Trainable params: 5,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7240 samples, validate on 2414 samples\n",
      "Epoch 1/1000\n",
      "7240/7240 [==============================] - 1s 100us/sample - loss: 63.0470 - mae: 4.9136 - mse: 55.2426 - val_loss: 19.0466 - val_mae: 2.0899 - val_mse: 8.2004\n",
      "Epoch 2/1000\n",
      "7240/7240 [==============================] - 0s 29us/sample - loss: 15.1899 - mae: 1.6631 - mse: 4.5290 - val_loss: 15.2751 - val_mae: 1.5548 - val_mse: 4.7225\n",
      "Epoch 3/1000\n",
      "7240/7240 [==============================] - 0s 30us/sample - loss: 13.5965 - mae: 1.3072 - mse: 2.8292 - val_loss: 15.1732 - val_mae: 1.3685 - val_mse: 3.4244\n",
      "Epoch 4/1000\n",
      "7240/7240 [==============================] - 0s 30us/sample - loss: 13.2617 - mae: 1.2195 - mse: 2.4549 - val_loss: 14.7364 - val_mae: 1.4252 - val_mse: 3.6509\n",
      "Epoch 5/1000\n",
      "7240/7240 [==============================] - 0s 29us/sample - loss: 13.0983 - mae: 1.1726 - mse: 2.2839 - val_loss: 15.6857 - val_mae: 1.3758 - val_mse: 3.3131\n",
      "Epoch 6/1000\n",
      "7240/7240 [==============================] - 0s 30us/sample - loss: 13.0043 - mae: 1.1431 - mse: 2.1770 - val_loss: 14.4840 - val_mae: 1.2528 - val_mse: 2.8992\n",
      "Epoch 7/1000\n",
      "7240/7240 [==============================] - 0s 30us/sample - loss: 12.8986 - mae: 1.1114 - mse: 2.0742 - val_loss: 14.7124 - val_mae: 1.2498 - val_mse: 2.8612\n",
      "Epoch 8/1000\n",
      "7240/7240 [==============================] - 0s 31us/sample - loss: 12.8154 - mae: 1.0848 - mse: 1.9826 - val_loss: 14.0984 - val_mae: 1.4278 - val_mse: 3.6488\n",
      "Epoch 9/1000\n",
      "7240/7240 [==============================] - 0s 30us/sample - loss: 12.7201 - mae: 1.0529 - mse: 1.8879 - val_loss: 15.1335 - val_mae: 1.2580 - val_mse: 2.9197\n",
      "Epoch 10/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 12.6337 - mae: 1.0199 - mse: 1.7883 - val_loss: 14.0787 - val_mae: 1.4852 - val_mse: 3.8644\n",
      "Epoch 11/1000\n",
      "7240/7240 [==============================] - 0s 32us/sample - loss: 12.5819 - mae: 1.0032 - mse: 1.7413 - val_loss: 13.7982 - val_mae: 1.2251 - val_mse: 2.8353\n",
      "Epoch 12/1000\n",
      "7240/7240 [==============================] - 0s 31us/sample - loss: 12.5197 - mae: 0.9826 - mse: 1.6752 - val_loss: 13.8288 - val_mae: 1.1697 - val_mse: 2.6731\n",
      "Epoch 13/1000\n",
      "7240/7240 [==============================] - 0s 32us/sample - loss: 12.4862 - mae: 0.9654 - mse: 1.6368 - val_loss: 13.8314 - val_mae: 1.1642 - val_mse: 2.5851\n",
      "Epoch 14/1000\n",
      "7240/7240 [==============================] - 0s 32us/sample - loss: 12.4276 - mae: 0.9453 - mse: 1.5774 - val_loss: 14.3017 - val_mae: 1.6152 - val_mse: 4.4212\n",
      "Epoch 15/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 12.3870 - mae: 0.9318 - mse: 1.5425 - val_loss: 13.7791 - val_mae: 1.2041 - val_mse: 2.8409\n",
      "Epoch 16/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 12.3524 - mae: 0.9196 - mse: 1.5035 - val_loss: 13.7767 - val_mae: 1.1331 - val_mse: 2.5538\n",
      "Epoch 17/1000\n",
      "7240/7240 [==============================] - 0s 31us/sample - loss: 12.3362 - mae: 0.9157 - mse: 1.4878 - val_loss: 14.1587 - val_mae: 1.2151 - val_mse: 2.8407\n",
      "Epoch 18/1000\n",
      "7240/7240 [==============================] - 0s 31us/sample - loss: 12.3096 - mae: 0.9060 - mse: 1.4595 - val_loss: 13.5512 - val_mae: 1.1539 - val_mse: 2.6080\n",
      "Epoch 19/1000\n",
      "7240/7240 [==============================] - 0s 30us/sample - loss: 12.2866 - mae: 0.8972 - mse: 1.4395 - val_loss: 13.9741 - val_mae: 1.0825 - val_mse: 2.3547\n",
      "Epoch 20/1000\n",
      "7240/7240 [==============================] - 0s 31us/sample - loss: 12.2544 - mae: 0.8875 - mse: 1.4046 - val_loss: 14.0100 - val_mae: 1.1118 - val_mse: 2.4745\n",
      "Epoch 21/1000\n",
      "7240/7240 [==============================] - 0s 30us/sample - loss: 12.2395 - mae: 0.8839 - mse: 1.3897 - val_loss: 13.8031 - val_mae: 1.0682 - val_mse: 2.3422\n",
      "Epoch 22/1000\n",
      "7240/7240 [==============================] - 0s 32us/sample - loss: 12.2170 - mae: 0.8767 - mse: 1.3699 - val_loss: 13.5181 - val_mae: 1.0894 - val_mse: 2.3952\n",
      "Epoch 23/1000\n",
      "7240/7240 [==============================] - 0s 31us/sample - loss: 12.1892 - mae: 0.8683 - mse: 1.3444 - val_loss: 13.5802 - val_mae: 1.3713 - val_mse: 3.2937\n",
      "Epoch 24/1000\n",
      "7240/7240 [==============================] - 0s 32us/sample - loss: 12.1781 - mae: 0.8666 - mse: 1.3336 - val_loss: 13.4109 - val_mae: 1.1535 - val_mse: 2.5901\n",
      "Epoch 25/1000\n",
      "7240/7240 [==============================] - 0s 30us/sample - loss: 12.1610 - mae: 0.8602 - mse: 1.3154 - val_loss: 13.5444 - val_mae: 1.1636 - val_mse: 2.6720\n",
      "Epoch 26/1000\n",
      "7240/7240 [==============================] - 0s 32us/sample - loss: 12.1505 - mae: 0.8554 - mse: 1.3090 - val_loss: 13.7037 - val_mae: 1.0400 - val_mse: 2.2276\n",
      "Epoch 27/1000\n",
      "7240/7240 [==============================] - 0s 30us/sample - loss: 12.1369 - mae: 0.8512 - mse: 1.2945 - val_loss: 13.6463 - val_mae: 1.0191 - val_mse: 2.1647\n",
      "Epoch 28/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 12.1241 - mae: 0.8480 - mse: 1.2818 - val_loss: 13.5251 - val_mae: 1.2119 - val_mse: 2.8314\n",
      "Epoch 29/1000\n",
      "7240/7240 [==============================] - 0s 30us/sample - loss: 12.1148 - mae: 0.8436 - mse: 1.2747 - val_loss: 13.5353 - val_mae: 1.0473 - val_mse: 2.2417\n",
      "Epoch 30/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 12.1051 - mae: 0.8408 - mse: 1.2628 - val_loss: 13.3907 - val_mae: 1.0986 - val_mse: 2.4566\n",
      "Epoch 31/1000\n",
      "7240/7240 [==============================] - 0s 37us/sample - loss: 12.0902 - mae: 0.8371 - mse: 1.2540 - val_loss: 14.0065 - val_mae: 1.0189 - val_mse: 2.1843\n",
      "Epoch 32/1000\n",
      "7240/7240 [==============================] - 0s 31us/sample - loss: 12.0779 - mae: 0.8325 - mse: 1.2352 - val_loss: 13.5677 - val_mae: 1.0125 - val_mse: 2.1453\n",
      "Epoch 33/1000\n",
      "7240/7240 [==============================] - 0s 32us/sample - loss: 12.0730 - mae: 0.8309 - mse: 1.2342 - val_loss: 13.4222 - val_mae: 1.2412 - val_mse: 2.9107\n",
      "Epoch 34/1000\n",
      "7240/7240 [==============================] - 0s 50us/sample - loss: 12.0685 - mae: 0.8314 - mse: 1.2305 - val_loss: 13.3121 - val_mae: 1.1093 - val_mse: 2.4519\n",
      "Epoch 35/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 12.0569 - mae: 0.8256 - mse: 1.2215 - val_loss: 13.8829 - val_mae: 1.0603 - val_mse: 2.3134\n",
      "Epoch 36/1000\n",
      "7240/7240 [==============================] - 0s 39us/sample - loss: 12.0453 - mae: 0.8236 - mse: 1.2082 - val_loss: 13.6869 - val_mae: 0.9940 - val_mse: 2.1210\n",
      "Epoch 37/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 12.0375 - mae: 0.8207 - mse: 1.2002 - val_loss: 13.8470 - val_mae: 0.9842 - val_mse: 2.1073\n",
      "Epoch 38/1000\n",
      "7240/7240 [==============================] - 0s 36us/sample - loss: 12.0350 - mae: 0.8214 - mse: 1.2004 - val_loss: 13.5568 - val_mae: 1.0256 - val_mse: 2.2193\n",
      "Epoch 39/1000\n",
      "7240/7240 [==============================] - 0s 37us/sample - loss: 12.0220 - mae: 0.8168 - mse: 1.1888 - val_loss: 13.3745 - val_mae: 1.0274 - val_mse: 2.2257\n",
      "Epoch 40/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7240/7240 [==============================] - 0s 57us/sample - loss: 12.0167 - mae: 0.8160 - mse: 1.1842 - val_loss: 13.8024 - val_mae: 1.0809 - val_mse: 2.4003\n",
      "Epoch 41/1000\n",
      "7240/7240 [==============================] - 0s 39us/sample - loss: 12.0108 - mae: 0.8157 - mse: 1.1807 - val_loss: 14.0640 - val_mae: 1.0001 - val_mse: 2.1519\n",
      "Epoch 42/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 12.0080 - mae: 0.8113 - mse: 1.1744 - val_loss: 13.3935 - val_mae: 1.1251 - val_mse: 2.5359\n",
      "Epoch 43/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 12.0001 - mae: 0.8092 - mse: 1.1722 - val_loss: 13.2871 - val_mae: 1.0747 - val_mse: 2.3340\n",
      "Epoch 44/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.9839 - mae: 0.8047 - mse: 1.1543 - val_loss: 13.2486 - val_mae: 1.1331 - val_mse: 2.5309\n",
      "Epoch 45/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.9805 - mae: 0.8032 - mse: 1.1515 - val_loss: 13.8504 - val_mae: 1.5077 - val_mse: 3.9245\n",
      "Epoch 46/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 11.9717 - mae: 0.8017 - mse: 1.1456 - val_loss: 14.0523 - val_mae: 1.0383 - val_mse: 2.2498\n",
      "Epoch 47/1000\n",
      "7240/7240 [==============================] - 0s 62us/sample - loss: 11.9682 - mae: 0.8020 - mse: 1.1413 - val_loss: 13.3059 - val_mae: 1.2203 - val_mse: 2.7809\n",
      "Epoch 48/1000\n",
      "7240/7240 [==============================] - 0s 53us/sample - loss: 11.9672 - mae: 0.8009 - mse: 1.1427 - val_loss: 14.5744 - val_mae: 1.1863 - val_mse: 2.7109\n",
      "Epoch 49/1000\n",
      "7240/7240 [==============================] - 0s 56us/sample - loss: 11.9649 - mae: 0.7992 - mse: 1.1326 - val_loss: 13.3664 - val_mae: 1.0060 - val_mse: 2.1590\n",
      "Epoch 50/1000\n",
      "7240/7240 [==============================] - 0s 47us/sample - loss: 11.9421 - mae: 0.7927 - mse: 1.1164 - val_loss: 13.2691 - val_mae: 1.1169 - val_mse: 2.4121\n",
      "Epoch 51/1000\n",
      "7240/7240 [==============================] - 0s 42us/sample - loss: 11.9518 - mae: 0.7952 - mse: 1.1259 - val_loss: 13.9404 - val_mae: 0.9972 - val_mse: 2.1749\n",
      "Epoch 52/1000\n",
      "7240/7240 [==============================] - 0s 47us/sample - loss: 11.9340 - mae: 0.7894 - mse: 1.1064 - val_loss: 13.5113 - val_mae: 1.4035 - val_mse: 3.4363\n",
      "Epoch 53/1000\n",
      "7240/7240 [==============================] - 0s 44us/sample - loss: 11.9437 - mae: 0.7920 - mse: 1.1220 - val_loss: 13.3801 - val_mae: 1.1142 - val_mse: 2.4859\n",
      "Epoch 54/1000\n",
      "7240/7240 [==============================] - 0s 48us/sample - loss: 11.9331 - mae: 0.7891 - mse: 1.1076 - val_loss: 13.2957 - val_mae: 1.0921 - val_mse: 2.4242\n",
      "Epoch 55/1000\n",
      "7240/7240 [==============================] - 0s 51us/sample - loss: 11.9224 - mae: 0.7874 - mse: 1.1013 - val_loss: 13.8509 - val_mae: 1.0740 - val_mse: 2.3881\n",
      "Epoch 56/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.9238 - mae: 0.7868 - mse: 1.0984 - val_loss: 13.2127 - val_mae: 1.1648 - val_mse: 2.5882\n",
      "Epoch 57/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.9127 - mae: 0.7856 - mse: 1.0928 - val_loss: 13.3135 - val_mae: 1.1022 - val_mse: 2.4534\n",
      "Epoch 58/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.9116 - mae: 0.7819 - mse: 1.0909 - val_loss: 13.2300 - val_mae: 1.0764 - val_mse: 2.3794\n",
      "Epoch 59/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.8977 - mae: 0.7786 - mse: 1.0756 - val_loss: 13.7102 - val_mae: 1.0075 - val_mse: 2.1835\n",
      "Epoch 60/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 11.8994 - mae: 0.7772 - mse: 1.0776 - val_loss: 13.1538 - val_mae: 1.0474 - val_mse: 2.2680\n",
      "Epoch 61/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.8901 - mae: 0.7774 - mse: 1.0708 - val_loss: 13.1992 - val_mae: 1.0151 - val_mse: 2.1557\n",
      "Epoch 62/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.8883 - mae: 0.7772 - mse: 1.0689 - val_loss: 13.6176 - val_mae: 1.4848 - val_mse: 3.6781\n",
      "Epoch 63/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.8831 - mae: 0.7760 - mse: 1.0680 - val_loss: 13.3987 - val_mae: 1.3451 - val_mse: 3.1680\n",
      "Epoch 64/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.8797 - mae: 0.7732 - mse: 1.0615 - val_loss: 13.2908 - val_mae: 0.9770 - val_mse: 2.0691\n",
      "Epoch 65/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 11.8756 - mae: 0.7706 - mse: 1.0530 - val_loss: 13.1836 - val_mae: 1.1981 - val_mse: 2.6931\n",
      "Epoch 66/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.8680 - mae: 0.7703 - mse: 1.0494 - val_loss: 13.2140 - val_mae: 0.9798 - val_mse: 2.0762\n",
      "Epoch 67/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.8674 - mae: 0.7697 - mse: 1.0457 - val_loss: 13.3350 - val_mae: 0.9374 - val_mse: 1.9842\n",
      "Epoch 68/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.8585 - mae: 0.7667 - mse: 1.0375 - val_loss: 13.1016 - val_mae: 1.0764 - val_mse: 2.3424\n",
      "Epoch 69/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.8482 - mae: 0.7635 - mse: 1.0298 - val_loss: 13.2069 - val_mae: 1.0704 - val_mse: 2.3209\n",
      "Epoch 70/1000\n",
      "7240/7240 [==============================] - 0s 50us/sample - loss: 11.8498 - mae: 0.7638 - mse: 1.0294 - val_loss: 13.0731 - val_mae: 1.1566 - val_mse: 2.5580\n",
      "Epoch 71/1000\n",
      "7240/7240 [==============================] - 0s 51us/sample - loss: 11.8385 - mae: 0.7603 - mse: 1.0185 - val_loss: 14.6560 - val_mae: 1.0749 - val_mse: 2.3484\n",
      "Epoch 72/1000\n",
      "7240/7240 [==============================] - 0s 39us/sample - loss: 11.8329 - mae: 0.7583 - mse: 1.0091 - val_loss: 13.2057 - val_mae: 0.9233 - val_mse: 1.9294\n",
      "Epoch 73/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.8282 - mae: 0.7547 - mse: 1.0076 - val_loss: 13.0680 - val_mae: 1.0412 - val_mse: 2.2074\n",
      "Epoch 74/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.8346 - mae: 0.7600 - mse: 1.0159 - val_loss: 13.1259 - val_mae: 1.1987 - val_mse: 2.6744\n",
      "Epoch 75/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.8252 - mae: 0.7566 - mse: 1.0080 - val_loss: 13.1771 - val_mae: 0.9331 - val_mse: 1.9553\n",
      "Epoch 76/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.8141 - mae: 0.7508 - mse: 0.9928 - val_loss: 13.0768 - val_mae: 1.0656 - val_mse: 2.2875\n",
      "Epoch 77/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.8016 - mae: 0.7516 - mse: 0.9830 - val_loss: 13.0924 - val_mae: 1.1569 - val_mse: 2.5583\n",
      "Epoch 78/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.8067 - mae: 0.7490 - mse: 0.9876 - val_loss: 13.0119 - val_mae: 1.0640 - val_mse: 2.2592\n",
      "Epoch 79/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 11.8005 - mae: 0.7520 - mse: 0.9857 - val_loss: 13.2163 - val_mae: 0.9720 - val_mse: 2.0276\n",
      "Epoch 80/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.7953 - mae: 0.7473 - mse: 0.9755 - val_loss: 13.1672 - val_mae: 0.9868 - val_mse: 2.0771\n",
      "Epoch 81/1000\n",
      "7240/7240 [==============================] - 0s 39us/sample - loss: 11.7869 - mae: 0.7473 - mse: 0.9676 - val_loss: 13.9280 - val_mae: 0.9737 - val_mse: 2.0517\n",
      "Epoch 82/1000\n",
      "7240/7240 [==============================] - 1s 70us/sample - loss: 11.7888 - mae: 0.7457 - mse: 0.9653 - val_loss: 13.2766 - val_mae: 0.9013 - val_mse: 1.8534\n",
      "Epoch 83/1000\n",
      "7240/7240 [==============================] - 0s 42us/sample - loss: 11.7771 - mae: 0.7411 - mse: 0.9559 - val_loss: 13.0868 - val_mae: 1.1248 - val_mse: 2.4185\n",
      "Epoch 84/1000\n",
      "7240/7240 [==============================] - 0s 48us/sample - loss: 11.7775 - mae: 0.7422 - mse: 0.9590 - val_loss: 13.1062 - val_mae: 0.9639 - val_mse: 2.0093\n",
      "Epoch 85/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.7725 - mae: 0.7403 - mse: 0.9551 - val_loss: 13.5443 - val_mae: 0.8995 - val_mse: 1.8389\n",
      "Epoch 86/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.7689 - mae: 0.7380 - mse: 0.9470 - val_loss: 13.3558 - val_mae: 0.9818 - val_mse: 2.0618\n",
      "Epoch 87/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7240/7240 [==============================] - 0s 33us/sample - loss: 11.7655 - mae: 0.7405 - mse: 0.9462 - val_loss: 13.0159 - val_mae: 0.9837 - val_mse: 2.0419\n",
      "Epoch 88/1000\n",
      "7240/7240 [==============================] - 0s 66us/sample - loss: 11.7642 - mae: 0.7388 - mse: 0.9464 - val_loss: 13.0058 - val_mae: 1.0825 - val_mse: 2.3085\n",
      "Epoch 89/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.7556 - mae: 0.7378 - mse: 0.9388 - val_loss: 13.1131 - val_mae: 0.9325 - val_mse: 1.9087\n",
      "Epoch 90/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.7530 - mae: 0.7358 - mse: 0.9327 - val_loss: 13.1494 - val_mae: 0.9596 - val_mse: 1.9891\n",
      "Epoch 91/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.7463 - mae: 0.7326 - mse: 0.9280 - val_loss: 12.9338 - val_mae: 1.0407 - val_mse: 2.1333\n",
      "Epoch 92/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.7527 - mae: 0.7365 - mse: 0.9353 - val_loss: 13.0772 - val_mae: 1.1705 - val_mse: 2.5446\n",
      "Epoch 93/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 11.7414 - mae: 0.7319 - mse: 0.9263 - val_loss: 13.0210 - val_mae: 1.1969 - val_mse: 2.5425\n",
      "Epoch 94/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.7343 - mae: 0.7298 - mse: 0.9172 - val_loss: 13.0768 - val_mae: 1.1990 - val_mse: 2.6473\n",
      "Epoch 95/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.7343 - mae: 0.7286 - mse: 0.9177 - val_loss: 13.0166 - val_mae: 1.1540 - val_mse: 2.4575\n",
      "Epoch 96/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.7376 - mae: 0.7293 - mse: 0.9210 - val_loss: 13.2409 - val_mae: 0.9338 - val_mse: 1.9087\n",
      "Epoch 97/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 11.7246 - mae: 0.7251 - mse: 0.9074 - val_loss: 12.9909 - val_mae: 1.1531 - val_mse: 2.4600\n",
      "Epoch 98/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.7216 - mae: 0.7236 - mse: 0.9046 - val_loss: 13.1095 - val_mae: 1.1873 - val_mse: 2.5979\n",
      "Epoch 99/1000\n",
      "7240/7240 [==============================] - 0s 50us/sample - loss: 11.7219 - mae: 0.7261 - mse: 0.9071 - val_loss: 13.0602 - val_mae: 0.9646 - val_mse: 1.9541\n",
      "Epoch 100/1000\n",
      "7240/7240 [==============================] - 0s 54us/sample - loss: 11.7092 - mae: 0.7212 - mse: 0.8906 - val_loss: 13.0920 - val_mae: 1.1839 - val_mse: 2.4853\n",
      "Epoch 101/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.7234 - mae: 0.7258 - mse: 0.9070 - val_loss: 13.0201 - val_mae: 0.9867 - val_mse: 1.9961\n",
      "Epoch 102/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.7116 - mae: 0.7219 - mse: 0.8940 - val_loss: 13.1905 - val_mae: 0.9270 - val_mse: 1.9018\n",
      "Epoch 103/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 11.7077 - mae: 0.7190 - mse: 0.8897 - val_loss: 13.1500 - val_mae: 1.3040 - val_mse: 2.9229\n",
      "Epoch 104/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.7165 - mae: 0.7213 - mse: 0.9006 - val_loss: 13.0342 - val_mae: 0.9702 - val_mse: 1.9820\n",
      "Epoch 105/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.6986 - mae: 0.7146 - mse: 0.8800 - val_loss: 13.0019 - val_mae: 1.0225 - val_mse: 2.1153\n",
      "Epoch 106/1000\n",
      "7240/7240 [==============================] - 0s 38us/sample - loss: 11.7052 - mae: 0.7191 - mse: 0.8884 - val_loss: 12.9572 - val_mae: 0.9636 - val_mse: 1.9260\n",
      "Epoch 107/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6929 - mae: 0.7152 - mse: 0.8752 - val_loss: 12.9594 - val_mae: 1.0766 - val_mse: 2.2628\n",
      "Epoch 108/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.6947 - mae: 0.7176 - mse: 0.8789 - val_loss: 12.9321 - val_mae: 0.9946 - val_mse: 2.0066\n",
      "Epoch 109/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.6955 - mae: 0.7144 - mse: 0.8783 - val_loss: 13.0430 - val_mae: 0.9261 - val_mse: 1.8605\n",
      "Epoch 110/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6945 - mae: 0.7159 - mse: 0.8770 - val_loss: 13.1038 - val_mae: 1.2378 - val_mse: 2.7249\n",
      "Epoch 111/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.6897 - mae: 0.7133 - mse: 0.8742 - val_loss: 13.1861 - val_mae: 1.3360 - val_mse: 3.0467\n",
      "Epoch 112/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6850 - mae: 0.7129 - mse: 0.8714 - val_loss: 13.1622 - val_mae: 0.9264 - val_mse: 1.8797\n",
      "Epoch 113/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6846 - mae: 0.7120 - mse: 0.8682 - val_loss: 13.3390 - val_mae: 0.9065 - val_mse: 1.8433\n",
      "Epoch 114/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 11.6827 - mae: 0.7114 - mse: 0.8666 - val_loss: 13.0409 - val_mae: 1.1556 - val_mse: 2.4839\n",
      "Epoch 115/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6739 - mae: 0.7070 - mse: 0.8591 - val_loss: 13.1925 - val_mae: 0.8774 - val_mse: 1.7569\n",
      "Epoch 116/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6732 - mae: 0.7055 - mse: 0.8563 - val_loss: 12.9468 - val_mae: 0.9620 - val_mse: 1.9321\n",
      "Epoch 117/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6681 - mae: 0.7100 - mse: 0.8533 - val_loss: 13.1586 - val_mae: 0.8829 - val_mse: 1.7596\n",
      "Epoch 118/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6775 - mae: 0.7094 - mse: 0.8602 - val_loss: 13.1428 - val_mae: 0.9515 - val_mse: 1.9336\n",
      "Epoch 119/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6692 - mae: 0.7056 - mse: 0.8521 - val_loss: 13.3552 - val_mae: 0.9123 - val_mse: 1.8427\n",
      "Epoch 120/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.6732 - mae: 0.7088 - mse: 0.8572 - val_loss: 13.0140 - val_mae: 1.2395 - val_mse: 2.6522\n",
      "Epoch 121/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.6670 - mae: 0.7066 - mse: 0.8550 - val_loss: 13.2082 - val_mae: 0.8685 - val_mse: 1.7338\n",
      "Epoch 122/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6628 - mae: 0.7038 - mse: 0.8462 - val_loss: 13.1463 - val_mae: 1.1803 - val_mse: 2.5701\n",
      "Epoch 123/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6573 - mae: 0.7026 - mse: 0.8444 - val_loss: 13.7039 - val_mae: 0.8785 - val_mse: 1.7801\n",
      "Epoch 124/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6583 - mae: 0.7040 - mse: 0.8409 - val_loss: 13.0855 - val_mae: 0.8957 - val_mse: 1.7911\n",
      "Epoch 125/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6591 - mae: 0.7027 - mse: 0.8441 - val_loss: 12.9119 - val_mae: 1.0337 - val_mse: 2.0960\n",
      "Epoch 126/1000\n",
      "7240/7240 [==============================] - 0s 36us/sample - loss: 11.6567 - mae: 0.7030 - mse: 0.8432 - val_loss: 12.8878 - val_mae: 1.0601 - val_mse: 2.1401\n",
      "Epoch 127/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.6560 - mae: 0.7029 - mse: 0.8424 - val_loss: 12.9474 - val_mae: 1.0675 - val_mse: 2.2107\n",
      "Epoch 128/1000\n",
      "7240/7240 [==============================] - 0s 36us/sample - loss: 11.6508 - mae: 0.7029 - mse: 0.8383 - val_loss: 12.9354 - val_mae: 1.1270 - val_mse: 2.3355\n",
      "Epoch 129/1000\n",
      "7240/7240 [==============================] - 0s 38us/sample - loss: 11.6455 - mae: 0.6981 - mse: 0.8301 - val_loss: 13.1352 - val_mae: 1.3307 - val_mse: 2.9753\n",
      "Epoch 130/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6479 - mae: 0.7008 - mse: 0.8386 - val_loss: 12.9136 - val_mae: 1.0441 - val_mse: 2.1124\n",
      "Epoch 131/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.6447 - mae: 0.6984 - mse: 0.8317 - val_loss: 12.9226 - val_mae: 1.0086 - val_mse: 2.0086\n",
      "Epoch 132/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.6461 - mae: 0.6988 - mse: 0.8325 - val_loss: 13.1162 - val_mae: 0.9157 - val_mse: 1.8493\n",
      "Epoch 133/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 11.6439 - mae: 0.6977 - mse: 0.8311 - val_loss: 13.2533 - val_mae: 0.8793 - val_mse: 1.7720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6387 - mae: 0.6950 - mse: 0.8240 - val_loss: 13.3121 - val_mae: 0.9229 - val_mse: 1.8775\n",
      "Epoch 135/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.6361 - mae: 0.6968 - mse: 0.8229 - val_loss: 13.0003 - val_mae: 0.9526 - val_mse: 1.9039\n",
      "Epoch 136/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.6353 - mae: 0.6968 - mse: 0.8226 - val_loss: 12.9751 - val_mae: 0.9964 - val_mse: 1.9845\n",
      "Epoch 137/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6330 - mae: 0.6957 - mse: 0.8193 - val_loss: 12.8931 - val_mae: 1.1001 - val_mse: 2.2719\n",
      "Epoch 138/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.6321 - mae: 0.6949 - mse: 0.8211 - val_loss: 13.2590 - val_mae: 0.8830 - val_mse: 1.7782\n",
      "Epoch 139/1000\n",
      "7240/7240 [==============================] - 0s 35us/sample - loss: 11.6266 - mae: 0.6929 - mse: 0.8137 - val_loss: 13.6792 - val_mae: 0.9077 - val_mse: 1.8410\n",
      "Epoch 140/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6269 - mae: 0.6932 - mse: 0.8118 - val_loss: 13.0141 - val_mae: 0.9162 - val_mse: 1.8381\n",
      "Epoch 141/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6299 - mae: 0.6943 - mse: 0.8185 - val_loss: 12.9017 - val_mae: 1.0723 - val_mse: 2.1793\n",
      "Epoch 142/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6256 - mae: 0.6942 - mse: 0.8155 - val_loss: 12.9939 - val_mae: 0.9911 - val_mse: 1.9957\n",
      "Epoch 143/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6210 - mae: 0.6927 - mse: 0.8094 - val_loss: 12.9019 - val_mae: 1.1024 - val_mse: 2.2600\n",
      "Epoch 144/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6219 - mae: 0.6903 - mse: 0.8109 - val_loss: 13.8095 - val_mae: 0.8957 - val_mse: 1.8269\n",
      "Epoch 145/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6181 - mae: 0.6892 - mse: 0.8045 - val_loss: 12.9879 - val_mae: 1.2101 - val_mse: 2.5659\n",
      "Epoch 146/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6186 - mae: 0.6921 - mse: 0.8101 - val_loss: 12.9298 - val_mae: 1.0628 - val_mse: 2.1834\n",
      "Epoch 147/1000\n",
      "7240/7240 [==============================] - 0s 33us/sample - loss: 11.6131 - mae: 0.6885 - mse: 0.8026 - val_loss: 13.0371 - val_mae: 0.9123 - val_mse: 1.8226\n",
      "Epoch 148/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6151 - mae: 0.6893 - mse: 0.8028 - val_loss: 13.0811 - val_mae: 0.9569 - val_mse: 1.9403\n",
      "Epoch 149/1000\n",
      "7240/7240 [==============================] - 0s 34us/sample - loss: 11.6157 - mae: 0.6889 - mse: 0.8045 - val_loss: 13.3695 - val_mae: 0.8816 - val_mse: 1.7820\n",
      "Epoch 150/1000\n",
      "6816/7240 [===========================>..] - ETA: 0s - loss: 11.6103 - mae: 0.6893 - mse: 0.8035WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "7240/7240 [==============================] - 0s 31us/sample - loss: 11.6139 - mae: 0.6891 - mse: 0.8024\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-416731f5546d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Megallen 2.0/Working Directory/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_validation, y_validation)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             callbacks=self.callbacks, validation_data=(X_validation, y_validation))\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                   mode=ModeKeys.TEST):\n\u001b[1;32m    357\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0meval_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m                   eval_result = run_one_epoch(\n\u001b[1;32m    360\u001b[0m                       \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_training_eval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0;31m# Reset metrics on all the distributed (cloned) models.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mvariables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1711\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \"\"\"\n\u001b[0;32m-> 1713\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mweights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    968\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \"\"\"\n\u001b[0;32m--> 970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_trainable_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mtrainable_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    945\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0mnested\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather_children_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainable_weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dedup_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnested\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_gather_children_attribute\u001b[0;34m(self, attribute)\u001b[0m\n\u001b[1;32m   2331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_layers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2332\u001b[0m       nested_layers = trackable_layer_utils.filter_empty_layer_containers(\n\u001b[0;32m-> 2333\u001b[0;31m           self._layers)\n\u001b[0m\u001b[1;32m   2334\u001b[0m       return list(\n\u001b[1;32m   2335\u001b[0m           itertools.chain.from_iterable(\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mfilter_empty_layer_containers\u001b[0;34m(layer_list)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0mfiltered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"layers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m       \u001b[0;31m# Trackable data structures will not show up in \".layers\" lists, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0;31m# the layers they contain will.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/data_structures.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m     if (hasattr(type(self), name)\n\u001b[0m\u001b[1;32m    688\u001b[0m         and isinstance(getattr(type(self), name), property)):\n\u001b[1;32m    689\u001b[0m       \u001b[0;31m# Bypass ObjectProxy for properties. Whether this workaround is necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for f in range(1, 11, 1):\n",
    "    frac = f / 10.0\n",
    "    sample = data.sample(frac=frac, random_state=12345)\n",
    "    train, validation, test = train_validation_test_split(sample)\n",
    "\n",
    "    train.sort_values(\"time\", inplace=True)\n",
    "    validation.sort_values(\"time\", inplace=True)\n",
    "    test.sort_values(\"time\", inplace=True)\n",
    "\n",
    "    train_rolled = train.groupby(\"location\").rolling(15, min_periods=1).mean().reset_index()\n",
    "    validation_rolled = validation.groupby(\"location\").rolling(15, min_periods=1).mean().reset_index()\n",
    "    test_rolled = test.groupby(\"location\").rolling(15, min_periods=1).mean().reset_index()\n",
    "\n",
    "    train_imputed = train_rolled.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    train_imputed.fillna(0, inplace=True)\n",
    "    train_imputed.reset_index(inplace=True)\n",
    "\n",
    "    validation_imputed = validation_rolled.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    validation_imputed.fillna(0, inplace=True)\n",
    "    validation_imputed.reset_index(inplace=True)\n",
    "\n",
    "    test_imputed = test_rolled.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    test_imputed.fillna(0, inplace=True)\n",
    "    test_imputed.reset_index(inplace=True)\n",
    "\n",
    "    train_imputed[\"X\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "    train_imputed[\"Y\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])\n",
    "\n",
    "    validation_imputed[\"X\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "    validation_imputed[\"Y\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])\n",
    "\n",
    "    test_imputed[\"X\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "    test_imputed[\"Y\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])\n",
    "\n",
    "    X_train, y_train = train_imputed[scanners].values, train_imputed[[\"X\", \"Y\"]].values\n",
    "    X_validation, y_validation = validation_imputed[scanners].values, validation_imputed[[\"X\", \"Y\"]].values\n",
    "    X_test, y_test = test_imputed[scanners].values, test_imputed[[\"X\", \"Y\"]].values\n",
    "\n",
    "    model = MLP()\n",
    "\n",
    "    history = model.fit(X_train, y_train, X_validation, y_validation)\n",
    "    train_loss.append(history.history['loss'][-1])\n",
    "    val_loss.append(history.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "plt.plot(x, train_loss, label='Training loss')\n",
    "plt.plot(x, val_loss, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Dataset size\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Small_MLP_Regression_Rolling_FFill_MinMax.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
