{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width: 98% !important }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<style>.container { width: 98% !important }</style>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    parts = tf.strings.split(parts[-2], '-')\n",
    "    return [tf.strings.to_number(parts[-2]), tf.strings.to_number(parts[-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "    return tf.image.convert_image_dtype(img, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.list_files('../Data/train_images/*/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(32)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare_for_training(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.data.Dataset.list_files('../Data/test_images/*/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_ds.map(process_path, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_testing(ds, cache=True, shuffle_buffer_size=1000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(32)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = prepare_for_testing(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(17, 34, 1)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 15, 32, 32)        320       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 15360)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                983104    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 983,554\n",
      "Trainable params: 983,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1000 steps, validate for 250 steps\n",
      "Epoch 1/200\n",
      "1000/1000 [==============================] - 9s 9ms/step - loss: 6.5167 - mae: 1.6550 - mse: 6.5167 - val_loss: 4.0693 - val_mae: 1.5084 - val_mse: 4.0693\n",
      "Epoch 2/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 2.1691 - mae: 1.1457 - mse: 2.1691 - val_loss: 4.1255 - val_mae: 1.5598 - val_mse: 4.1255\n",
      "Epoch 3/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.9469 - mae: 1.0775 - mse: 1.9469 - val_loss: 4.3143 - val_mae: 1.6025 - val_mse: 4.3143\n",
      "Epoch 4/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 1.7627 - mae: 1.0183 - mse: 1.7627 - val_loss: 3.3610 - val_mae: 1.4075 - val_mse: 3.3610\n",
      "Epoch 5/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.4712 - mae: 0.9175 - mse: 1.4712 - val_loss: 3.5533 - val_mae: 1.5075 - val_mse: 3.5533\n",
      "Epoch 6/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.1740 - mae: 0.8110 - mse: 1.1740 - val_loss: 2.9110 - val_mae: 1.3697 - val_mse: 2.9110\n",
      "Epoch 7/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 1.0062 - mae: 0.7424 - mse: 1.0062 - val_loss: 2.6461 - val_mae: 1.2730 - val_mse: 2.6461\n",
      "Epoch 8/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.8855 - mae: 0.6870 - mse: 0.8855 - val_loss: 2.7276 - val_mae: 1.2905 - val_mse: 2.7276\n",
      "Epoch 9/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.8086 - mae: 0.6525 - mse: 0.8086 - val_loss: 2.9879 - val_mae: 1.3634 - val_mse: 2.9879\n",
      "Epoch 10/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.7217 - mae: 0.6094 - mse: 0.7217 - val_loss: 2.6833 - val_mae: 1.2890 - val_mse: 2.6833\n",
      "Epoch 11/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.6645 - mae: 0.5817 - mse: 0.6645 - val_loss: 2.6182 - val_mae: 1.2588 - val_mse: 2.6182\n",
      "Epoch 12/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.5930 - mae: 0.5496 - mse: 0.5930 - val_loss: 2.7447 - val_mae: 1.2963 - val_mse: 2.7447\n",
      "Epoch 13/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.5598 - mae: 0.5289 - mse: 0.5598 - val_loss: 2.8583 - val_mae: 1.3101 - val_mse: 2.8583\n",
      "Epoch 14/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.5308 - mae: 0.5149 - mse: 0.5308 - val_loss: 2.9249 - val_mae: 1.3328 - val_mse: 2.9249\n",
      "Epoch 15/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.4923 - mae: 0.4970 - mse: 0.4923 - val_loss: 2.7863 - val_mae: 1.2949 - val_mse: 2.7863\n",
      "Epoch 16/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.4566 - mae: 0.4755 - mse: 0.4566 - val_loss: 3.1694 - val_mae: 1.3436 - val_mse: 3.1694\n",
      "Epoch 17/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.4211 - mae: 0.4561 - mse: 0.4211 - val_loss: 2.8807 - val_mae: 1.3016 - val_mse: 2.8807\n",
      "Epoch 18/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3778 - mae: 0.4333 - mse: 0.3778 - val_loss: 2.7592 - val_mae: 1.2657 - val_mse: 2.7592\n",
      "Epoch 19/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3651 - mae: 0.4224 - mse: 0.3651 - val_loss: 2.8761 - val_mae: 1.2590 - val_mse: 2.8761\n",
      "Epoch 20/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3373 - mae: 0.4040 - mse: 0.3373 - val_loss: 2.7810 - val_mae: 1.2573 - val_mse: 2.7810\n",
      "Epoch 21/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3149 - mae: 0.3933 - mse: 0.3149 - val_loss: 2.7788 - val_mae: 1.2529 - val_mse: 2.7788\n",
      "Epoch 22/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.3113 - mae: 0.3854 - mse: 0.3113 - val_loss: 2.6829 - val_mae: 1.2482 - val_mse: 2.6829\n",
      "Epoch 23/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2960 - mae: 0.3785 - mse: 0.2960 - val_loss: 2.6647 - val_mae: 1.2423 - val_mse: 2.6647\n",
      "Epoch 24/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2722 - mae: 0.3611 - mse: 0.2722 - val_loss: 2.7594 - val_mae: 1.2482 - val_mse: 2.7594\n",
      "Epoch 25/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2720 - mae: 0.3555 - mse: 0.2720 - val_loss: 2.5328 - val_mae: 1.2131 - val_mse: 2.5328\n",
      "Epoch 26/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2571 - mae: 0.3469 - mse: 0.2571 - val_loss: 2.6431 - val_mae: 1.2250 - val_mse: 2.6431\n",
      "Epoch 27/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2516 - mae: 0.3441 - mse: 0.2516 - val_loss: 2.5988 - val_mae: 1.2039 - val_mse: 2.5988\n",
      "Epoch 28/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2494 - mae: 0.3382 - mse: 0.2494 - val_loss: 2.5126 - val_mae: 1.2022 - val_mse: 2.5126\n",
      "Epoch 29/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2313 - mae: 0.3267 - mse: 0.2313 - val_loss: 2.8945 - val_mae: 1.2632 - val_mse: 2.8945\n",
      "Epoch 30/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2270 - mae: 0.3248 - mse: 0.2270 - val_loss: 2.5996 - val_mae: 1.2088 - val_mse: 2.5996\n",
      "Epoch 31/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2246 - mae: 0.3168 - mse: 0.2246 - val_loss: 2.7092 - val_mae: 1.2333 - val_mse: 2.7092\n",
      "Epoch 32/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2063 - mae: 0.3104 - mse: 0.2063 - val_loss: 2.6661 - val_mae: 1.2307 - val_mse: 2.6661\n",
      "Epoch 33/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2180 - mae: 0.3095 - mse: 0.2180 - val_loss: 2.6503 - val_mae: 1.2181 - val_mse: 2.6503\n",
      "Epoch 34/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2085 - mae: 0.3053 - mse: 0.2085 - val_loss: 2.5890 - val_mae: 1.2230 - val_mse: 2.5890\n",
      "Epoch 35/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1942 - mae: 0.2968 - mse: 0.1942 - val_loss: 2.5242 - val_mae: 1.2004 - val_mse: 2.5242\n",
      "Epoch 36/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.2016 - mae: 0.2972 - mse: 0.2016 - val_loss: 2.5454 - val_mae: 1.1998 - val_mse: 2.5454\n",
      "Epoch 37/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1913 - mae: 0.2918 - mse: 0.1913 - val_loss: 2.8234 - val_mae: 1.2530 - val_mse: 2.8234\n",
      "Epoch 38/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1902 - mae: 0.2915 - mse: 0.1902 - val_loss: 2.6563 - val_mae: 1.2272 - val_mse: 2.6563\n",
      "Epoch 39/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1907 - mae: 0.2883 - mse: 0.1907 - val_loss: 2.7071 - val_mae: 1.2349 - val_mse: 2.7071\n",
      "Epoch 40/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1807 - mae: 0.2837 - mse: 0.1807 - val_loss: 2.5609 - val_mae: 1.1955 - val_mse: 2.5609\n",
      "Epoch 41/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1800 - mae: 0.2833 - mse: 0.1800 - val_loss: 2.5009 - val_mae: 1.1841 - val_mse: 2.5009\n",
      "Epoch 42/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1844 - mae: 0.2808 - mse: 0.1844 - val_loss: 2.6322 - val_mae: 1.2175 - val_mse: 2.6322\n",
      "Epoch 43/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1742 - mae: 0.2761 - mse: 0.1742 - val_loss: 2.5073 - val_mae: 1.1843 - val_mse: 2.5073\n",
      "Epoch 44/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1725 - mae: 0.2786 - mse: 0.1725 - val_loss: 2.5161 - val_mae: 1.1914 - val_mse: 2.5161\n",
      "Epoch 45/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1741 - mae: 0.2714 - mse: 0.1741 - val_loss: 2.5289 - val_mae: 1.1939 - val_mse: 2.5289\n",
      "Epoch 46/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1569 - mae: 0.2658 - mse: 0.1569 - val_loss: 2.5824 - val_mae: 1.2001 - val_mse: 2.5824\n",
      "Epoch 47/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1751 - mae: 0.2723 - mse: 0.1751 - val_loss: 2.6587 - val_mae: 1.2209 - val_mse: 2.6587\n",
      "Epoch 48/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1632 - mae: 0.2635 - mse: 0.1632 - val_loss: 2.6112 - val_mae: 1.2100 - val_mse: 2.6112\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1606 - mae: 0.2680 - mse: 0.1606 - val_loss: 2.5263 - val_mae: 1.1855 - val_mse: 2.5263\n",
      "Epoch 50/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1627 - mae: 0.2619 - mse: 0.1627 - val_loss: 2.5033 - val_mae: 1.1814 - val_mse: 2.5033\n",
      "Epoch 51/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1588 - mae: 0.2600 - mse: 0.1588 - val_loss: 2.5521 - val_mae: 1.1928 - val_mse: 2.5521\n",
      "Epoch 52/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1534 - mae: 0.2582 - mse: 0.1534 - val_loss: 2.5981 - val_mae: 1.2022 - val_mse: 2.5981\n",
      "Epoch 53/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1570 - mae: 0.2563 - mse: 0.1570 - val_loss: 2.4637 - val_mae: 1.1688 - val_mse: 2.4637\n",
      "Epoch 54/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1518 - mae: 0.2553 - mse: 0.1518 - val_loss: 2.5372 - val_mae: 1.1943 - val_mse: 2.5372\n",
      "Epoch 55/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1453 - mae: 0.2511 - mse: 0.1453 - val_loss: 2.4713 - val_mae: 1.1783 - val_mse: 2.4713\n",
      "Epoch 56/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1528 - mae: 0.2507 - mse: 0.1528 - val_loss: 2.5137 - val_mae: 1.1786 - val_mse: 2.5137\n",
      "Epoch 57/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1439 - mae: 0.2483 - mse: 0.1439 - val_loss: 2.5406 - val_mae: 1.1968 - val_mse: 2.5406\n",
      "Epoch 58/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1426 - mae: 0.2485 - mse: 0.1426 - val_loss: 2.4683 - val_mae: 1.1726 - val_mse: 2.4683\n",
      "Epoch 59/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1439 - mae: 0.2429 - mse: 0.1439 - val_loss: 2.5580 - val_mae: 1.1938 - val_mse: 2.5580\n",
      "Epoch 60/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1304 - mae: 0.2393 - mse: 0.1304 - val_loss: 2.5839 - val_mae: 1.1919 - val_mse: 2.5839\n",
      "Epoch 61/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1479 - mae: 0.2482 - mse: 0.1479 - val_loss: 2.6116 - val_mae: 1.1958 - val_mse: 2.6116\n",
      "Epoch 62/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1401 - mae: 0.2409 - mse: 0.1401 - val_loss: 2.5366 - val_mae: 1.1942 - val_mse: 2.5366\n",
      "Epoch 63/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1272 - mae: 0.2367 - mse: 0.1272 - val_loss: 2.5593 - val_mae: 1.1903 - val_mse: 2.5593\n",
      "Epoch 64/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1391 - mae: 0.2396 - mse: 0.1391 - val_loss: 2.5507 - val_mae: 1.1969 - val_mse: 2.5507\n",
      "Epoch 65/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1364 - mae: 0.2387 - mse: 0.1364 - val_loss: 2.5589 - val_mae: 1.1927 - val_mse: 2.5589\n",
      "Epoch 66/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1242 - mae: 0.2318 - mse: 0.1242 - val_loss: 2.5820 - val_mae: 1.1976 - val_mse: 2.5820\n",
      "Epoch 67/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1354 - mae: 0.2365 - mse: 0.1354 - val_loss: 2.5990 - val_mae: 1.2023 - val_mse: 2.5990\n",
      "Epoch 68/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1286 - mae: 0.2332 - mse: 0.1286 - val_loss: 2.6559 - val_mae: 1.2181 - val_mse: 2.6559\n",
      "Epoch 69/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1248 - mae: 0.2315 - mse: 0.1248 - val_loss: 2.6246 - val_mae: 1.2126 - val_mse: 2.6246\n",
      "Epoch 70/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1323 - mae: 0.2326 - mse: 0.1323 - val_loss: 2.5161 - val_mae: 1.1853 - val_mse: 2.5161\n",
      "Epoch 71/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1221 - mae: 0.2272 - mse: 0.1221 - val_loss: 2.7372 - val_mae: 1.2370 - val_mse: 2.7372\n",
      "Epoch 72/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1203 - mae: 0.2274 - mse: 0.1203 - val_loss: 2.5668 - val_mae: 1.2016 - val_mse: 2.5668\n",
      "Epoch 73/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1273 - mae: 0.2267 - mse: 0.1273 - val_loss: 2.6159 - val_mae: 1.1990 - val_mse: 2.6159\n",
      "Epoch 74/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1116 - mae: 0.2194 - mse: 0.1116 - val_loss: 2.7335 - val_mae: 1.2420 - val_mse: 2.7335\n",
      "Epoch 75/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1228 - mae: 0.2267 - mse: 0.1228 - val_loss: 2.5841 - val_mae: 1.1852 - val_mse: 2.5841\n",
      "Epoch 76/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1228 - mae: 0.2225 - mse: 0.1228 - val_loss: 2.5365 - val_mae: 1.1857 - val_mse: 2.5365\n",
      "Epoch 77/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1085 - mae: 0.2182 - mse: 0.1085 - val_loss: 2.5455 - val_mae: 1.1840 - val_mse: 2.5454\n",
      "Epoch 78/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1211 - mae: 0.2214 - mse: 0.1211 - val_loss: 2.5894 - val_mae: 1.1896 - val_mse: 2.5894\n",
      "Epoch 79/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1178 - mae: 0.2199 - mse: 0.1178 - val_loss: 2.6844 - val_mae: 1.2172 - val_mse: 2.6844\n",
      "Epoch 80/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1090 - mae: 0.2188 - mse: 0.1090 - val_loss: 2.5517 - val_mae: 1.1883 - val_mse: 2.5517\n",
      "Epoch 81/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1172 - mae: 0.2176 - mse: 0.1172 - val_loss: 2.7391 - val_mae: 1.2351 - val_mse: 2.7391\n",
      "Epoch 82/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1128 - mae: 0.2171 - mse: 0.1128 - val_loss: 2.6517 - val_mae: 1.2146 - val_mse: 2.6517\n",
      "Epoch 83/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1086 - mae: 0.2141 - mse: 0.1086 - val_loss: 2.5874 - val_mae: 1.2103 - val_mse: 2.5874\n",
      "Epoch 84/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1136 - mae: 0.2147 - mse: 0.1136 - val_loss: 2.6365 - val_mae: 1.2136 - val_mse: 2.6365\n",
      "Epoch 85/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1091 - mae: 0.2139 - mse: 0.1091 - val_loss: 2.7903 - val_mae: 1.2487 - val_mse: 2.7903\n",
      "Epoch 86/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1062 - mae: 0.2126 - mse: 0.1062 - val_loss: 2.5659 - val_mae: 1.1988 - val_mse: 2.5659\n",
      "Epoch 87/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1132 - mae: 0.2120 - mse: 0.1132 - val_loss: 2.6824 - val_mae: 1.2239 - val_mse: 2.6824\n",
      "Epoch 88/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1057 - mae: 0.2100 - mse: 0.1057 - val_loss: 2.9320 - val_mae: 1.2838 - val_mse: 2.9320\n",
      "Epoch 89/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1041 - mae: 0.2114 - mse: 0.1041 - val_loss: 2.6149 - val_mae: 1.2094 - val_mse: 2.6149\n",
      "Epoch 90/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1085 - mae: 0.2083 - mse: 0.1085 - val_loss: 2.8164 - val_mae: 1.2439 - val_mse: 2.8164\n",
      "Epoch 91/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0983 - mae: 0.2069 - mse: 0.0983 - val_loss: 2.6980 - val_mae: 1.2186 - val_mse: 2.6980\n",
      "Epoch 92/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1070 - mae: 0.2085 - mse: 0.1070 - val_loss: 2.7562 - val_mae: 1.2398 - val_mse: 2.7562\n",
      "Epoch 93/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1027 - mae: 0.2051 - mse: 0.1027 - val_loss: 2.8211 - val_mae: 1.2618 - val_mse: 2.8211\n",
      "Epoch 94/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0961 - mae: 0.2025 - mse: 0.0961 - val_loss: 2.5552 - val_mae: 1.1947 - val_mse: 2.5552\n",
      "Epoch 95/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1053 - mae: 0.2059 - mse: 0.1053 - val_loss: 2.7342 - val_mae: 1.2487 - val_mse: 2.7342\n",
      "Epoch 96/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.1006 - mae: 0.2047 - mse: 0.1006 - val_loss: 2.9035 - val_mae: 1.2689 - val_mse: 2.9035\n",
      "Epoch 97/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0967 - mae: 0.2009 - mse: 0.0967 - val_loss: 2.6795 - val_mae: 1.2256 - val_mse: 2.6795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1031 - mae: 0.2031 - mse: 0.1031 - val_loss: 2.7362 - val_mae: 1.2288 - val_mse: 2.7362\n",
      "Epoch 99/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0976 - mae: 0.2020 - mse: 0.0976 - val_loss: 2.9399 - val_mae: 1.2788 - val_mse: 2.9399\n",
      "Epoch 100/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0938 - mae: 0.1999 - mse: 0.0938 - val_loss: 2.8039 - val_mae: 1.2524 - val_mse: 2.8039\n",
      "Epoch 101/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1003 - mae: 0.1992 - mse: 0.1003 - val_loss: 2.6682 - val_mae: 1.2178 - val_mse: 2.6682\n",
      "Epoch 102/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0932 - mae: 0.1999 - mse: 0.0932 - val_loss: 2.7953 - val_mae: 1.2403 - val_mse: 2.7953\n",
      "Epoch 103/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0957 - mae: 0.1995 - mse: 0.0957 - val_loss: 2.7249 - val_mae: 1.2323 - val_mse: 2.7249\n",
      "Epoch 104/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.1002 - mae: 0.1997 - mse: 0.1002 - val_loss: 2.7229 - val_mae: 1.2518 - val_mse: 2.7229\n",
      "Epoch 105/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0877 - mae: 0.1971 - mse: 0.0877 - val_loss: 2.8049 - val_mae: 1.2484 - val_mse: 2.8049\n",
      "Epoch 106/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0994 - mae: 0.2008 - mse: 0.0994 - val_loss: 2.7234 - val_mae: 1.2259 - val_mse: 2.7234\n",
      "Epoch 107/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0942 - mae: 0.1959 - mse: 0.0942 - val_loss: 2.8694 - val_mae: 1.2688 - val_mse: 2.8694\n",
      "Epoch 108/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0879 - mae: 0.1933 - mse: 0.0879 - val_loss: 2.7146 - val_mae: 1.2376 - val_mse: 2.7146\n",
      "Epoch 109/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0994 - mae: 0.2005 - mse: 0.0994 - val_loss: 2.6795 - val_mae: 1.2288 - val_mse: 2.6795\n",
      "Epoch 110/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0904 - mae: 0.1913 - mse: 0.0904 - val_loss: 2.9603 - val_mae: 1.2900 - val_mse: 2.9603\n",
      "Epoch 111/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0892 - mae: 0.1945 - mse: 0.0892 - val_loss: 2.6954 - val_mae: 1.2273 - val_mse: 2.6954\n",
      "Epoch 112/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0956 - mae: 0.1951 - mse: 0.0956 - val_loss: 2.7144 - val_mae: 1.2461 - val_mse: 2.7144\n",
      "Epoch 113/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0899 - mae: 0.1925 - mse: 0.0899 - val_loss: 2.8960 - val_mae: 1.2632 - val_mse: 2.8960\n",
      "Epoch 114/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0859 - mae: 0.1911 - mse: 0.0859 - val_loss: 2.6674 - val_mae: 1.2394 - val_mse: 2.6674\n",
      "Epoch 115/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0960 - mae: 0.1933 - mse: 0.0960 - val_loss: 2.7262 - val_mae: 1.2384 - val_mse: 2.7262\n",
      "Epoch 116/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0871 - mae: 0.1913 - mse: 0.0871 - val_loss: 2.8800 - val_mae: 1.2630 - val_mse: 2.8800\n",
      "Epoch 117/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0885 - mae: 0.1949 - mse: 0.0885 - val_loss: 2.6126 - val_mae: 1.2243 - val_mse: 2.6126\n",
      "Epoch 118/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0934 - mae: 0.1914 - mse: 0.0934 - val_loss: 2.8113 - val_mae: 1.2428 - val_mse: 2.8113\n",
      "Epoch 119/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0805 - mae: 0.1849 - mse: 0.0805 - val_loss: 2.7596 - val_mae: 1.2355 - val_mse: 2.7596\n",
      "Epoch 120/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0891 - mae: 0.1914 - mse: 0.0891 - val_loss: 2.7179 - val_mae: 1.2217 - val_mse: 2.7179\n",
      "Epoch 121/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0891 - mae: 0.1879 - mse: 0.0891 - val_loss: 2.7681 - val_mae: 1.2393 - val_mse: 2.7681\n",
      "Epoch 122/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0807 - mae: 0.1892 - mse: 0.0807 - val_loss: 2.7627 - val_mae: 1.2389 - val_mse: 2.7627\n",
      "Epoch 123/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0926 - mae: 0.1920 - mse: 0.0926 - val_loss: 2.7017 - val_mae: 1.2134 - val_mse: 2.7017\n",
      "Epoch 124/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0855 - mae: 0.1857 - mse: 0.0855 - val_loss: 2.7617 - val_mae: 1.2401 - val_mse: 2.7617\n",
      "Epoch 125/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0803 - mae: 0.1857 - mse: 0.0803 - val_loss: 2.8388 - val_mae: 1.2576 - val_mse: 2.8388\n",
      "Epoch 126/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0878 - mae: 0.1868 - mse: 0.0878 - val_loss: 2.7745 - val_mae: 1.2457 - val_mse: 2.7745\n",
      "Epoch 127/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0850 - mae: 0.1868 - mse: 0.0850 - val_loss: 3.0402 - val_mae: 1.3250 - val_mse: 3.0402\n",
      "Epoch 128/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0803 - mae: 0.1832 - mse: 0.0803 - val_loss: 2.8254 - val_mae: 1.2612 - val_mse: 2.8254\n",
      "Epoch 129/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0884 - mae: 0.1872 - mse: 0.0884 - val_loss: 2.7949 - val_mae: 1.2464 - val_mse: 2.7949\n",
      "Epoch 130/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0797 - mae: 0.1818 - mse: 0.0797 - val_loss: 2.9084 - val_mae: 1.2779 - val_mse: 2.9084\n",
      "Epoch 131/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0801 - mae: 0.1840 - mse: 0.0801 - val_loss: 2.8040 - val_mae: 1.2496 - val_mse: 2.8040\n",
      "Epoch 132/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0884 - mae: 0.1852 - mse: 0.0884 - val_loss: 2.8832 - val_mae: 1.2720 - val_mse: 2.8832\n",
      "Epoch 133/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0768 - mae: 0.1812 - mse: 0.0768 - val_loss: 2.8710 - val_mae: 1.2592 - val_mse: 2.8710\n",
      "Epoch 134/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0815 - mae: 0.1830 - mse: 0.0815 - val_loss: 2.8582 - val_mae: 1.2535 - val_mse: 2.8582\n",
      "Epoch 135/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0838 - mae: 0.1825 - mse: 0.0838 - val_loss: 2.7704 - val_mae: 1.2318 - val_mse: 2.7704\n",
      "Epoch 136/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0763 - mae: 0.1843 - mse: 0.0763 - val_loss: 2.7341 - val_mae: 1.2327 - val_mse: 2.7341\n",
      "Epoch 137/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0851 - mae: 0.1831 - mse: 0.0851 - val_loss: 2.8489 - val_mae: 1.2667 - val_mse: 2.8489\n",
      "Epoch 138/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0807 - mae: 0.1799 - mse: 0.0807 - val_loss: 2.8302 - val_mae: 1.2529 - val_mse: 2.8302\n",
      "Epoch 139/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0726 - mae: 0.1755 - mse: 0.0726 - val_loss: 2.7769 - val_mae: 1.2427 - val_mse: 2.7769\n",
      "Epoch 140/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0865 - mae: 0.1867 - mse: 0.0865 - val_loss: 2.8782 - val_mae: 1.2752 - val_mse: 2.8782\n",
      "Epoch 141/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0798 - mae: 0.1807 - mse: 0.0798 - val_loss: 3.0116 - val_mae: 1.2903 - val_mse: 3.0116\n",
      "Epoch 142/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0750 - mae: 0.1766 - mse: 0.0750 - val_loss: 2.9778 - val_mae: 1.2946 - val_mse: 2.9778\n",
      "Epoch 143/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0846 - mae: 0.1846 - mse: 0.0846 - val_loss: 2.8236 - val_mae: 1.2552 - val_mse: 2.8236\n",
      "Epoch 144/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0775 - mae: 0.1799 - mse: 0.0775 - val_loss: 2.8962 - val_mae: 1.2663 - val_mse: 2.8962\n",
      "Epoch 145/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0756 - mae: 0.1779 - mse: 0.0756 - val_loss: 2.7925 - val_mae: 1.2455 - val_mse: 2.7925\n",
      "Epoch 146/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0832 - mae: 0.1800 - mse: 0.0832 - val_loss: 2.7552 - val_mae: 1.2423 - val_mse: 2.7552\n",
      "Epoch 147/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0775 - mae: 0.1792 - mse: 0.0775 - val_loss: 2.8796 - val_mae: 1.2688 - val_mse: 2.8796\n",
      "Epoch 148/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0740 - mae: 0.1767 - mse: 0.0740 - val_loss: 2.8576 - val_mae: 1.2633 - val_mse: 2.8576\n",
      "Epoch 149/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0806 - mae: 0.1773 - mse: 0.0806 - val_loss: 2.9855 - val_mae: 1.3005 - val_mse: 2.9855\n",
      "Epoch 150/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0688 - mae: 0.1726 - mse: 0.0688 - val_loss: 2.7919 - val_mae: 1.2381 - val_mse: 2.7919\n",
      "Epoch 151/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0796 - mae: 0.1785 - mse: 0.0796 - val_loss: 2.7236 - val_mae: 1.2300 - val_mse: 2.7236\n",
      "Epoch 152/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0764 - mae: 0.1751 - mse: 0.0764 - val_loss: 2.9394 - val_mae: 1.2753 - val_mse: 2.9394\n",
      "Epoch 153/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0698 - mae: 0.1714 - mse: 0.0698 - val_loss: 2.8356 - val_mae: 1.2562 - val_mse: 2.8356\n",
      "Epoch 154/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0835 - mae: 0.1800 - mse: 0.0835 - val_loss: 2.8818 - val_mae: 1.2780 - val_mse: 2.8818\n",
      "Epoch 155/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0748 - mae: 0.1738 - mse: 0.0748 - val_loss: 2.8913 - val_mae: 1.2730 - val_mse: 2.8913\n",
      "Epoch 156/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0715 - mae: 0.1732 - mse: 0.0715 - val_loss: 2.8183 - val_mae: 1.2578 - val_mse: 2.8183\n",
      "Epoch 157/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0791 - mae: 0.1758 - mse: 0.0791 - val_loss: 2.9204 - val_mae: 1.2786 - val_mse: 2.9204\n",
      "Epoch 158/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0730 - mae: 0.1723 - mse: 0.0730 - val_loss: 2.8533 - val_mae: 1.2524 - val_mse: 2.8533\n",
      "Epoch 159/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0711 - mae: 0.1747 - mse: 0.0711 - val_loss: 2.7952 - val_mae: 1.2659 - val_mse: 2.7952\n",
      "Epoch 160/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0785 - mae: 0.1751 - mse: 0.0785 - val_loss: 2.8491 - val_mae: 1.2588 - val_mse: 2.8491\n",
      "Epoch 161/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0723 - mae: 0.1737 - mse: 0.0723 - val_loss: 3.0348 - val_mae: 1.3141 - val_mse: 3.0348\n",
      "Epoch 162/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0709 - mae: 0.1718 - mse: 0.0709 - val_loss: 2.8508 - val_mae: 1.2642 - val_mse: 2.8508\n",
      "Epoch 163/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0797 - mae: 0.1782 - mse: 0.0797 - val_loss: 2.9714 - val_mae: 1.2921 - val_mse: 2.9714\n",
      "Epoch 164/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0677 - mae: 0.1683 - mse: 0.0677 - val_loss: 3.0582 - val_mae: 1.3090 - val_mse: 3.0582\n",
      "Epoch 165/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0723 - mae: 0.1718 - mse: 0.0723 - val_loss: 2.7481 - val_mae: 1.2312 - val_mse: 2.7481\n",
      "Epoch 166/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0749 - mae: 0.1713 - mse: 0.0749 - val_loss: 2.7272 - val_mae: 1.2374 - val_mse: 2.7272\n",
      "Epoch 167/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0628 - mae: 0.1649 - mse: 0.0628 - val_loss: 2.8299 - val_mae: 1.2532 - val_mse: 2.8299\n",
      "Epoch 168/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0771 - mae: 0.1739 - mse: 0.0771 - val_loss: 3.0133 - val_mae: 1.3038 - val_mse: 3.0133\n",
      "Epoch 169/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0751 - mae: 0.1739 - mse: 0.0751 - val_loss: 3.0251 - val_mae: 1.2994 - val_mse: 3.0251\n",
      "Epoch 170/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0639 - mae: 0.1635 - mse: 0.0639 - val_loss: 2.8422 - val_mae: 1.2529 - val_mse: 2.8422\n",
      "Epoch 171/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0753 - mae: 0.1726 - mse: 0.0753 - val_loss: 2.8305 - val_mae: 1.2612 - val_mse: 2.8305\n",
      "Epoch 172/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0699 - mae: 0.1680 - mse: 0.0699 - val_loss: 2.8548 - val_mae: 1.2505 - val_mse: 2.8548\n",
      "Epoch 173/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0651 - mae: 0.1664 - mse: 0.0651 - val_loss: 2.8383 - val_mae: 1.2597 - val_mse: 2.8383\n",
      "Epoch 174/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0753 - mae: 0.1700 - mse: 0.0753 - val_loss: 2.8881 - val_mae: 1.2714 - val_mse: 2.8881\n",
      "Epoch 175/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0677 - mae: 0.1657 - mse: 0.0677 - val_loss: 3.0243 - val_mae: 1.3020 - val_mse: 3.0243\n",
      "Epoch 176/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0677 - mae: 0.1696 - mse: 0.0677 - val_loss: 2.8310 - val_mae: 1.2618 - val_mse: 2.8310\n",
      "Epoch 177/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0749 - mae: 0.1691 - mse: 0.0749 - val_loss: 2.9857 - val_mae: 1.2827 - val_mse: 2.9857\n",
      "Epoch 178/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0659 - mae: 0.1646 - mse: 0.0659 - val_loss: 3.0361 - val_mae: 1.2961 - val_mse: 3.0361\n",
      "Epoch 179/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0664 - mae: 0.1664 - mse: 0.0664 - val_loss: 2.8720 - val_mae: 1.2560 - val_mse: 2.8720\n",
      "Epoch 180/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0756 - mae: 0.1719 - mse: 0.0756 - val_loss: 2.9804 - val_mae: 1.2857 - val_mse: 2.9804\n",
      "Epoch 181/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0607 - mae: 0.1623 - mse: 0.0607 - val_loss: 2.9053 - val_mae: 1.2686 - val_mse: 2.9053\n",
      "Epoch 182/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0733 - mae: 0.1702 - mse: 0.0733 - val_loss: 2.8040 - val_mae: 1.2501 - val_mse: 2.8040\n",
      "Epoch 183/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0693 - mae: 0.1661 - mse: 0.0693 - val_loss: 2.9151 - val_mae: 1.2728 - val_mse: 2.9151\n",
      "Epoch 184/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0613 - mae: 0.1611 - mse: 0.0613 - val_loss: 2.7868 - val_mae: 1.2533 - val_mse: 2.7868\n",
      "Epoch 185/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0714 - mae: 0.1672 - mse: 0.0714 - val_loss: 2.9049 - val_mae: 1.2821 - val_mse: 2.9049\n",
      "Epoch 186/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0675 - mae: 0.1648 - mse: 0.0675 - val_loss: 3.0104 - val_mae: 1.3010 - val_mse: 3.0104\n",
      "Epoch 187/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0622 - mae: 0.1612 - mse: 0.0622 - val_loss: 2.8678 - val_mae: 1.2637 - val_mse: 2.8678\n",
      "Epoch 188/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0707 - mae: 0.1675 - mse: 0.0707 - val_loss: 2.8207 - val_mae: 1.2625 - val_mse: 2.8207\n",
      "Epoch 189/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0644 - mae: 0.1621 - mse: 0.0644 - val_loss: 2.9747 - val_mae: 1.2848 - val_mse: 2.9747\n",
      "Epoch 190/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0627 - mae: 0.1617 - mse: 0.0627 - val_loss: 2.7779 - val_mae: 1.2467 - val_mse: 2.7779\n",
      "Epoch 191/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0713 - mae: 0.1651 - mse: 0.0713 - val_loss: 2.8683 - val_mae: 1.2630 - val_mse: 2.8683\n",
      "Epoch 192/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0620 - mae: 0.1604 - mse: 0.0620 - val_loss: 2.8773 - val_mae: 1.2788 - val_mse: 2.8773\n",
      "Epoch 193/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0638 - mae: 0.1630 - mse: 0.0638 - val_loss: 2.7747 - val_mae: 1.2412 - val_mse: 2.7747\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0701 - mae: 0.1657 - mse: 0.0701 - val_loss: 2.8404 - val_mae: 1.2537 - val_mse: 2.8404\n",
      "Epoch 195/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0580 - mae: 0.1575 - mse: 0.0580 - val_loss: 2.9736 - val_mae: 1.2997 - val_mse: 2.9736\n",
      "Epoch 196/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0676 - mae: 0.1625 - mse: 0.0676 - val_loss: 2.8142 - val_mae: 1.2485 - val_mse: 2.8142\n",
      "Epoch 197/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0672 - mae: 0.1640 - mse: 0.0672 - val_loss: 2.8450 - val_mae: 1.2625 - val_mse: 2.8450\n",
      "Epoch 198/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0603 - mae: 0.1602 - mse: 0.0603 - val_loss: 2.9268 - val_mae: 1.2908 - val_mse: 2.9268\n",
      "Epoch 199/200\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.0683 - mae: 0.1638 - mse: 0.0683 - val_loss: 2.9560 - val_mae: 1.2911 - val_mse: 2.9560\n",
      "Epoch 200/200\n",
      "1000/1000 [==============================] - 7s 7ms/step - loss: 0.0640 - mae: 0.1606 - mse: 0.0640 - val_loss: 2.8619 - val_mae: 1.2592 - val_mse: 2.8619\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mae', 'mse'])\n",
    "\n",
    "history = model.fit(train_ds, epochs=200, steps_per_epoch=1000, validation_data=test_ds, validation_steps=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
