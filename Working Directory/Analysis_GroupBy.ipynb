{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width: 98% !important }<style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width: 98% !important }<style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pin_file = \"../Data/pin.csv\"\n",
    "\n",
    "pin = read_pin(pin_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All beacons: ['0117C55D14E4']\n",
      "Selecting 0117C55D14E4\n"
     ]
    }
   ],
   "source": [
    "filename = \"../Data/rssi4.csv\"\n",
    "B1 = \"0117C55D14E4\"\n",
    "\n",
    "data = read_data(filename, B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[scanners] = minMaxScaling(data[scanners])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grouped = data.groupby([\"location\", pd.Grouper(key=\"time\", freq=\"1s\")]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Validation Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test = train_validation_test_split(data_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C400A2E19293</th>\n",
       "      <th>CD4533FFC0E1</th>\n",
       "      <th>D2B6503554D7</th>\n",
       "      <th>DB8B36A69C56</th>\n",
       "      <th>DD697EA75B68</th>\n",
       "      <th>DF231643E227</th>\n",
       "      <th>E13B805C6CB0</th>\n",
       "      <th>E43355CA8B96</th>\n",
       "      <th>E6D9D20DD197</th>\n",
       "      <th>E8FD0B453DC4</th>\n",
       "      <th>E96AF2C858BA</th>\n",
       "      <th>EC72840D9AD3</th>\n",
       "      <th>F1307ECB3B90</th>\n",
       "      <th>F1EDAF28E08A</th>\n",
       "      <th>F69A86823B96</th>\n",
       "      <th>FB2EE01C18CE</th>\n",
       "      <th>FDAE5980F28C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1_11</th>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>41</td>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>52</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_12</th>\n",
       "      <td>53</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>64</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>41</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_13</th>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_14</th>\n",
       "      <td>27</td>\n",
       "      <td>64</td>\n",
       "      <td>34</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "      <td>62</td>\n",
       "      <td>39</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_20</th>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_21</th>\n",
       "      <td>44</td>\n",
       "      <td>57</td>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>39</td>\n",
       "      <td>63</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_22</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>38</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>64</td>\n",
       "      <td>67</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>66</td>\n",
       "      <td>43</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>51</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_23</th>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>42</td>\n",
       "      <td>37</td>\n",
       "      <td>26</td>\n",
       "      <td>73</td>\n",
       "      <td>63</td>\n",
       "      <td>34</td>\n",
       "      <td>76</td>\n",
       "      <td>23</td>\n",
       "      <td>64</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_24</th>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>31</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_28</th>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>47</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_29</th>\n",
       "      <td>36</td>\n",
       "      <td>61</td>\n",
       "      <td>55</td>\n",
       "      <td>38</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>61</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>26</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_30</th>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>72</td>\n",
       "      <td>69</td>\n",
       "      <td>24</td>\n",
       "      <td>75</td>\n",
       "      <td>17</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_31</th>\n",
       "      <td>17</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>57</td>\n",
       "      <td>47</td>\n",
       "      <td>18</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1_32</th>\n",
       "      <td>27</td>\n",
       "      <td>52</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>28</td>\n",
       "      <td>72</td>\n",
       "      <td>17</td>\n",
       "      <td>69</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>58</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          C400A2E19293  CD4533FFC0E1  D2B6503554D7  DB8B36A69C56  \\\n",
       "location                                                           \n",
       "V1_11               37            46            38            48   \n",
       "V1_12               53            43            36            56   \n",
       "V1_13               39            55            37            50   \n",
       "V1_14               27            64            34            42   \n",
       "V1_20               61            58            56            53   \n",
       "V1_21               44            57            39            48   \n",
       "V1_22               45            45            38            46   \n",
       "V1_23               40            47            42            37   \n",
       "V1_24               16            37            39            34   \n",
       "V1_28               47            44            48            35   \n",
       "V1_29               36            61            55            38   \n",
       "V1_30               25            49            42            26   \n",
       "V1_31               17            39            32            38   \n",
       "V1_32               27            52            39            35   \n",
       "\n",
       "          DD697EA75B68  DF231643E227  E13B805C6CB0  E43355CA8B96  \\\n",
       "location                                                           \n",
       "V1_11               49            47            41            49   \n",
       "V1_12               53            52            35            37   \n",
       "V1_13               31            44            48            48   \n",
       "V1_14               37            49            62            39   \n",
       "V1_20               56            53            45            44   \n",
       "V1_21               54            48            58            39   \n",
       "V1_22               41            64            67            24   \n",
       "V1_23               26            73            63            34   \n",
       "V1_24               30            47            47            31   \n",
       "V1_28               46            38            43            41   \n",
       "V1_29               48            47            61            38   \n",
       "V1_30               42            72            69            24   \n",
       "V1_31               34            57            47            18   \n",
       "V1_32               36            60            62            28   \n",
       "\n",
       "          E6D9D20DD197  E8FD0B453DC4  E96AF2C858BA  EC72840D9AD3  \\\n",
       "location                                                           \n",
       "V1_11               45            31            38            52   \n",
       "V1_12               64            38            43            65   \n",
       "V1_13               67            11            31            50   \n",
       "V1_14               65             9            64            32   \n",
       "V1_20               47            25            40            51   \n",
       "V1_21               63            18            48            49   \n",
       "V1_22               64            24            66            43   \n",
       "V1_23               76            23            64            43   \n",
       "V1_24               64            15            56            33   \n",
       "V1_28               47            40            35            39   \n",
       "V1_29               57            26            49            42   \n",
       "V1_30               75            17            52            48   \n",
       "V1_31               59             6            67            35   \n",
       "V1_32               72            17            69            43   \n",
       "\n",
       "          F1307ECB3B90  F1EDAF28E08A  F69A86823B96  FB2EE01C18CE  FDAE5980F28C  \n",
       "location                                                                        \n",
       "V1_11               51            19            18            19            43  \n",
       "V1_12               64            41            53            40            44  \n",
       "V1_13               48            50            51            13            41  \n",
       "V1_14               49            40            52            41            46  \n",
       "V1_20               67            11            38            19            41  \n",
       "V1_21               43            41            41            37            39  \n",
       "V1_22               36             7            53            51            32  \n",
       "V1_23               48             7            59            55            31  \n",
       "V1_24               42            16            36            51            17  \n",
       "V1_28               34            47            37            24            45  \n",
       "V1_29               57            27            48            58            43  \n",
       "V1_30               34            15            40            56            43  \n",
       "V1_31               35             7            47            60            34  \n",
       "V1_32               32            11            35            58            52  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(\"location\")[scanners].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 19)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(\"time\", inplace=True)\n",
    "validation.sort_values(\"time\", inplace=True)\n",
    "test.sort_values(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "1. Forward fill\n",
    "2. Fill NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imputed = train.set_index(\"location\").groupby(\"location\").ffill()\n",
    "train_imputed.fillna(0, inplace=True)\n",
    "train_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_imputed = validation.set_index(\"location\").groupby(\"location\").ffill()\n",
    "validation_imputed.fillna(0, inplace=True)\n",
    "validation_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imputed = test.set_index(\"location\").groupby(\"location\").ffill()\n",
    "test_imputed.fillna(0, inplace=True)\n",
    "test_imputed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Location to Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imputed[\"X\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "train_imputed[\"Y\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_imputed[\"X\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "validation_imputed[\"Y\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imputed[\"X\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "test_imputed[\"Y\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_imputed[scanners].values, train_imputed[[\"X\", \"Y\"]].values\n",
    "X_validation, y_validation = validation_imputed[scanners].values, validation_imputed[[\"X\", \"Y\"]].values\n",
    "X_test, y_test = test_imputed[scanners].values, test_imputed[[\"X\", \"Y\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                576       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MLP(size='small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1030 samples, validate on 344 samples\n",
      "Epoch 1/1000\n",
      "1030/1030 [==============================] - 1s 593us/sample - loss: 276.9697 - mae: 14.9914 - mse: 276.9034 - val_loss: 262.9070 - val_mae: 14.6224 - val_mse: 262.8294\n",
      "Epoch 2/1000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 254.9735 - mae: 14.3669 - mse: 254.8685 - val_loss: 239.9541 - val_mae: 13.9325 - val_mse: 239.8114\n",
      "Epoch 3/1000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 229.5449 - mae: 13.5805 - mse: 229.3386 - val_loss: 213.6350 - val_mae: 13.0614 - val_mse: 213.3506\n",
      "Epoch 4/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 201.1832 - mae: 12.5923 - mse: 200.7761 - val_loss: 184.2776 - val_mae: 11.9637 - val_mse: 183.7294\n",
      "Epoch 5/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 169.8867 - mae: 11.3596 - mse: 169.1232 - val_loss: 152.7090 - val_mae: 10.6315 - val_mse: 151.7102\n",
      "Epoch 6/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 137.1507 - mae: 9.8708 - mse: 135.7932 - val_loss: 120.6376 - val_mae: 9.0371 - val_mse: 118.9125\n",
      "Epoch 7/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 105.6094 - mae: 8.1705 - mse: 103.3440 - val_loss: 91.6368 - val_mae: 7.3852 - val_mse: 88.8616\n",
      "Epoch 8/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 78.0248 - mae: 6.6254 - mse: 74.4940 - val_loss: 67.2441 - val_mae: 5.9113 - val_mse: 62.9992\n",
      "Epoch 9/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 57.2454 - mae: 5.3243 - mse: 52.0675 - val_loss: 50.7995 - val_mae: 4.9339 - val_mse: 44.8758\n",
      "Epoch 10/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 43.9429 - mae: 4.5898 - mse: 37.0473 - val_loss: 41.2946 - val_mae: 4.4218 - val_mse: 33.8453\n",
      "Epoch 11/1000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 36.8586 - mae: 4.1917 - mse: 28.4526 - val_loss: 37.1436 - val_mae: 4.1555 - val_mse: 28.5922\n",
      "Epoch 12/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 34.0172 - mae: 3.9675 - mse: 24.8036 - val_loss: 34.9505 - val_mae: 3.9953 - val_mse: 25.6877\n",
      "Epoch 13/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 32.2820 - mae: 3.8160 - mse: 22.6272 - val_loss: 33.4083 - val_mae: 3.8683 - val_mse: 24.1358\n",
      "Epoch 14/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 30.6935 - mae: 3.6818 - mse: 20.9792 - val_loss: 31.7385 - val_mae: 3.7176 - val_mse: 22.3565\n",
      "Epoch 15/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 29.0736 - mae: 3.5326 - mse: 19.2782 - val_loss: 30.1196 - val_mae: 3.5703 - val_mse: 20.6143\n",
      "Epoch 16/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 27.5704 - mae: 3.3892 - mse: 17.6749 - val_loss: 28.7068 - val_mae: 3.4491 - val_mse: 19.2521\n",
      "Epoch 17/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 26.1744 - mae: 3.2637 - mse: 16.2558 - val_loss: 27.3167 - val_mae: 3.3140 - val_mse: 17.8779\n",
      "Epoch 18/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 24.7307 - mae: 3.1163 - mse: 14.8024 - val_loss: 25.7652 - val_mae: 3.1691 - val_mse: 15.9025\n",
      "Epoch 19/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 23.3958 - mae: 2.9775 - mse: 13.3012 - val_loss: 24.5061 - val_mae: 3.0559 - val_mse: 14.8542\n",
      "Epoch 20/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 22.2233 - mae: 2.8627 - mse: 12.1978 - val_loss: 23.3752 - val_mae: 2.9119 - val_mse: 13.5274\n",
      "Epoch 21/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 21.0829 - mae: 2.7232 - mse: 10.9468 - val_loss: 22.2317 - val_mae: 2.7600 - val_mse: 12.1908\n",
      "Epoch 22/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 19.9953 - mae: 2.5783 - mse: 9.7374 - val_loss: 21.2994 - val_mae: 2.6531 - val_mse: 11.6229\n",
      "Epoch 23/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 19.0997 - mae: 2.4588 - mse: 8.8895 - val_loss: 20.4673 - val_mae: 2.5213 - val_mse: 10.7674\n",
      "Epoch 24/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 18.3418 - mae: 2.3410 - mse: 8.0808 - val_loss: 19.7800 - val_mae: 2.4153 - val_mse: 10.0075\n",
      "Epoch 25/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 17.7698 - mae: 2.2440 - mse: 7.4466 - val_loss: 19.2070 - val_mae: 2.3318 - val_mse: 9.2518\n",
      "Epoch 26/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 17.3218 - mae: 2.1656 - mse: 6.9500 - val_loss: 18.7695 - val_mae: 2.2349 - val_mse: 8.5187\n",
      "Epoch 27/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 17.0059 - mae: 2.0938 - mse: 6.5156 - val_loss: 18.5515 - val_mae: 2.2174 - val_mse: 8.5630\n",
      "Epoch 28/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 16.7858 - mae: 2.0568 - mse: 6.3082 - val_loss: 18.3585 - val_mae: 2.1916 - val_mse: 8.3922\n",
      "Epoch 29/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 16.6151 - mae: 2.0212 - mse: 6.1237 - val_loss: 18.1717 - val_mae: 2.1728 - val_mse: 8.1510\n",
      "Epoch 30/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 16.4983 - mae: 2.0042 - mse: 5.9957 - val_loss: 17.9968 - val_mae: 2.1372 - val_mse: 7.8554\n",
      "Epoch 31/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 16.3809 - mae: 1.9846 - mse: 5.8439 - val_loss: 17.8521 - val_mae: 2.0951 - val_mse: 7.6639\n",
      "Epoch 32/1000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 16.2730 - mae: 1.9538 - mse: 5.7017 - val_loss: 17.7881 - val_mae: 2.0981 - val_mse: 7.7403\n",
      "Epoch 33/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 16.1822 - mae: 1.9401 - mse: 5.6254 - val_loss: 17.5828 - val_mae: 2.0190 - val_mse: 7.1870\n",
      "Epoch 34/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 16.0784 - mae: 1.9222 - mse: 5.4858 - val_loss: 17.5046 - val_mae: 1.9978 - val_mse: 7.1437\n",
      "Epoch 35/1000\n",
      "1030/1030 [==============================] - 0s 57us/sample - loss: 16.0091 - mae: 1.8968 - mse: 5.3773 - val_loss: 17.5718 - val_mae: 2.1246 - val_mse: 7.7326\n",
      "Epoch 36/1000\n",
      "1030/1030 [==============================] - 0s 89us/sample - loss: 15.9246 - mae: 1.9045 - mse: 5.4068 - val_loss: 17.2736 - val_mae: 1.9492 - val_mse: 6.7098\n",
      "Epoch 37/1000\n",
      "1030/1030 [==============================] - 0s 75us/sample - loss: 15.8598 - mae: 1.8742 - mse: 5.2072 - val_loss: 17.2326 - val_mae: 2.0290 - val_mse: 7.1551\n",
      "Epoch 38/1000\n",
      "1030/1030 [==============================] - 0s 73us/sample - loss: 15.7655 - mae: 1.8658 - mse: 5.2002 - val_loss: 17.0462 - val_mae: 1.9275 - val_mse: 6.5326\n",
      "Epoch 39/1000\n",
      "1030/1030 [==============================] - 0s 78us/sample - loss: 15.6910 - mae: 1.8474 - mse: 5.0429 - val_loss: 16.9370 - val_mae: 1.9336 - val_mse: 6.5338\n",
      "Epoch 40/1000\n",
      "1030/1030 [==============================] - 0s 72us/sample - loss: 15.5952 - mae: 1.8319 - mse: 4.9401 - val_loss: 16.8551 - val_mae: 1.9259 - val_mse: 6.5471\n",
      "Epoch 41/1000\n",
      "1030/1030 [==============================] - 0s 71us/sample - loss: 15.5256 - mae: 1.8227 - mse: 4.9018 - val_loss: 16.7564 - val_mae: 1.8821 - val_mse: 6.3076\n",
      "Epoch 42/1000\n",
      "1030/1030 [==============================] - 0s 64us/sample - loss: 15.4561 - mae: 1.8020 - mse: 4.8144 - val_loss: 16.6977 - val_mae: 1.9139 - val_mse: 6.4738\n",
      "Epoch 43/1000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 15.3676 - mae: 1.7840 - mse: 4.7283 - val_loss: 16.5879 - val_mae: 1.9280 - val_mse: 6.4417\n",
      "Epoch 44/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 15.2774 - mae: 1.7773 - mse: 4.6711 - val_loss: 16.4274 - val_mae: 1.8459 - val_mse: 6.0186\n",
      "Epoch 45/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 15.1901 - mae: 1.7537 - mse: 4.5467 - val_loss: 16.3040 - val_mae: 1.8326 - val_mse: 5.8957\n",
      "Epoch 46/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 15.1067 - mae: 1.7341 - mse: 4.4362 - val_loss: 16.3480 - val_mae: 1.8948 - val_mse: 6.3121\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 46us/sample - loss: 15.0321 - mae: 1.7249 - mse: 4.4232 - val_loss: 16.1569 - val_mae: 1.8083 - val_mse: 5.8617\n",
      "Epoch 48/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 14.9525 - mae: 1.7017 - mse: 4.3047 - val_loss: 16.0475 - val_mae: 1.7740 - val_mse: 5.6768\n",
      "Epoch 49/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 14.8641 - mae: 1.6790 - mse: 4.1970 - val_loss: 15.9754 - val_mae: 1.8098 - val_mse: 5.7982\n",
      "Epoch 50/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 14.7961 - mae: 1.6675 - mse: 4.1353 - val_loss: 15.8887 - val_mae: 1.8107 - val_mse: 5.7427\n",
      "Epoch 51/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 14.7123 - mae: 1.6481 - mse: 4.0585 - val_loss: 15.7530 - val_mae: 1.7962 - val_mse: 5.5297\n",
      "Epoch 52/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 14.6297 - mae: 1.6326 - mse: 3.9584 - val_loss: 15.6284 - val_mae: 1.7219 - val_mse: 5.2665\n",
      "Epoch 53/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 14.5541 - mae: 1.6041 - mse: 3.8691 - val_loss: 15.5290 - val_mae: 1.6971 - val_mse: 5.1422\n",
      "Epoch 54/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 14.4801 - mae: 1.5877 - mse: 3.7901 - val_loss: 15.4905 - val_mae: 1.7089 - val_mse: 5.2495\n",
      "Epoch 55/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 14.4068 - mae: 1.5691 - mse: 3.7307 - val_loss: 15.3787 - val_mae: 1.6638 - val_mse: 5.0188\n",
      "Epoch 56/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 14.3299 - mae: 1.5487 - mse: 3.6304 - val_loss: 15.3165 - val_mae: 1.6741 - val_mse: 5.0664\n",
      "Epoch 57/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 14.2671 - mae: 1.5340 - mse: 3.5774 - val_loss: 15.2260 - val_mae: 1.5864 - val_mse: 4.7560\n",
      "Epoch 58/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 14.1909 - mae: 1.5083 - mse: 3.4798 - val_loss: 15.1729 - val_mae: 1.5580 - val_mse: 4.6734\n",
      "Epoch 59/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 14.1309 - mae: 1.4844 - mse: 3.4111 - val_loss: 15.0197 - val_mae: 1.5387 - val_mse: 4.3905\n",
      "Epoch 60/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 14.0677 - mae: 1.4686 - mse: 3.3175 - val_loss: 15.0150 - val_mae: 1.5768 - val_mse: 4.7038\n",
      "Epoch 61/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 13.9980 - mae: 1.4527 - mse: 3.2852 - val_loss: 14.9121 - val_mae: 1.5089 - val_mse: 4.4002\n",
      "Epoch 62/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 13.9426 - mae: 1.4329 - mse: 3.2090 - val_loss: 14.8426 - val_mae: 1.4732 - val_mse: 4.2116\n",
      "Epoch 63/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 13.9021 - mae: 1.4121 - mse: 3.1167 - val_loss: 14.7817 - val_mae: 1.5200 - val_mse: 4.4095\n",
      "Epoch 64/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 13.8465 - mae: 1.4038 - mse: 3.0895 - val_loss: 14.6983 - val_mae: 1.4773 - val_mse: 4.2137\n",
      "Epoch 65/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 13.7944 - mae: 1.3877 - mse: 3.0247 - val_loss: 14.7763 - val_mae: 1.5287 - val_mse: 4.5208\n",
      "Epoch 66/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 13.7654 - mae: 1.3771 - mse: 3.0178 - val_loss: 14.5399 - val_mae: 1.4449 - val_mse: 3.9555\n",
      "Epoch 67/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 13.7266 - mae: 1.3678 - mse: 2.9528 - val_loss: 14.5170 - val_mae: 1.4070 - val_mse: 3.8168\n",
      "Epoch 68/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 13.6962 - mae: 1.3505 - mse: 2.8847 - val_loss: 14.5645 - val_mae: 1.5111 - val_mse: 4.3037\n",
      "Epoch 69/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 13.6702 - mae: 1.3465 - mse: 2.8891 - val_loss: 14.5455 - val_mae: 1.5475 - val_mse: 4.3846\n",
      "Epoch 70/1000\n",
      "1030/1030 [==============================] - 0s 68us/sample - loss: 13.6431 - mae: 1.3541 - mse: 2.9110 - val_loss: 14.4870 - val_mae: 1.3940 - val_mse: 3.8509\n",
      "Epoch 71/1000\n",
      "1030/1030 [==============================] - 0s 67us/sample - loss: 13.6138 - mae: 1.3234 - mse: 2.7968 - val_loss: 14.3696 - val_mae: 1.4227 - val_mse: 3.8808\n",
      "Epoch 72/1000\n",
      "1030/1030 [==============================] - 0s 81us/sample - loss: 13.5795 - mae: 1.3201 - mse: 2.7850 - val_loss: 14.3321 - val_mae: 1.3479 - val_mse: 3.5599\n",
      "Epoch 73/1000\n",
      "1030/1030 [==============================] - 0s 90us/sample - loss: 13.5616 - mae: 1.3096 - mse: 2.7345 - val_loss: 14.2934 - val_mae: 1.3833 - val_mse: 3.7093\n",
      "Epoch 74/1000\n",
      "1030/1030 [==============================] - 0s 75us/sample - loss: 13.5347 - mae: 1.3031 - mse: 2.7109 - val_loss: 14.3771 - val_mae: 1.3994 - val_mse: 3.8180\n",
      "Epoch 75/1000\n",
      "1030/1030 [==============================] - 0s 84us/sample - loss: 13.5178 - mae: 1.2950 - mse: 2.6916 - val_loss: 14.2918 - val_mae: 1.3743 - val_mse: 3.6801\n",
      "Epoch 76/1000\n",
      "1030/1030 [==============================] - 0s 78us/sample - loss: 13.5019 - mae: 1.2926 - mse: 2.6766 - val_loss: 14.2871 - val_mae: 1.3702 - val_mse: 3.6597\n",
      "Epoch 77/1000\n",
      "1030/1030 [==============================] - 0s 83us/sample - loss: 13.4901 - mae: 1.2877 - mse: 2.6618 - val_loss: 14.2342 - val_mae: 1.3492 - val_mse: 3.5533\n",
      "Epoch 78/1000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 13.4695 - mae: 1.2772 - mse: 2.6106 - val_loss: 14.1758 - val_mae: 1.4247 - val_mse: 3.7862\n",
      "Epoch 79/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 13.4504 - mae: 1.2846 - mse: 2.6434 - val_loss: 14.1636 - val_mae: 1.2834 - val_mse: 3.2442\n",
      "Epoch 80/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 13.4391 - mae: 1.2612 - mse: 2.5558 - val_loss: 14.1410 - val_mae: 1.3708 - val_mse: 3.5928\n",
      "Epoch 81/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 13.4161 - mae: 1.2654 - mse: 2.5789 - val_loss: 14.0733 - val_mae: 1.3687 - val_mse: 3.5445\n",
      "Epoch 82/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 13.4117 - mae: 1.2683 - mse: 2.5799 - val_loss: 14.0432 - val_mae: 1.3026 - val_mse: 3.2799\n",
      "Epoch 83/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 13.4084 - mae: 1.2569 - mse: 2.5313 - val_loss: 14.1030 - val_mae: 1.4152 - val_mse: 3.7132\n",
      "Epoch 84/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 13.3860 - mae: 1.2621 - mse: 2.5537 - val_loss: 14.0106 - val_mae: 1.3222 - val_mse: 3.3519\n",
      "Epoch 85/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 13.3612 - mae: 1.2437 - mse: 2.4899 - val_loss: 14.1538 - val_mae: 1.4502 - val_mse: 3.8322\n",
      "Epoch 86/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 13.3709 - mae: 1.2533 - mse: 2.5252 - val_loss: 14.0033 - val_mae: 1.2991 - val_mse: 3.2575\n",
      "Epoch 87/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 13.3539 - mae: 1.2405 - mse: 2.4800 - val_loss: 13.9742 - val_mae: 1.3114 - val_mse: 3.2937\n",
      "Epoch 88/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 13.3412 - mae: 1.2414 - mse: 2.4809 - val_loss: 13.9900 - val_mae: 1.2720 - val_mse: 3.1449\n",
      "Epoch 89/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 13.3289 - mae: 1.2304 - mse: 2.4385 - val_loss: 13.9707 - val_mae: 1.3552 - val_mse: 3.4418\n",
      "Epoch 90/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 13.3121 - mae: 1.2325 - mse: 2.4344 - val_loss: 14.0265 - val_mae: 1.4060 - val_mse: 3.6254\n",
      "Epoch 91/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 13.3075 - mae: 1.2335 - mse: 2.4558 - val_loss: 13.8952 - val_mae: 1.3221 - val_mse: 3.2979\n",
      "Epoch 92/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 13.2951 - mae: 1.2289 - mse: 2.4328 - val_loss: 13.9436 - val_mae: 1.3665 - val_mse: 3.4595\n",
      "Epoch 93/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 13.2910 - mae: 1.2328 - mse: 2.4451 - val_loss: 13.9179 - val_mae: 1.3437 - val_mse: 3.3698\n",
      "Epoch 94/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 0s 45us/sample - loss: 13.2804 - mae: 1.2254 - mse: 2.4134 - val_loss: 13.8441 - val_mae: 1.2905 - val_mse: 3.1602\n",
      "Epoch 95/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 13.2737 - mae: 1.2186 - mse: 2.3902 - val_loss: 13.8448 - val_mae: 1.3173 - val_mse: 3.2519\n",
      "Epoch 96/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 13.2606 - mae: 1.2142 - mse: 2.3823 - val_loss: 13.8572 - val_mae: 1.2897 - val_mse: 3.1534\n",
      "Epoch 97/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 13.2439 - mae: 1.2103 - mse: 2.3644 - val_loss: 13.9404 - val_mae: 1.3750 - val_mse: 3.4593\n",
      "Epoch 98/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 13.2395 - mae: 1.2095 - mse: 2.3662 - val_loss: 13.8313 - val_mae: 1.3145 - val_mse: 3.2291\n",
      "Epoch 99/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 13.2277 - mae: 1.2084 - mse: 2.3450 - val_loss: 13.7940 - val_mae: 1.3075 - val_mse: 3.1936\n",
      "Epoch 100/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 13.2147 - mae: 1.1982 - mse: 2.3201 - val_loss: 13.9023 - val_mae: 1.4018 - val_mse: 3.5272\n",
      "Epoch 101/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 13.2138 - mae: 1.2067 - mse: 2.3518 - val_loss: 13.7688 - val_mae: 1.3010 - val_mse: 3.1541\n",
      "Epoch 102/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 13.2014 - mae: 1.1987 - mse: 2.3270 - val_loss: 13.7773 - val_mae: 1.2669 - val_mse: 3.0303\n",
      "Epoch 103/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 13.1976 - mae: 1.1934 - mse: 2.3014 - val_loss: 13.8227 - val_mae: 1.3892 - val_mse: 3.4523\n",
      "Epoch 104/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 13.1720 - mae: 1.1986 - mse: 2.3121 - val_loss: 13.7990 - val_mae: 1.2584 - val_mse: 2.9927\n",
      "Epoch 105/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 13.1847 - mae: 1.1905 - mse: 2.2904 - val_loss: 13.7424 - val_mae: 1.2691 - val_mse: 3.0205\n",
      "Epoch 106/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 13.1665 - mae: 1.1856 - mse: 2.2788 - val_loss: 13.6816 - val_mae: 1.2726 - val_mse: 3.0209\n",
      "Epoch 107/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 13.1646 - mae: 1.1845 - mse: 2.2742 - val_loss: 13.7678 - val_mae: 1.3566 - val_mse: 3.3125\n",
      "Epoch 108/1000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 13.1546 - mae: 1.1860 - mse: 2.2781 - val_loss: 13.6706 - val_mae: 1.2687 - val_mse: 2.9974\n",
      "Epoch 109/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 13.1450 - mae: 1.1807 - mse: 2.2581 - val_loss: 13.6951 - val_mae: 1.3397 - val_mse: 3.2401\n",
      "Epoch 110/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 13.1361 - mae: 1.1855 - mse: 2.2718 - val_loss: 13.6560 - val_mae: 1.2505 - val_mse: 2.9233\n",
      "Epoch 111/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 13.1291 - mae: 1.1704 - mse: 2.2220 - val_loss: 13.8466 - val_mae: 1.4364 - val_mse: 3.5744\n",
      "Epoch 112/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 13.1350 - mae: 1.1918 - mse: 2.2935 - val_loss: 13.6338 - val_mae: 1.2843 - val_mse: 3.0317\n",
      "Epoch 113/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 13.1170 - mae: 1.1689 - mse: 2.2173 - val_loss: 13.7025 - val_mae: 1.3652 - val_mse: 3.3088\n",
      "Epoch 114/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 13.1072 - mae: 1.1727 - mse: 2.2288 - val_loss: 13.6142 - val_mae: 1.2656 - val_mse: 2.9565\n",
      "Epoch 115/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 13.1079 - mae: 1.1692 - mse: 2.2149 - val_loss: 13.6054 - val_mae: 1.2136 - val_mse: 2.7763\n",
      "Epoch 116/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 13.1019 - mae: 1.1642 - mse: 2.2033 - val_loss: 13.6418 - val_mae: 1.1963 - val_mse: 2.7159\n",
      "Epoch 117/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 13.0956 - mae: 1.1570 - mse: 2.1796 - val_loss: 13.6063 - val_mae: 1.2687 - val_mse: 2.9524\n",
      "Epoch 118/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 13.0844 - mae: 1.1613 - mse: 2.1888 - val_loss: 13.5639 - val_mae: 1.2167 - val_mse: 2.7738\n",
      "Epoch 119/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 13.0786 - mae: 1.1542 - mse: 2.1580 - val_loss: 13.6867 - val_mae: 1.3891 - val_mse: 3.3631\n",
      "Epoch 120/1000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 13.0739 - mae: 1.1649 - mse: 2.2019 - val_loss: 13.5721 - val_mae: 1.2945 - val_mse: 3.0292\n",
      "Epoch 121/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 13.0684 - mae: 1.1525 - mse: 2.1578 - val_loss: 13.7158 - val_mae: 1.3790 - val_mse: 3.3198\n",
      "Epoch 122/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 13.0554 - mae: 1.1584 - mse: 2.1835 - val_loss: 13.5261 - val_mae: 1.2127 - val_mse: 2.7427\n",
      "Epoch 123/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 13.0556 - mae: 1.1473 - mse: 2.1389 - val_loss: 13.5466 - val_mae: 1.2209 - val_mse: 2.7654\n",
      "Epoch 124/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 13.0548 - mae: 1.1451 - mse: 2.1335 - val_loss: 13.5348 - val_mae: 1.2578 - val_mse: 2.8862\n",
      "Epoch 125/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 13.0429 - mae: 1.1459 - mse: 2.1350 - val_loss: 13.5082 - val_mae: 1.2649 - val_mse: 2.9121\n",
      "Epoch 126/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 13.0450 - mae: 1.1434 - mse: 2.1348 - val_loss: 13.5564 - val_mae: 1.2879 - val_mse: 2.9801\n",
      "Epoch 127/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 13.0293 - mae: 1.1462 - mse: 2.1416 - val_loss: 13.5084 - val_mae: 1.2478 - val_mse: 2.8393\n",
      "Epoch 128/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 13.0206 - mae: 1.1403 - mse: 2.1121 - val_loss: 13.5671 - val_mae: 1.3003 - val_mse: 3.0101\n",
      "Epoch 129/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 13.0165 - mae: 1.1432 - mse: 2.1184 - val_loss: 13.6292 - val_mae: 1.3209 - val_mse: 3.0788\n",
      "Epoch 130/1000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 13.0165 - mae: 1.1391 - mse: 2.1243 - val_loss: 13.4683 - val_mae: 1.2120 - val_mse: 2.7099\n",
      "Epoch 131/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 13.0106 - mae: 1.1334 - mse: 2.0934 - val_loss: 13.4876 - val_mae: 1.2529 - val_mse: 2.8423\n",
      "Epoch 132/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 13.0013 - mae: 1.1326 - mse: 2.0933 - val_loss: 13.4459 - val_mae: 1.2322 - val_mse: 2.7785\n",
      "Epoch 133/1000\n",
      "1030/1030 [==============================] - 0s 69us/sample - loss: 13.0010 - mae: 1.1338 - mse: 2.0957 - val_loss: 13.4598 - val_mae: 1.1808 - val_mse: 2.6007\n",
      "Epoch 134/1000\n",
      "1030/1030 [==============================] - 0s 71us/sample - loss: 12.9945 - mae: 1.1260 - mse: 2.0728 - val_loss: 13.4598 - val_mae: 1.2288 - val_mse: 2.7492\n",
      "Epoch 135/1000\n",
      "1030/1030 [==============================] - 0s 88us/sample - loss: 12.9901 - mae: 1.1325 - mse: 2.0921 - val_loss: 13.4734 - val_mae: 1.1904 - val_mse: 2.6250\n",
      "Epoch 136/1000\n",
      "1030/1030 [==============================] - 0s 77us/sample - loss: 12.9822 - mae: 1.1227 - mse: 2.0625 - val_loss: 13.4844 - val_mae: 1.2609 - val_mse: 2.8493\n",
      "Epoch 137/1000\n",
      "1030/1030 [==============================] - 0s 77us/sample - loss: 12.9775 - mae: 1.1278 - mse: 2.0791 - val_loss: 13.4218 - val_mae: 1.2180 - val_mse: 2.7082\n",
      "Epoch 138/1000\n",
      "1030/1030 [==============================] - 0s 76us/sample - loss: 12.9675 - mae: 1.1262 - mse: 2.0622 - val_loss: 13.5656 - val_mae: 1.2986 - val_mse: 2.9675\n",
      "Epoch 139/1000\n",
      "1030/1030 [==============================] - 0s 70us/sample - loss: 12.9682 - mae: 1.1249 - mse: 2.0664 - val_loss: 13.4351 - val_mae: 1.2848 - val_mse: 2.9261\n",
      "Epoch 140/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.9666 - mae: 1.1283 - mse: 2.0797 - val_loss: 13.4383 - val_mae: 1.1965 - val_mse: 2.6267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.9613 - mae: 1.1210 - mse: 2.0547 - val_loss: 13.3943 - val_mae: 1.1899 - val_mse: 2.6054\n",
      "Epoch 142/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.9515 - mae: 1.1174 - mse: 2.0429 - val_loss: 13.3919 - val_mae: 1.2220 - val_mse: 2.7069\n",
      "Epoch 143/1000\n",
      "1030/1030 [==============================] - 0s 60us/sample - loss: 12.9522 - mae: 1.1224 - mse: 2.0577 - val_loss: 13.4234 - val_mae: 1.1768 - val_mse: 2.5618\n",
      "Epoch 144/1000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 12.9496 - mae: 1.1102 - mse: 2.0265 - val_loss: 13.4399 - val_mae: 1.2485 - val_mse: 2.7849\n",
      "Epoch 145/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.9411 - mae: 1.1163 - mse: 2.0393 - val_loss: 13.3906 - val_mae: 1.1988 - val_mse: 2.6215\n",
      "Epoch 146/1000\n",
      "1030/1030 [==============================] - 0s 58us/sample - loss: 12.9361 - mae: 1.1110 - mse: 2.0229 - val_loss: 13.3673 - val_mae: 1.2324 - val_mse: 2.7327\n",
      "Epoch 147/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.9263 - mae: 1.1131 - mse: 2.0353 - val_loss: 13.4366 - val_mae: 1.1708 - val_mse: 2.5351\n",
      "Epoch 148/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.9278 - mae: 1.1048 - mse: 1.9957 - val_loss: 13.3950 - val_mae: 1.2765 - val_mse: 2.8717\n",
      "Epoch 149/1000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 12.9217 - mae: 1.1168 - mse: 2.0402 - val_loss: 13.3866 - val_mae: 1.1788 - val_mse: 2.5493\n",
      "Epoch 150/1000\n",
      "1030/1030 [==============================] - 0s 75us/sample - loss: 12.9150 - mae: 1.1062 - mse: 2.0066 - val_loss: 13.3434 - val_mae: 1.1849 - val_mse: 2.5670\n",
      "Epoch 151/1000\n",
      "1030/1030 [==============================] - 0s 71us/sample - loss: 12.9176 - mae: 1.0977 - mse: 1.9798 - val_loss: 13.3587 - val_mae: 1.2328 - val_mse: 2.7160\n",
      "Epoch 152/1000\n",
      "1030/1030 [==============================] - 0s 75us/sample - loss: 12.9133 - mae: 1.1042 - mse: 2.0031 - val_loss: 13.4059 - val_mae: 1.2686 - val_mse: 2.8279\n",
      "Epoch 153/1000\n",
      "1030/1030 [==============================] - 0s 72us/sample - loss: 12.9077 - mae: 1.1085 - mse: 2.0120 - val_loss: 13.3247 - val_mae: 1.2091 - val_mse: 2.6371\n",
      "Epoch 154/1000\n",
      "1030/1030 [==============================] - 0s 70us/sample - loss: 12.9058 - mae: 1.1029 - mse: 2.0009 - val_loss: 13.3284 - val_mae: 1.1969 - val_mse: 2.5927\n",
      "Epoch 155/1000\n",
      "1030/1030 [==============================] - 0s 73us/sample - loss: 12.9028 - mae: 1.1010 - mse: 1.9888 - val_loss: 13.3425 - val_mae: 1.2564 - val_mse: 2.7926\n",
      "Epoch 156/1000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 12.8982 - mae: 1.1010 - mse: 2.0016 - val_loss: 13.3055 - val_mae: 1.1918 - val_mse: 2.5767\n",
      "Epoch 157/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.8941 - mae: 1.0939 - mse: 1.9780 - val_loss: 13.3664 - val_mae: 1.1347 - val_mse: 2.4024\n",
      "Epoch 158/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.8908 - mae: 1.0897 - mse: 1.9543 - val_loss: 13.3168 - val_mae: 1.1876 - val_mse: 2.5554\n",
      "Epoch 159/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.8847 - mae: 1.0863 - mse: 1.9497 - val_loss: 13.3456 - val_mae: 1.2582 - val_mse: 2.7790\n",
      "Epoch 160/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.8838 - mae: 1.1024 - mse: 1.9954 - val_loss: 13.3030 - val_mae: 1.1409 - val_mse: 2.4153\n",
      "Epoch 161/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.8782 - mae: 1.0869 - mse: 1.9472 - val_loss: 13.3750 - val_mae: 1.2932 - val_mse: 2.8938\n",
      "Epoch 162/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.8739 - mae: 1.0951 - mse: 1.9753 - val_loss: 13.2905 - val_mae: 1.2207 - val_mse: 2.6685\n",
      "Epoch 163/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.8732 - mae: 1.0968 - mse: 1.9783 - val_loss: 13.3132 - val_mae: 1.1632 - val_mse: 2.4731\n",
      "Epoch 164/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.8632 - mae: 1.0856 - mse: 1.9492 - val_loss: 13.2725 - val_mae: 1.1854 - val_mse: 2.5457\n",
      "Epoch 165/1000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 12.8652 - mae: 1.0875 - mse: 1.9497 - val_loss: 13.2759 - val_mae: 1.1771 - val_mse: 2.5136\n",
      "Epoch 166/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.8599 - mae: 1.0897 - mse: 1.9627 - val_loss: 13.3894 - val_mae: 1.0736 - val_mse: 2.2015\n",
      "Epoch 167/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.8700 - mae: 1.0773 - mse: 1.9065 - val_loss: 13.2720 - val_mae: 1.2091 - val_mse: 2.6180\n",
      "Epoch 168/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.8566 - mae: 1.0894 - mse: 1.9591 - val_loss: 13.3262 - val_mae: 1.0925 - val_mse: 2.2638\n",
      "Epoch 169/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.8529 - mae: 1.0739 - mse: 1.9073 - val_loss: 13.2780 - val_mae: 1.1747 - val_mse: 2.4982\n",
      "Epoch 170/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.8566 - mae: 1.0855 - mse: 1.9486 - val_loss: 13.2640 - val_mae: 1.1321 - val_mse: 2.3738\n",
      "Epoch 171/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.8510 - mae: 1.0786 - mse: 1.9227 - val_loss: 13.2722 - val_mae: 1.1606 - val_mse: 2.4520\n",
      "Epoch 172/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.8415 - mae: 1.0759 - mse: 1.9106 - val_loss: 13.2738 - val_mae: 1.2087 - val_mse: 2.5958\n",
      "Epoch 173/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.8450 - mae: 1.0818 - mse: 1.9306 - val_loss: 13.2536 - val_mae: 1.1689 - val_mse: 2.4762\n",
      "Epoch 174/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.8401 - mae: 1.0784 - mse: 1.9271 - val_loss: 13.2679 - val_mae: 1.1858 - val_mse: 2.5227\n",
      "Epoch 175/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.8415 - mae: 1.0793 - mse: 1.9285 - val_loss: 13.2536 - val_mae: 1.1570 - val_mse: 2.4384\n",
      "Epoch 176/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.8310 - mae: 1.0728 - mse: 1.9059 - val_loss: 13.2454 - val_mae: 1.1189 - val_mse: 2.3298\n",
      "Epoch 177/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.8320 - mae: 1.0660 - mse: 1.8907 - val_loss: 13.2547 - val_mae: 1.2005 - val_mse: 2.5637\n",
      "Epoch 178/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.8243 - mae: 1.0717 - mse: 1.9041 - val_loss: 13.3413 - val_mae: 1.3141 - val_mse: 2.9419\n",
      "Epoch 179/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.8263 - mae: 1.0857 - mse: 1.9528 - val_loss: 13.2580 - val_mae: 1.1620 - val_mse: 2.4459\n",
      "Epoch 180/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.8220 - mae: 1.0719 - mse: 1.9023 - val_loss: 13.2488 - val_mae: 1.1595 - val_mse: 2.4365\n",
      "Epoch 181/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.8263 - mae: 1.0775 - mse: 1.9228 - val_loss: 13.2453 - val_mae: 1.1375 - val_mse: 2.3718\n",
      "Epoch 182/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.8127 - mae: 1.0651 - mse: 1.8799 - val_loss: 13.3752 - val_mae: 1.2962 - val_mse: 2.8600\n",
      "Epoch 183/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.8233 - mae: 1.0799 - mse: 1.9248 - val_loss: 13.2513 - val_mae: 1.1360 - val_mse: 2.3622\n",
      "Epoch 184/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.8154 - mae: 1.0646 - mse: 1.8833 - val_loss: 13.2512 - val_mae: 1.1612 - val_mse: 2.4362\n",
      "Epoch 185/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.8094 - mae: 1.0636 - mse: 1.8804 - val_loss: 13.3378 - val_mae: 1.2912 - val_mse: 2.8417\n",
      "Epoch 186/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.8127 - mae: 1.0749 - mse: 1.9162 - val_loss: 13.2899 - val_mae: 1.2242 - val_mse: 2.6230\n",
      "Epoch 187/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.8057 - mae: 1.0681 - mse: 1.8879 - val_loss: 13.2749 - val_mae: 1.2765 - val_mse: 2.8063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.8024 - mae: 1.0730 - mse: 1.9166 - val_loss: 13.2416 - val_mae: 1.1359 - val_mse: 2.3569\n",
      "Epoch 189/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.7985 - mae: 1.0608 - mse: 1.8747 - val_loss: 13.2056 - val_mae: 1.1379 - val_mse: 2.3682\n",
      "Epoch 190/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.7986 - mae: 1.0654 - mse: 1.8870 - val_loss: 13.2474 - val_mae: 1.1209 - val_mse: 2.3118\n",
      "Epoch 191/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.7956 - mae: 1.0597 - mse: 1.8703 - val_loss: 13.2213 - val_mae: 1.1518 - val_mse: 2.4023\n",
      "Epoch 192/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.7921 - mae: 1.0612 - mse: 1.8707 - val_loss: 13.2007 - val_mae: 1.1683 - val_mse: 2.4517\n",
      "Epoch 193/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.7903 - mae: 1.0639 - mse: 1.8736 - val_loss: 13.1967 - val_mae: 1.2033 - val_mse: 2.5686\n",
      "Epoch 194/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.7903 - mae: 1.0681 - mse: 1.9018 - val_loss: 13.1934 - val_mae: 1.1152 - val_mse: 2.2983\n",
      "Epoch 195/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.7827 - mae: 1.0588 - mse: 1.8578 - val_loss: 13.2025 - val_mae: 1.1904 - val_mse: 2.5141\n",
      "Epoch 196/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7822 - mae: 1.0595 - mse: 1.8690 - val_loss: 13.2359 - val_mae: 1.2444 - val_mse: 2.6908\n",
      "Epoch 197/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.7787 - mae: 1.0633 - mse: 1.8763 - val_loss: 13.2403 - val_mae: 1.2258 - val_mse: 2.6198\n",
      "Epoch 198/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.7781 - mae: 1.0614 - mse: 1.8733 - val_loss: 13.2311 - val_mae: 1.1123 - val_mse: 2.2762\n",
      "Epoch 199/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.7768 - mae: 1.0508 - mse: 1.8339 - val_loss: 13.2658 - val_mae: 1.2622 - val_mse: 2.7384\n",
      "Epoch 200/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.7749 - mae: 1.0678 - mse: 1.8944 - val_loss: 13.2712 - val_mae: 1.0871 - val_mse: 2.1976\n",
      "Epoch 201/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.7705 - mae: 1.0461 - mse: 1.8328 - val_loss: 13.2783 - val_mae: 1.2196 - val_mse: 2.5949\n",
      "Epoch 202/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.7766 - mae: 1.0584 - mse: 1.8667 - val_loss: 13.2064 - val_mae: 1.1553 - val_mse: 2.4021\n",
      "Epoch 203/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7701 - mae: 1.0502 - mse: 1.8400 - val_loss: 13.2671 - val_mae: 1.2004 - val_mse: 2.5366\n",
      "Epoch 204/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.7658 - mae: 1.0518 - mse: 1.8373 - val_loss: 13.2593 - val_mae: 1.2605 - val_mse: 2.7323\n",
      "Epoch 205/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.7654 - mae: 1.0603 - mse: 1.8722 - val_loss: 13.1669 - val_mae: 1.1644 - val_mse: 2.4378\n",
      "Epoch 206/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7709 - mae: 1.0577 - mse: 1.8732 - val_loss: 13.1787 - val_mae: 1.1400 - val_mse: 2.3554\n",
      "Epoch 207/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.7668 - mae: 1.0521 - mse: 1.8491 - val_loss: 13.1752 - val_mae: 1.1643 - val_mse: 2.4261\n",
      "Epoch 208/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7598 - mae: 1.0522 - mse: 1.8451 - val_loss: 13.2284 - val_mae: 1.2428 - val_mse: 2.6710\n",
      "Epoch 209/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7622 - mae: 1.0646 - mse: 1.8832 - val_loss: 13.1644 - val_mae: 1.1461 - val_mse: 2.3764\n",
      "Epoch 210/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.7564 - mae: 1.0484 - mse: 1.8379 - val_loss: 13.1904 - val_mae: 1.2015 - val_mse: 2.5412\n",
      "Epoch 211/1000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 12.7566 - mae: 1.0528 - mse: 1.8507 - val_loss: 13.1873 - val_mae: 1.1925 - val_mse: 2.5089\n",
      "Epoch 212/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.7496 - mae: 1.0536 - mse: 1.8531 - val_loss: 13.2007 - val_mae: 1.1058 - val_mse: 2.2520\n",
      "Epoch 213/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7511 - mae: 1.0497 - mse: 1.8300 - val_loss: 13.1945 - val_mae: 1.1752 - val_mse: 2.4525\n",
      "Epoch 214/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.7432 - mae: 1.0445 - mse: 1.8273 - val_loss: 13.1837 - val_mae: 1.2201 - val_mse: 2.5994\n",
      "Epoch 215/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7447 - mae: 1.0539 - mse: 1.8554 - val_loss: 13.1815 - val_mae: 1.1543 - val_mse: 2.3891\n",
      "Epoch 216/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.7454 - mae: 1.0492 - mse: 1.8303 - val_loss: 13.1859 - val_mae: 1.1147 - val_mse: 2.2748\n",
      "Epoch 217/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.7418 - mae: 1.0437 - mse: 1.8181 - val_loss: 13.1872 - val_mae: 1.1168 - val_mse: 2.2803\n",
      "Epoch 218/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.7420 - mae: 1.0425 - mse: 1.8145 - val_loss: 13.2006 - val_mae: 1.1590 - val_mse: 2.4022\n",
      "Epoch 219/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7385 - mae: 1.0441 - mse: 1.8158 - val_loss: 13.1712 - val_mae: 1.2058 - val_mse: 2.5576\n",
      "Epoch 220/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.7355 - mae: 1.0490 - mse: 1.8363 - val_loss: 13.1559 - val_mae: 1.1725 - val_mse: 2.4488\n",
      "Epoch 221/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7314 - mae: 1.0421 - mse: 1.8160 - val_loss: 13.1681 - val_mae: 1.1934 - val_mse: 2.5114\n",
      "Epoch 222/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.7393 - mae: 1.0506 - mse: 1.8442 - val_loss: 13.1847 - val_mae: 1.0894 - val_mse: 2.2021\n",
      "Epoch 223/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7364 - mae: 1.0377 - mse: 1.8053 - val_loss: 13.1698 - val_mae: 1.1086 - val_mse: 2.2562\n",
      "Epoch 224/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7324 - mae: 1.0409 - mse: 1.8123 - val_loss: 13.1592 - val_mae: 1.1256 - val_mse: 2.3045\n",
      "Epoch 225/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.7235 - mae: 1.0430 - mse: 1.8173 - val_loss: 13.1651 - val_mae: 1.0858 - val_mse: 2.1968\n",
      "Epoch 226/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.7305 - mae: 1.0415 - mse: 1.8136 - val_loss: 13.2180 - val_mae: 1.1203 - val_mse: 2.2849\n",
      "Epoch 227/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7152 - mae: 1.0360 - mse: 1.7962 - val_loss: 13.2115 - val_mae: 1.0502 - val_mse: 2.0975\n",
      "Epoch 228/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.7235 - mae: 1.0328 - mse: 1.7918 - val_loss: 13.1341 - val_mae: 1.1189 - val_mse: 2.2912\n",
      "Epoch 229/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.7225 - mae: 1.0411 - mse: 1.8255 - val_loss: 13.2074 - val_mae: 1.1131 - val_mse: 2.2602\n",
      "Epoch 230/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.7211 - mae: 1.0418 - mse: 1.8094 - val_loss: 13.1690 - val_mae: 1.1138 - val_mse: 2.2649\n",
      "Epoch 231/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.7183 - mae: 1.0387 - mse: 1.8001 - val_loss: 13.1239 - val_mae: 1.1228 - val_mse: 2.2983\n",
      "Epoch 232/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.7190 - mae: 1.0405 - mse: 1.8126 - val_loss: 13.1374 - val_mae: 1.1892 - val_mse: 2.4951\n",
      "Epoch 233/1000\n",
      "1030/1030 [==============================] - 0s 37us/sample - loss: 12.7166 - mae: 1.0439 - mse: 1.8219 - val_loss: 13.1553 - val_mae: 1.2055 - val_mse: 2.5402\n",
      "Epoch 234/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.7119 - mae: 1.0413 - mse: 1.8114 - val_loss: 13.1716 - val_mae: 1.2473 - val_mse: 2.6888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7190 - mae: 1.0481 - mse: 1.8368 - val_loss: 13.1947 - val_mae: 1.2219 - val_mse: 2.5857\n",
      "Epoch 236/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.7038 - mae: 1.0450 - mse: 1.8287 - val_loss: 13.2298 - val_mae: 1.0441 - val_mse: 2.0687\n",
      "Epoch 237/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7089 - mae: 1.0294 - mse: 1.7764 - val_loss: 13.1191 - val_mae: 1.1034 - val_mse: 2.2469\n",
      "Epoch 238/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.7095 - mae: 1.0351 - mse: 1.7989 - val_loss: 13.1359 - val_mae: 1.1956 - val_mse: 2.5152\n",
      "Epoch 239/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.7085 - mae: 1.0438 - mse: 1.8269 - val_loss: 13.1216 - val_mae: 1.1030 - val_mse: 2.2437\n",
      "Epoch 240/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7042 - mae: 1.0317 - mse: 1.7854 - val_loss: 13.1273 - val_mae: 1.1367 - val_mse: 2.3342\n",
      "Epoch 241/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7013 - mae: 1.0345 - mse: 1.7957 - val_loss: 13.1310 - val_mae: 1.2017 - val_mse: 2.5375\n",
      "Epoch 242/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.7009 - mae: 1.0412 - mse: 1.8121 - val_loss: 13.1686 - val_mae: 1.2047 - val_mse: 2.5324\n",
      "Epoch 243/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6965 - mae: 1.0436 - mse: 1.8143 - val_loss: 13.1144 - val_mae: 1.1261 - val_mse: 2.3037\n",
      "Epoch 244/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6940 - mae: 1.0301 - mse: 1.7778 - val_loss: 13.1850 - val_mae: 1.2441 - val_mse: 2.6578\n",
      "Epoch 245/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6991 - mae: 1.0389 - mse: 1.8088 - val_loss: 13.2105 - val_mae: 1.1581 - val_mse: 2.3833\n",
      "Epoch 246/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6934 - mae: 1.0284 - mse: 1.7817 - val_loss: 13.1583 - val_mae: 1.2264 - val_mse: 2.6061\n",
      "Epoch 247/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6937 - mae: 1.0385 - mse: 1.8059 - val_loss: 13.1663 - val_mae: 1.1810 - val_mse: 2.4536\n",
      "Epoch 248/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6897 - mae: 1.0326 - mse: 1.7926 - val_loss: 13.1366 - val_mae: 1.2197 - val_mse: 2.5995\n",
      "Epoch 249/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6889 - mae: 1.0376 - mse: 1.8084 - val_loss: 13.1077 - val_mae: 1.1515 - val_mse: 2.3746\n",
      "Epoch 250/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6879 - mae: 1.0348 - mse: 1.7901 - val_loss: 13.1354 - val_mae: 1.1815 - val_mse: 2.4594\n",
      "Epoch 251/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.6930 - mae: 1.0362 - mse: 1.7997 - val_loss: 13.1634 - val_mae: 1.2367 - val_mse: 2.6335\n",
      "Epoch 252/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6860 - mae: 1.0452 - mse: 1.8230 - val_loss: 13.1814 - val_mae: 1.0631 - val_mse: 2.1131\n",
      "Epoch 253/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6867 - mae: 1.0250 - mse: 1.7605 - val_loss: 13.1477 - val_mae: 1.2209 - val_mse: 2.5859\n",
      "Epoch 254/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.6821 - mae: 1.0361 - mse: 1.7947 - val_loss: 13.1231 - val_mae: 1.1213 - val_mse: 2.2804\n",
      "Epoch 255/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6824 - mae: 1.0283 - mse: 1.7695 - val_loss: 13.0974 - val_mae: 1.1536 - val_mse: 2.3815\n",
      "Epoch 256/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.6775 - mae: 1.0285 - mse: 1.7705 - val_loss: 13.1804 - val_mae: 1.2695 - val_mse: 2.7426\n",
      "Epoch 257/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6830 - mae: 1.0400 - mse: 1.8088 - val_loss: 13.0940 - val_mae: 1.1716 - val_mse: 2.4474\n",
      "Epoch 258/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6787 - mae: 1.0325 - mse: 1.7905 - val_loss: 13.1165 - val_mae: 1.2049 - val_mse: 2.5454\n",
      "Epoch 259/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.6777 - mae: 1.0321 - mse: 1.7892 - val_loss: 13.1749 - val_mae: 1.2531 - val_mse: 2.6825\n",
      "Epoch 260/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6726 - mae: 1.0365 - mse: 1.7968 - val_loss: 13.1075 - val_mae: 1.1193 - val_mse: 2.2732\n",
      "Epoch 261/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6749 - mae: 1.0297 - mse: 1.7702 - val_loss: 13.0799 - val_mae: 1.1281 - val_mse: 2.3177\n",
      "Epoch 262/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6712 - mae: 1.0302 - mse: 1.7783 - val_loss: 13.0984 - val_mae: 1.1907 - val_mse: 2.5016\n",
      "Epoch 263/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.6716 - mae: 1.0312 - mse: 1.7898 - val_loss: 13.0924 - val_mae: 1.1594 - val_mse: 2.3968\n",
      "Epoch 264/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6673 - mae: 1.0287 - mse: 1.7746 - val_loss: 13.1999 - val_mae: 1.1830 - val_mse: 2.4512\n",
      "Epoch 265/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6709 - mae: 1.0318 - mse: 1.7771 - val_loss: 13.1557 - val_mae: 1.1133 - val_mse: 2.2490\n",
      "Epoch 266/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6674 - mae: 1.0223 - mse: 1.7497 - val_loss: 13.0910 - val_mae: 1.1719 - val_mse: 2.4346\n",
      "Epoch 267/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6682 - mae: 1.0247 - mse: 1.7746 - val_loss: 13.0951 - val_mae: 1.1135 - val_mse: 2.2545\n",
      "Epoch 268/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6655 - mae: 1.0235 - mse: 1.7589 - val_loss: 13.1004 - val_mae: 1.1971 - val_mse: 2.5156\n",
      "Epoch 269/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6655 - mae: 1.0276 - mse: 1.7726 - val_loss: 13.1341 - val_mae: 1.2258 - val_mse: 2.5965\n",
      "Epoch 270/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6602 - mae: 1.0311 - mse: 1.7823 - val_loss: 13.0775 - val_mae: 1.1665 - val_mse: 2.4302\n",
      "Epoch 271/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6628 - mae: 1.0279 - mse: 1.7686 - val_loss: 13.1008 - val_mae: 1.0919 - val_mse: 2.1936\n",
      "Epoch 272/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.6550 - mae: 1.0204 - mse: 1.7558 - val_loss: 13.1489 - val_mae: 1.2293 - val_mse: 2.5996\n",
      "Epoch 273/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6600 - mae: 1.0291 - mse: 1.7729 - val_loss: 13.1471 - val_mae: 1.2536 - val_mse: 2.6857\n",
      "Epoch 274/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6550 - mae: 1.0291 - mse: 1.7837 - val_loss: 13.0871 - val_mae: 1.1837 - val_mse: 2.4769\n",
      "Epoch 275/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6547 - mae: 1.0267 - mse: 1.7795 - val_loss: 13.1229 - val_mae: 1.0649 - val_mse: 2.1173\n",
      "Epoch 276/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6548 - mae: 1.0183 - mse: 1.7451 - val_loss: 13.1229 - val_mae: 1.1078 - val_mse: 2.2337\n",
      "Epoch 277/1000\n",
      "1030/1030 [==============================] - 0s 38us/sample - loss: 12.6552 - mae: 1.0223 - mse: 1.7530 - val_loss: 13.1038 - val_mae: 1.0769 - val_mse: 2.1521\n",
      "Epoch 278/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 12.6591 - mae: 1.0204 - mse: 1.7553 - val_loss: 13.0634 - val_mae: 1.1485 - val_mse: 2.3735\n",
      "Epoch 279/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6442 - mae: 1.0191 - mse: 1.7548 - val_loss: 13.1424 - val_mae: 1.2446 - val_mse: 2.6475\n",
      "Epoch 280/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6505 - mae: 1.0292 - mse: 1.7801 - val_loss: 13.0829 - val_mae: 1.1270 - val_mse: 2.2922\n",
      "Epoch 281/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6418 - mae: 1.0256 - mse: 1.7605 - val_loss: 13.1130 - val_mae: 1.0923 - val_mse: 2.1905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.6459 - mae: 1.0206 - mse: 1.7591 - val_loss: 13.0620 - val_mae: 1.1395 - val_mse: 2.3384\n",
      "Epoch 283/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.6475 - mae: 1.0233 - mse: 1.7681 - val_loss: 13.0927 - val_mae: 1.1221 - val_mse: 2.2771\n",
      "Epoch 284/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6453 - mae: 1.0223 - mse: 1.7564 - val_loss: 13.0619 - val_mae: 1.1561 - val_mse: 2.3944\n",
      "Epoch 285/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.6427 - mae: 1.0243 - mse: 1.7683 - val_loss: 13.1141 - val_mae: 1.0847 - val_mse: 2.1679\n",
      "Epoch 286/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.6401 - mae: 1.0196 - mse: 1.7484 - val_loss: 13.1308 - val_mae: 1.1308 - val_mse: 2.2967\n",
      "Epoch 287/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6403 - mae: 1.0149 - mse: 1.7315 - val_loss: 13.1236 - val_mae: 1.1964 - val_mse: 2.4963\n",
      "Epoch 288/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6347 - mae: 1.0188 - mse: 1.7473 - val_loss: 13.1178 - val_mae: 1.2213 - val_mse: 2.5791\n",
      "Epoch 289/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.6371 - mae: 1.0263 - mse: 1.7658 - val_loss: 13.0527 - val_mae: 1.1232 - val_mse: 2.2965\n",
      "Epoch 290/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6343 - mae: 1.0188 - mse: 1.7527 - val_loss: 13.1167 - val_mae: 1.1693 - val_mse: 2.4093\n",
      "Epoch 291/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6394 - mae: 1.0193 - mse: 1.7496 - val_loss: 13.0646 - val_mae: 1.1811 - val_mse: 2.4674\n",
      "Epoch 292/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6327 - mae: 1.0252 - mse: 1.7728 - val_loss: 13.0569 - val_mae: 1.1085 - val_mse: 2.2448\n",
      "Epoch 293/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6315 - mae: 1.0188 - mse: 1.7521 - val_loss: 13.0985 - val_mae: 1.1335 - val_mse: 2.3053\n",
      "Epoch 294/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.6363 - mae: 1.0183 - mse: 1.7430 - val_loss: 13.0534 - val_mae: 1.1170 - val_mse: 2.2693\n",
      "Epoch 295/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.6276 - mae: 1.0189 - mse: 1.7451 - val_loss: 13.0759 - val_mae: 1.0889 - val_mse: 2.1820\n",
      "Epoch 296/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6257 - mae: 1.0123 - mse: 1.7268 - val_loss: 13.0714 - val_mae: 1.1830 - val_mse: 2.4627\n",
      "Epoch 297/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6235 - mae: 1.0202 - mse: 1.7460 - val_loss: 13.1161 - val_mae: 1.2483 - val_mse: 2.6694\n",
      "Epoch 298/1000\n",
      "1030/1030 [==============================] - 0s 37us/sample - loss: 12.6266 - mae: 1.0264 - mse: 1.7759 - val_loss: 13.0844 - val_mae: 1.1738 - val_mse: 2.4279\n",
      "Epoch 299/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 12.6214 - mae: 1.0168 - mse: 1.7358 - val_loss: 13.0495 - val_mae: 1.1252 - val_mse: 2.2925\n",
      "Epoch 300/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6217 - mae: 1.0152 - mse: 1.7390 - val_loss: 13.0758 - val_mae: 1.0977 - val_mse: 2.2061\n",
      "Epoch 301/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6213 - mae: 1.0161 - mse: 1.7349 - val_loss: 13.1217 - val_mae: 1.0610 - val_mse: 2.0985\n",
      "Epoch 302/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.6240 - mae: 1.0095 - mse: 1.7266 - val_loss: 13.0444 - val_mae: 1.1233 - val_mse: 2.2835\n",
      "Epoch 303/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.6200 - mae: 1.0170 - mse: 1.7382 - val_loss: 13.0606 - val_mae: 1.1451 - val_mse: 2.3446\n",
      "Epoch 304/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6207 - mae: 1.0175 - mse: 1.7372 - val_loss: 13.0553 - val_mae: 1.1059 - val_mse: 2.2336\n",
      "Epoch 305/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6188 - mae: 1.0162 - mse: 1.7449 - val_loss: 13.0597 - val_mae: 1.1531 - val_mse: 2.3699\n",
      "Epoch 306/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.6214 - mae: 1.0183 - mse: 1.7418 - val_loss: 13.0929 - val_mae: 1.1941 - val_mse: 2.4871\n",
      "Epoch 307/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.6194 - mae: 1.0214 - mse: 1.7490 - val_loss: 13.0717 - val_mae: 1.1671 - val_mse: 2.4094\n",
      "Epoch 308/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.6088 - mae: 1.0185 - mse: 1.7397 - val_loss: 13.1316 - val_mae: 1.0296 - val_mse: 2.0212\n",
      "Epoch 309/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.6184 - mae: 1.0094 - mse: 1.7166 - val_loss: 13.0651 - val_mae: 1.1460 - val_mse: 2.3461\n",
      "Epoch 310/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6159 - mae: 1.0203 - mse: 1.7458 - val_loss: 13.0643 - val_mae: 1.1289 - val_mse: 2.2953\n",
      "Epoch 311/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.6114 - mae: 1.0117 - mse: 1.7358 - val_loss: 13.0441 - val_mae: 1.1248 - val_mse: 2.2897\n",
      "Epoch 312/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6072 - mae: 1.0134 - mse: 1.7304 - val_loss: 13.1153 - val_mae: 1.2079 - val_mse: 2.5252\n",
      "Epoch 313/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.6126 - mae: 1.0189 - mse: 1.7487 - val_loss: 13.0955 - val_mae: 1.0849 - val_mse: 2.1650\n",
      "Epoch 314/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.6120 - mae: 1.0075 - mse: 1.7143 - val_loss: 13.0529 - val_mae: 1.1883 - val_mse: 2.4921\n",
      "Epoch 315/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6064 - mae: 1.0207 - mse: 1.7495 - val_loss: 13.0536 - val_mae: 1.0703 - val_mse: 2.1378\n",
      "Epoch 316/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6116 - mae: 1.0102 - mse: 1.7192 - val_loss: 13.0790 - val_mae: 1.2264 - val_mse: 2.5997\n",
      "Epoch 317/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6073 - mae: 1.0201 - mse: 1.7507 - val_loss: 13.0683 - val_mae: 1.1104 - val_mse: 2.2393\n",
      "Epoch 318/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.5999 - mae: 1.0051 - mse: 1.7107 - val_loss: 13.0680 - val_mae: 1.1566 - val_mse: 2.3736\n",
      "Epoch 319/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.6037 - mae: 1.0127 - mse: 1.7247 - val_loss: 13.0620 - val_mae: 1.0813 - val_mse: 2.1619\n",
      "Epoch 320/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.6005 - mae: 1.0049 - mse: 1.7090 - val_loss: 13.0525 - val_mae: 1.1628 - val_mse: 2.3990\n",
      "Epoch 321/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.6033 - mae: 1.0129 - mse: 1.7234 - val_loss: 13.0232 - val_mae: 1.1274 - val_mse: 2.3096\n",
      "Epoch 322/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.6006 - mae: 1.0146 - mse: 1.7340 - val_loss: 13.1044 - val_mae: 1.1645 - val_mse: 2.3910\n",
      "Epoch 323/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.5983 - mae: 1.0160 - mse: 1.7386 - val_loss: 13.0672 - val_mae: 1.1507 - val_mse: 2.3549\n",
      "Epoch 324/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.5951 - mae: 1.0083 - mse: 1.7231 - val_loss: 13.0376 - val_mae: 1.0917 - val_mse: 2.1924\n",
      "Epoch 325/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.5950 - mae: 1.0104 - mse: 1.7216 - val_loss: 13.1391 - val_mae: 1.0192 - val_mse: 1.9897\n",
      "Epoch 326/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.6029 - mae: 0.9985 - mse: 1.6811 - val_loss: 13.0451 - val_mae: 1.1568 - val_mse: 2.3772\n",
      "Epoch 327/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.5986 - mae: 1.0113 - mse: 1.7282 - val_loss: 13.0353 - val_mae: 1.1222 - val_mse: 2.2794\n",
      "Epoch 328/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.5989 - mae: 1.0123 - mse: 1.7295 - val_loss: 13.0413 - val_mae: 1.1398 - val_mse: 2.3260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.5940 - mae: 1.0096 - mse: 1.7235 - val_loss: 13.0626 - val_mae: 1.1426 - val_mse: 2.3267\n",
      "Epoch 330/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.5890 - mae: 1.0135 - mse: 1.7232 - val_loss: 13.0234 - val_mae: 1.0977 - val_mse: 2.2218\n",
      "Epoch 331/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.5898 - mae: 1.0083 - mse: 1.7095 - val_loss: 13.0524 - val_mae: 1.0860 - val_mse: 2.1735\n",
      "Epoch 332/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.5913 - mae: 1.0011 - mse: 1.7010 - val_loss: 13.0522 - val_mae: 1.1964 - val_mse: 2.5033\n",
      "Epoch 333/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.5850 - mae: 1.0154 - mse: 1.7421 - val_loss: 13.0438 - val_mae: 1.1022 - val_mse: 2.2160\n",
      "Epoch 334/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.5870 - mae: 1.0049 - mse: 1.7033 - val_loss: 13.0554 - val_mae: 1.1030 - val_mse: 2.2195\n",
      "Epoch 335/1000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 12.5864 - mae: 1.0096 - mse: 1.7178 - val_loss: 13.0548 - val_mae: 1.0712 - val_mse: 2.1342\n",
      "Epoch 336/1000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 12.5834 - mae: 1.0023 - mse: 1.6945 - val_loss: 13.0764 - val_mae: 1.2315 - val_mse: 2.6094\n",
      "Epoch 337/1000\n",
      "1030/1030 [==============================] - 0s 58us/sample - loss: 12.5898 - mae: 1.0193 - mse: 1.7466 - val_loss: 13.0531 - val_mae: 1.0634 - val_mse: 2.1109\n",
      "Epoch 338/1000\n",
      "1030/1030 [==============================] - 0s 57us/sample - loss: 12.5824 - mae: 0.9993 - mse: 1.6910 - val_loss: 13.1117 - val_mae: 1.1730 - val_mse: 2.4155\n",
      "Epoch 339/1000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 12.5826 - mae: 1.0078 - mse: 1.7075 - val_loss: 13.0996 - val_mae: 1.2360 - val_mse: 2.6188\n",
      "Epoch 340/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 12.5796 - mae: 1.0134 - mse: 1.7300 - val_loss: 13.0278 - val_mae: 1.1646 - val_mse: 2.4135\n",
      "Epoch 341/1000\n",
      "1030/1030 [==============================] - 0s 77us/sample - loss: 12.5807 - mae: 1.0078 - mse: 1.7179 - val_loss: 13.0987 - val_mae: 1.2079 - val_mse: 2.5255\n",
      "Epoch 342/1000\n",
      "1030/1030 [==============================] - 0s 62us/sample - loss: 12.5764 - mae: 1.0120 - mse: 1.7224 - val_loss: 13.0838 - val_mae: 1.1447 - val_mse: 2.3326\n",
      "Epoch 343/1000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 12.5814 - mae: 1.0118 - mse: 1.7213 - val_loss: 13.0263 - val_mae: 1.0934 - val_mse: 2.1974\n",
      "Epoch 344/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.5785 - mae: 1.0043 - mse: 1.6992 - val_loss: 13.0088 - val_mae: 1.1216 - val_mse: 2.2961\n",
      "Epoch 345/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 12.5714 - mae: 1.0023 - mse: 1.6990 - val_loss: 13.0633 - val_mae: 1.1541 - val_mse: 2.3607\n",
      "Epoch 346/1000\n",
      "1030/1030 [==============================] - 0s 55us/sample - loss: 12.5755 - mae: 1.0055 - mse: 1.7098 - val_loss: 13.0088 - val_mae: 1.0971 - val_mse: 2.2174\n",
      "Epoch 347/1000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 12.5772 - mae: 1.0075 - mse: 1.7079 - val_loss: 13.0237 - val_mae: 1.1435 - val_mse: 2.3411\n",
      "Epoch 348/1000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 12.5749 - mae: 1.0050 - mse: 1.7077 - val_loss: 13.0608 - val_mae: 1.1971 - val_mse: 2.4961\n",
      "Epoch 349/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 12.5769 - mae: 1.0088 - mse: 1.7198 - val_loss: 13.0132 - val_mae: 1.0967 - val_mse: 2.2133\n",
      "Epoch 350/1000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 12.5729 - mae: 1.0029 - mse: 1.7018 - val_loss: 13.0107 - val_mae: 1.1576 - val_mse: 2.3975\n",
      "Epoch 351/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.5691 - mae: 1.0086 - mse: 1.7190 - val_loss: 13.0625 - val_mae: 1.1501 - val_mse: 2.3451\n",
      "Epoch 352/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5677 - mae: 1.0071 - mse: 1.7126 - val_loss: 13.0526 - val_mae: 1.0680 - val_mse: 2.1192\n",
      "Epoch 353/1000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 12.5673 - mae: 1.0022 - mse: 1.6953 - val_loss: 13.0502 - val_mae: 1.1626 - val_mse: 2.3884\n",
      "Epoch 354/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5728 - mae: 1.0073 - mse: 1.7112 - val_loss: 13.0399 - val_mae: 1.1199 - val_mse: 2.2645\n",
      "Epoch 355/1000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 12.5668 - mae: 0.9999 - mse: 1.6922 - val_loss: 13.0314 - val_mae: 1.0878 - val_mse: 2.1790\n",
      "Epoch 356/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.5629 - mae: 0.9963 - mse: 1.6769 - val_loss: 13.0458 - val_mae: 1.1866 - val_mse: 2.4658\n",
      "Epoch 357/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.5683 - mae: 1.0119 - mse: 1.7309 - val_loss: 13.0904 - val_mae: 1.0296 - val_mse: 2.0098\n",
      "Epoch 358/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5665 - mae: 0.9978 - mse: 1.6871 - val_loss: 13.0516 - val_mae: 1.0390 - val_mse: 2.0446\n",
      "Epoch 359/1000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 12.5648 - mae: 0.9989 - mse: 1.6890 - val_loss: 13.1012 - val_mae: 1.1290 - val_mse: 2.2831\n",
      "Epoch 360/1000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 12.5605 - mae: 0.9978 - mse: 1.6767 - val_loss: 13.0888 - val_mae: 1.2651 - val_mse: 2.7224\n",
      "Epoch 361/1000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 12.5673 - mae: 1.0156 - mse: 1.7419 - val_loss: 13.0511 - val_mae: 1.1848 - val_mse: 2.4575\n",
      "Epoch 362/1000\n",
      "1030/1030 [==============================] - 0s 75us/sample - loss: 12.5610 - mae: 1.0066 - mse: 1.7044 - val_loss: 13.0167 - val_mae: 1.0914 - val_mse: 2.1939\n",
      "Epoch 363/1000\n",
      "1030/1030 [==============================] - 0s 89us/sample - loss: 12.5597 - mae: 1.0041 - mse: 1.7019 - val_loss: 13.0624 - val_mae: 1.0533 - val_mse: 2.0786\n",
      "Epoch 364/1000\n",
      "1030/1030 [==============================] - 0s 68us/sample - loss: 12.5617 - mae: 1.0023 - mse: 1.6920 - val_loss: 13.0238 - val_mae: 1.1408 - val_mse: 2.3313\n",
      "Epoch 365/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5567 - mae: 1.0037 - mse: 1.7018 - val_loss: 13.0208 - val_mae: 1.1094 - val_mse: 2.2430\n",
      "Epoch 366/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5573 - mae: 1.0005 - mse: 1.6919 - val_loss: 13.0305 - val_mae: 1.0764 - val_mse: 2.1467\n",
      "Epoch 367/1000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 12.5518 - mae: 1.0029 - mse: 1.6893 - val_loss: 13.0321 - val_mae: 1.1061 - val_mse: 2.2272\n",
      "Epoch 368/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5582 - mae: 0.9970 - mse: 1.6908 - val_loss: 13.0398 - val_mae: 1.1327 - val_mse: 2.2991\n",
      "Epoch 369/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5575 - mae: 1.0023 - mse: 1.6907 - val_loss: 13.0438 - val_mae: 1.0622 - val_mse: 2.1020\n",
      "Epoch 370/1000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 12.5529 - mae: 0.9945 - mse: 1.6692 - val_loss: 12.9875 - val_mae: 1.1176 - val_mse: 2.2772\n",
      "Epoch 371/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5538 - mae: 1.0004 - mse: 1.6863 - val_loss: 13.0285 - val_mae: 1.1287 - val_mse: 2.2857\n",
      "Epoch 372/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5522 - mae: 0.9995 - mse: 1.6851 - val_loss: 13.0068 - val_mae: 1.1601 - val_mse: 2.3909\n",
      "Epoch 373/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5502 - mae: 1.0022 - mse: 1.7001 - val_loss: 13.0412 - val_mae: 1.0857 - val_mse: 2.1649\n",
      "Epoch 374/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5509 - mae: 0.9949 - mse: 1.6783 - val_loss: 12.9886 - val_mae: 1.1342 - val_mse: 2.3266\n",
      "Epoch 375/1000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 12.5467 - mae: 1.0040 - mse: 1.7008 - val_loss: 13.0513 - val_mae: 1.0410 - val_mse: 2.0448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5433 - mae: 0.9898 - mse: 1.6515 - val_loss: 13.0481 - val_mae: 1.2203 - val_mse: 2.5689\n",
      "Epoch 377/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5404 - mae: 1.0046 - mse: 1.7023 - val_loss: 13.0274 - val_mae: 1.1303 - val_mse: 2.2915\n",
      "Epoch 378/1000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 12.5471 - mae: 0.9984 - mse: 1.6888 - val_loss: 13.0211 - val_mae: 1.1744 - val_mse: 2.4267\n",
      "Epoch 379/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5423 - mae: 1.0006 - mse: 1.6912 - val_loss: 13.0101 - val_mae: 1.1599 - val_mse: 2.3872\n",
      "Epoch 380/1000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 12.5445 - mae: 1.0008 - mse: 1.6935 - val_loss: 12.9887 - val_mae: 1.1035 - val_mse: 2.2314\n",
      "Epoch 381/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5419 - mae: 0.9985 - mse: 1.6827 - val_loss: 13.0156 - val_mae: 1.1108 - val_mse: 2.2400\n",
      "Epoch 382/1000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 12.5416 - mae: 1.0022 - mse: 1.6938 - val_loss: 13.0820 - val_mae: 1.0302 - val_mse: 2.0083\n",
      "Epoch 383/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5420 - mae: 0.9879 - mse: 1.6489 - val_loss: 13.0471 - val_mae: 1.0672 - val_mse: 2.1085\n",
      "Epoch 384/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5410 - mae: 0.9942 - mse: 1.6631 - val_loss: 13.0338 - val_mae: 1.0824 - val_mse: 2.1544\n",
      "Epoch 385/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5398 - mae: 0.9936 - mse: 1.6704 - val_loss: 13.0070 - val_mae: 1.1187 - val_mse: 2.2590\n",
      "Epoch 386/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5379 - mae: 0.9942 - mse: 1.6718 - val_loss: 12.9973 - val_mae: 1.1814 - val_mse: 2.4693\n",
      "Epoch 387/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5425 - mae: 1.0051 - mse: 1.7112 - val_loss: 13.0329 - val_mae: 1.0417 - val_mse: 2.0476\n",
      "Epoch 388/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5362 - mae: 0.9888 - mse: 1.6577 - val_loss: 13.0506 - val_mae: 1.0933 - val_mse: 2.1783\n",
      "Epoch 389/1000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 12.5416 - mae: 0.9905 - mse: 1.6630 - val_loss: 13.0439 - val_mae: 1.2077 - val_mse: 2.5252\n",
      "Epoch 390/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5378 - mae: 1.0021 - mse: 1.6986 - val_loss: 12.9803 - val_mae: 1.1420 - val_mse: 2.3562\n",
      "Epoch 391/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5362 - mae: 1.0020 - mse: 1.6959 - val_loss: 13.0341 - val_mae: 1.1143 - val_mse: 2.2424\n",
      "Epoch 392/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.5386 - mae: 1.0010 - mse: 1.6897 - val_loss: 12.9871 - val_mae: 1.0986 - val_mse: 2.2135\n",
      "Epoch 393/1000\n",
      "1030/1030 [==============================] - 0s 83us/sample - loss: 12.5326 - mae: 0.9926 - mse: 1.6719 - val_loss: 13.0276 - val_mae: 1.2145 - val_mse: 2.5505\n",
      "Epoch 394/1000\n",
      "1030/1030 [==============================] - 0s 76us/sample - loss: 12.5299 - mae: 1.0044 - mse: 1.7042 - val_loss: 12.9779 - val_mae: 1.0876 - val_mse: 2.1894\n",
      "Epoch 395/1000\n",
      "1030/1030 [==============================] - 0s 82us/sample - loss: 12.5315 - mae: 1.0000 - mse: 1.6909 - val_loss: 13.0093 - val_mae: 1.0514 - val_mse: 2.0803\n",
      "Epoch 396/1000\n",
      "1030/1030 [==============================] - 0s 85us/sample - loss: 12.5325 - mae: 0.9910 - mse: 1.6614 - val_loss: 12.9901 - val_mae: 1.1597 - val_mse: 2.3908\n",
      "Epoch 397/1000\n",
      "1030/1030 [==============================] - 0s 87us/sample - loss: 12.5261 - mae: 0.9958 - mse: 1.6772 - val_loss: 13.0212 - val_mae: 1.2137 - val_mse: 2.5509\n",
      "Epoch 398/1000\n",
      "1030/1030 [==============================] - 0s 86us/sample - loss: 12.5298 - mae: 1.0015 - mse: 1.6967 - val_loss: 13.0023 - val_mae: 1.0710 - val_mse: 2.1325\n",
      "Epoch 399/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.5254 - mae: 0.9908 - mse: 1.6663 - val_loss: 12.9827 - val_mae: 1.1446 - val_mse: 2.3481\n",
      "Epoch 400/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.5294 - mae: 0.9962 - mse: 1.6784 - val_loss: 12.9958 - val_mae: 1.1842 - val_mse: 2.4712\n",
      "Epoch 401/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5276 - mae: 0.9960 - mse: 1.6808 - val_loss: 13.0436 - val_mae: 1.2284 - val_mse: 2.5912\n",
      "Epoch 402/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5262 - mae: 1.0011 - mse: 1.6934 - val_loss: 12.9757 - val_mae: 1.1535 - val_mse: 2.3801\n",
      "Epoch 403/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.5265 - mae: 0.9962 - mse: 1.6758 - val_loss: 12.9733 - val_mae: 1.0941 - val_mse: 2.2243\n",
      "Epoch 404/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5226 - mae: 0.9989 - mse: 1.6896 - val_loss: 13.0589 - val_mae: 1.0178 - val_mse: 1.9796\n",
      "Epoch 405/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5262 - mae: 0.9862 - mse: 1.6517 - val_loss: 13.0038 - val_mae: 1.1635 - val_mse: 2.3889\n",
      "Epoch 406/1000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 12.5140 - mae: 0.9866 - mse: 1.6507 - val_loss: 13.0422 - val_mae: 1.2532 - val_mse: 2.6913\n",
      "Epoch 407/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5236 - mae: 1.0027 - mse: 1.7070 - val_loss: 12.9666 - val_mae: 1.1105 - val_mse: 2.2616\n",
      "Epoch 408/1000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 12.5208 - mae: 0.9898 - mse: 1.6628 - val_loss: 12.9957 - val_mae: 1.1923 - val_mse: 2.4980\n",
      "Epoch 409/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5251 - mae: 0.9980 - mse: 1.6867 - val_loss: 12.9999 - val_mae: 1.1412 - val_mse: 2.3248\n",
      "Epoch 410/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.5173 - mae: 0.9921 - mse: 1.6677 - val_loss: 13.0282 - val_mae: 1.1842 - val_mse: 2.4506\n",
      "Epoch 411/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.5195 - mae: 0.9983 - mse: 1.6842 - val_loss: 12.9882 - val_mae: 1.1468 - val_mse: 2.3472\n",
      "Epoch 412/1000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 12.5168 - mae: 0.9975 - mse: 1.6810 - val_loss: 13.0422 - val_mae: 1.0319 - val_mse: 2.0091\n",
      "Epoch 413/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 12.5209 - mae: 0.9857 - mse: 1.6527 - val_loss: 13.0070 - val_mae: 1.0345 - val_mse: 2.0325\n",
      "Epoch 414/1000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 12.5181 - mae: 0.9810 - mse: 1.6373 - val_loss: 12.9833 - val_mae: 1.1779 - val_mse: 2.4494\n",
      "Epoch 415/1000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 12.5168 - mae: 0.9988 - mse: 1.6932 - val_loss: 12.9752 - val_mae: 1.0717 - val_mse: 2.1314\n",
      "Epoch 416/1000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 12.5158 - mae: 0.9904 - mse: 1.6656 - val_loss: 12.9555 - val_mae: 1.0921 - val_mse: 2.1963\n",
      "Epoch 417/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.5157 - mae: 0.9891 - mse: 1.6544 - val_loss: 12.9621 - val_mae: 1.1229 - val_mse: 2.2792\n",
      "Epoch 418/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.5106 - mae: 0.9893 - mse: 1.6577 - val_loss: 13.0015 - val_mae: 1.1667 - val_mse: 2.3976\n",
      "Epoch 419/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 12.5136 - mae: 0.9920 - mse: 1.6655 - val_loss: 12.9926 - val_mae: 1.1864 - val_mse: 2.4650\n",
      "Epoch 420/1000\n",
      "1030/1030 [==============================] - 0s 54us/sample - loss: 12.5185 - mae: 0.9967 - mse: 1.6801 - val_loss: 12.9600 - val_mae: 1.1415 - val_mse: 2.3429\n",
      "Epoch 421/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 12.5101 - mae: 0.9888 - mse: 1.6599 - val_loss: 12.9637 - val_mae: 1.1357 - val_mse: 2.3221\n",
      "Epoch 422/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 12.5078 - mae: 0.9870 - mse: 1.6592 - val_loss: 12.9501 - val_mae: 1.0990 - val_mse: 2.2272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 423/1000\n",
      "1030/1030 [==============================] - 0s 65us/sample - loss: 12.5089 - mae: 0.9906 - mse: 1.6680 - val_loss: 12.9939 - val_mae: 1.1059 - val_mse: 2.2146\n",
      "Epoch 424/1000\n",
      "1030/1030 [==============================] - 0s 61us/sample - loss: 12.5083 - mae: 0.9851 - mse: 1.6424 - val_loss: 12.9532 - val_mae: 1.0841 - val_mse: 2.1765\n",
      "Epoch 425/1000\n",
      "1030/1030 [==============================] - 0s 64us/sample - loss: 12.5077 - mae: 0.9875 - mse: 1.6495 - val_loss: 12.9838 - val_mae: 1.0764 - val_mse: 2.1409\n",
      "Epoch 426/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 12.5094 - mae: 0.9840 - mse: 1.6496 - val_loss: 12.9681 - val_mae: 1.0621 - val_mse: 2.1122\n",
      "Epoch 427/1000\n",
      "1030/1030 [==============================] - 0s 56us/sample - loss: 12.5061 - mae: 0.9836 - mse: 1.6409 - val_loss: 12.9880 - val_mae: 1.1668 - val_mse: 2.4042\n",
      "Epoch 428/1000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 12.4974 - mae: 0.9898 - mse: 1.6541 - val_loss: 13.0171 - val_mae: 1.2191 - val_mse: 2.5618\n",
      "Epoch 429/1000\n",
      "1030/1030 [==============================] - 0s 60us/sample - loss: 12.5062 - mae: 0.9930 - mse: 1.6745 - val_loss: 12.9678 - val_mae: 1.1581 - val_mse: 2.3848\n",
      "Epoch 430/1000\n",
      "1030/1030 [==============================] - 0s 52us/sample - loss: 12.5029 - mae: 0.9920 - mse: 1.6722 - val_loss: 13.0327 - val_mae: 1.0949 - val_mse: 2.1782\n",
      "Epoch 431/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 12.5033 - mae: 0.9846 - mse: 1.6480 - val_loss: 12.9500 - val_mae: 1.1047 - val_mse: 2.2431\n",
      "Epoch 432/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.5044 - mae: 0.9881 - mse: 1.6553 - val_loss: 13.0312 - val_mae: 1.2373 - val_mse: 2.6177\n",
      "Epoch 433/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.5060 - mae: 1.0037 - mse: 1.6999 - val_loss: 13.0041 - val_mae: 1.0742 - val_mse: 2.1258\n",
      "Epoch 434/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4993 - mae: 0.9822 - mse: 1.6321 - val_loss: 12.9558 - val_mae: 1.1294 - val_mse: 2.3024\n",
      "Epoch 435/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4910 - mae: 0.9843 - mse: 1.6446 - val_loss: 12.9483 - val_mae: 1.1166 - val_mse: 2.2712\n",
      "Epoch 436/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4989 - mae: 0.9896 - mse: 1.6610 - val_loss: 12.9670 - val_mae: 1.1395 - val_mse: 2.3264\n",
      "Epoch 437/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4974 - mae: 0.9865 - mse: 1.6503 - val_loss: 12.9599 - val_mae: 1.1693 - val_mse: 2.4377\n",
      "Epoch 438/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4981 - mae: 0.9942 - mse: 1.6806 - val_loss: 12.9559 - val_mae: 1.1023 - val_mse: 2.2220\n",
      "Epoch 439/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4946 - mae: 0.9846 - mse: 1.6424 - val_loss: 12.9842 - val_mae: 1.1858 - val_mse: 2.4647\n",
      "Epoch 440/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4954 - mae: 0.9896 - mse: 1.6621 - val_loss: 13.0000 - val_mae: 1.1668 - val_mse: 2.4003\n",
      "Epoch 441/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.4922 - mae: 0.9832 - mse: 1.6448 - val_loss: 12.9947 - val_mae: 1.1929 - val_mse: 2.4831\n",
      "Epoch 442/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4939 - mae: 0.9882 - mse: 1.6591 - val_loss: 12.9556 - val_mae: 1.1564 - val_mse: 2.3898\n",
      "Epoch 443/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4942 - mae: 0.9916 - mse: 1.6695 - val_loss: 12.9674 - val_mae: 1.0860 - val_mse: 2.1659\n",
      "Epoch 444/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4933 - mae: 0.9848 - mse: 1.6403 - val_loss: 12.9871 - val_mae: 1.0632 - val_mse: 2.0951\n",
      "Epoch 445/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4924 - mae: 0.9801 - mse: 1.6322 - val_loss: 12.9725 - val_mae: 1.1172 - val_mse: 2.2528\n",
      "Epoch 446/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4949 - mae: 0.9808 - mse: 1.6386 - val_loss: 12.9906 - val_mae: 1.2042 - val_mse: 2.5189\n",
      "Epoch 447/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4943 - mae: 0.9909 - mse: 1.6679 - val_loss: 12.9641 - val_mae: 1.1686 - val_mse: 2.4183\n",
      "Epoch 448/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4945 - mae: 0.9942 - mse: 1.6776 - val_loss: 12.9593 - val_mae: 1.0513 - val_mse: 2.0840\n",
      "Epoch 449/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4925 - mae: 0.9823 - mse: 1.6340 - val_loss: 12.9514 - val_mae: 1.1445 - val_mse: 2.3481\n",
      "Epoch 450/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4873 - mae: 0.9864 - mse: 1.6507 - val_loss: 12.9468 - val_mae: 1.0938 - val_mse: 2.1995\n",
      "Epoch 451/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4899 - mae: 0.9869 - mse: 1.6530 - val_loss: 12.9604 - val_mae: 1.0860 - val_mse: 2.1704\n",
      "Epoch 452/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4862 - mae: 0.9786 - mse: 1.6321 - val_loss: 12.9520 - val_mae: 1.0740 - val_mse: 2.1443\n",
      "Epoch 453/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.4834 - mae: 0.9796 - mse: 1.6323 - val_loss: 12.9502 - val_mae: 1.1520 - val_mse: 2.3892\n",
      "Epoch 454/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4901 - mae: 0.9921 - mse: 1.6724 - val_loss: 12.9329 - val_mae: 1.1076 - val_mse: 2.2486\n",
      "Epoch 455/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4864 - mae: 0.9850 - mse: 1.6476 - val_loss: 12.9547 - val_mae: 1.1290 - val_mse: 2.2976\n",
      "Epoch 456/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4834 - mae: 0.9819 - mse: 1.6430 - val_loss: 13.0219 - val_mae: 1.1808 - val_mse: 2.4361\n",
      "Epoch 457/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4892 - mae: 0.9907 - mse: 1.6624 - val_loss: 12.9367 - val_mae: 1.0976 - val_mse: 2.2155\n",
      "Epoch 458/1000\n",
      "1030/1030 [==============================] - 0s 57us/sample - loss: 12.4782 - mae: 0.9826 - mse: 1.6368 - val_loss: 12.9577 - val_mae: 1.0665 - val_mse: 2.1171\n",
      "Epoch 459/1000\n",
      "1030/1030 [==============================] - 0s 73us/sample - loss: 12.4819 - mae: 0.9790 - mse: 1.6303 - val_loss: 12.9439 - val_mae: 1.0915 - val_mse: 2.1975\n",
      "Epoch 460/1000\n",
      "1030/1030 [==============================] - 0s 75us/sample - loss: 12.4811 - mae: 0.9781 - mse: 1.6307 - val_loss: 13.0203 - val_mae: 1.2325 - val_mse: 2.6008\n",
      "Epoch 461/1000\n",
      "1030/1030 [==============================] - 0s 57us/sample - loss: 12.4839 - mae: 0.9898 - mse: 1.6613 - val_loss: 12.9660 - val_mae: 1.1889 - val_mse: 2.4909\n",
      "Epoch 462/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4812 - mae: 0.9922 - mse: 1.6699 - val_loss: 12.9844 - val_mae: 1.0909 - val_mse: 2.1744\n",
      "Epoch 463/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4778 - mae: 0.9751 - mse: 1.6200 - val_loss: 12.9729 - val_mae: 1.1786 - val_mse: 2.4406\n",
      "Epoch 464/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4794 - mae: 0.9843 - mse: 1.6508 - val_loss: 12.9816 - val_mae: 1.1754 - val_mse: 2.4276\n",
      "Epoch 465/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4777 - mae: 0.9857 - mse: 1.6465 - val_loss: 12.9793 - val_mae: 1.1933 - val_mse: 2.4830\n",
      "Epoch 466/1000\n",
      "1030/1030 [==============================] - 0s 72us/sample - loss: 12.4764 - mae: 0.9903 - mse: 1.6661 - val_loss: 12.9914 - val_mae: 1.0968 - val_mse: 2.1860\n",
      "Epoch 467/1000\n",
      "1030/1030 [==============================] - 0s 71us/sample - loss: 12.4759 - mae: 0.9790 - mse: 1.6290 - val_loss: 12.9573 - val_mae: 1.0643 - val_mse: 2.1088\n",
      "Epoch 468/1000\n",
      "1030/1030 [==============================] - 0s 70us/sample - loss: 12.4732 - mae: 0.9762 - mse: 1.6241 - val_loss: 12.9424 - val_mae: 1.0572 - val_mse: 2.1093\n",
      "Epoch 469/1000\n",
      "1030/1030 [==============================] - 0s 70us/sample - loss: 12.4738 - mae: 0.9806 - mse: 1.6284 - val_loss: 12.9317 - val_mae: 1.0851 - val_mse: 2.1789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.4703 - mae: 0.9803 - mse: 1.6337 - val_loss: 12.9535 - val_mae: 1.1424 - val_mse: 2.3381\n",
      "Epoch 471/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4765 - mae: 0.9827 - mse: 1.6435 - val_loss: 12.9861 - val_mae: 1.1827 - val_mse: 2.4480\n",
      "Epoch 472/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4723 - mae: 0.9869 - mse: 1.6511 - val_loss: 12.9288 - val_mae: 1.1135 - val_mse: 2.2653\n",
      "Epoch 473/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4711 - mae: 0.9835 - mse: 1.6385 - val_loss: 12.9693 - val_mae: 1.0579 - val_mse: 2.0840\n",
      "Epoch 474/1000\n",
      "1030/1030 [==============================] - 0s 59us/sample - loss: 12.4705 - mae: 0.9773 - mse: 1.6169 - val_loss: 12.9521 - val_mae: 1.1044 - val_mse: 2.2221\n",
      "Epoch 475/1000\n",
      "1030/1030 [==============================] - 0s 75us/sample - loss: 12.4720 - mae: 0.9779 - mse: 1.6341 - val_loss: 12.9357 - val_mae: 1.1308 - val_mse: 2.3095\n",
      "Epoch 476/1000\n",
      "1030/1030 [==============================] - 0s 74us/sample - loss: 12.4723 - mae: 0.9851 - mse: 1.6447 - val_loss: 12.9279 - val_mae: 1.0843 - val_mse: 2.1766\n",
      "Epoch 477/1000\n",
      "1030/1030 [==============================] - 0s 69us/sample - loss: 12.4689 - mae: 0.9777 - mse: 1.6224 - val_loss: 12.9205 - val_mae: 1.1088 - val_mse: 2.2597\n",
      "Epoch 478/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.4696 - mae: 0.9841 - mse: 1.6444 - val_loss: 12.9433 - val_mae: 1.1538 - val_mse: 2.3763\n",
      "Epoch 479/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4650 - mae: 0.9820 - mse: 1.6399 - val_loss: 12.9799 - val_mae: 1.1542 - val_mse: 2.3623\n",
      "Epoch 480/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4680 - mae: 0.9849 - mse: 1.6438 - val_loss: 12.9517 - val_mae: 1.0736 - val_mse: 2.1340\n",
      "Epoch 481/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4686 - mae: 0.9763 - mse: 1.6186 - val_loss: 12.9423 - val_mae: 1.0924 - val_mse: 2.1871\n",
      "Epoch 482/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.4633 - mae: 0.9787 - mse: 1.6270 - val_loss: 12.9432 - val_mae: 1.1084 - val_mse: 2.2357\n",
      "Epoch 483/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4653 - mae: 0.9793 - mse: 1.6273 - val_loss: 12.9391 - val_mae: 1.1498 - val_mse: 2.3660\n",
      "Epoch 484/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.4673 - mae: 0.9840 - mse: 1.6440 - val_loss: 12.9197 - val_mae: 1.1018 - val_mse: 2.2338\n",
      "Epoch 485/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4576 - mae: 0.9775 - mse: 1.6272 - val_loss: 12.9401 - val_mae: 1.0493 - val_mse: 2.0795\n",
      "Epoch 486/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4615 - mae: 0.9718 - mse: 1.6072 - val_loss: 13.0012 - val_mae: 1.2306 - val_mse: 2.5980\n",
      "Epoch 487/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4669 - mae: 0.9908 - mse: 1.6622 - val_loss: 12.9679 - val_mae: 1.1119 - val_mse: 2.2349\n",
      "Epoch 488/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4628 - mae: 0.9730 - mse: 1.6162 - val_loss: 12.9443 - val_mae: 1.0923 - val_mse: 2.1863\n",
      "Epoch 489/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4618 - mae: 0.9759 - mse: 1.6173 - val_loss: 12.9269 - val_mae: 1.0838 - val_mse: 2.1718\n",
      "Epoch 490/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4604 - mae: 0.9742 - mse: 1.6127 - val_loss: 12.9439 - val_mae: 1.1252 - val_mse: 2.2789\n",
      "Epoch 491/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4649 - mae: 0.9806 - mse: 1.6306 - val_loss: 12.9400 - val_mae: 1.0840 - val_mse: 2.1634\n",
      "Epoch 492/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4627 - mae: 0.9771 - mse: 1.6265 - val_loss: 12.9192 - val_mae: 1.0774 - val_mse: 2.1611\n",
      "Epoch 493/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4637 - mae: 0.9743 - mse: 1.6194 - val_loss: 12.9933 - val_mae: 1.1971 - val_mse: 2.4910\n",
      "Epoch 494/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4589 - mae: 0.9816 - mse: 1.6371 - val_loss: 12.9230 - val_mae: 1.1182 - val_mse: 2.2784\n",
      "Epoch 495/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4585 - mae: 0.9788 - mse: 1.6280 - val_loss: 12.9484 - val_mae: 1.1719 - val_mse: 2.4260\n",
      "Epoch 496/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4574 - mae: 0.9829 - mse: 1.6418 - val_loss: 12.9357 - val_mae: 1.0958 - val_mse: 2.2009\n",
      "Epoch 497/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4559 - mae: 0.9746 - mse: 1.6203 - val_loss: 12.9355 - val_mae: 1.0950 - val_mse: 2.1962\n",
      "Epoch 498/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4516 - mae: 0.9694 - mse: 1.5984 - val_loss: 12.9301 - val_mae: 1.0939 - val_mse: 2.1965\n",
      "Epoch 499/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4519 - mae: 0.9725 - mse: 1.6103 - val_loss: 12.9114 - val_mae: 1.0977 - val_mse: 2.2272\n",
      "Epoch 500/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4555 - mae: 0.9717 - mse: 1.6108 - val_loss: 12.9250 - val_mae: 1.1132 - val_mse: 2.2554\n",
      "Epoch 501/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4564 - mae: 0.9803 - mse: 1.6324 - val_loss: 12.9164 - val_mae: 1.0845 - val_mse: 2.1839\n",
      "Epoch 502/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.4552 - mae: 0.9769 - mse: 1.6205 - val_loss: 12.9312 - val_mae: 1.1538 - val_mse: 2.3756\n",
      "Epoch 503/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4537 - mae: 0.9742 - mse: 1.6182 - val_loss: 13.0101 - val_mae: 1.2430 - val_mse: 2.6378\n",
      "Epoch 504/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4601 - mae: 0.9892 - mse: 1.6671 - val_loss: 12.9267 - val_mae: 1.0824 - val_mse: 2.1614\n",
      "Epoch 505/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4533 - mae: 0.9780 - mse: 1.6205 - val_loss: 12.9689 - val_mae: 1.0349 - val_mse: 2.0213\n",
      "Epoch 506/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4507 - mae: 0.9665 - mse: 1.5945 - val_loss: 12.9340 - val_mae: 1.1163 - val_mse: 2.2574\n",
      "Epoch 507/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4494 - mae: 0.9795 - mse: 1.6260 - val_loss: 12.9065 - val_mae: 1.0895 - val_mse: 2.2029\n",
      "Epoch 508/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4487 - mae: 0.9768 - mse: 1.6255 - val_loss: 12.9754 - val_mae: 1.0542 - val_mse: 2.0691\n",
      "Epoch 509/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.4518 - mae: 0.9684 - mse: 1.5920 - val_loss: 12.9238 - val_mae: 1.1153 - val_mse: 2.2644\n",
      "Epoch 510/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4514 - mae: 0.9762 - mse: 1.6238 - val_loss: 12.9403 - val_mae: 1.1292 - val_mse: 2.2927\n",
      "Epoch 511/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.4425 - mae: 0.9720 - mse: 1.6126 - val_loss: 12.9458 - val_mae: 1.1732 - val_mse: 2.4261\n",
      "Epoch 512/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4486 - mae: 0.9772 - mse: 1.6225 - val_loss: 12.9108 - val_mae: 1.1176 - val_mse: 2.2813\n",
      "Epoch 513/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4459 - mae: 0.9769 - mse: 1.6238 - val_loss: 12.9121 - val_mae: 1.0728 - val_mse: 2.1473\n",
      "Epoch 514/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.4472 - mae: 0.9765 - mse: 1.6180 - val_loss: 12.9664 - val_mae: 1.1243 - val_mse: 2.2664\n",
      "Epoch 515/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4408 - mae: 0.9724 - mse: 1.6040 - val_loss: 12.9093 - val_mae: 1.1130 - val_mse: 2.2686\n",
      "Epoch 516/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4448 - mae: 0.9747 - mse: 1.6130 - val_loss: 12.9312 - val_mae: 1.0829 - val_mse: 2.1567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4489 - mae: 0.9781 - mse: 1.6218 - val_loss: 12.9584 - val_mae: 1.0654 - val_mse: 2.1017\n",
      "Epoch 518/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 12.4422 - mae: 0.9691 - mse: 1.5976 - val_loss: 12.9272 - val_mae: 1.0805 - val_mse: 2.1566\n",
      "Epoch 519/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4388 - mae: 0.9732 - mse: 1.6124 - val_loss: 13.0000 - val_mae: 1.0619 - val_mse: 2.0832\n",
      "Epoch 520/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4461 - mae: 0.9690 - mse: 1.5991 - val_loss: 12.9238 - val_mae: 1.1594 - val_mse: 2.4019\n",
      "Epoch 521/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4406 - mae: 0.9813 - mse: 1.6351 - val_loss: 12.9581 - val_mae: 1.0187 - val_mse: 1.9892\n",
      "Epoch 522/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4435 - mae: 0.9700 - mse: 1.6012 - val_loss: 12.9335 - val_mae: 1.0518 - val_mse: 2.0762\n",
      "Epoch 523/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4419 - mae: 0.9687 - mse: 1.5979 - val_loss: 12.9053 - val_mae: 1.1130 - val_mse: 2.2666\n",
      "Epoch 524/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4342 - mae: 0.9762 - mse: 1.6190 - val_loss: 12.9746 - val_mae: 1.0414 - val_mse: 2.0364\n",
      "Epoch 525/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.4338 - mae: 0.9616 - mse: 1.5805 - val_loss: 12.9063 - val_mae: 1.0925 - val_mse: 2.2074\n",
      "Epoch 526/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4435 - mae: 0.9721 - mse: 1.6102 - val_loss: 12.9123 - val_mae: 1.1139 - val_mse: 2.2600\n",
      "Epoch 527/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4391 - mae: 0.9727 - mse: 1.6144 - val_loss: 12.9719 - val_mae: 1.1399 - val_mse: 2.3124\n",
      "Epoch 528/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.4397 - mae: 0.9774 - mse: 1.6233 - val_loss: 12.9341 - val_mae: 1.0989 - val_mse: 2.2019\n",
      "Epoch 529/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4328 - mae: 0.9687 - mse: 1.5924 - val_loss: 12.9161 - val_mae: 1.1573 - val_mse: 2.4053\n",
      "Epoch 530/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.4396 - mae: 0.9782 - mse: 1.6274 - val_loss: 12.9636 - val_mae: 1.1342 - val_mse: 2.2967\n",
      "Epoch 531/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.4364 - mae: 0.9726 - mse: 1.6016 - val_loss: 12.9178 - val_mae: 1.1554 - val_mse: 2.3914\n",
      "Epoch 532/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4373 - mae: 0.9750 - mse: 1.6192 - val_loss: 12.9600 - val_mae: 1.1958 - val_mse: 2.4921\n",
      "Epoch 533/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4362 - mae: 0.9792 - mse: 1.6305 - val_loss: 12.9118 - val_mae: 1.0656 - val_mse: 2.1206\n",
      "Epoch 534/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4356 - mae: 0.9715 - mse: 1.6052 - val_loss: 12.9111 - val_mae: 1.0642 - val_mse: 2.1185\n",
      "Epoch 535/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.4339 - mae: 0.9655 - mse: 1.5927 - val_loss: 12.9825 - val_mae: 1.2217 - val_mse: 2.5651\n",
      "Epoch 536/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.4364 - mae: 0.9801 - mse: 1.6258 - val_loss: 12.9265 - val_mae: 1.1296 - val_mse: 2.2994\n",
      "Epoch 537/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4349 - mae: 0.9723 - mse: 1.6104 - val_loss: 12.9178 - val_mae: 1.0691 - val_mse: 2.1258\n",
      "Epoch 538/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4328 - mae: 0.9678 - mse: 1.6027 - val_loss: 12.8977 - val_mae: 1.0797 - val_mse: 2.1815\n",
      "Epoch 539/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4343 - mae: 0.9699 - mse: 1.6077 - val_loss: 12.8979 - val_mae: 1.1187 - val_mse: 2.2888\n",
      "Epoch 540/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4332 - mae: 0.9698 - mse: 1.6032 - val_loss: 12.9340 - val_mae: 1.1402 - val_mse: 2.3246\n",
      "Epoch 541/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.4312 - mae: 0.9708 - mse: 1.6120 - val_loss: 12.9057 - val_mae: 1.0519 - val_mse: 2.0886\n",
      "Epoch 542/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4269 - mae: 0.9663 - mse: 1.5955 - val_loss: 12.9184 - val_mae: 1.0886 - val_mse: 2.1802\n",
      "Epoch 543/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4292 - mae: 0.9687 - mse: 1.6007 - val_loss: 12.9251 - val_mae: 1.0918 - val_mse: 2.1862\n",
      "Epoch 544/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4323 - mae: 0.9703 - mse: 1.6033 - val_loss: 12.9131 - val_mae: 1.1240 - val_mse: 2.2874\n",
      "Epoch 545/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.4292 - mae: 0.9781 - mse: 1.6269 - val_loss: 12.9430 - val_mae: 1.0188 - val_mse: 1.9915\n",
      "Epoch 546/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.4328 - mae: 0.9640 - mse: 1.5902 - val_loss: 12.9336 - val_mae: 1.0406 - val_mse: 2.0429\n",
      "Epoch 547/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4282 - mae: 0.9611 - mse: 1.5801 - val_loss: 12.9106 - val_mae: 1.0712 - val_mse: 2.1286\n",
      "Epoch 548/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4277 - mae: 0.9666 - mse: 1.5929 - val_loss: 12.9296 - val_mae: 1.1621 - val_mse: 2.3930\n",
      "Epoch 549/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4245 - mae: 0.9753 - mse: 1.6131 - val_loss: 12.8902 - val_mae: 1.0959 - val_mse: 2.2192\n",
      "Epoch 550/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4282 - mae: 0.9674 - mse: 1.5927 - val_loss: 12.9518 - val_mae: 1.2168 - val_mse: 2.5858\n",
      "Epoch 551/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4283 - mae: 0.9819 - mse: 1.6376 - val_loss: 12.9070 - val_mae: 1.1553 - val_mse: 2.3878\n",
      "Epoch 552/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4307 - mae: 0.9761 - mse: 1.6186 - val_loss: 12.9086 - val_mae: 1.1375 - val_mse: 2.3270\n",
      "Epoch 553/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4235 - mae: 0.9734 - mse: 1.6116 - val_loss: 12.9269 - val_mae: 1.1539 - val_mse: 2.3707\n",
      "Epoch 554/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4221 - mae: 0.9703 - mse: 1.6083 - val_loss: 12.9031 - val_mae: 1.1328 - val_mse: 2.3193\n",
      "Epoch 555/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4190 - mae: 0.9687 - mse: 1.6005 - val_loss: 12.9280 - val_mae: 1.0653 - val_mse: 2.1071\n",
      "Epoch 556/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.4219 - mae: 0.9652 - mse: 1.5871 - val_loss: 12.9443 - val_mae: 1.1048 - val_mse: 2.2116\n",
      "Epoch 557/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.4206 - mae: 0.9721 - mse: 1.6037 - val_loss: 12.9101 - val_mae: 1.1182 - val_mse: 2.2651\n",
      "Epoch 558/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.4252 - mae: 0.9737 - mse: 1.6088 - val_loss: 12.9315 - val_mae: 1.1554 - val_mse: 2.3719\n",
      "Epoch 559/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4213 - mae: 0.9749 - mse: 1.6211 - val_loss: 12.9336 - val_mae: 1.0780 - val_mse: 2.1420\n",
      "Epoch 560/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.4199 - mae: 0.9617 - mse: 1.5837 - val_loss: 12.9044 - val_mae: 1.0854 - val_mse: 2.1739\n",
      "Epoch 561/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4183 - mae: 0.9688 - mse: 1.5947 - val_loss: 12.9109 - val_mae: 1.1619 - val_mse: 2.4057\n",
      "Epoch 562/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4205 - mae: 0.9754 - mse: 1.6171 - val_loss: 12.8874 - val_mae: 1.1057 - val_mse: 2.2491\n",
      "Epoch 563/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4216 - mae: 0.9648 - mse: 1.5873 - val_loss: 12.9177 - val_mae: 1.1602 - val_mse: 2.3958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 564/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.4216 - mae: 0.9731 - mse: 1.6154 - val_loss: 12.8861 - val_mae: 1.0872 - val_mse: 2.2055\n",
      "Epoch 565/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 12.4178 - mae: 0.9689 - mse: 1.5993 - val_loss: 12.9486 - val_mae: 1.1363 - val_mse: 2.3070\n",
      "Epoch 566/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4168 - mae: 0.9672 - mse: 1.5955 - val_loss: 12.9347 - val_mae: 1.1682 - val_mse: 2.4100\n",
      "Epoch 567/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4213 - mae: 0.9715 - mse: 1.6137 - val_loss: 12.9116 - val_mae: 1.0761 - val_mse: 2.1433\n",
      "Epoch 568/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4164 - mae: 0.9636 - mse: 1.5869 - val_loss: 12.9090 - val_mae: 1.0687 - val_mse: 2.1208\n",
      "Epoch 569/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.4177 - mae: 0.9660 - mse: 1.5874 - val_loss: 12.8805 - val_mae: 1.0832 - val_mse: 2.1817\n",
      "Epoch 570/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4168 - mae: 0.9699 - mse: 1.6027 - val_loss: 12.9379 - val_mae: 1.0957 - val_mse: 2.1834\n",
      "Epoch 571/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4122 - mae: 0.9688 - mse: 1.5924 - val_loss: 12.8981 - val_mae: 1.1032 - val_mse: 2.2250\n",
      "Epoch 572/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.4139 - mae: 0.9670 - mse: 1.5960 - val_loss: 12.9032 - val_mae: 1.0884 - val_mse: 2.1783\n",
      "Epoch 573/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4143 - mae: 0.9683 - mse: 1.5940 - val_loss: 12.9184 - val_mae: 1.0285 - val_mse: 2.0328\n",
      "Epoch 574/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4186 - mae: 0.9661 - mse: 1.5886 - val_loss: 12.8953 - val_mae: 1.0985 - val_mse: 2.2112\n",
      "Epoch 575/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.4148 - mae: 0.9688 - mse: 1.5959 - val_loss: 12.9190 - val_mae: 1.0625 - val_mse: 2.0969\n",
      "Epoch 576/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4104 - mae: 0.9619 - mse: 1.5708 - val_loss: 12.8758 - val_mae: 1.0976 - val_mse: 2.2253\n",
      "Epoch 577/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4130 - mae: 0.9673 - mse: 1.5962 - val_loss: 12.9044 - val_mae: 1.1528 - val_mse: 2.3695\n",
      "Epoch 578/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4135 - mae: 0.9742 - mse: 1.6105 - val_loss: 12.9190 - val_mae: 1.1323 - val_mse: 2.3005\n",
      "Epoch 579/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.4096 - mae: 0.9669 - mse: 1.5947 - val_loss: 12.9425 - val_mae: 1.1913 - val_mse: 2.4782\n",
      "Epoch 580/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.4116 - mae: 0.9725 - mse: 1.6088 - val_loss: 12.9090 - val_mae: 1.1411 - val_mse: 2.3372\n",
      "Epoch 581/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4103 - mae: 0.9716 - mse: 1.6114 - val_loss: 12.8818 - val_mae: 1.0959 - val_mse: 2.2151\n",
      "Epoch 582/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4079 - mae: 0.9679 - mse: 1.5996 - val_loss: 12.8825 - val_mae: 1.0676 - val_mse: 2.1340\n",
      "Epoch 583/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.4094 - mae: 0.9614 - mse: 1.5787 - val_loss: 12.8871 - val_mae: 1.1288 - val_mse: 2.3129\n",
      "Epoch 584/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4078 - mae: 0.9721 - mse: 1.6038 - val_loss: 12.9389 - val_mae: 1.1035 - val_mse: 2.2050\n",
      "Epoch 585/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4113 - mae: 0.9655 - mse: 1.5937 - val_loss: 12.9000 - val_mae: 1.0659 - val_mse: 2.1154\n",
      "Epoch 586/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3984 - mae: 0.9617 - mse: 1.5737 - val_loss: 12.9066 - val_mae: 1.0439 - val_mse: 2.0615\n",
      "Epoch 587/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 12.4086 - mae: 0.9637 - mse: 1.5818 - val_loss: 12.9264 - val_mae: 1.0368 - val_mse: 2.0285\n",
      "Epoch 588/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4082 - mae: 0.9590 - mse: 1.5745 - val_loss: 12.9355 - val_mae: 1.1126 - val_mse: 2.2337\n",
      "Epoch 589/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4053 - mae: 0.9657 - mse: 1.5868 - val_loss: 12.8818 - val_mae: 1.0934 - val_mse: 2.2055\n",
      "Epoch 590/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.4011 - mae: 0.9689 - mse: 1.5980 - val_loss: 12.8809 - val_mae: 1.0862 - val_mse: 2.1859\n",
      "Epoch 591/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.4048 - mae: 0.9643 - mse: 1.5867 - val_loss: 12.9266 - val_mae: 1.0999 - val_mse: 2.1987\n",
      "Epoch 592/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4003 - mae: 0.9630 - mse: 1.5759 - val_loss: 12.8975 - val_mae: 1.1216 - val_mse: 2.2796\n",
      "Epoch 593/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.4026 - mae: 0.9677 - mse: 1.5911 - val_loss: 12.8994 - val_mae: 1.1316 - val_mse: 2.3092\n",
      "Epoch 594/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3990 - mae: 0.9681 - mse: 1.5883 - val_loss: 12.9479 - val_mae: 1.1021 - val_mse: 2.2007\n",
      "Epoch 595/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.4019 - mae: 0.9651 - mse: 1.5847 - val_loss: 12.8883 - val_mae: 1.0715 - val_mse: 2.1603\n",
      "Epoch 596/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4029 - mae: 0.9609 - mse: 1.5746 - val_loss: 12.9475 - val_mae: 1.2224 - val_mse: 2.5884\n",
      "Epoch 597/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.4049 - mae: 0.9776 - mse: 1.6223 - val_loss: 12.8998 - val_mae: 1.0931 - val_mse: 2.1891\n",
      "Epoch 598/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.4030 - mae: 0.9638 - mse: 1.5765 - val_loss: 12.9309 - val_mae: 1.1531 - val_mse: 2.3600\n",
      "Epoch 599/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3990 - mae: 0.9662 - mse: 1.5891 - val_loss: 12.9133 - val_mae: 1.1662 - val_mse: 2.4089\n",
      "Epoch 600/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 12.4019 - mae: 0.9675 - mse: 1.5945 - val_loss: 12.9064 - val_mae: 1.0289 - val_mse: 2.0154\n",
      "Epoch 601/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3960 - mae: 0.9538 - mse: 1.5588 - val_loss: 12.8806 - val_mae: 1.0773 - val_mse: 2.1522\n",
      "Epoch 602/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3972 - mae: 0.9633 - mse: 1.5793 - val_loss: 12.9223 - val_mae: 1.1306 - val_mse: 2.2866\n",
      "Epoch 603/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.3963 - mae: 0.9682 - mse: 1.5899 - val_loss: 12.9187 - val_mae: 1.1167 - val_mse: 2.2487\n",
      "Epoch 604/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.4004 - mae: 0.9664 - mse: 1.5913 - val_loss: 12.9088 - val_mae: 1.1474 - val_mse: 2.3498\n",
      "Epoch 605/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3930 - mae: 0.9634 - mse: 1.5837 - val_loss: 12.9690 - val_mae: 1.1494 - val_mse: 2.3366\n",
      "Epoch 606/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.4002 - mae: 0.9644 - mse: 1.5859 - val_loss: 12.8819 - val_mae: 1.0597 - val_mse: 2.1044\n",
      "Epoch 607/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.3921 - mae: 0.9560 - mse: 1.5640 - val_loss: 12.8910 - val_mae: 1.1027 - val_mse: 2.2232\n",
      "Epoch 608/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3965 - mae: 0.9646 - mse: 1.5902 - val_loss: 12.9376 - val_mae: 1.0113 - val_mse: 1.9612\n",
      "Epoch 609/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3957 - mae: 0.9552 - mse: 1.5488 - val_loss: 12.8936 - val_mae: 1.1452 - val_mse: 2.3578\n",
      "Epoch 610/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3950 - mae: 0.9643 - mse: 1.5843 - val_loss: 12.9144 - val_mae: 1.1527 - val_mse: 2.3729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3943 - mae: 0.9698 - mse: 1.6066 - val_loss: 12.9279 - val_mae: 1.0318 - val_mse: 2.0180\n",
      "Epoch 612/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3934 - mae: 0.9520 - mse: 1.5557 - val_loss: 12.9071 - val_mae: 1.1586 - val_mse: 2.3895\n",
      "Epoch 613/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3885 - mae: 0.9672 - mse: 1.5954 - val_loss: 12.9203 - val_mae: 1.0122 - val_mse: 1.9757\n",
      "Epoch 614/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.3980 - mae: 0.9605 - mse: 1.5754 - val_loss: 12.9158 - val_mae: 1.0726 - val_mse: 2.1223\n",
      "Epoch 615/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.3969 - mae: 0.9602 - mse: 1.5779 - val_loss: 12.9085 - val_mae: 1.0981 - val_mse: 2.1942\n",
      "Epoch 616/1000\n",
      "1030/1030 [==============================] - 0s 38us/sample - loss: 12.3894 - mae: 0.9602 - mse: 1.5657 - val_loss: 12.8788 - val_mae: 1.0803 - val_mse: 2.1615\n",
      "Epoch 617/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3960 - mae: 0.9614 - mse: 1.5760 - val_loss: 12.9183 - val_mae: 1.1858 - val_mse: 2.4695\n",
      "Epoch 618/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3931 - mae: 0.9697 - mse: 1.5988 - val_loss: 12.8852 - val_mae: 1.1574 - val_mse: 2.4019\n",
      "Epoch 619/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.3939 - mae: 0.9730 - mse: 1.6105 - val_loss: 12.9199 - val_mae: 1.1138 - val_mse: 2.2405\n",
      "Epoch 620/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3890 - mae: 0.9629 - mse: 1.5829 - val_loss: 12.9067 - val_mae: 1.0884 - val_mse: 2.1675\n",
      "Epoch 621/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.3917 - mae: 0.9612 - mse: 1.5739 - val_loss: 12.8709 - val_mae: 1.1206 - val_mse: 2.2913\n",
      "Epoch 622/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3899 - mae: 0.9617 - mse: 1.5822 - val_loss: 12.8684 - val_mae: 1.1036 - val_mse: 2.2436\n",
      "Epoch 623/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.3881 - mae: 0.9663 - mse: 1.5878 - val_loss: 12.9627 - val_mae: 1.0607 - val_mse: 2.0828\n",
      "Epoch 624/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3892 - mae: 0.9542 - mse: 1.5516 - val_loss: 12.9216 - val_mae: 1.1435 - val_mse: 2.3315\n",
      "Epoch 625/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3902 - mae: 0.9627 - mse: 1.5823 - val_loss: 12.8660 - val_mae: 1.1106 - val_mse: 2.2642\n",
      "Epoch 626/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3900 - mae: 0.9628 - mse: 1.5829 - val_loss: 12.8802 - val_mae: 1.0680 - val_mse: 2.1271\n",
      "Epoch 627/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3853 - mae: 0.9556 - mse: 1.5630 - val_loss: 12.9265 - val_mae: 1.1974 - val_mse: 2.4980\n",
      "Epoch 628/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.3852 - mae: 0.9673 - mse: 1.5944 - val_loss: 12.8786 - val_mae: 1.1418 - val_mse: 2.3477\n",
      "Epoch 629/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3842 - mae: 0.9689 - mse: 1.5961 - val_loss: 12.8974 - val_mae: 1.0475 - val_mse: 2.0598\n",
      "Epoch 630/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3924 - mae: 0.9560 - mse: 1.5620 - val_loss: 12.8895 - val_mae: 1.1634 - val_mse: 2.4094\n",
      "Epoch 631/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3894 - mae: 0.9709 - mse: 1.6025 - val_loss: 12.8798 - val_mae: 1.0532 - val_mse: 2.0812\n",
      "Epoch 632/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.3917 - mae: 0.9637 - mse: 1.5803 - val_loss: 12.8905 - val_mae: 1.1027 - val_mse: 2.2171\n",
      "Epoch 633/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3844 - mae: 0.9588 - mse: 1.5723 - val_loss: 12.8635 - val_mae: 1.0729 - val_mse: 2.1480\n",
      "Epoch 634/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3803 - mae: 0.9609 - mse: 1.5771 - val_loss: 12.9215 - val_mae: 1.0054 - val_mse: 1.9547\n",
      "Epoch 635/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3861 - mae: 0.9521 - mse: 1.5552 - val_loss: 12.8658 - val_mae: 1.0966 - val_mse: 2.2136\n",
      "Epoch 636/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.3822 - mae: 0.9621 - mse: 1.5763 - val_loss: 12.9139 - val_mae: 1.1107 - val_mse: 2.2280\n",
      "Epoch 637/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3846 - mae: 0.9641 - mse: 1.5798 - val_loss: 12.8901 - val_mae: 1.0526 - val_mse: 2.0756\n",
      "Epoch 638/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3811 - mae: 0.9565 - mse: 1.5615 - val_loss: 12.8657 - val_mae: 1.0967 - val_mse: 2.2127\n",
      "Epoch 639/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3817 - mae: 0.9579 - mse: 1.5656 - val_loss: 12.8715 - val_mae: 1.1388 - val_mse: 2.3522\n",
      "Epoch 640/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.3826 - mae: 0.9642 - mse: 1.5826 - val_loss: 12.9161 - val_mae: 1.1863 - val_mse: 2.4691\n",
      "Epoch 641/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3809 - mae: 0.9655 - mse: 1.5913 - val_loss: 12.8761 - val_mae: 1.0344 - val_mse: 2.0385\n",
      "Epoch 642/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3778 - mae: 0.9527 - mse: 1.5478 - val_loss: 12.8903 - val_mae: 1.1597 - val_mse: 2.3938\n",
      "Epoch 643/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3822 - mae: 0.9646 - mse: 1.5844 - val_loss: 12.8607 - val_mae: 1.0658 - val_mse: 2.1266\n",
      "Epoch 644/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3759 - mae: 0.9594 - mse: 1.5737 - val_loss: 12.8815 - val_mae: 1.0308 - val_mse: 2.0219\n",
      "Epoch 645/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3796 - mae: 0.9575 - mse: 1.5648 - val_loss: 12.8942 - val_mae: 1.1342 - val_mse: 2.3082\n",
      "Epoch 646/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3787 - mae: 0.9653 - mse: 1.5791 - val_loss: 12.8887 - val_mae: 1.0285 - val_mse: 2.0160\n",
      "Epoch 647/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.3784 - mae: 0.9561 - mse: 1.5542 - val_loss: 12.8844 - val_mae: 1.1538 - val_mse: 2.3763\n",
      "Epoch 648/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3793 - mae: 0.9603 - mse: 1.5744 - val_loss: 12.8880 - val_mae: 1.0849 - val_mse: 2.1637\n",
      "Epoch 649/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3779 - mae: 0.9571 - mse: 1.5646 - val_loss: 12.8736 - val_mae: 1.1246 - val_mse: 2.2920\n",
      "Epoch 650/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3755 - mae: 0.9607 - mse: 1.5769 - val_loss: 12.8707 - val_mae: 1.1269 - val_mse: 2.3006\n",
      "Epoch 651/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3711 - mae: 0.9606 - mse: 1.5769 - val_loss: 12.8601 - val_mae: 1.1152 - val_mse: 2.2695\n",
      "Epoch 652/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.3746 - mae: 0.9663 - mse: 1.5848 - val_loss: 12.9123 - val_mae: 1.0554 - val_mse: 2.0745\n",
      "Epoch 653/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3721 - mae: 0.9458 - mse: 1.5399 - val_loss: 12.8775 - val_mae: 1.1414 - val_mse: 2.3403\n",
      "Epoch 654/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3786 - mae: 0.9632 - mse: 1.5769 - val_loss: 12.8731 - val_mae: 1.0825 - val_mse: 2.1635\n",
      "Epoch 655/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3752 - mae: 0.9568 - mse: 1.5660 - val_loss: 12.8612 - val_mae: 1.1268 - val_mse: 2.3116\n",
      "Epoch 656/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3764 - mae: 0.9630 - mse: 1.5831 - val_loss: 12.8538 - val_mae: 1.0799 - val_mse: 2.1681\n",
      "Epoch 657/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.3774 - mae: 0.9610 - mse: 1.5786 - val_loss: 12.8943 - val_mae: 1.0280 - val_mse: 2.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 658/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3708 - mae: 0.9478 - mse: 1.5371 - val_loss: 12.8909 - val_mae: 1.1080 - val_mse: 2.2229\n",
      "Epoch 659/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3780 - mae: 0.9613 - mse: 1.5815 - val_loss: 12.9060 - val_mae: 1.1380 - val_mse: 2.3080\n",
      "Epoch 660/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3708 - mae: 0.9576 - mse: 1.5636 - val_loss: 12.8757 - val_mae: 1.1116 - val_mse: 2.2415\n",
      "Epoch 661/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3678 - mae: 0.9591 - mse: 1.5672 - val_loss: 12.8551 - val_mae: 1.0957 - val_mse: 2.2104\n",
      "Epoch 662/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3717 - mae: 0.9579 - mse: 1.5630 - val_loss: 12.8515 - val_mae: 1.1069 - val_mse: 2.2462\n",
      "Epoch 663/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3705 - mae: 0.9578 - mse: 1.5697 - val_loss: 12.8542 - val_mae: 1.1213 - val_mse: 2.2844\n",
      "Epoch 664/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3715 - mae: 0.9607 - mse: 1.5777 - val_loss: 12.8712 - val_mae: 1.1111 - val_mse: 2.2394\n",
      "Epoch 665/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3690 - mae: 0.9564 - mse: 1.5584 - val_loss: 12.8657 - val_mae: 1.1293 - val_mse: 2.2987\n",
      "Epoch 666/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.3730 - mae: 0.9627 - mse: 1.5840 - val_loss: 12.8779 - val_mae: 1.0186 - val_mse: 1.9952\n",
      "Epoch 667/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.3692 - mae: 0.9516 - mse: 1.5428 - val_loss: 12.8586 - val_mae: 1.0857 - val_mse: 2.1755\n",
      "Epoch 668/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3697 - mae: 0.9584 - mse: 1.5648 - val_loss: 12.8809 - val_mae: 1.1119 - val_mse: 2.2434\n",
      "Epoch 669/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.3693 - mae: 0.9603 - mse: 1.5740 - val_loss: 12.8808 - val_mae: 1.0571 - val_mse: 2.0874\n",
      "Epoch 670/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3709 - mae: 0.9526 - mse: 1.5513 - val_loss: 12.8541 - val_mae: 1.0514 - val_mse: 2.0821\n",
      "Epoch 671/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3692 - mae: 0.9559 - mse: 1.5565 - val_loss: 12.8833 - val_mae: 1.0395 - val_mse: 2.0326\n",
      "Epoch 672/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3661 - mae: 0.9526 - mse: 1.5453 - val_loss: 12.8882 - val_mae: 1.0236 - val_mse: 1.9942\n",
      "Epoch 673/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 12.3636 - mae: 0.9484 - mse: 1.5310 - val_loss: 12.8618 - val_mae: 1.1036 - val_mse: 2.2282\n",
      "Epoch 674/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3661 - mae: 0.9597 - mse: 1.5660 - val_loss: 12.8513 - val_mae: 1.1180 - val_mse: 2.2880\n",
      "Epoch 675/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3691 - mae: 0.9592 - mse: 1.5698 - val_loss: 12.8711 - val_mae: 1.1441 - val_mse: 2.3410\n",
      "Epoch 676/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3650 - mae: 0.9648 - mse: 1.5812 - val_loss: 12.8770 - val_mae: 1.0194 - val_mse: 1.9983\n",
      "Epoch 677/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3651 - mae: 0.9468 - mse: 1.5360 - val_loss: 12.8650 - val_mae: 1.1171 - val_mse: 2.2652\n",
      "Epoch 678/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3658 - mae: 0.9574 - mse: 1.5687 - val_loss: 12.8934 - val_mae: 1.0590 - val_mse: 2.0830\n",
      "Epoch 679/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3643 - mae: 0.9522 - mse: 1.5531 - val_loss: 12.8946 - val_mae: 1.0065 - val_mse: 1.9475\n",
      "Epoch 680/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.3649 - mae: 0.9475 - mse: 1.5242 - val_loss: 12.8427 - val_mae: 1.0947 - val_mse: 2.2173\n",
      "Epoch 681/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3619 - mae: 0.9577 - mse: 1.5689 - val_loss: 12.8584 - val_mae: 1.0907 - val_mse: 2.1790\n",
      "Epoch 682/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3638 - mae: 0.9564 - mse: 1.5562 - val_loss: 12.8642 - val_mae: 1.0489 - val_mse: 2.0640\n",
      "Epoch 683/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3643 - mae: 0.9524 - mse: 1.5496 - val_loss: 12.8783 - val_mae: 1.0230 - val_mse: 1.9945\n",
      "Epoch 684/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3597 - mae: 0.9468 - mse: 1.5320 - val_loss: 12.8580 - val_mae: 1.0329 - val_mse: 2.0437\n",
      "Epoch 685/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3624 - mae: 0.9493 - mse: 1.5375 - val_loss: 12.8585 - val_mae: 1.1393 - val_mse: 2.3454\n",
      "Epoch 686/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3611 - mae: 0.9586 - mse: 1.5706 - val_loss: 12.8953 - val_mae: 1.0975 - val_mse: 2.1871\n",
      "Epoch 687/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3594 - mae: 0.9521 - mse: 1.5512 - val_loss: 12.8389 - val_mae: 1.0902 - val_mse: 2.2006\n",
      "Epoch 688/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3592 - mae: 0.9589 - mse: 1.5680 - val_loss: 12.8709 - val_mae: 1.0447 - val_mse: 2.0489\n",
      "Epoch 689/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3630 - mae: 0.9513 - mse: 1.5419 - val_loss: 12.8716 - val_mae: 1.1637 - val_mse: 2.4109\n",
      "Epoch 690/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3605 - mae: 0.9594 - mse: 1.5694 - val_loss: 12.9139 - val_mae: 1.1589 - val_mse: 2.3683\n",
      "Epoch 691/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3593 - mae: 0.9570 - mse: 1.5601 - val_loss: 12.8581 - val_mae: 1.0469 - val_mse: 2.0665\n",
      "Epoch 692/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3601 - mae: 0.9519 - mse: 1.5482 - val_loss: 12.8590 - val_mae: 1.0574 - val_mse: 2.0924\n",
      "Epoch 693/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3601 - mae: 0.9537 - mse: 1.5572 - val_loss: 12.8498 - val_mae: 1.0957 - val_mse: 2.2077\n",
      "Epoch 694/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3624 - mae: 0.9558 - mse: 1.5597 - val_loss: 12.8741 - val_mae: 1.1516 - val_mse: 2.3590\n",
      "Epoch 695/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.3593 - mae: 0.9556 - mse: 1.5573 - val_loss: 12.9776 - val_mae: 1.2625 - val_mse: 2.6892\n",
      "Epoch 696/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3678 - mae: 0.9736 - mse: 1.6096 - val_loss: 12.8450 - val_mae: 1.0857 - val_mse: 2.1823\n",
      "Epoch 697/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3600 - mae: 0.9561 - mse: 1.5683 - val_loss: 12.8540 - val_mae: 1.0544 - val_mse: 2.0860\n",
      "Epoch 698/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3594 - mae: 0.9529 - mse: 1.5491 - val_loss: 12.8612 - val_mae: 1.1160 - val_mse: 2.2613\n",
      "Epoch 699/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3520 - mae: 0.9530 - mse: 1.5485 - val_loss: 12.8693 - val_mae: 1.1579 - val_mse: 2.3921\n",
      "Epoch 700/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3570 - mae: 0.9585 - mse: 1.5715 - val_loss: 12.8556 - val_mae: 1.0597 - val_mse: 2.0993\n",
      "Epoch 701/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3570 - mae: 0.9542 - mse: 1.5548 - val_loss: 12.8687 - val_mae: 1.0906 - val_mse: 2.1787\n",
      "Epoch 702/1000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 12.3497 - mae: 0.9485 - mse: 1.5357 - val_loss: 12.8399 - val_mae: 1.1029 - val_mse: 2.2518\n",
      "Epoch 703/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 12.3562 - mae: 0.9540 - mse: 1.5575 - val_loss: 12.8549 - val_mae: 1.0673 - val_mse: 2.1200\n",
      "Epoch 704/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 12.3521 - mae: 0.9522 - mse: 1.5477 - val_loss: 12.8818 - val_mae: 1.0672 - val_mse: 2.1061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 705/1000\n",
      "1030/1030 [==============================] - 0s 51us/sample - loss: 12.3531 - mae: 0.9512 - mse: 1.5406 - val_loss: 12.9165 - val_mae: 1.1536 - val_mse: 2.3489\n",
      "Epoch 706/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.3522 - mae: 0.9588 - mse: 1.5602 - val_loss: 12.8587 - val_mae: 1.0496 - val_mse: 2.0671\n",
      "Epoch 707/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.3538 - mae: 0.9521 - mse: 1.5483 - val_loss: 12.8429 - val_mae: 1.1071 - val_mse: 2.2411\n",
      "Epoch 708/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3517 - mae: 0.9564 - mse: 1.5546 - val_loss: 12.8668 - val_mae: 1.0439 - val_mse: 2.0524\n",
      "Epoch 709/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3557 - mae: 0.9525 - mse: 1.5478 - val_loss: 12.8566 - val_mae: 1.0818 - val_mse: 2.1655\n",
      "Epoch 710/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3556 - mae: 0.9558 - mse: 1.5600 - val_loss: 12.8688 - val_mae: 1.0538 - val_mse: 2.0762\n",
      "Epoch 711/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.3473 - mae: 0.9486 - mse: 1.5361 - val_loss: 12.8614 - val_mae: 1.1345 - val_mse: 2.3132\n",
      "Epoch 712/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3516 - mae: 0.9586 - mse: 1.5703 - val_loss: 12.8469 - val_mae: 1.0937 - val_mse: 2.1983\n",
      "Epoch 713/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3481 - mae: 0.9514 - mse: 1.5461 - val_loss: 12.8378 - val_mae: 1.1014 - val_mse: 2.2379\n",
      "Epoch 714/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3546 - mae: 0.9552 - mse: 1.5616 - val_loss: 12.8370 - val_mae: 1.0814 - val_mse: 2.1684\n",
      "Epoch 715/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3484 - mae: 0.9485 - mse: 1.5350 - val_loss: 12.8467 - val_mae: 1.1179 - val_mse: 2.2650\n",
      "Epoch 716/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3523 - mae: 0.9563 - mse: 1.5549 - val_loss: 12.8835 - val_mae: 1.0807 - val_mse: 2.1445\n",
      "Epoch 717/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3484 - mae: 0.9468 - mse: 1.5339 - val_loss: 12.8814 - val_mae: 1.1634 - val_mse: 2.3964\n",
      "Epoch 718/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3470 - mae: 0.9554 - mse: 1.5569 - val_loss: 12.8578 - val_mae: 1.1366 - val_mse: 2.3633\n",
      "Epoch 719/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.3492 - mae: 0.9574 - mse: 1.5596 - val_loss: 12.8591 - val_mae: 1.0914 - val_mse: 2.1842\n",
      "Epoch 720/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3483 - mae: 0.9541 - mse: 1.5543 - val_loss: 12.8991 - val_mae: 1.0113 - val_mse: 1.9540\n",
      "Epoch 721/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3478 - mae: 0.9444 - mse: 1.5198 - val_loss: 12.8531 - val_mae: 1.0461 - val_mse: 2.0592\n",
      "Epoch 722/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3461 - mae: 0.9499 - mse: 1.5409 - val_loss: 12.8980 - val_mae: 1.0605 - val_mse: 2.0829\n",
      "Epoch 723/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3491 - mae: 0.9508 - mse: 1.5438 - val_loss: 12.8476 - val_mae: 1.0605 - val_mse: 2.1054\n",
      "Epoch 724/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3397 - mae: 0.9465 - mse: 1.5347 - val_loss: 12.8446 - val_mae: 1.0699 - val_mse: 2.1299\n",
      "Epoch 725/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3472 - mae: 0.9518 - mse: 1.5503 - val_loss: 12.8601 - val_mae: 1.0729 - val_mse: 2.1294\n",
      "Epoch 726/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3451 - mae: 0.9498 - mse: 1.5401 - val_loss: 12.8669 - val_mae: 1.0129 - val_mse: 1.9879\n",
      "Epoch 727/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3486 - mae: 0.9453 - mse: 1.5319 - val_loss: 12.8296 - val_mae: 1.0742 - val_mse: 2.1473\n",
      "Epoch 728/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3435 - mae: 0.9534 - mse: 1.5479 - val_loss: 12.8542 - val_mae: 1.0259 - val_mse: 2.0029\n",
      "Epoch 729/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.3446 - mae: 0.9446 - mse: 1.5292 - val_loss: 12.8503 - val_mae: 1.1368 - val_mse: 2.3293\n",
      "Epoch 730/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3413 - mae: 0.9531 - mse: 1.5490 - val_loss: 12.8418 - val_mae: 1.0800 - val_mse: 2.1560\n",
      "Epoch 731/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3488 - mae: 0.9546 - mse: 1.5556 - val_loss: 12.8435 - val_mae: 1.0768 - val_mse: 2.1495\n",
      "Epoch 732/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3463 - mae: 0.9507 - mse: 1.5453 - val_loss: 12.8672 - val_mae: 1.0370 - val_mse: 2.0284\n",
      "Epoch 733/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3426 - mae: 0.9459 - mse: 1.5252 - val_loss: 12.8485 - val_mae: 1.0471 - val_mse: 2.0623\n",
      "Epoch 734/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3428 - mae: 0.9480 - mse: 1.5422 - val_loss: 12.8878 - val_mae: 1.0455 - val_mse: 2.0441\n",
      "Epoch 735/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3423 - mae: 0.9451 - mse: 1.5307 - val_loss: 12.8753 - val_mae: 1.0789 - val_mse: 2.1370\n",
      "Epoch 736/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3399 - mae: 0.9499 - mse: 1.5359 - val_loss: 12.8456 - val_mae: 1.1363 - val_mse: 2.3571\n",
      "Epoch 737/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.3431 - mae: 0.9611 - mse: 1.5776 - val_loss: 12.8689 - val_mae: 1.0800 - val_mse: 2.1432\n",
      "Epoch 738/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3391 - mae: 0.9519 - mse: 1.5486 - val_loss: 12.9049 - val_mae: 0.9914 - val_mse: 1.9081\n",
      "Epoch 739/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3442 - mae: 0.9408 - mse: 1.5095 - val_loss: 12.8501 - val_mae: 1.0304 - val_mse: 2.0207\n",
      "Epoch 740/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3371 - mae: 0.9478 - mse: 1.5348 - val_loss: 12.8712 - val_mae: 1.0848 - val_mse: 2.1563\n",
      "Epoch 741/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3408 - mae: 0.9471 - mse: 1.5297 - val_loss: 12.8304 - val_mae: 1.0901 - val_mse: 2.1967\n",
      "Epoch 742/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3372 - mae: 0.9502 - mse: 1.5390 - val_loss: 12.8462 - val_mae: 1.0879 - val_mse: 2.1798\n",
      "Epoch 743/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3419 - mae: 0.9516 - mse: 1.5551 - val_loss: 12.8308 - val_mae: 1.0678 - val_mse: 2.1347\n",
      "Epoch 744/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3410 - mae: 0.9496 - mse: 1.5423 - val_loss: 12.8358 - val_mae: 1.1081 - val_mse: 2.2491\n",
      "Epoch 745/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3375 - mae: 0.9518 - mse: 1.5450 - val_loss: 12.8799 - val_mae: 1.1424 - val_mse: 2.3283\n",
      "Epoch 746/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3400 - mae: 0.9526 - mse: 1.5521 - val_loss: 12.8289 - val_mae: 1.0891 - val_mse: 2.2072\n",
      "Epoch 747/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3361 - mae: 0.9511 - mse: 1.5517 - val_loss: 12.9048 - val_mae: 1.0111 - val_mse: 1.9530\n",
      "Epoch 748/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3361 - mae: 0.9426 - mse: 1.5139 - val_loss: 12.8685 - val_mae: 1.1072 - val_mse: 2.2218\n",
      "Epoch 749/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3350 - mae: 0.9488 - mse: 1.5401 - val_loss: 12.8699 - val_mae: 1.1305 - val_mse: 2.2900\n",
      "Epoch 750/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3364 - mae: 0.9516 - mse: 1.5425 - val_loss: 12.8792 - val_mae: 1.1662 - val_mse: 2.4052\n",
      "Epoch 751/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3388 - mae: 0.9576 - mse: 1.5654 - val_loss: 12.9066 - val_mae: 1.0782 - val_mse: 2.1281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 752/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3377 - mae: 0.9517 - mse: 1.5440 - val_loss: 12.8888 - val_mae: 1.0409 - val_mse: 2.0355\n",
      "Epoch 753/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.3361 - mae: 0.9509 - mse: 1.5411 - val_loss: 12.9294 - val_mae: 0.9783 - val_mse: 1.8743\n",
      "Epoch 754/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3341 - mae: 0.9383 - mse: 1.5120 - val_loss: 12.8311 - val_mae: 1.0895 - val_mse: 2.1892\n",
      "Epoch 755/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3329 - mae: 0.9513 - mse: 1.5406 - val_loss: 12.8671 - val_mae: 1.1299 - val_mse: 2.2963\n",
      "Epoch 756/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3354 - mae: 0.9550 - mse: 1.5581 - val_loss: 12.9142 - val_mae: 1.0053 - val_mse: 1.9370\n",
      "Epoch 757/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.3334 - mae: 0.9394 - mse: 1.5136 - val_loss: 12.8871 - val_mae: 1.0051 - val_mse: 1.9471\n",
      "Epoch 758/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3380 - mae: 0.9417 - mse: 1.5252 - val_loss: 12.8455 - val_mae: 1.1222 - val_mse: 2.2801\n",
      "Epoch 759/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3354 - mae: 0.9524 - mse: 1.5485 - val_loss: 12.8338 - val_mae: 1.0921 - val_mse: 2.1991\n",
      "Epoch 760/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.3323 - mae: 0.9517 - mse: 1.5514 - val_loss: 12.8362 - val_mae: 1.0390 - val_mse: 2.0644\n",
      "Epoch 761/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3351 - mae: 0.9489 - mse: 1.5445 - val_loss: 12.8388 - val_mae: 1.0589 - val_mse: 2.0945\n",
      "Epoch 762/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3349 - mae: 0.9490 - mse: 1.5447 - val_loss: 12.8524 - val_mae: 1.0156 - val_mse: 1.9767\n",
      "Epoch 763/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3323 - mae: 0.9439 - mse: 1.5158 - val_loss: 12.8469 - val_mae: 1.0945 - val_mse: 2.1948\n",
      "Epoch 764/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3299 - mae: 0.9502 - mse: 1.5396 - val_loss: 12.8472 - val_mae: 1.0938 - val_mse: 2.1936\n",
      "Epoch 765/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.3266 - mae: 0.9506 - mse: 1.5494 - val_loss: 12.8413 - val_mae: 1.0194 - val_mse: 2.0053\n",
      "Epoch 766/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3326 - mae: 0.9470 - mse: 1.5287 - val_loss: 12.8578 - val_mae: 1.0320 - val_mse: 2.0136\n",
      "Epoch 767/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3301 - mae: 0.9442 - mse: 1.5193 - val_loss: 12.8427 - val_mae: 1.0427 - val_mse: 2.0496\n",
      "Epoch 768/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3363 - mae: 0.9484 - mse: 1.5356 - val_loss: 12.8246 - val_mae: 1.0680 - val_mse: 2.1302\n",
      "Epoch 769/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3289 - mae: 0.9477 - mse: 1.5348 - val_loss: 12.8262 - val_mae: 1.1156 - val_mse: 2.2713\n",
      "Epoch 770/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3322 - mae: 0.9520 - mse: 1.5472 - val_loss: 12.8282 - val_mae: 1.0642 - val_mse: 2.1189\n",
      "Epoch 771/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3324 - mae: 0.9458 - mse: 1.5309 - val_loss: 12.8233 - val_mae: 1.1114 - val_mse: 2.2725\n",
      "Epoch 772/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.3307 - mae: 0.9489 - mse: 1.5424 - val_loss: 12.8561 - val_mae: 1.1117 - val_mse: 2.2429\n",
      "Epoch 773/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.3289 - mae: 0.9473 - mse: 1.5363 - val_loss: 12.8791 - val_mae: 1.1929 - val_mse: 2.4924\n",
      "Epoch 774/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3225 - mae: 0.9578 - mse: 1.5634 - val_loss: 12.8232 - val_mae: 1.0721 - val_mse: 2.1423\n",
      "Epoch 775/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3308 - mae: 0.9460 - mse: 1.5347 - val_loss: 12.8964 - val_mae: 1.1728 - val_mse: 2.4131\n",
      "Epoch 776/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3259 - mae: 0.9565 - mse: 1.5585 - val_loss: 12.8456 - val_mae: 1.1116 - val_mse: 2.2398\n",
      "Epoch 777/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3272 - mae: 0.9508 - mse: 1.5434 - val_loss: 12.8236 - val_mae: 1.0494 - val_mse: 2.0832\n",
      "Epoch 778/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.3288 - mae: 0.9516 - mse: 1.5392 - val_loss: 12.8189 - val_mae: 1.0642 - val_mse: 2.1176\n",
      "Epoch 779/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3240 - mae: 0.9508 - mse: 1.5355 - val_loss: 12.8377 - val_mae: 1.1038 - val_mse: 2.2206\n",
      "Epoch 780/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3263 - mae: 0.9473 - mse: 1.5312 - val_loss: 12.8688 - val_mae: 1.1713 - val_mse: 2.4151\n",
      "Epoch 781/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3292 - mae: 0.9544 - mse: 1.5550 - val_loss: 12.9034 - val_mae: 1.1155 - val_mse: 2.2333\n",
      "Epoch 782/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3230 - mae: 0.9477 - mse: 1.5325 - val_loss: 12.8270 - val_mae: 1.0910 - val_mse: 2.1871\n",
      "Epoch 783/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3312 - mae: 0.9492 - mse: 1.5426 - val_loss: 12.8557 - val_mae: 1.0532 - val_mse: 2.0702\n",
      "Epoch 784/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.3285 - mae: 0.9459 - mse: 1.5314 - val_loss: 12.8171 - val_mae: 1.1007 - val_mse: 2.2301\n",
      "Epoch 785/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 12.3270 - mae: 0.9492 - mse: 1.5413 - val_loss: 12.8197 - val_mae: 1.0728 - val_mse: 2.1428\n",
      "Epoch 786/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3259 - mae: 0.9503 - mse: 1.5405 - val_loss: 12.8256 - val_mae: 1.1178 - val_mse: 2.2810\n",
      "Epoch 787/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.3249 - mae: 0.9503 - mse: 1.5473 - val_loss: 12.8139 - val_mae: 1.0912 - val_mse: 2.2072\n",
      "Epoch 788/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3263 - mae: 0.9521 - mse: 1.5488 - val_loss: 12.8558 - val_mae: 1.0161 - val_mse: 1.9787\n",
      "Epoch 789/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3213 - mae: 0.9390 - mse: 1.5101 - val_loss: 12.8287 - val_mae: 1.0861 - val_mse: 2.1754\n",
      "Epoch 790/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3256 - mae: 0.9486 - mse: 1.5399 - val_loss: 12.8315 - val_mae: 1.1083 - val_mse: 2.2423\n",
      "Epoch 791/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.3251 - mae: 0.9493 - mse: 1.5408 - val_loss: 12.8804 - val_mae: 1.0773 - val_mse: 2.1303\n",
      "Epoch 792/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3212 - mae: 0.9443 - mse: 1.5239 - val_loss: 12.8522 - val_mae: 1.0925 - val_mse: 2.1838\n",
      "Epoch 793/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3203 - mae: 0.9455 - mse: 1.5274 - val_loss: 12.8150 - val_mae: 1.0634 - val_mse: 2.1355\n",
      "Epoch 794/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3267 - mae: 0.9474 - mse: 1.5324 - val_loss: 12.8142 - val_mae: 1.0923 - val_mse: 2.2022\n",
      "Epoch 795/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3210 - mae: 0.9453 - mse: 1.5280 - val_loss: 12.8348 - val_mae: 1.1222 - val_mse: 2.2863\n",
      "Epoch 796/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3209 - mae: 0.9461 - mse: 1.5295 - val_loss: 12.8501 - val_mae: 1.1395 - val_mse: 2.3257\n",
      "Epoch 797/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.3208 - mae: 0.9509 - mse: 1.5485 - val_loss: 12.8447 - val_mae: 1.0701 - val_mse: 2.1190\n",
      "Epoch 798/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3167 - mae: 0.9419 - mse: 1.5160 - val_loss: 12.8262 - val_mae: 1.1305 - val_mse: 2.3243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3190 - mae: 0.9499 - mse: 1.5462 - val_loss: 12.8643 - val_mae: 1.0487 - val_mse: 2.0568\n",
      "Epoch 800/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3193 - mae: 0.9427 - mse: 1.5159 - val_loss: 12.8194 - val_mae: 1.1025 - val_mse: 2.2329\n",
      "Epoch 801/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3180 - mae: 0.9441 - mse: 1.5254 - val_loss: 12.8382 - val_mae: 1.1466 - val_mse: 2.3552\n",
      "Epoch 802/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3223 - mae: 0.9537 - mse: 1.5544 - val_loss: 12.8130 - val_mae: 1.0518 - val_mse: 2.0813\n",
      "Epoch 803/1000\n",
      "1030/1030 [==============================] - 0s 38us/sample - loss: 12.3213 - mae: 0.9439 - mse: 1.5220 - val_loss: 12.8288 - val_mae: 1.0621 - val_mse: 2.1047\n",
      "Epoch 804/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3203 - mae: 0.9439 - mse: 1.5272 - val_loss: 12.8084 - val_mae: 1.1033 - val_mse: 2.2440\n",
      "Epoch 805/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3167 - mae: 0.9475 - mse: 1.5396 - val_loss: 12.8253 - val_mae: 1.1282 - val_mse: 2.3061\n",
      "Epoch 806/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3192 - mae: 0.9507 - mse: 1.5399 - val_loss: 12.8108 - val_mae: 1.0740 - val_mse: 2.1541\n",
      "Epoch 807/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3207 - mae: 0.9460 - mse: 1.5296 - val_loss: 12.8778 - val_mae: 1.1798 - val_mse: 2.4399\n",
      "Epoch 808/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.3226 - mae: 0.9537 - mse: 1.5460 - val_loss: 12.8071 - val_mae: 1.0771 - val_mse: 2.1756\n",
      "Epoch 809/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3160 - mae: 0.9464 - mse: 1.5369 - val_loss: 12.8097 - val_mae: 1.0697 - val_mse: 2.1609\n",
      "Epoch 810/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3148 - mae: 0.9461 - mse: 1.5246 - val_loss: 12.8092 - val_mae: 1.0812 - val_mse: 2.1784\n",
      "Epoch 811/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3118 - mae: 0.9409 - mse: 1.5206 - val_loss: 12.8193 - val_mae: 1.0428 - val_mse: 2.0793\n",
      "Epoch 812/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.3171 - mae: 0.9432 - mse: 1.5229 - val_loss: 12.8325 - val_mae: 1.0219 - val_mse: 1.9973\n",
      "Epoch 813/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3196 - mae: 0.9493 - mse: 1.5376 - val_loss: 12.8167 - val_mae: 1.0518 - val_mse: 2.0832\n",
      "Epoch 814/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3167 - mae: 0.9427 - mse: 1.5219 - val_loss: 12.8255 - val_mae: 1.0553 - val_mse: 2.0831\n",
      "Epoch 815/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3130 - mae: 0.9439 - mse: 1.5217 - val_loss: 12.8449 - val_mae: 1.0126 - val_mse: 1.9720\n",
      "Epoch 816/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3151 - mae: 0.9403 - mse: 1.5087 - val_loss: 12.8497 - val_mae: 1.0026 - val_mse: 1.9485\n",
      "Epoch 817/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3120 - mae: 0.9338 - mse: 1.4980 - val_loss: 12.8844 - val_mae: 1.2097 - val_mse: 2.5377\n",
      "Epoch 818/1000\n",
      "1030/1030 [==============================] - 0s 38us/sample - loss: 12.3193 - mae: 0.9591 - mse: 1.5664 - val_loss: 12.8176 - val_mae: 1.0345 - val_mse: 2.0339\n",
      "Epoch 819/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3129 - mae: 0.9400 - mse: 1.5199 - val_loss: 12.8259 - val_mae: 1.0994 - val_mse: 2.2078\n",
      "Epoch 820/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3123 - mae: 0.9454 - mse: 1.5279 - val_loss: 12.8080 - val_mae: 1.1019 - val_mse: 2.2311\n",
      "Epoch 821/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3145 - mae: 0.9432 - mse: 1.5291 - val_loss: 12.8021 - val_mae: 1.0673 - val_mse: 2.1319\n",
      "Epoch 822/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3145 - mae: 0.9427 - mse: 1.5208 - val_loss: 12.8196 - val_mae: 1.0526 - val_mse: 2.0794\n",
      "Epoch 823/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.3135 - mae: 0.9391 - mse: 1.5086 - val_loss: 12.8508 - val_mae: 1.1758 - val_mse: 2.4718\n",
      "Epoch 824/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3173 - mae: 0.9570 - mse: 1.5605 - val_loss: 12.8145 - val_mae: 1.0728 - val_mse: 2.1447\n",
      "Epoch 825/1000\n",
      "1030/1030 [==============================] - 0s 50us/sample - loss: 12.3110 - mae: 0.9443 - mse: 1.5241 - val_loss: 12.8325 - val_mae: 1.0626 - val_mse: 2.1043\n",
      "Epoch 826/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3080 - mae: 0.9429 - mse: 1.5172 - val_loss: 12.8349 - val_mae: 1.0244 - val_mse: 2.0077\n",
      "Epoch 827/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3089 - mae: 0.9363 - mse: 1.5113 - val_loss: 12.8206 - val_mae: 1.0402 - val_mse: 2.0465\n",
      "Epoch 828/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.3128 - mae: 0.9378 - mse: 1.5105 - val_loss: 12.8812 - val_mae: 1.2079 - val_mse: 2.5401\n",
      "Epoch 829/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3121 - mae: 0.9536 - mse: 1.5520 - val_loss: 12.8401 - val_mae: 1.1551 - val_mse: 2.3822\n",
      "Epoch 830/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3116 - mae: 0.9465 - mse: 1.5248 - val_loss: 12.8909 - val_mae: 1.2209 - val_mse: 2.5858\n",
      "Epoch 831/1000\n",
      "1030/1030 [==============================] - 0s 49us/sample - loss: 12.3191 - mae: 0.9570 - mse: 1.5636 - val_loss: 12.8366 - val_mae: 1.0875 - val_mse: 2.1654\n",
      "Epoch 832/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3062 - mae: 0.9418 - mse: 1.5182 - val_loss: 12.8225 - val_mae: 1.0547 - val_mse: 2.0828\n",
      "Epoch 833/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3082 - mae: 0.9405 - mse: 1.5180 - val_loss: 12.9122 - val_mae: 1.1684 - val_mse: 2.3907\n",
      "Epoch 834/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3105 - mae: 0.9491 - mse: 1.5417 - val_loss: 12.8541 - val_mae: 0.9930 - val_mse: 1.9261\n",
      "Epoch 835/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3116 - mae: 0.9345 - mse: 1.5008 - val_loss: 12.8216 - val_mae: 1.1375 - val_mse: 2.3345\n",
      "Epoch 836/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3073 - mae: 0.9503 - mse: 1.5392 - val_loss: 12.8377 - val_mae: 1.0969 - val_mse: 2.1940\n",
      "Epoch 837/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3078 - mae: 0.9409 - mse: 1.5157 - val_loss: 12.8073 - val_mae: 1.1166 - val_mse: 2.2837\n",
      "Epoch 838/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.3073 - mae: 0.9443 - mse: 1.5269 - val_loss: 12.8247 - val_mae: 1.1374 - val_mse: 2.3339\n",
      "Epoch 839/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.3061 - mae: 0.9485 - mse: 1.5423 - val_loss: 12.8189 - val_mae: 1.0674 - val_mse: 2.1182\n",
      "Epoch 840/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3061 - mae: 0.9367 - mse: 1.5094 - val_loss: 12.8838 - val_mae: 1.2071 - val_mse: 2.5277\n",
      "Epoch 841/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3092 - mae: 0.9588 - mse: 1.5686 - val_loss: 12.8762 - val_mae: 0.9999 - val_mse: 1.9273\n",
      "Epoch 842/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3092 - mae: 0.9328 - mse: 1.4946 - val_loss: 12.8606 - val_mae: 1.1245 - val_mse: 2.2672\n",
      "Epoch 843/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3080 - mae: 0.9461 - mse: 1.5302 - val_loss: 12.8198 - val_mae: 1.0542 - val_mse: 2.0856\n",
      "Epoch 844/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.3061 - mae: 0.9382 - mse: 1.5067 - val_loss: 12.8051 - val_mae: 1.0917 - val_mse: 2.1965\n",
      "Epoch 845/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.3061 - mae: 0.9378 - mse: 1.5083 - val_loss: 12.8088 - val_mae: 1.0833 - val_mse: 2.1716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 846/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.3036 - mae: 0.9427 - mse: 1.5158 - val_loss: 12.8127 - val_mae: 1.1307 - val_mse: 2.3268\n",
      "Epoch 847/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3034 - mae: 0.9484 - mse: 1.5411 - val_loss: 12.8417 - val_mae: 1.0103 - val_mse: 1.9687\n",
      "Epoch 848/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3019 - mae: 0.9381 - mse: 1.5055 - val_loss: 12.9081 - val_mae: 0.9938 - val_mse: 1.9060\n",
      "Epoch 849/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3072 - mae: 0.9359 - mse: 1.4987 - val_loss: 12.8359 - val_mae: 1.1108 - val_mse: 2.2350\n",
      "Epoch 850/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2998 - mae: 0.9402 - mse: 1.5080 - val_loss: 12.8315 - val_mae: 1.0873 - val_mse: 2.1714\n",
      "Epoch 851/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.3003 - mae: 0.9456 - mse: 1.5222 - val_loss: 12.8097 - val_mae: 1.0456 - val_mse: 2.0734\n",
      "Epoch 852/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2997 - mae: 0.9379 - mse: 1.5057 - val_loss: 12.8028 - val_mae: 1.0664 - val_mse: 2.1310\n",
      "Epoch 853/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3029 - mae: 0.9389 - mse: 1.5154 - val_loss: 12.8346 - val_mae: 1.1287 - val_mse: 2.2948\n",
      "Epoch 854/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3005 - mae: 0.9435 - mse: 1.5213 - val_loss: 12.8485 - val_mae: 1.1654 - val_mse: 2.4099\n",
      "Epoch 855/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.3047 - mae: 0.9514 - mse: 1.5464 - val_loss: 12.8303 - val_mae: 1.0209 - val_mse: 2.0027\n",
      "Epoch 856/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3021 - mae: 0.9408 - mse: 1.5148 - val_loss: 12.8272 - val_mae: 1.0796 - val_mse: 2.1560\n",
      "Epoch 857/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2910 - mae: 0.9436 - mse: 1.5171 - val_loss: 12.8335 - val_mae: 1.0155 - val_mse: 2.0031\n",
      "Epoch 858/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3034 - mae: 0.9374 - mse: 1.5097 - val_loss: 12.8445 - val_mae: 1.1110 - val_mse: 2.2284\n",
      "Epoch 859/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.2991 - mae: 0.9401 - mse: 1.5130 - val_loss: 12.8448 - val_mae: 1.1614 - val_mse: 2.3925\n",
      "Epoch 860/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.3007 - mae: 0.9474 - mse: 1.5300 - val_loss: 12.8270 - val_mae: 1.1424 - val_mse: 2.3479\n",
      "Epoch 861/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3011 - mae: 0.9452 - mse: 1.5353 - val_loss: 12.8134 - val_mae: 1.0760 - val_mse: 2.1477\n",
      "Epoch 862/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.2960 - mae: 0.9403 - mse: 1.5074 - val_loss: 12.8302 - val_mae: 1.0692 - val_mse: 2.1244\n",
      "Epoch 863/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.2983 - mae: 0.9390 - mse: 1.5183 - val_loss: 12.8241 - val_mae: 1.0346 - val_mse: 2.0304\n",
      "Epoch 864/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.3050 - mae: 0.9440 - mse: 1.5219 - val_loss: 12.8071 - val_mae: 1.0947 - val_mse: 2.2071\n",
      "Epoch 865/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.2955 - mae: 0.9422 - mse: 1.5246 - val_loss: 12.8709 - val_mae: 1.0820 - val_mse: 2.1411\n",
      "Epoch 866/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.2995 - mae: 0.9403 - mse: 1.5120 - val_loss: 12.7980 - val_mae: 1.0809 - val_mse: 2.1813\n",
      "Epoch 867/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.2963 - mae: 0.9378 - mse: 1.5012 - val_loss: 12.8060 - val_mae: 1.1108 - val_mse: 2.2644\n",
      "Epoch 868/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.2990 - mae: 0.9435 - mse: 1.5196 - val_loss: 12.8038 - val_mae: 1.1031 - val_mse: 2.2482\n",
      "Epoch 869/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2949 - mae: 0.9393 - mse: 1.5135 - val_loss: 12.8035 - val_mae: 1.0581 - val_mse: 2.1160\n",
      "Epoch 870/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2987 - mae: 0.9367 - mse: 1.5077 - val_loss: 12.8188 - val_mae: 1.0964 - val_mse: 2.2003\n",
      "Epoch 871/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.2968 - mae: 0.9432 - mse: 1.5199 - val_loss: 12.8704 - val_mae: 1.1330 - val_mse: 2.2867\n",
      "Epoch 872/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2969 - mae: 0.9466 - mse: 1.5262 - val_loss: 12.8766 - val_mae: 1.0177 - val_mse: 1.9723\n",
      "Epoch 873/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.2975 - mae: 0.9390 - mse: 1.5008 - val_loss: 12.8022 - val_mae: 1.0517 - val_mse: 2.0854\n",
      "Epoch 874/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2970 - mae: 0.9363 - mse: 1.5016 - val_loss: 12.8612 - val_mae: 1.1849 - val_mse: 2.4631\n",
      "Epoch 875/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.2995 - mae: 0.9455 - mse: 1.5280 - val_loss: 12.8156 - val_mae: 1.1103 - val_mse: 2.2450\n",
      "Epoch 876/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2958 - mae: 0.9477 - mse: 1.5305 - val_loss: 12.9014 - val_mae: 0.9697 - val_mse: 1.8614\n",
      "Epoch 877/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.3043 - mae: 0.9242 - mse: 1.4711 - val_loss: 12.8212 - val_mae: 1.0242 - val_mse: 2.0098\n",
      "Epoch 878/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.3010 - mae: 0.9364 - mse: 1.5011 - val_loss: 12.7926 - val_mae: 1.0816 - val_mse: 2.1761\n",
      "Epoch 879/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.2936 - mae: 0.9412 - mse: 1.5110 - val_loss: 12.8029 - val_mae: 1.0506 - val_mse: 2.0856\n",
      "Epoch 880/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.2948 - mae: 0.9378 - mse: 1.5102 - val_loss: 12.8270 - val_mae: 1.1421 - val_mse: 2.3446\n",
      "Epoch 881/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2958 - mae: 0.9478 - mse: 1.5339 - val_loss: 12.8462 - val_mae: 1.0478 - val_mse: 2.0567\n",
      "Epoch 882/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2889 - mae: 0.9362 - mse: 1.5027 - val_loss: 12.8089 - val_mae: 1.0446 - val_mse: 2.0596\n",
      "Epoch 883/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.2968 - mae: 0.9379 - mse: 1.5021 - val_loss: 12.8282 - val_mae: 1.0666 - val_mse: 2.1142\n",
      "Epoch 884/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.2916 - mae: 0.9397 - mse: 1.5060 - val_loss: 12.8193 - val_mae: 1.1294 - val_mse: 2.3086\n",
      "Epoch 885/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2956 - mae: 0.9424 - mse: 1.5173 - val_loss: 12.7932 - val_mae: 1.0566 - val_mse: 2.1119\n",
      "Epoch 886/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2960 - mae: 0.9363 - mse: 1.5056 - val_loss: 12.8181 - val_mae: 1.1452 - val_mse: 2.3538\n",
      "Epoch 887/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.2957 - mae: 0.9414 - mse: 1.5176 - val_loss: 12.7924 - val_mae: 1.0611 - val_mse: 2.1162\n",
      "Epoch 888/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2981 - mae: 0.9424 - mse: 1.5171 - val_loss: 12.8118 - val_mae: 1.0696 - val_mse: 2.1281\n",
      "Epoch 889/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2922 - mae: 0.9360 - mse: 1.5027 - val_loss: 12.8067 - val_mae: 1.1200 - val_mse: 2.2873\n",
      "Epoch 890/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.2936 - mae: 0.9473 - mse: 1.5326 - val_loss: 12.8820 - val_mae: 1.0566 - val_mse: 2.0692\n",
      "Epoch 891/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.2959 - mae: 0.9336 - mse: 1.5003 - val_loss: 12.8518 - val_mae: 1.0655 - val_mse: 2.0999\n",
      "Epoch 892/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.2880 - mae: 0.9375 - mse: 1.4985 - val_loss: 12.8027 - val_mae: 1.0587 - val_mse: 2.1010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 893/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2879 - mae: 0.9367 - mse: 1.5030 - val_loss: 12.8714 - val_mae: 1.1710 - val_mse: 2.4080\n",
      "Epoch 894/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2893 - mae: 0.9485 - mse: 1.5320 - val_loss: 12.8034 - val_mae: 1.1248 - val_mse: 2.3047\n",
      "Epoch 895/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.2925 - mae: 0.9481 - mse: 1.5371 - val_loss: 12.8223 - val_mae: 1.0135 - val_mse: 1.9726\n",
      "Epoch 896/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2915 - mae: 0.9327 - mse: 1.4924 - val_loss: 12.8367 - val_mae: 1.0787 - val_mse: 2.1401\n",
      "Epoch 897/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.2856 - mae: 0.9351 - mse: 1.4907 - val_loss: 12.8146 - val_mae: 1.1161 - val_mse: 2.2603\n",
      "Epoch 898/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.2893 - mae: 0.9448 - mse: 1.5230 - val_loss: 12.8456 - val_mae: 1.0560 - val_mse: 2.0796\n",
      "Epoch 899/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.2884 - mae: 0.9379 - mse: 1.5037 - val_loss: 12.7937 - val_mae: 1.0815 - val_mse: 2.1826\n",
      "Epoch 900/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2873 - mae: 0.9376 - mse: 1.5066 - val_loss: 12.8057 - val_mae: 1.1374 - val_mse: 2.3444\n",
      "Epoch 901/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2905 - mae: 0.9429 - mse: 1.5223 - val_loss: 12.8399 - val_mae: 1.1803 - val_mse: 2.4561\n",
      "Epoch 902/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.2883 - mae: 0.9520 - mse: 1.5440 - val_loss: 12.8119 - val_mae: 1.0352 - val_mse: 2.0304\n",
      "Epoch 903/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.2836 - mae: 0.9366 - mse: 1.4966 - val_loss: 12.7920 - val_mae: 1.0454 - val_mse: 2.0750\n",
      "Epoch 904/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2858 - mae: 0.9411 - mse: 1.5131 - val_loss: 12.8540 - val_mae: 0.9918 - val_mse: 1.9172\n",
      "Epoch 905/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2894 - mae: 0.9335 - mse: 1.4924 - val_loss: 12.8452 - val_mae: 0.9898 - val_mse: 1.9199\n",
      "Epoch 906/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2892 - mae: 0.9339 - mse: 1.4918 - val_loss: 12.8085 - val_mae: 1.1132 - val_mse: 2.2506\n",
      "Epoch 907/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.2892 - mae: 0.9423 - mse: 1.5205 - val_loss: 12.8669 - val_mae: 1.0122 - val_mse: 1.9555\n",
      "Epoch 908/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2937 - mae: 0.9327 - mse: 1.4871 - val_loss: 12.8382 - val_mae: 1.0330 - val_mse: 2.0146\n",
      "Epoch 909/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2836 - mae: 0.9301 - mse: 1.4812 - val_loss: 12.8012 - val_mae: 1.0844 - val_mse: 2.1748\n",
      "Epoch 910/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.2876 - mae: 0.9430 - mse: 1.5191 - val_loss: 12.7949 - val_mae: 1.0936 - val_mse: 2.2084\n",
      "Epoch 911/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.2844 - mae: 0.9410 - mse: 1.5145 - val_loss: 12.8273 - val_mae: 1.0066 - val_mse: 1.9562\n",
      "Epoch 912/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.2778 - mae: 0.9311 - mse: 1.4876 - val_loss: 12.8391 - val_mae: 1.0170 - val_mse: 1.9753\n",
      "Epoch 913/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.2854 - mae: 0.9326 - mse: 1.4919 - val_loss: 12.8232 - val_mae: 1.1485 - val_mse: 2.3610\n",
      "Epoch 914/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.2827 - mae: 0.9464 - mse: 1.5363 - val_loss: 12.8281 - val_mae: 1.0017 - val_mse: 1.9442\n",
      "Epoch 915/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2830 - mae: 0.9345 - mse: 1.4927 - val_loss: 12.8427 - val_mae: 1.1388 - val_mse: 2.3139\n",
      "Epoch 916/1000\n",
      "1030/1030 [==============================] - 0s 38us/sample - loss: 12.2791 - mae: 0.9451 - mse: 1.5191 - val_loss: 12.8418 - val_mae: 0.9993 - val_mse: 1.9614\n",
      "Epoch 917/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.2819 - mae: 0.9369 - mse: 1.5001 - val_loss: 12.8637 - val_mae: 0.9810 - val_mse: 1.8851\n",
      "Epoch 918/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2830 - mae: 0.9325 - mse: 1.4842 - val_loss: 12.8181 - val_mae: 1.0887 - val_mse: 2.1755\n",
      "Epoch 919/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2846 - mae: 0.9371 - mse: 1.5001 - val_loss: 12.8069 - val_mae: 1.0969 - val_mse: 2.2061\n",
      "Epoch 920/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2809 - mae: 0.9404 - mse: 1.5109 - val_loss: 12.8076 - val_mae: 1.0767 - val_mse: 2.1424\n",
      "Epoch 921/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2846 - mae: 0.9414 - mse: 1.5124 - val_loss: 12.8226 - val_mae: 1.0704 - val_mse: 2.1166\n",
      "Epoch 922/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2872 - mae: 0.9410 - mse: 1.5113 - val_loss: 12.8154 - val_mae: 1.0292 - val_mse: 2.0138\n",
      "Epoch 923/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.2776 - mae: 0.9253 - mse: 1.4697 - val_loss: 12.8146 - val_mae: 1.1496 - val_mse: 2.3726\n",
      "Epoch 924/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2825 - mae: 0.9458 - mse: 1.5293 - val_loss: 12.8532 - val_mae: 1.0069 - val_mse: 1.9455\n",
      "Epoch 925/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2809 - mae: 0.9262 - mse: 1.4679 - val_loss: 12.8419 - val_mae: 1.1513 - val_mse: 2.3504\n",
      "Epoch 926/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2843 - mae: 0.9455 - mse: 1.5206 - val_loss: 12.7863 - val_mae: 1.0938 - val_mse: 2.2276\n",
      "Epoch 927/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.2832 - mae: 0.9432 - mse: 1.5219 - val_loss: 12.7996 - val_mae: 1.0488 - val_mse: 2.0720\n",
      "Epoch 928/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2816 - mae: 0.9400 - mse: 1.5093 - val_loss: 12.8117 - val_mae: 1.0714 - val_mse: 2.1245\n",
      "Epoch 929/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2770 - mae: 0.9386 - mse: 1.5019 - val_loss: 12.7934 - val_mae: 1.0646 - val_mse: 2.1209\n",
      "Epoch 930/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2797 - mae: 0.9386 - mse: 1.5044 - val_loss: 12.8535 - val_mae: 0.9926 - val_mse: 1.9127\n",
      "Epoch 931/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2854 - mae: 0.9286 - mse: 1.4783 - val_loss: 12.7882 - val_mae: 1.0791 - val_mse: 2.1700\n",
      "Epoch 932/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2796 - mae: 0.9419 - mse: 1.5186 - val_loss: 12.7948 - val_mae: 1.0825 - val_mse: 2.1689\n",
      "Epoch 933/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.2789 - mae: 0.9400 - mse: 1.5078 - val_loss: 12.7912 - val_mae: 1.0316 - val_mse: 2.0401\n",
      "Epoch 934/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2802 - mae: 0.9344 - mse: 1.4916 - val_loss: 12.8166 - val_mae: 1.1441 - val_mse: 2.3522\n",
      "Epoch 935/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.2780 - mae: 0.9405 - mse: 1.5109 - val_loss: 12.7869 - val_mae: 1.1072 - val_mse: 2.2555\n",
      "Epoch 936/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2793 - mae: 0.9397 - mse: 1.5075 - val_loss: 12.8138 - val_mae: 1.1572 - val_mse: 2.4046\n",
      "Epoch 937/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2780 - mae: 0.9476 - mse: 1.5350 - val_loss: 12.8147 - val_mae: 1.0648 - val_mse: 2.1114\n",
      "Epoch 938/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.2762 - mae: 0.9368 - mse: 1.5042 - val_loss: 12.8371 - val_mae: 1.0153 - val_mse: 1.9717\n",
      "Epoch 939/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.2809 - mae: 0.9299 - mse: 1.4881 - val_loss: 12.8233 - val_mae: 1.0152 - val_mse: 1.9741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 940/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2785 - mae: 0.9263 - mse: 1.4774 - val_loss: 12.7921 - val_mae: 1.0952 - val_mse: 2.2010\n",
      "Epoch 941/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.2803 - mae: 0.9428 - mse: 1.5156 - val_loss: 12.8349 - val_mae: 0.9922 - val_mse: 1.9222\n",
      "Epoch 942/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2791 - mae: 0.9312 - mse: 1.4922 - val_loss: 12.8266 - val_mae: 0.9999 - val_mse: 1.9499\n",
      "Epoch 943/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.2796 - mae: 0.9310 - mse: 1.4898 - val_loss: 12.8217 - val_mae: 1.0106 - val_mse: 1.9677\n",
      "Epoch 944/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2777 - mae: 0.9298 - mse: 1.4836 - val_loss: 12.7965 - val_mae: 1.0914 - val_mse: 2.1929\n",
      "Epoch 945/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2774 - mae: 0.9406 - mse: 1.5167 - val_loss: 12.8578 - val_mae: 1.0338 - val_mse: 2.0152\n",
      "Epoch 946/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2798 - mae: 0.9314 - mse: 1.4833 - val_loss: 12.8423 - val_mae: 1.1290 - val_mse: 2.2833\n",
      "Epoch 947/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2729 - mae: 0.9345 - mse: 1.4999 - val_loss: 12.7903 - val_mae: 1.0457 - val_mse: 2.0695\n",
      "Epoch 948/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2750 - mae: 0.9347 - mse: 1.4951 - val_loss: 12.8053 - val_mae: 1.0108 - val_mse: 1.9855\n",
      "Epoch 949/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.2711 - mae: 0.9261 - mse: 1.4716 - val_loss: 12.7969 - val_mae: 1.0913 - val_mse: 2.1903\n",
      "Epoch 950/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.2700 - mae: 0.9414 - mse: 1.5115 - val_loss: 12.8846 - val_mae: 0.9879 - val_mse: 1.8936\n",
      "Epoch 951/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.2778 - mae: 0.9297 - mse: 1.4788 - val_loss: 12.8225 - val_mae: 1.0250 - val_mse: 1.9978\n",
      "Epoch 952/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2692 - mae: 0.9323 - mse: 1.4872 - val_loss: 12.8164 - val_mae: 0.9976 - val_mse: 1.9415\n",
      "Epoch 953/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.2763 - mae: 0.9299 - mse: 1.4892 - val_loss: 12.8190 - val_mae: 1.0224 - val_mse: 1.9909\n",
      "Epoch 954/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.2756 - mae: 0.9325 - mse: 1.4822 - val_loss: 12.7930 - val_mae: 1.1121 - val_mse: 2.2558\n",
      "Epoch 955/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.2723 - mae: 0.9392 - mse: 1.5089 - val_loss: 12.7916 - val_mae: 1.0489 - val_mse: 2.0759\n",
      "Epoch 956/1000\n",
      "1030/1030 [==============================] - 0s 42us/sample - loss: 12.2716 - mae: 0.9330 - mse: 1.4933 - val_loss: 12.8389 - val_mae: 0.9949 - val_mse: 1.9201\n",
      "Epoch 957/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2706 - mae: 0.9251 - mse: 1.4644 - val_loss: 12.7773 - val_mae: 1.0491 - val_mse: 2.0926\n",
      "Epoch 958/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2701 - mae: 0.9402 - mse: 1.5011 - val_loss: 12.8035 - val_mae: 1.1238 - val_mse: 2.2866\n",
      "Epoch 959/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2749 - mae: 0.9396 - mse: 1.5101 - val_loss: 12.8318 - val_mae: 1.1684 - val_mse: 2.4183\n",
      "Epoch 960/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.2753 - mae: 0.9476 - mse: 1.5363 - val_loss: 12.8106 - val_mae: 1.0082 - val_mse: 1.9680\n",
      "Epoch 961/1000\n",
      "1030/1030 [==============================] - 0s 56us/sample - loss: 12.2727 - mae: 0.9354 - mse: 1.4944 - val_loss: 12.8278 - val_mae: 1.0888 - val_mse: 2.1658\n",
      "Epoch 962/1000\n",
      "1030/1030 [==============================] - 0s 34us/sample - loss: 12.2680 - mae: 0.9346 - mse: 1.4936 - val_loss: 12.7933 - val_mae: 1.1246 - val_mse: 2.3060\n",
      "Epoch 963/1000\n",
      "1030/1030 [==============================] - 0s 35us/sample - loss: 12.2721 - mae: 0.9436 - mse: 1.5221 - val_loss: 12.8086 - val_mae: 1.0891 - val_mse: 2.1816\n",
      "Epoch 964/1000\n",
      "1030/1030 [==============================] - 0s 36us/sample - loss: 12.2712 - mae: 0.9357 - mse: 1.4977 - val_loss: 12.8046 - val_mae: 1.0592 - val_mse: 2.0951\n",
      "Epoch 965/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.2721 - mae: 0.9338 - mse: 1.4894 - val_loss: 12.7798 - val_mae: 1.0912 - val_mse: 2.2093\n",
      "Epoch 966/1000\n",
      "1030/1030 [==============================] - 0s 58us/sample - loss: 12.2644 - mae: 0.9333 - mse: 1.4987 - val_loss: 12.8011 - val_mae: 1.0112 - val_mse: 1.9787\n",
      "Epoch 967/1000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 12.2698 - mae: 0.9274 - mse: 1.4738 - val_loss: 12.7929 - val_mae: 1.0863 - val_mse: 2.1761\n",
      "Epoch 968/1000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 12.2723 - mae: 0.9380 - mse: 1.5067 - val_loss: 12.8097 - val_mae: 1.0400 - val_mse: 2.0402\n",
      "Epoch 969/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.2749 - mae: 0.9359 - mse: 1.4950 - val_loss: 12.7885 - val_mae: 1.0955 - val_mse: 2.2018\n",
      "Epoch 970/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2654 - mae: 0.9391 - mse: 1.5022 - val_loss: 12.7843 - val_mae: 1.0345 - val_mse: 2.0422\n",
      "Epoch 971/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2691 - mae: 0.9301 - mse: 1.4830 - val_loss: 12.7946 - val_mae: 1.0704 - val_mse: 2.1257\n",
      "Epoch 972/1000\n",
      "1030/1030 [==============================] - 0s 44us/sample - loss: 12.2715 - mae: 0.9351 - mse: 1.5005 - val_loss: 12.7863 - val_mae: 1.1055 - val_mse: 2.2384\n",
      "Epoch 973/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.2682 - mae: 0.9343 - mse: 1.4900 - val_loss: 12.8163 - val_mae: 1.1189 - val_mse: 2.2594\n",
      "Epoch 974/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.2680 - mae: 0.9311 - mse: 1.4874 - val_loss: 12.7916 - val_mae: 1.0925 - val_mse: 2.1977\n",
      "Epoch 975/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.2713 - mae: 0.9353 - mse: 1.5009 - val_loss: 12.8105 - val_mae: 1.0818 - val_mse: 2.1495\n",
      "Epoch 976/1000\n",
      "1030/1030 [==============================] - 0s 53us/sample - loss: 12.2699 - mae: 0.9351 - mse: 1.4936 - val_loss: 12.7876 - val_mae: 1.1213 - val_mse: 2.2958\n",
      "Epoch 977/1000\n",
      "1030/1030 [==============================] - 0s 56us/sample - loss: 12.2678 - mae: 0.9371 - mse: 1.5025 - val_loss: 12.7938 - val_mae: 1.1389 - val_mse: 2.3441\n",
      "Epoch 978/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2648 - mae: 0.9381 - mse: 1.5082 - val_loss: 12.7850 - val_mae: 1.0601 - val_mse: 2.1001\n",
      "Epoch 979/1000\n",
      "1030/1030 [==============================] - 0s 41us/sample - loss: 12.2692 - mae: 0.9385 - mse: 1.5025 - val_loss: 12.7766 - val_mae: 1.0540 - val_mse: 2.0975\n",
      "Epoch 980/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2678 - mae: 0.9333 - mse: 1.4905 - val_loss: 12.7820 - val_mae: 1.1020 - val_mse: 2.2392\n",
      "Epoch 981/1000\n",
      "1030/1030 [==============================] - 0s 43us/sample - loss: 12.2674 - mae: 0.9347 - mse: 1.5010 - val_loss: 12.7884 - val_mae: 1.0261 - val_mse: 2.0209\n",
      "Epoch 982/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2650 - mae: 0.9298 - mse: 1.4826 - val_loss: 12.7794 - val_mae: 1.0607 - val_mse: 2.1116\n",
      "Epoch 983/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2622 - mae: 0.9303 - mse: 1.4815 - val_loss: 12.7745 - val_mae: 1.0775 - val_mse: 2.1788\n",
      "Epoch 984/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.2657 - mae: 0.9394 - mse: 1.5098 - val_loss: 12.8166 - val_mae: 1.0693 - val_mse: 2.1167\n",
      "Epoch 985/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2710 - mae: 0.9350 - mse: 1.4982 - val_loss: 12.7987 - val_mae: 1.0205 - val_mse: 2.0032\n",
      "Epoch 986/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2676 - mae: 0.9322 - mse: 1.4931 - val_loss: 12.8219 - val_mae: 1.0923 - val_mse: 2.1787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 987/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.2658 - mae: 0.9390 - mse: 1.5045 - val_loss: 12.8011 - val_mae: 1.0200 - val_mse: 1.9935\n",
      "Epoch 988/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2683 - mae: 0.9298 - mse: 1.4812 - val_loss: 12.8011 - val_mae: 1.0767 - val_mse: 2.1440\n",
      "Epoch 989/1000\n",
      "1030/1030 [==============================] - 0s 45us/sample - loss: 12.2652 - mae: 0.9347 - mse: 1.4961 - val_loss: 12.7795 - val_mae: 1.0971 - val_mse: 2.2313\n",
      "Epoch 990/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2684 - mae: 0.9325 - mse: 1.4891 - val_loss: 12.7939 - val_mae: 1.1147 - val_mse: 2.2744\n",
      "Epoch 991/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.2652 - mae: 0.9388 - mse: 1.5071 - val_loss: 12.7901 - val_mae: 1.0255 - val_mse: 2.0244\n",
      "Epoch 992/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2664 - mae: 0.9314 - mse: 1.4927 - val_loss: 12.8357 - val_mae: 1.0063 - val_mse: 1.9489\n",
      "Epoch 993/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.2667 - mae: 0.9276 - mse: 1.4749 - val_loss: 12.7893 - val_mae: 1.1191 - val_mse: 2.2866\n",
      "Epoch 994/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2661 - mae: 0.9359 - mse: 1.4979 - val_loss: 12.7957 - val_mae: 1.1289 - val_mse: 2.3163\n",
      "Epoch 995/1000\n",
      "1030/1030 [==============================] - 0s 39us/sample - loss: 12.2639 - mae: 0.9378 - mse: 1.5108 - val_loss: 12.7957 - val_mae: 1.0321 - val_mse: 2.0261\n",
      "Epoch 996/1000\n",
      "1030/1030 [==============================] - 0s 47us/sample - loss: 12.2635 - mae: 0.9279 - mse: 1.4739 - val_loss: 12.8080 - val_mae: 1.1397 - val_mse: 2.3362\n",
      "Epoch 997/1000\n",
      "1030/1030 [==============================] - 0s 40us/sample - loss: 12.2666 - mae: 0.9391 - mse: 1.5067 - val_loss: 12.7813 - val_mae: 1.0727 - val_mse: 2.1504\n",
      "Epoch 998/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2626 - mae: 0.9363 - mse: 1.5004 - val_loss: 12.7801 - val_mae: 1.0817 - val_mse: 2.1732\n",
      "Epoch 999/1000\n",
      "1030/1030 [==============================] - 0s 46us/sample - loss: 12.2626 - mae: 0.9347 - mse: 1.4943 - val_loss: 12.8179 - val_mae: 1.1536 - val_mse: 2.3753\n",
      "Epoch 1000/1000\n",
      "1030/1030 [==============================] - 0s 48us/sample - loss: 12.2638 - mae: 0.9431 - mse: 1.5114 - val_loss: 12.8086 - val_mae: 1.0181 - val_mse: 1.9865\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.show_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.model_validation(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344/1 - 0s - loss: 10.8523 - mae: 1.0750 - mse: 1.9500\n",
      "Test loss: 13.149299377618833\n",
      "Mean absolute error: 1.0750041\n",
      "Mean squared error: 1.9499893\n"
     ]
    }
   ],
   "source": [
    "model.model_testing(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,442\n",
      "Trainable params: 5,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 103 samples, validate on 34 samples\n",
      "Epoch 1/1000\n",
      "103/103 [==============================] - 1s 5ms/sample - loss: 276.4519 - mae: 14.7452 - mse: 276.3667 - val_loss: 276.7728 - val_mae: 14.8453 - val_mse: 276.6838\n",
      "Epoch 2/1000\n",
      "103/103 [==============================] - 0s 135us/sample - loss: 266.6088 - mae: 14.4725 - mse: 266.5167 - val_loss: 268.2690 - val_mae: 14.6049 - val_mse: 268.1688\n",
      "Epoch 3/1000\n",
      "103/103 [==============================] - 0s 189us/sample - loss: 257.0227 - mae: 14.1993 - mse: 256.9151 - val_loss: 257.4536 - val_mae: 14.2926 - val_mse: 257.3298\n",
      "Epoch 4/1000\n",
      "103/103 [==============================] - 0s 154us/sample - loss: 245.0871 - mae: 13.8470 - mse: 244.9486 - val_loss: 245.3480 - val_mae: 13.9325 - val_mse: 245.1840\n",
      "Epoch 5/1000\n",
      "103/103 [==============================] - 0s 207us/sample - loss: 231.3214 - mae: 13.4317 - mse: 231.1293 - val_loss: 230.9762 - val_mae: 13.4923 - val_mse: 230.7442\n",
      "Epoch 6/1000\n",
      "103/103 [==============================] - 0s 267us/sample - loss: 215.2791 - mae: 12.9269 - mse: 214.9970 - val_loss: 215.4162 - val_mae: 12.9841 - val_mse: 215.0830\n",
      "Epoch 7/1000\n",
      "103/103 [==============================] - 0s 154us/sample - loss: 198.0669 - mae: 12.3498 - mse: 197.6540 - val_loss: 199.2889 - val_mae: 12.4314 - val_mse: 198.8161\n",
      "Epoch 8/1000\n",
      "103/103 [==============================] - 0s 221us/sample - loss: 180.2763 - mae: 11.7157 - mse: 179.6805 - val_loss: 182.2804 - val_mae: 11.8106 - val_mse: 181.6165\n",
      "Epoch 9/1000\n",
      "103/103 [==============================] - 0s 242us/sample - loss: 161.8116 - mae: 11.0023 - mse: 160.9653 - val_loss: 164.3300 - val_mae: 11.1131 - val_mse: 163.4049\n",
      "Epoch 10/1000\n",
      "103/103 [==============================] - 0s 214us/sample - loss: 142.4644 - mae: 10.2191 - mse: 141.2856 - val_loss: 145.7690 - val_mae: 10.3282 - val_mse: 144.4954\n",
      "Epoch 11/1000\n",
      "103/103 [==============================] - 0s 283us/sample - loss: 123.0632 - mae: 9.3292 - mse: 121.4386 - val_loss: 127.6331 - val_mae: 9.4834 - val_mse: 125.9196\n",
      "Epoch 12/1000\n",
      "103/103 [==============================] - 0s 202us/sample - loss: 104.4537 - mae: 8.3948 - mse: 102.2831 - val_loss: 110.6210 - val_mae: 8.5952 - val_mse: 108.3752\n",
      "Epoch 13/1000\n",
      "103/103 [==============================] - 0s 266us/sample - loss: 87.4615 - mae: 7.4042 - mse: 84.6240 - val_loss: 95.5745 - val_mae: 7.7022 - val_mse: 92.7217\n",
      "Epoch 14/1000\n",
      "103/103 [==============================] - 0s 224us/sample - loss: 72.8753 - mae: 6.4112 - mse: 69.2791 - val_loss: 82.1608 - val_mae: 6.8584 - val_mse: 78.6075\n",
      "Epoch 15/1000\n",
      "103/103 [==============================] - 0s 258us/sample - loss: 60.5070 - mae: 5.5803 - mse: 56.0366 - val_loss: 71.2244 - val_mae: 6.1425 - val_mse: 66.9287\n",
      "Epoch 16/1000\n",
      "103/103 [==============================] - 0s 210us/sample - loss: 50.9611 - mae: 4.9618 - mse: 45.5887 - val_loss: 62.7299 - val_mae: 5.5859 - val_mse: 57.6804\n",
      "Epoch 17/1000\n",
      "103/103 [==============================] - 0s 257us/sample - loss: 44.1017 - mae: 4.5043 - mse: 37.8376 - val_loss: 56.2450 - val_mae: 5.2164 - val_mse: 50.4379\n",
      "Epoch 18/1000\n",
      "103/103 [==============================] - 0s 173us/sample - loss: 39.5150 - mae: 4.2430 - mse: 32.3637 - val_loss: 52.5410 - val_mae: 5.0454 - val_mse: 46.2242\n",
      "Epoch 19/1000\n",
      "103/103 [==============================] - 0s 210us/sample - loss: 37.2192 - mae: 4.1032 - mse: 29.4385 - val_loss: 50.0314 - val_mae: 4.9290 - val_mse: 43.3447\n",
      "Epoch 20/1000\n",
      "103/103 [==============================] - 0s 203us/sample - loss: 35.6033 - mae: 3.9775 - mse: 27.4991 - val_loss: 46.0112 - val_mae: 4.7205 - val_mse: 38.4379\n",
      "Epoch 21/1000\n",
      "103/103 [==============================] - 0s 342us/sample - loss: 34.0162 - mae: 3.8920 - mse: 24.9325 - val_loss: 44.7243 - val_mae: 4.6401 - val_mse: 36.9905\n",
      "Epoch 22/1000\n",
      "103/103 [==============================] - 0s 227us/sample - loss: 33.3427 - mae: 3.8511 - mse: 24.0019 - val_loss: 43.9713 - val_mae: 4.5895 - val_mse: 36.2965\n",
      "Epoch 23/1000\n",
      "103/103 [==============================] - 0s 217us/sample - loss: 32.5798 - mae: 3.7818 - mse: 23.3417 - val_loss: 42.6615 - val_mae: 4.4971 - val_mse: 34.8666\n",
      "Epoch 24/1000\n",
      "103/103 [==============================] - 0s 297us/sample - loss: 31.6513 - mae: 3.7017 - mse: 22.4645 - val_loss: 40.2687 - val_mae: 4.3749 - val_mse: 31.8538\n",
      "Epoch 25/1000\n",
      "103/103 [==============================] - 0s 211us/sample - loss: 30.7239 - mae: 3.6445 - mse: 21.0402 - val_loss: 39.1974 - val_mae: 4.2896 - val_mse: 30.9314\n",
      "Epoch 26/1000\n",
      "103/103 [==============================] - 0s 309us/sample - loss: 29.7931 - mae: 3.5710 - mse: 20.2860 - val_loss: 37.3821 - val_mae: 4.1900 - val_mse: 28.7710\n",
      "Epoch 27/1000\n",
      "103/103 [==============================] - 0s 203us/sample - loss: 28.8967 - mae: 3.5132 - mse: 19.1585 - val_loss: 36.0334 - val_mae: 4.0847 - val_mse: 27.3039\n",
      "Epoch 28/1000\n",
      "103/103 [==============================] - 0s 218us/sample - loss: 28.4520 - mae: 3.4629 - mse: 18.6120 - val_loss: 35.6447 - val_mae: 4.0236 - val_mse: 27.3601\n",
      "Epoch 29/1000\n",
      "103/103 [==============================] - 0s 290us/sample - loss: 27.0891 - mae: 3.3010 - mse: 17.6562 - val_loss: 33.7028 - val_mae: 3.9010 - val_mse: 24.9687\n",
      "Epoch 30/1000\n",
      "103/103 [==============================] - 0s 218us/sample - loss: 26.2445 - mae: 3.2523 - mse: 16.4628 - val_loss: 32.0221 - val_mae: 3.7763 - val_mse: 22.8385\n",
      "Epoch 31/1000\n",
      "103/103 [==============================] - 0s 220us/sample - loss: 25.4298 - mae: 3.1873 - mse: 15.3976 - val_loss: 31.1602 - val_mae: 3.6913 - val_mse: 22.2339\n",
      "Epoch 32/1000\n",
      "103/103 [==============================] - 0s 220us/sample - loss: 24.6471 - mae: 3.1062 - mse: 14.6421 - val_loss: 30.3090 - val_mae: 3.6055 - val_mse: 21.5595\n",
      "Epoch 33/1000\n",
      "103/103 [==============================] - 0s 203us/sample - loss: 23.7716 - mae: 3.0090 - mse: 14.0005 - val_loss: 29.0433 - val_mae: 3.5084 - val_mse: 20.0283\n",
      "Epoch 34/1000\n",
      "103/103 [==============================] - 0s 203us/sample - loss: 23.0933 - mae: 2.9255 - mse: 13.3717 - val_loss: 27.4333 - val_mae: 3.3887 - val_mse: 17.9129\n",
      "Epoch 35/1000\n",
      "103/103 [==============================] - 0s 264us/sample - loss: 22.4952 - mae: 2.8860 - mse: 12.3587 - val_loss: 28.2134 - val_mae: 3.3957 - val_mse: 19.9017\n",
      "Epoch 36/1000\n",
      "103/103 [==============================] - 0s 271us/sample - loss: 21.7844 - mae: 2.7637 - mse: 12.3595 - val_loss: 26.5211 - val_mae: 3.2473 - val_mse: 17.8092\n",
      "Epoch 37/1000\n",
      "103/103 [==============================] - 0s 248us/sample - loss: 21.1233 - mae: 2.7114 - mse: 11.4227 - val_loss: 25.5565 - val_mae: 3.1773 - val_mse: 16.6953\n",
      "Epoch 38/1000\n",
      "103/103 [==============================] - 0s 328us/sample - loss: 20.4031 - mae: 2.6172 - mse: 10.7723 - val_loss: 23.9495 - val_mae: 3.0292 - val_mse: 14.3681\n",
      "Epoch 39/1000\n",
      "103/103 [==============================] - 0s 192us/sample - loss: 19.9881 - mae: 2.5778 - mse: 9.9510 - val_loss: 23.4096 - val_mae: 2.9728 - val_mse: 13.8509\n",
      "Epoch 40/1000\n",
      "103/103 [==============================] - 0s 201us/sample - loss: 19.3412 - mae: 2.4729 - mse: 9.2335 - val_loss: 22.6439 - val_mae: 2.8796 - val_mse: 13.1137\n",
      "Epoch 41/1000\n",
      "103/103 [==============================] - 0s 202us/sample - loss: 18.8853 - mae: 2.4203 - mse: 8.9493 - val_loss: 21.8943 - val_mae: 2.7655 - val_mse: 11.7631\n",
      "Epoch 42/1000\n",
      "103/103 [==============================] - 0s 264us/sample - loss: 18.6622 - mae: 2.3538 - mse: 8.4587 - val_loss: 21.2810 - val_mae: 2.6686 - val_mse: 10.8466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "103/103 [==============================] - 0s 202us/sample - loss: 18.4853 - mae: 2.3468 - mse: 8.1008 - val_loss: 20.7261 - val_mae: 2.6053 - val_mse: 10.6710\n",
      "Epoch 44/1000\n",
      "103/103 [==============================] - 0s 230us/sample - loss: 17.8047 - mae: 2.2434 - mse: 7.5567 - val_loss: 20.4299 - val_mae: 2.5441 - val_mse: 10.1663\n",
      "Epoch 45/1000\n",
      "103/103 [==============================] - 0s 211us/sample - loss: 17.7412 - mae: 2.2455 - mse: 7.4095 - val_loss: 20.2479 - val_mae: 2.5194 - val_mse: 10.1894\n",
      "Epoch 46/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 17.3530 - mae: 2.1516 - mse: 6.9625 - val_loss: 20.0131 - val_mae: 2.4894 - val_mse: 10.3534\n",
      "Epoch 47/1000\n",
      "103/103 [==============================] - 0s 162us/sample - loss: 17.2088 - mae: 2.1824 - mse: 7.0973 - val_loss: 19.5527 - val_mae: 2.3984 - val_mse: 9.4389\n",
      "Epoch 48/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 16.9585 - mae: 2.1211 - mse: 6.7580 - val_loss: 19.3778 - val_mae: 2.3668 - val_mse: 9.3955\n",
      "Epoch 49/1000\n",
      "103/103 [==============================] - 0s 172us/sample - loss: 16.8533 - mae: 2.1185 - mse: 6.7262 - val_loss: 19.6678 - val_mae: 2.4507 - val_mse: 10.3597\n",
      "Epoch 50/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 16.7048 - mae: 2.1265 - mse: 6.7744 - val_loss: 19.1907 - val_mae: 2.3753 - val_mse: 9.6832\n",
      "Epoch 51/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 16.5772 - mae: 2.0863 - mse: 6.5489 - val_loss: 19.5862 - val_mae: 2.4823 - val_mse: 10.4660\n",
      "Epoch 52/1000\n",
      "103/103 [==============================] - 0s 163us/sample - loss: 16.5239 - mae: 2.1083 - mse: 6.7673 - val_loss: 18.7012 - val_mae: 2.2445 - val_mse: 8.8170\n",
      "Epoch 53/1000\n",
      "103/103 [==============================] - 0s 162us/sample - loss: 16.2169 - mae: 2.0152 - mse: 6.1152 - val_loss: 18.6464 - val_mae: 2.2785 - val_mse: 8.9779\n",
      "Epoch 54/1000\n",
      "103/103 [==============================] - 0s 172us/sample - loss: 16.1163 - mae: 2.0039 - mse: 6.1147 - val_loss: 18.4814 - val_mae: 2.1541 - val_mse: 7.6113\n",
      "Epoch 55/1000\n",
      "103/103 [==============================] - 0s 173us/sample - loss: 16.1435 - mae: 1.9490 - mse: 5.6942 - val_loss: 18.3802 - val_mae: 2.1652 - val_mse: 8.2875\n",
      "Epoch 56/1000\n",
      "103/103 [==============================] - 0s 174us/sample - loss: 15.9850 - mae: 1.9494 - mse: 5.8943 - val_loss: 18.2454 - val_mae: 2.1154 - val_mse: 7.7495\n",
      "Epoch 57/1000\n",
      "103/103 [==============================] - 0s 168us/sample - loss: 15.8942 - mae: 1.9344 - mse: 5.6532 - val_loss: 18.0735 - val_mae: 2.0919 - val_mse: 7.5294\n",
      "Epoch 58/1000\n",
      "103/103 [==============================] - 0s 170us/sample - loss: 15.7887 - mae: 1.9016 - mse: 5.4812 - val_loss: 18.2597 - val_mae: 2.2068 - val_mse: 8.5755\n",
      "Epoch 59/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 15.8758 - mae: 1.9472 - mse: 5.7922 - val_loss: 18.3820 - val_mae: 2.2865 - val_mse: 8.8983\n",
      "Epoch 60/1000\n",
      "103/103 [==============================] - 0s 187us/sample - loss: 15.6214 - mae: 1.9286 - mse: 5.6731 - val_loss: 17.8964 - val_mae: 2.1229 - val_mse: 7.9035\n",
      "Epoch 61/1000\n",
      "103/103 [==============================] - 0s 180us/sample - loss: 15.4980 - mae: 1.8597 - mse: 5.3136 - val_loss: 17.8847 - val_mae: 2.0650 - val_mse: 7.1260\n",
      "Epoch 62/1000\n",
      "103/103 [==============================] - 0s 178us/sample - loss: 15.5672 - mae: 1.8479 - mse: 5.1949 - val_loss: 17.9205 - val_mae: 2.1197 - val_mse: 7.9732\n",
      "Epoch 63/1000\n",
      "103/103 [==============================] - 0s 176us/sample - loss: 15.3337 - mae: 1.8255 - mse: 5.1501 - val_loss: 18.1264 - val_mae: 2.1737 - val_mse: 8.4179\n",
      "Epoch 64/1000\n",
      "103/103 [==============================] - 0s 173us/sample - loss: 15.2988 - mae: 1.8090 - mse: 5.1408 - val_loss: 18.0933 - val_mae: 2.1875 - val_mse: 8.4607\n",
      "Epoch 65/1000\n",
      "103/103 [==============================] - 0s 168us/sample - loss: 15.1634 - mae: 1.8277 - mse: 5.1868 - val_loss: 17.6157 - val_mae: 2.0268 - val_mse: 7.0791\n",
      "Epoch 66/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 15.3197 - mae: 1.7873 - mse: 4.8870 - val_loss: 18.2670 - val_mae: 2.2930 - val_mse: 8.9204\n",
      "Epoch 67/1000\n",
      "103/103 [==============================] - 0s 172us/sample - loss: 15.2702 - mae: 1.8675 - mse: 5.3663 - val_loss: 17.5185 - val_mae: 2.0513 - val_mse: 7.3650\n",
      "Epoch 68/1000\n",
      "103/103 [==============================] - 0s 178us/sample - loss: 15.0691 - mae: 1.7798 - mse: 4.8788 - val_loss: 17.5841 - val_mae: 2.0300 - val_mse: 7.2648\n",
      "Epoch 69/1000\n",
      "103/103 [==============================] - 0s 182us/sample - loss: 15.0147 - mae: 1.7629 - mse: 4.8137 - val_loss: 17.8765 - val_mae: 2.0440 - val_mse: 6.5986\n",
      "Epoch 70/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 15.1709 - mae: 1.7252 - mse: 4.4918 - val_loss: 17.4669 - val_mae: 2.0695 - val_mse: 7.4600\n",
      "Epoch 71/1000\n",
      "103/103 [==============================] - 0s 168us/sample - loss: 14.8710 - mae: 1.7572 - mse: 4.7036 - val_loss: 17.5659 - val_mae: 2.0889 - val_mse: 7.6460\n",
      "Epoch 72/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 14.8048 - mae: 1.7305 - mse: 4.7223 - val_loss: 17.4781 - val_mae: 2.0019 - val_mse: 6.8867\n",
      "Epoch 73/1000\n",
      "103/103 [==============================] - 0s 168us/sample - loss: 14.6821 - mae: 1.6564 - mse: 4.2000 - val_loss: 17.8525 - val_mae: 2.2002 - val_mse: 8.3630\n",
      "Epoch 74/1000\n",
      "103/103 [==============================] - 0s 166us/sample - loss: 14.6903 - mae: 1.7550 - mse: 4.7119 - val_loss: 17.4468 - val_mae: 2.0028 - val_mse: 6.6440\n",
      "Epoch 75/1000\n",
      "103/103 [==============================] - 0s 161us/sample - loss: 14.5886 - mae: 1.6363 - mse: 4.1428 - val_loss: 17.2485 - val_mae: 2.0117 - val_mse: 7.0570\n",
      "Epoch 76/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 14.6478 - mae: 1.6867 - mse: 4.3101 - val_loss: 17.3142 - val_mae: 1.9904 - val_mse: 6.8971\n",
      "Epoch 77/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 14.5651 - mae: 1.6833 - mse: 4.3144 - val_loss: 17.5643 - val_mae: 2.1037 - val_mse: 7.7960\n",
      "Epoch 78/1000\n",
      "103/103 [==============================] - 0s 186us/sample - loss: 14.5458 - mae: 1.6948 - mse: 4.3950 - val_loss: 17.5848 - val_mae: 2.0702 - val_mse: 7.6839\n",
      "Epoch 79/1000\n",
      "103/103 [==============================] - 0s 192us/sample - loss: 14.4578 - mae: 1.6575 - mse: 4.2980 - val_loss: 17.2788 - val_mae: 1.9940 - val_mse: 7.0727\n",
      "Epoch 80/1000\n",
      "103/103 [==============================] - 0s 183us/sample - loss: 14.3884 - mae: 1.6154 - mse: 4.1253 - val_loss: 17.0173 - val_mae: 1.9532 - val_mse: 6.6532\n",
      "Epoch 81/1000\n",
      "103/103 [==============================] - 0s 172us/sample - loss: 14.4057 - mae: 1.6418 - mse: 4.0660 - val_loss: 16.9976 - val_mae: 1.9427 - val_mse: 6.5485\n",
      "Epoch 82/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 14.2861 - mae: 1.6017 - mse: 3.9254 - val_loss: 17.0678 - val_mae: 1.9970 - val_mse: 6.9792\n",
      "Epoch 83/1000\n",
      "103/103 [==============================] - 0s 174us/sample - loss: 14.2531 - mae: 1.6177 - mse: 4.0170 - val_loss: 17.0176 - val_mae: 1.9260 - val_mse: 6.2362\n",
      "Epoch 84/1000\n",
      "103/103 [==============================] - 0s 168us/sample - loss: 14.1904 - mae: 1.5706 - mse: 3.7899 - val_loss: 17.0364 - val_mae: 1.9507 - val_mse: 6.6734\n",
      "Epoch 85/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 14.1516 - mae: 1.5809 - mse: 3.8204 - val_loss: 17.0913 - val_mae: 2.0487 - val_mse: 7.2476\n",
      "Epoch 86/1000\n",
      "103/103 [==============================] - 0s 184us/sample - loss: 14.1073 - mae: 1.6016 - mse: 3.9743 - val_loss: 16.8555 - val_mae: 1.9253 - val_mse: 6.4704\n",
      "Epoch 87/1000\n",
      "103/103 [==============================] - 0s 188us/sample - loss: 14.1204 - mae: 1.5935 - mse: 3.8086 - val_loss: 16.9958 - val_mae: 2.0306 - val_mse: 7.1013\n",
      "Epoch 88/1000\n",
      "103/103 [==============================] - 0s 176us/sample - loss: 14.1187 - mae: 1.5903 - mse: 3.9068 - val_loss: 17.1673 - val_mae: 1.9459 - val_mse: 6.0214\n",
      "Epoch 89/1000\n",
      "103/103 [==============================] - 0s 179us/sample - loss: 14.2041 - mae: 1.5760 - mse: 3.7381 - val_loss: 16.9871 - val_mae: 1.9118 - val_mse: 5.9223\n",
      "Epoch 90/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 167us/sample - loss: 14.0627 - mae: 1.5377 - mse: 3.5520 - val_loss: 16.8078 - val_mae: 1.8869 - val_mse: 5.9815\n",
      "Epoch 91/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 13.9355 - mae: 1.5114 - mse: 3.4725 - val_loss: 16.6932 - val_mae: 1.9243 - val_mse: 6.3922\n",
      "Epoch 92/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 13.8828 - mae: 1.5115 - mse: 3.4807 - val_loss: 16.9672 - val_mae: 2.0303 - val_mse: 7.1322\n",
      "Epoch 93/1000\n",
      "103/103 [==============================] - 0s 178us/sample - loss: 14.0645 - mae: 1.5941 - mse: 3.9359 - val_loss: 16.8576 - val_mae: 1.9118 - val_mse: 6.5067\n",
      "Epoch 94/1000\n",
      "103/103 [==============================] - 0s 181us/sample - loss: 13.8107 - mae: 1.5117 - mse: 3.5959 - val_loss: 16.7359 - val_mae: 1.8894 - val_mse: 6.1694\n",
      "Epoch 95/1000\n",
      "103/103 [==============================] - 0s 187us/sample - loss: 13.7294 - mae: 1.4663 - mse: 3.3118 - val_loss: 16.7139 - val_mae: 1.9404 - val_mse: 6.5597\n",
      "Epoch 96/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 13.7173 - mae: 1.5012 - mse: 3.4227 - val_loss: 16.8201 - val_mae: 1.9989 - val_mse: 6.9153\n",
      "Epoch 97/1000\n",
      "103/103 [==============================] - 0s 180us/sample - loss: 13.9572 - mae: 1.5610 - mse: 3.8328 - val_loss: 16.9687 - val_mae: 2.0124 - val_mse: 7.0856\n",
      "Epoch 98/1000\n",
      "103/103 [==============================] - 0s 180us/sample - loss: 13.7833 - mae: 1.5144 - mse: 3.6456 - val_loss: 16.9364 - val_mae: 2.0041 - val_mse: 7.0365\n",
      "Epoch 99/1000\n",
      "103/103 [==============================] - 0s 179us/sample - loss: 13.7358 - mae: 1.4919 - mse: 3.5943 - val_loss: 16.5573 - val_mae: 1.8558 - val_mse: 6.0625\n",
      "Epoch 100/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 13.5861 - mae: 1.4472 - mse: 3.2318 - val_loss: 16.6098 - val_mae: 1.9045 - val_mse: 6.3614\n",
      "Epoch 101/1000\n",
      "103/103 [==============================] - 0s 184us/sample - loss: 13.5649 - mae: 1.4594 - mse: 3.3333 - val_loss: 16.6953 - val_mae: 1.8576 - val_mse: 5.6864\n",
      "Epoch 102/1000\n",
      "103/103 [==============================] - 0s 164us/sample - loss: 13.5734 - mae: 1.4098 - mse: 3.0827 - val_loss: 16.6302 - val_mae: 1.9632 - val_mse: 6.6564\n",
      "Epoch 103/1000\n",
      "103/103 [==============================] - 0s 188us/sample - loss: 13.5045 - mae: 1.4485 - mse: 3.3078 - val_loss: 16.8860 - val_mae: 1.8807 - val_mse: 5.6476\n",
      "Epoch 104/1000\n",
      "103/103 [==============================] - 0s 161us/sample - loss: 13.6089 - mae: 1.3913 - mse: 3.0393 - val_loss: 16.4627 - val_mae: 1.8812 - val_mse: 6.1820\n",
      "Epoch 105/1000\n",
      "103/103 [==============================] - 0s 170us/sample - loss: 13.5749 - mae: 1.4703 - mse: 3.3981 - val_loss: 16.7098 - val_mae: 1.8806 - val_mse: 5.8976\n",
      "Epoch 106/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 13.5630 - mae: 1.4440 - mse: 3.2919 - val_loss: 16.7088 - val_mae: 1.8479 - val_mse: 5.5556\n",
      "Epoch 107/1000\n",
      "103/103 [==============================] - 0s 168us/sample - loss: 13.4383 - mae: 1.3654 - mse: 2.9587 - val_loss: 16.5780 - val_mae: 1.8131 - val_mse: 5.4865\n",
      "Epoch 108/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 13.4226 - mae: 1.3860 - mse: 2.9548 - val_loss: 16.4968 - val_mae: 1.8604 - val_mse: 6.0029\n",
      "Epoch 109/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 13.3206 - mae: 1.3806 - mse: 3.0076 - val_loss: 16.4950 - val_mae: 1.9133 - val_mse: 6.4163\n",
      "Epoch 110/1000\n",
      "103/103 [==============================] - 0s 177us/sample - loss: 13.4028 - mae: 1.4302 - mse: 3.1409 - val_loss: 16.3884 - val_mae: 1.8417 - val_mse: 5.8641\n",
      "Epoch 111/1000\n",
      "103/103 [==============================] - 0s 181us/sample - loss: 13.3132 - mae: 1.3762 - mse: 3.0006 - val_loss: 16.3465 - val_mae: 1.8334 - val_mse: 5.8115\n",
      "Epoch 112/1000\n",
      "103/103 [==============================] - 0s 189us/sample - loss: 13.2839 - mae: 1.3717 - mse: 2.9499 - val_loss: 16.6980 - val_mae: 2.0062 - val_mse: 6.9190\n",
      "Epoch 113/1000\n",
      "103/103 [==============================] - 0s 175us/sample - loss: 13.3448 - mae: 1.4431 - mse: 3.1941 - val_loss: 16.3910 - val_mae: 1.7884 - val_mse: 5.4842\n",
      "Epoch 114/1000\n",
      "103/103 [==============================] - 0s 172us/sample - loss: 13.2188 - mae: 1.3040 - mse: 2.6821 - val_loss: 16.4098 - val_mae: 1.8370 - val_mse: 5.8103\n",
      "Epoch 115/1000\n",
      "103/103 [==============================] - 0s 173us/sample - loss: 13.1629 - mae: 1.3393 - mse: 2.8375 - val_loss: 16.9143 - val_mae: 1.8619 - val_mse: 5.4590\n",
      "Epoch 116/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 13.2539 - mae: 1.2791 - mse: 2.6052 - val_loss: 16.7017 - val_mae: 1.9885 - val_mse: 6.8763\n",
      "Epoch 117/1000\n",
      "103/103 [==============================] - 0s 170us/sample - loss: 13.2199 - mae: 1.3794 - mse: 3.0950 - val_loss: 16.4707 - val_mae: 1.9061 - val_mse: 6.2925\n",
      "Epoch 118/1000\n",
      "103/103 [==============================] - 0s 175us/sample - loss: 13.3350 - mae: 1.4261 - mse: 3.1970 - val_loss: 16.3282 - val_mae: 1.8670 - val_mse: 6.0167\n",
      "Epoch 119/1000\n",
      "103/103 [==============================] - 0s 179us/sample - loss: 13.0659 - mae: 1.3265 - mse: 2.8322 - val_loss: 16.8836 - val_mae: 1.8977 - val_mse: 5.6640\n",
      "Epoch 120/1000\n",
      "103/103 [==============================] - 0s 179us/sample - loss: 13.2067 - mae: 1.3040 - mse: 2.6795 - val_loss: 16.5949 - val_mae: 1.9002 - val_mse: 6.2994\n",
      "Epoch 121/1000\n",
      "103/103 [==============================] - 0s 182us/sample - loss: 13.2369 - mae: 1.3294 - mse: 2.8624 - val_loss: 16.3441 - val_mae: 1.8070 - val_mse: 5.6045\n",
      "Epoch 122/1000\n",
      "103/103 [==============================] - 0s 173us/sample - loss: 13.0754 - mae: 1.2888 - mse: 2.6646 - val_loss: 16.4490 - val_mae: 1.8041 - val_mse: 5.4388\n",
      "Epoch 123/1000\n",
      "103/103 [==============================] - 0s 174us/sample - loss: 13.0494 - mae: 1.2547 - mse: 2.5841 - val_loss: 16.2609 - val_mae: 1.7957 - val_mse: 5.6085\n",
      "Epoch 124/1000\n",
      "103/103 [==============================] - 0s 166us/sample - loss: 13.0349 - mae: 1.2567 - mse: 2.5823 - val_loss: 16.5791 - val_mae: 1.9776 - val_mse: 6.7478\n",
      "Epoch 125/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 13.1158 - mae: 1.3637 - mse: 2.9512 - val_loss: 16.3263 - val_mae: 1.8452 - val_mse: 6.0074\n",
      "Epoch 126/1000\n",
      "103/103 [==============================] - 0s 174us/sample - loss: 13.0370 - mae: 1.3265 - mse: 2.8687 - val_loss: 16.2544 - val_mae: 1.7745 - val_mse: 5.4856\n",
      "Epoch 127/1000\n",
      "103/103 [==============================] - 0s 177us/sample - loss: 13.0410 - mae: 1.2787 - mse: 2.6725 - val_loss: 16.3946 - val_mae: 1.9115 - val_mse: 6.3221\n",
      "Epoch 128/1000\n",
      "103/103 [==============================] - 0s 181us/sample - loss: 12.9667 - mae: 1.3199 - mse: 2.8651 - val_loss: 16.7915 - val_mae: 1.8292 - val_mse: 5.3152\n",
      "Epoch 129/1000\n",
      "103/103 [==============================] - 0s 176us/sample - loss: 13.1228 - mae: 1.2821 - mse: 2.5814 - val_loss: 16.9535 - val_mae: 1.8627 - val_mse: 5.3976\n",
      "Epoch 130/1000\n",
      "103/103 [==============================] - 0s 164us/sample - loss: 13.1493 - mae: 1.2491 - mse: 2.4823 - val_loss: 16.2452 - val_mae: 1.8401 - val_mse: 5.9345\n",
      "Epoch 131/1000\n",
      "103/103 [==============================] - 0s 185us/sample - loss: 12.9150 - mae: 1.2833 - mse: 2.6383 - val_loss: 16.5900 - val_mae: 1.9666 - val_mse: 6.7040\n",
      "Epoch 132/1000\n",
      "103/103 [==============================] - 0s 173us/sample - loss: 13.0250 - mae: 1.3399 - mse: 2.8987 - val_loss: 16.2025 - val_mae: 1.8058 - val_mse: 5.7029\n",
      "Epoch 133/1000\n",
      "103/103 [==============================] - 0s 178us/sample - loss: 12.9511 - mae: 1.2570 - mse: 2.5535 - val_loss: 16.2143 - val_mae: 1.8145 - val_mse: 5.7719\n",
      "Epoch 134/1000\n",
      "103/103 [==============================] - 0s 174us/sample - loss: 12.9632 - mae: 1.2957 - mse: 2.6833 - val_loss: 16.4840 - val_mae: 1.8857 - val_mse: 6.2099\n",
      "Epoch 135/1000\n",
      "103/103 [==============================] - 0s 190us/sample - loss: 13.0433 - mae: 1.3228 - mse: 2.7750 - val_loss: 16.5564 - val_mae: 1.9207 - val_mse: 6.4554\n",
      "Epoch 136/1000\n",
      "103/103 [==============================] - 0s 170us/sample - loss: 12.9989 - mae: 1.3192 - mse: 2.7213 - val_loss: 16.2310 - val_mae: 1.8310 - val_mse: 5.8184\n",
      "Epoch 137/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 172us/sample - loss: 12.8792 - mae: 1.2486 - mse: 2.4942 - val_loss: 16.4189 - val_mae: 1.9095 - val_mse: 6.3224\n",
      "Epoch 138/1000\n",
      "103/103 [==============================] - 0s 188us/sample - loss: 12.9895 - mae: 1.2966 - mse: 2.7700 - val_loss: 16.2186 - val_mae: 1.7752 - val_mse: 5.4145\n",
      "Epoch 139/1000\n",
      "103/103 [==============================] - 0s 172us/sample - loss: 12.7787 - mae: 1.1796 - mse: 2.2943 - val_loss: 16.3242 - val_mae: 1.8402 - val_mse: 5.8078\n",
      "Epoch 140/1000\n",
      "103/103 [==============================] - 0s 174us/sample - loss: 13.1558 - mae: 1.2910 - mse: 2.7541 - val_loss: 16.2548 - val_mae: 1.7572 - val_mse: 5.2826\n",
      "Epoch 141/1000\n",
      "103/103 [==============================] - 0s 176us/sample - loss: 12.8006 - mae: 1.1910 - mse: 2.2948 - val_loss: 16.2678 - val_mae: 1.8619 - val_mse: 6.0993\n",
      "Epoch 142/1000\n",
      "103/103 [==============================] - 0s 186us/sample - loss: 12.8930 - mae: 1.2763 - mse: 2.6511 - val_loss: 16.4023 - val_mae: 1.9327 - val_mse: 6.4536\n",
      "Epoch 143/1000\n",
      "103/103 [==============================] - 0s 184us/sample - loss: 12.8623 - mae: 1.2775 - mse: 2.6865 - val_loss: 16.1666 - val_mae: 1.7790 - val_mse: 5.4902\n",
      "Epoch 144/1000\n",
      "103/103 [==============================] - 0s 166us/sample - loss: 12.8050 - mae: 1.2150 - mse: 2.4085 - val_loss: 16.2072 - val_mae: 1.8218 - val_mse: 5.7161\n",
      "Epoch 145/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 12.7488 - mae: 1.1879 - mse: 2.3121 - val_loss: 16.4067 - val_mae: 1.9152 - val_mse: 6.4067\n",
      "Epoch 146/1000\n",
      "103/103 [==============================] - 0s 161us/sample - loss: 12.7577 - mae: 1.2607 - mse: 2.5626 - val_loss: 16.5352 - val_mae: 1.8362 - val_mse: 5.5367\n",
      "Epoch 147/1000\n",
      "103/103 [==============================] - 0s 166us/sample - loss: 12.8179 - mae: 1.2051 - mse: 2.3732 - val_loss: 16.3655 - val_mae: 1.9042 - val_mse: 6.2827\n",
      "Epoch 148/1000\n",
      "103/103 [==============================] - 0s 165us/sample - loss: 12.8658 - mae: 1.2856 - mse: 2.7147 - val_loss: 16.2212 - val_mae: 1.7550 - val_mse: 5.4842\n",
      "Epoch 149/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 12.7393 - mae: 1.1930 - mse: 2.3542 - val_loss: 16.4497 - val_mae: 1.7523 - val_mse: 5.2019\n",
      "Epoch 150/1000\n",
      "103/103 [==============================] - 0s 170us/sample - loss: 12.7303 - mae: 1.1762 - mse: 2.2487 - val_loss: 17.0648 - val_mae: 1.8709 - val_mse: 5.3447\n",
      "Epoch 151/1000\n",
      "103/103 [==============================] - 0s 178us/sample - loss: 12.9334 - mae: 1.2042 - mse: 2.3127 - val_loss: 16.2895 - val_mae: 1.8132 - val_mse: 5.6080\n",
      "Epoch 152/1000\n",
      "103/103 [==============================] - 0s 175us/sample - loss: 12.6702 - mae: 1.1996 - mse: 2.3059 - val_loss: 16.2183 - val_mae: 1.7386 - val_mse: 5.2719\n",
      "Epoch 153/1000\n",
      "103/103 [==============================] - 0s 177us/sample - loss: 12.7650 - mae: 1.1863 - mse: 2.3131 - val_loss: 16.8780 - val_mae: 1.8668 - val_mse: 5.3729\n",
      "Epoch 154/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 12.8485 - mae: 1.1651 - mse: 2.2086 - val_loss: 16.2037 - val_mae: 1.7734 - val_mse: 5.3619\n",
      "Epoch 155/1000\n",
      "103/103 [==============================] - 0s 190us/sample - loss: 12.6661 - mae: 1.1759 - mse: 2.1934 - val_loss: 16.1464 - val_mae: 1.7909 - val_mse: 5.5202\n",
      "Epoch 156/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 12.7960 - mae: 1.2160 - mse: 2.3706 - val_loss: 16.3282 - val_mae: 1.7405 - val_mse: 5.1840\n",
      "Epoch 157/1000\n",
      "103/103 [==============================] - 0s 162us/sample - loss: 12.6231 - mae: 1.1364 - mse: 2.1172 - val_loss: 16.3844 - val_mae: 1.7669 - val_mse: 5.1958\n",
      "Epoch 158/1000\n",
      "103/103 [==============================] - 0s 170us/sample - loss: 12.7288 - mae: 1.1956 - mse: 2.2705 - val_loss: 16.4176 - val_mae: 1.7303 - val_mse: 5.2023\n",
      "Epoch 159/1000\n",
      "103/103 [==============================] - 0s 178us/sample - loss: 12.6676 - mae: 1.1461 - mse: 2.1669 - val_loss: 16.2516 - val_mae: 1.7509 - val_mse: 5.2162\n",
      "Epoch 160/1000\n",
      "103/103 [==============================] - 0s 180us/sample - loss: 12.5941 - mae: 1.1421 - mse: 2.1008 - val_loss: 16.2804 - val_mae: 1.8337 - val_mse: 5.7487\n",
      "Epoch 161/1000\n",
      "103/103 [==============================] - 0s 180us/sample - loss: 12.6840 - mae: 1.2143 - mse: 2.3376 - val_loss: 16.5952 - val_mae: 1.8065 - val_mse: 5.2246\n",
      "Epoch 162/1000\n",
      "103/103 [==============================] - 0s 176us/sample - loss: 12.7950 - mae: 1.2033 - mse: 2.2641 - val_loss: 16.3303 - val_mae: 1.8168 - val_mse: 5.5851\n",
      "Epoch 163/1000\n",
      "103/103 [==============================] - 0s 184us/sample - loss: 12.6223 - mae: 1.1593 - mse: 2.1812 - val_loss: 16.1762 - val_mae: 1.8508 - val_mse: 5.9567\n",
      "Epoch 164/1000\n",
      "103/103 [==============================] - 0s 174us/sample - loss: 12.6723 - mae: 1.2494 - mse: 2.4139 - val_loss: 16.2079 - val_mae: 1.7791 - val_mse: 5.3735\n",
      "Epoch 165/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 12.6784 - mae: 1.1575 - mse: 2.2015 - val_loss: 16.1702 - val_mae: 1.7231 - val_mse: 5.2564\n",
      "Epoch 166/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 12.5697 - mae: 1.1683 - mse: 2.2066 - val_loss: 17.4060 - val_mae: 1.8562 - val_mse: 5.3311\n",
      "Epoch 167/1000\n",
      "103/103 [==============================] - 0s 176us/sample - loss: 12.8703 - mae: 1.1542 - mse: 2.1084 - val_loss: 16.2388 - val_mae: 1.8700 - val_mse: 6.0076\n",
      "Epoch 168/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 12.7171 - mae: 1.2522 - mse: 2.5526 - val_loss: 16.4008 - val_mae: 1.7308 - val_mse: 5.1270\n",
      "Epoch 169/1000\n",
      "103/103 [==============================] - 0s 178us/sample - loss: 12.6573 - mae: 1.1656 - mse: 2.1871 - val_loss: 16.7226 - val_mae: 1.8297 - val_mse: 5.2259\n",
      "Epoch 170/1000\n",
      "103/103 [==============================] - 0s 182us/sample - loss: 12.6287 - mae: 1.1323 - mse: 2.0638 - val_loss: 16.1279 - val_mae: 1.7348 - val_mse: 5.2743\n",
      "Epoch 171/1000\n",
      "103/103 [==============================] - 0s 189us/sample - loss: 12.5205 - mae: 1.1132 - mse: 2.0466 - val_loss: 16.1506 - val_mae: 1.8597 - val_mse: 5.9499\n",
      "Epoch 172/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 12.5756 - mae: 1.2065 - mse: 2.3511 - val_loss: 16.1269 - val_mae: 1.8115 - val_mse: 5.6413\n",
      "Epoch 173/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 12.5258 - mae: 1.1643 - mse: 2.1724 - val_loss: 16.1626 - val_mae: 1.8235 - val_mse: 5.6970\n",
      "Epoch 174/1000\n",
      "103/103 [==============================] - 0s 162us/sample - loss: 12.5758 - mae: 1.1715 - mse: 2.2066 - val_loss: 16.1054 - val_mae: 1.7665 - val_mse: 5.3491\n",
      "Epoch 175/1000\n",
      "103/103 [==============================] - 0s 168us/sample - loss: 12.5332 - mae: 1.1482 - mse: 2.1297 - val_loss: 16.1797 - val_mae: 1.7177 - val_mse: 5.2286\n",
      "Epoch 176/1000\n",
      "103/103 [==============================] - 0s 165us/sample - loss: 12.4973 - mae: 1.1346 - mse: 2.0997 - val_loss: 16.6586 - val_mae: 1.8305 - val_mse: 5.2483\n",
      "Epoch 177/1000\n",
      "103/103 [==============================] - 0s 177us/sample - loss: 12.5509 - mae: 1.1319 - mse: 2.0549 - val_loss: 16.0835 - val_mae: 1.7320 - val_mse: 5.1923\n",
      "Epoch 178/1000\n",
      "103/103 [==============================] - 0s 183us/sample - loss: 12.5263 - mae: 1.1282 - mse: 2.0817 - val_loss: 16.1870 - val_mae: 1.8365 - val_mse: 5.7003\n",
      "Epoch 179/1000\n",
      "103/103 [==============================] - 0s 189us/sample - loss: 12.7361 - mae: 1.2332 - mse: 2.5003 - val_loss: 16.4733 - val_mae: 1.7270 - val_mse: 5.0469\n",
      "Epoch 180/1000\n",
      "103/103 [==============================] - 0s 191us/sample - loss: 12.6609 - mae: 1.1675 - mse: 2.2357 - val_loss: 16.0729 - val_mae: 1.7225 - val_mse: 5.1851\n",
      "Epoch 181/1000\n",
      "103/103 [==============================] - 0s 184us/sample - loss: 12.5337 - mae: 1.1493 - mse: 2.1174 - val_loss: 16.0354 - val_mae: 1.8052 - val_mse: 5.6122\n",
      "Epoch 182/1000\n",
      "103/103 [==============================] - 0s 178us/sample - loss: 12.5125 - mae: 1.1896 - mse: 2.2626 - val_loss: 16.0244 - val_mae: 1.7895 - val_mse: 5.5117\n",
      "Epoch 183/1000\n",
      "103/103 [==============================] - 0s 175us/sample - loss: 12.5084 - mae: 1.1614 - mse: 2.2189 - val_loss: 16.4018 - val_mae: 1.7155 - val_mse: 4.9943\n",
      "Epoch 184/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 182us/sample - loss: 12.5421 - mae: 1.1006 - mse: 1.9418 - val_loss: 16.2488 - val_mae: 1.7797 - val_mse: 5.1848\n",
      "Epoch 185/1000\n",
      "103/103 [==============================] - 0s 180us/sample - loss: 12.5489 - mae: 1.1619 - mse: 2.1894 - val_loss: 15.9731 - val_mae: 1.7652 - val_mse: 5.3929\n",
      "Epoch 186/1000\n",
      "103/103 [==============================] - 0s 187us/sample - loss: 12.4662 - mae: 1.1571 - mse: 2.1720 - val_loss: 16.0167 - val_mae: 1.7434 - val_mse: 5.3720\n",
      "Epoch 187/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 12.4479 - mae: 1.1496 - mse: 2.1350 - val_loss: 16.1381 - val_mae: 1.7195 - val_mse: 5.0255\n",
      "Epoch 188/1000\n",
      "103/103 [==============================] - 0s 170us/sample - loss: 12.4366 - mae: 1.0806 - mse: 1.9161 - val_loss: 16.3663 - val_mae: 1.7201 - val_mse: 4.9622\n",
      "Epoch 189/1000\n",
      "103/103 [==============================] - 0s 179us/sample - loss: 12.5421 - mae: 1.1111 - mse: 2.0120 - val_loss: 16.0663 - val_mae: 1.8621 - val_mse: 5.8749\n",
      "Epoch 190/1000\n",
      "103/103 [==============================] - 0s 175us/sample - loss: 12.5387 - mae: 1.2064 - mse: 2.2870 - val_loss: 16.3587 - val_mae: 1.8065 - val_mse: 5.3259\n",
      "Epoch 191/1000\n",
      "103/103 [==============================] - 0s 196us/sample - loss: 12.4281 - mae: 1.1251 - mse: 2.0058 - val_loss: 16.0059 - val_mae: 1.7238 - val_mse: 5.2081\n",
      "Epoch 192/1000\n",
      "103/103 [==============================] - 0s 189us/sample - loss: 12.4216 - mae: 1.1028 - mse: 1.9934 - val_loss: 16.1560 - val_mae: 1.7488 - val_mse: 5.0787\n",
      "Epoch 193/1000\n",
      "103/103 [==============================] - 0s 186us/sample - loss: 12.5387 - mae: 1.0806 - mse: 1.9192 - val_loss: 16.0448 - val_mae: 1.8185 - val_mse: 5.6990\n",
      "Epoch 194/1000\n",
      "103/103 [==============================] - 0s 172us/sample - loss: 12.4706 - mae: 1.1756 - mse: 2.2007 - val_loss: 16.4588 - val_mae: 1.7314 - val_mse: 4.9894\n",
      "Epoch 195/1000\n",
      "103/103 [==============================] - 0s 179us/sample - loss: 12.5813 - mae: 1.1162 - mse: 2.0347 - val_loss: 15.9771 - val_mae: 1.7849 - val_mse: 5.5482\n",
      "Epoch 196/1000\n",
      "103/103 [==============================] - 0s 181us/sample - loss: 12.4134 - mae: 1.1249 - mse: 2.0960 - val_loss: 16.0563 - val_mae: 1.7686 - val_mse: 5.2561\n",
      "Epoch 197/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 12.4438 - mae: 1.1303 - mse: 2.0778 - val_loss: 15.9599 - val_mae: 1.7369 - val_mse: 5.2683\n",
      "Epoch 198/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 12.3960 - mae: 1.1148 - mse: 2.0108 - val_loss: 16.1860 - val_mae: 1.7139 - val_mse: 4.9518\n",
      "Epoch 199/1000\n",
      "103/103 [==============================] - 0s 175us/sample - loss: 12.6037 - mae: 1.1170 - mse: 2.0512 - val_loss: 16.4546 - val_mae: 1.7172 - val_mse: 4.9766\n",
      "Epoch 200/1000\n",
      "103/103 [==============================] - 0s 182us/sample - loss: 12.4523 - mae: 1.0552 - mse: 1.8015 - val_loss: 15.9937 - val_mae: 1.7269 - val_mse: 5.1765\n",
      "Epoch 201/1000\n",
      "103/103 [==============================] - 0s 166us/sample - loss: 12.3875 - mae: 1.0952 - mse: 1.9737 - val_loss: 15.9555 - val_mae: 1.7508 - val_mse: 5.3469\n",
      "Epoch 202/1000\n",
      "103/103 [==============================] - 0s 170us/sample - loss: 12.3767 - mae: 1.0957 - mse: 1.9528 - val_loss: 16.0430 - val_mae: 1.8006 - val_mse: 5.5697\n",
      "Epoch 203/1000\n",
      "103/103 [==============================] - 0s 163us/sample - loss: 12.5455 - mae: 1.1769 - mse: 2.3074 - val_loss: 16.1897 - val_mae: 1.7797 - val_mse: 5.2280\n",
      "Epoch 204/1000\n",
      "103/103 [==============================] - 0s 164us/sample - loss: 12.4005 - mae: 1.0574 - mse: 1.8916 - val_loss: 16.3309 - val_mae: 1.9721 - val_mse: 6.4644\n",
      "Epoch 205/1000\n",
      "103/103 [==============================] - 0s 172us/sample - loss: 12.6197 - mae: 1.2616 - mse: 2.6114 - val_loss: 16.1061 - val_mae: 1.7370 - val_mse: 5.0850\n",
      "Epoch 206/1000\n",
      "103/103 [==============================] - 0s 170us/sample - loss: 12.3379 - mae: 1.0784 - mse: 1.8910 - val_loss: 16.1347 - val_mae: 1.7259 - val_mse: 5.0280\n",
      "Epoch 207/1000\n",
      "103/103 [==============================] - 0s 177us/sample - loss: 12.3547 - mae: 1.0454 - mse: 1.8015 - val_loss: 15.9905 - val_mae: 1.7364 - val_mse: 5.1453\n",
      "Epoch 208/1000\n",
      "103/103 [==============================] - 0s 180us/sample - loss: 12.3024 - mae: 1.0800 - mse: 1.9100 - val_loss: 16.1678 - val_mae: 1.7192 - val_mse: 5.0015\n",
      "Epoch 209/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 12.3426 - mae: 1.0829 - mse: 1.9268 - val_loss: 16.2527 - val_mae: 1.7212 - val_mse: 4.9638\n",
      "Epoch 210/1000\n",
      "103/103 [==============================] - 0s 180us/sample - loss: 12.4173 - mae: 1.0891 - mse: 1.9311 - val_loss: 16.3209 - val_mae: 1.7392 - val_mse: 5.0038\n",
      "Epoch 211/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 12.4048 - mae: 1.1125 - mse: 1.9367 - val_loss: 16.1863 - val_mae: 1.8041 - val_mse: 5.4506\n",
      "Epoch 212/1000\n",
      "103/103 [==============================] - 0s 168us/sample - loss: 12.3888 - mae: 1.1138 - mse: 2.0708 - val_loss: 15.9469 - val_mae: 1.7494 - val_mse: 5.2812\n",
      "Epoch 213/1000\n",
      "103/103 [==============================] - 0s 166us/sample - loss: 12.3563 - mae: 1.1203 - mse: 2.0291 - val_loss: 15.9584 - val_mae: 1.8032 - val_mse: 5.5692\n",
      "Epoch 214/1000\n",
      "103/103 [==============================] - 0s 165us/sample - loss: 12.3222 - mae: 1.1285 - mse: 2.0599 - val_loss: 16.7658 - val_mae: 1.8061 - val_mse: 5.1247\n",
      "Epoch 215/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 12.4580 - mae: 1.0810 - mse: 1.8615 - val_loss: 16.4975 - val_mae: 1.7358 - val_mse: 4.9351\n",
      "Epoch 216/1000\n",
      "103/103 [==============================] - 0s 176us/sample - loss: 12.3849 - mae: 1.0572 - mse: 1.8660 - val_loss: 16.0742 - val_mae: 1.7144 - val_mse: 5.0113\n",
      "Epoch 217/1000\n",
      "103/103 [==============================] - 0s 175us/sample - loss: 12.3256 - mae: 1.0763 - mse: 1.8645 - val_loss: 16.0603 - val_mae: 1.7123 - val_mse: 4.9874\n",
      "Epoch 218/1000\n",
      "103/103 [==============================] - 0s 186us/sample - loss: 12.2780 - mae: 1.0600 - mse: 1.8368 - val_loss: 16.4396 - val_mae: 1.7091 - val_mse: 4.9261\n",
      "Epoch 219/1000\n",
      "103/103 [==============================] - 0s 173us/sample - loss: 12.4863 - mae: 1.0915 - mse: 1.8557 - val_loss: 16.2804 - val_mae: 1.7115 - val_mse: 5.0922\n",
      "Epoch 220/1000\n",
      "103/103 [==============================] - 0s 191us/sample - loss: 12.4139 - mae: 1.0987 - mse: 1.9401 - val_loss: 16.2480 - val_mae: 1.7008 - val_mse: 4.9952\n",
      "Epoch 221/1000\n",
      "103/103 [==============================] - 0s 178us/sample - loss: 12.3961 - mae: 1.0473 - mse: 1.8241 - val_loss: 16.1762 - val_mae: 1.7330 - val_mse: 4.9720\n",
      "Epoch 222/1000\n",
      "103/103 [==============================] - 0s 199us/sample - loss: 12.4005 - mae: 1.0851 - mse: 1.9063 - val_loss: 16.1891 - val_mae: 1.7304 - val_mse: 4.9570\n",
      "Epoch 223/1000\n",
      "103/103 [==============================] - 0s 202us/sample - loss: 12.2907 - mae: 1.0658 - mse: 1.8527 - val_loss: 15.9667 - val_mae: 1.7356 - val_mse: 5.0804\n",
      "Epoch 224/1000\n",
      "103/103 [==============================] - 0s 190us/sample - loss: 12.2520 - mae: 1.0635 - mse: 1.8605 - val_loss: 15.9465 - val_mae: 1.7266 - val_mse: 5.1009\n",
      "Epoch 225/1000\n",
      "103/103 [==============================] - 0s 179us/sample - loss: 12.2857 - mae: 1.0667 - mse: 1.8603 - val_loss: 16.0018 - val_mae: 1.7324 - val_mse: 5.2765\n",
      "Epoch 226/1000\n",
      "103/103 [==============================] - 0s 181us/sample - loss: 12.3485 - mae: 1.1133 - mse: 2.0600 - val_loss: 16.7964 - val_mae: 1.7507 - val_mse: 4.9760\n",
      "Epoch 227/1000\n",
      "103/103 [==============================] - 0s 196us/sample - loss: 12.6752 - mae: 1.1310 - mse: 2.0892 - val_loss: 16.0480 - val_mae: 1.7112 - val_mse: 4.9720\n",
      "Epoch 228/1000\n",
      "103/103 [==============================] - 0s 193us/sample - loss: 12.2626 - mae: 1.0594 - mse: 1.8136 - val_loss: 15.9126 - val_mae: 1.7808 - val_mse: 5.3968\n",
      "Epoch 229/1000\n",
      "103/103 [==============================] - 0s 172us/sample - loss: 12.3036 - mae: 1.0898 - mse: 1.9431 - val_loss: 15.9714 - val_mae: 1.7507 - val_mse: 5.3564\n",
      "Epoch 230/1000\n",
      "103/103 [==============================] - 0s 166us/sample - loss: 12.3149 - mae: 1.1071 - mse: 2.0111 - val_loss: 16.0217 - val_mae: 1.7495 - val_mse: 5.1195\n",
      "Epoch 231/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 179us/sample - loss: 12.2064 - mae: 1.0485 - mse: 1.8116 - val_loss: 16.1400 - val_mae: 1.7017 - val_mse: 4.9894\n",
      "Epoch 232/1000\n",
      "103/103 [==============================] - 0s 187us/sample - loss: 12.2341 - mae: 1.0505 - mse: 1.8047 - val_loss: 16.0472 - val_mae: 1.7122 - val_mse: 5.1805\n",
      "Epoch 233/1000\n",
      "103/103 [==============================] - 0s 196us/sample - loss: 12.2987 - mae: 1.0633 - mse: 1.8463 - val_loss: 15.9708 - val_mae: 1.8152 - val_mse: 5.6571\n",
      "Epoch 234/1000\n",
      "103/103 [==============================] - 0s 195us/sample - loss: 12.5186 - mae: 1.2074 - mse: 2.2962 - val_loss: 16.6827 - val_mae: 1.7681 - val_mse: 5.0046\n",
      "Epoch 235/1000\n",
      "103/103 [==============================] - 0s 177us/sample - loss: 12.3091 - mae: 1.0352 - mse: 1.7204 - val_loss: 16.2852 - val_mae: 1.7188 - val_mse: 4.9106\n",
      "Epoch 236/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 12.2113 - mae: 1.0218 - mse: 1.7102 - val_loss: 16.4055 - val_mae: 1.7616 - val_mse: 5.0043\n",
      "Epoch 237/1000\n",
      "103/103 [==============================] - 0s 181us/sample - loss: 12.2831 - mae: 1.0110 - mse: 1.6763 - val_loss: 15.9482 - val_mae: 1.8063 - val_mse: 5.5693\n",
      "Epoch 238/1000\n",
      "103/103 [==============================] - 0s 183us/sample - loss: 12.3804 - mae: 1.1364 - mse: 2.1419 - val_loss: 16.3554 - val_mae: 1.7098 - val_mse: 4.9398\n",
      "Epoch 239/1000\n",
      "103/103 [==============================] - 0s 189us/sample - loss: 12.2697 - mae: 1.0399 - mse: 1.7892 - val_loss: 16.7820 - val_mae: 1.8112 - val_mse: 5.1936\n",
      "Epoch 240/1000\n",
      "103/103 [==============================] - 0s 162us/sample - loss: 12.3303 - mae: 1.0556 - mse: 1.7692 - val_loss: 16.5332 - val_mae: 1.7173 - val_mse: 4.9161\n",
      "Epoch 241/1000\n",
      "103/103 [==============================] - 0s 181us/sample - loss: 12.3101 - mae: 1.0188 - mse: 1.7116 - val_loss: 15.9830 - val_mae: 1.7214 - val_mse: 5.0697\n",
      "Epoch 242/1000\n",
      "103/103 [==============================] - 0s 179us/sample - loss: 12.2741 - mae: 1.0905 - mse: 1.9214 - val_loss: 16.0335 - val_mae: 1.7242 - val_mse: 4.9987\n",
      "Epoch 243/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 12.2725 - mae: 1.0996 - mse: 1.9686 - val_loss: 16.5112 - val_mae: 1.7185 - val_mse: 4.9084\n",
      "Epoch 244/1000\n",
      "103/103 [==============================] - 0s 172us/sample - loss: 12.3602 - mae: 1.0600 - mse: 1.8326 - val_loss: 16.0633 - val_mae: 1.7195 - val_mse: 4.9478\n",
      "Epoch 245/1000\n",
      "103/103 [==============================] - 0s 177us/sample - loss: 12.1947 - mae: 1.0373 - mse: 1.7298 - val_loss: 15.9317 - val_mae: 1.7923 - val_mse: 5.4917\n",
      "Epoch 246/1000\n",
      "103/103 [==============================] - 0s 184us/sample - loss: 12.3518 - mae: 1.1078 - mse: 2.0159 - val_loss: 15.9301 - val_mae: 1.7410 - val_mse: 5.1354\n",
      "Epoch 247/1000\n",
      "103/103 [==============================] - 0s 190us/sample - loss: 12.2210 - mae: 1.0583 - mse: 1.8017 - val_loss: 16.4684 - val_mae: 1.7763 - val_mse: 5.0578\n",
      "Epoch 248/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 12.2281 - mae: 1.0501 - mse: 1.7690 - val_loss: 17.1716 - val_mae: 1.7619 - val_mse: 5.1093\n",
      "Epoch 249/1000\n",
      "103/103 [==============================] - 0s 173us/sample - loss: 12.3534 - mae: 1.0167 - mse: 1.6949 - val_loss: 15.9642 - val_mae: 1.7173 - val_mse: 5.0789\n",
      "Epoch 250/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 12.2116 - mae: 1.0724 - mse: 1.8725 - val_loss: 16.4745 - val_mae: 1.6993 - val_mse: 4.9214\n",
      "Epoch 251/1000\n",
      "103/103 [==============================] - 0s 178us/sample - loss: 12.3800 - mae: 1.0454 - mse: 1.7513 - val_loss: 16.3349 - val_mae: 1.6968 - val_mse: 4.9886\n",
      "Epoch 252/1000\n",
      "103/103 [==============================] - 0s 245us/sample - loss: 12.2948 - mae: 1.0368 - mse: 1.7722 - val_loss: 16.4151 - val_mae: 1.7052 - val_mse: 4.8880\n",
      "Epoch 253/1000\n",
      "103/103 [==============================] - 0s 231us/sample - loss: 12.2572 - mae: 1.0364 - mse: 1.7199 - val_loss: 16.6777 - val_mae: 1.7385 - val_mse: 4.9458\n",
      "Epoch 254/1000\n",
      "103/103 [==============================] - 0s 238us/sample - loss: 12.3636 - mae: 1.0458 - mse: 1.7826 - val_loss: 16.2840 - val_mae: 1.6975 - val_mse: 4.9887\n",
      "Epoch 255/1000\n",
      "103/103 [==============================] - 0s 242us/sample - loss: 12.1802 - mae: 1.0119 - mse: 1.6864 - val_loss: 16.2584 - val_mae: 1.7864 - val_mse: 5.2605\n",
      "Epoch 256/1000\n",
      "103/103 [==============================] - 0s 225us/sample - loss: 12.2541 - mae: 1.0605 - mse: 1.8268 - val_loss: 15.9412 - val_mae: 1.7674 - val_mse: 5.3081\n",
      "Epoch 257/1000\n",
      "103/103 [==============================] - 0s 230us/sample - loss: 12.2431 - mae: 1.0767 - mse: 1.9291 - val_loss: 16.3258 - val_mae: 1.7097 - val_mse: 4.8754\n",
      "Epoch 258/1000\n",
      "103/103 [==============================] - 0s 212us/sample - loss: 12.1809 - mae: 1.0141 - mse: 1.6923 - val_loss: 15.9471 - val_mae: 1.7255 - val_mse: 5.0136\n",
      "Epoch 259/1000\n",
      "103/103 [==============================] - 0s 230us/sample - loss: 12.3231 - mae: 1.0916 - mse: 1.9046 - val_loss: 16.0420 - val_mae: 1.8647 - val_mse: 5.8217\n",
      "Epoch 260/1000\n",
      "103/103 [==============================] - 0s 197us/sample - loss: 12.3467 - mae: 1.1919 - mse: 2.2101 - val_loss: 15.9039 - val_mae: 1.8045 - val_mse: 5.4768\n",
      "Epoch 261/1000\n",
      "103/103 [==============================] - 0s 214us/sample - loss: 12.2761 - mae: 1.1220 - mse: 2.0388 - val_loss: 15.9666 - val_mae: 1.7264 - val_mse: 4.9725\n",
      "Epoch 262/1000\n",
      "103/103 [==============================] - 0s 170us/sample - loss: 12.1675 - mae: 1.0083 - mse: 1.6734 - val_loss: 16.0093 - val_mae: 1.8515 - val_mse: 5.7901\n",
      "Epoch 263/1000\n",
      "103/103 [==============================] - 0s 168us/sample - loss: 12.3184 - mae: 1.1377 - mse: 2.1161 - val_loss: 16.1481 - val_mae: 1.7194 - val_mse: 4.9306\n",
      "Epoch 264/1000\n",
      "103/103 [==============================] - 0s 174us/sample - loss: 12.2696 - mae: 1.0176 - mse: 1.7349 - val_loss: 15.9113 - val_mae: 1.7577 - val_mse: 5.2784\n",
      "Epoch 265/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 12.1542 - mae: 1.0511 - mse: 1.8419 - val_loss: 16.0615 - val_mae: 1.7249 - val_mse: 5.2636\n",
      "Epoch 266/1000\n",
      "103/103 [==============================] - 0s 166us/sample - loss: 12.2820 - mae: 1.0853 - mse: 1.9283 - val_loss: 16.6245 - val_mae: 1.7107 - val_mse: 4.9482\n",
      "Epoch 267/1000\n",
      "103/103 [==============================] - 0s 164us/sample - loss: 12.2482 - mae: 1.0166 - mse: 1.6905 - val_loss: 16.9601 - val_mae: 1.7267 - val_mse: 5.1011\n",
      "Epoch 268/1000\n",
      "103/103 [==============================] - 0s 187us/sample - loss: 12.2649 - mae: 1.0127 - mse: 1.6205 - val_loss: 16.0971 - val_mae: 1.7024 - val_mse: 4.9375\n",
      "Epoch 269/1000\n",
      "103/103 [==============================] - 0s 186us/sample - loss: 12.1564 - mae: 0.9922 - mse: 1.6462 - val_loss: 16.1581 - val_mae: 1.7206 - val_mse: 4.9318\n",
      "Epoch 270/1000\n",
      "103/103 [==============================] - 0s 187us/sample - loss: 12.1498 - mae: 0.9905 - mse: 1.6525 - val_loss: 16.0251 - val_mae: 1.7517 - val_mse: 5.1037\n",
      "Epoch 271/1000\n",
      "103/103 [==============================] - 0s 176us/sample - loss: 12.2346 - mae: 1.0206 - mse: 1.7817 - val_loss: 16.0269 - val_mae: 1.6988 - val_mse: 5.0111\n",
      "Epoch 272/1000\n",
      "103/103 [==============================] - 0s 175us/sample - loss: 12.1843 - mae: 1.0482 - mse: 1.8072 - val_loss: 15.8983 - val_mae: 1.7651 - val_mse: 5.2153\n",
      "Epoch 273/1000\n",
      "103/103 [==============================] - 0s 172us/sample - loss: 12.1929 - mae: 1.0396 - mse: 1.8168 - val_loss: 16.4563 - val_mae: 1.7249 - val_mse: 4.8972\n",
      "Epoch 274/1000\n",
      "103/103 [==============================] - 0s 170us/sample - loss: 12.2367 - mae: 1.0152 - mse: 1.7052 - val_loss: 15.9505 - val_mae: 1.7446 - val_mse: 5.1212\n",
      "Epoch 275/1000\n",
      "103/103 [==============================] - 0s 178us/sample - loss: 12.1459 - mae: 1.0666 - mse: 1.8710 - val_loss: 16.2479 - val_mae: 1.7422 - val_mse: 4.9643\n",
      "Epoch 276/1000\n",
      "103/103 [==============================] - 0s 180us/sample - loss: 12.4261 - mae: 1.0534 - mse: 1.7894 - val_loss: 16.2468 - val_mae: 1.7209 - val_mse: 4.8863\n",
      "Epoch 277/1000\n",
      "103/103 [==============================] - 0s 173us/sample - loss: 12.1236 - mae: 0.9910 - mse: 1.6521 - val_loss: 16.7235 - val_mae: 1.7245 - val_mse: 4.9354\n",
      "Epoch 278/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 188us/sample - loss: 12.1998 - mae: 0.9971 - mse: 1.6351 - val_loss: 17.3405 - val_mae: 1.8063 - val_mse: 5.1801\n",
      "Epoch 279/1000\n",
      "103/103 [==============================] - 0s 190us/sample - loss: 12.2869 - mae: 0.9567 - mse: 1.5164 - val_loss: 15.9324 - val_mae: 1.7225 - val_mse: 5.0485\n",
      "Epoch 280/1000\n",
      "103/103 [==============================] - 0s 166us/sample - loss: 12.1712 - mae: 1.0439 - mse: 1.8174 - val_loss: 16.6781 - val_mae: 1.7353 - val_mse: 4.9338\n",
      "Epoch 281/1000\n",
      "103/103 [==============================] - 0s 183us/sample - loss: 12.2056 - mae: 0.9715 - mse: 1.5278 - val_loss: 15.8987 - val_mae: 1.7645 - val_mse: 5.2511\n",
      "Epoch 282/1000\n",
      "103/103 [==============================] - 0s 176us/sample - loss: 12.1135 - mae: 1.0368 - mse: 1.7954 - val_loss: 16.1432 - val_mae: 1.6911 - val_mse: 4.9254\n",
      "Epoch 283/1000\n",
      "103/103 [==============================] - 0s 181us/sample - loss: 12.1009 - mae: 0.9754 - mse: 1.6133 - val_loss: 16.0307 - val_mae: 1.8725 - val_mse: 5.8753\n",
      "Epoch 284/1000\n",
      "103/103 [==============================] - 0s 185us/sample - loss: 12.3677 - mae: 1.1507 - mse: 2.1926 - val_loss: 16.3589 - val_mae: 1.6863 - val_mse: 4.9581\n",
      "Epoch 285/1000\n",
      "103/103 [==============================] - 0s 165us/sample - loss: 12.1496 - mae: 1.0004 - mse: 1.6649 - val_loss: 15.9145 - val_mae: 1.7659 - val_mse: 5.3326\n",
      "Epoch 286/1000\n",
      "103/103 [==============================] - 0s 175us/sample - loss: 12.2135 - mae: 1.0609 - mse: 1.8710 - val_loss: 15.9625 - val_mae: 1.7257 - val_mse: 5.1456\n",
      "Epoch 287/1000\n",
      "103/103 [==============================] - 0s 175us/sample - loss: 12.1003 - mae: 1.0280 - mse: 1.7618 - val_loss: 16.7302 - val_mae: 1.7147 - val_mse: 4.9564\n",
      "Epoch 288/1000\n",
      "103/103 [==============================] - 0s 174us/sample - loss: 12.1541 - mae: 0.9916 - mse: 1.6235 - val_loss: 16.0213 - val_mae: 1.7131 - val_mse: 4.9468\n",
      "Epoch 289/1000\n",
      "103/103 [==============================] - 0s 176us/sample - loss: 12.0933 - mae: 1.0116 - mse: 1.6635 - val_loss: 16.0987 - val_mae: 1.7024 - val_mse: 4.9115\n",
      "Epoch 290/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 12.1098 - mae: 0.9793 - mse: 1.5993 - val_loss: 16.1158 - val_mae: 1.6870 - val_mse: 4.9476\n",
      "Epoch 291/1000\n",
      "103/103 [==============================] - 0s 187us/sample - loss: 12.1039 - mae: 1.0116 - mse: 1.6799 - val_loss: 15.9825 - val_mae: 1.7179 - val_mse: 5.0323\n",
      "Epoch 292/1000\n",
      "103/103 [==============================] - 0s 181us/sample - loss: 12.3829 - mae: 1.0968 - mse: 1.9612 - val_loss: 16.0230 - val_mae: 1.7238 - val_mse: 4.9961\n",
      "Epoch 293/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 12.0845 - mae: 0.9984 - mse: 1.6415 - val_loss: 16.1562 - val_mae: 1.7007 - val_mse: 4.9055\n",
      "Epoch 294/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 12.0951 - mae: 1.0006 - mse: 1.6429 - val_loss: 15.9327 - val_mae: 1.7410 - val_mse: 5.0942\n",
      "Epoch 295/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 12.1314 - mae: 1.0233 - mse: 1.7462 - val_loss: 15.8781 - val_mae: 1.7514 - val_mse: 5.2384\n",
      "Epoch 296/1000\n",
      "103/103 [==============================] - 0s 173us/sample - loss: 12.2957 - mae: 1.1066 - mse: 1.9846 - val_loss: 16.2306 - val_mae: 1.6836 - val_mse: 4.9269\n",
      "Epoch 297/1000\n",
      "103/103 [==============================] - 0s 165us/sample - loss: 12.0925 - mae: 1.0086 - mse: 1.6781 - val_loss: 17.6242 - val_mae: 1.7982 - val_mse: 5.2840\n",
      "Epoch 298/1000\n",
      "103/103 [==============================] - 0s 172us/sample - loss: 12.3842 - mae: 0.9963 - mse: 1.6380 - val_loss: 16.3081 - val_mae: 1.6878 - val_mse: 4.8468\n",
      "Epoch 299/1000\n",
      "103/103 [==============================] - 0s 172us/sample - loss: 12.0755 - mae: 0.9467 - mse: 1.5072 - val_loss: 15.9054 - val_mae: 1.7634 - val_mse: 5.2928\n",
      "Epoch 300/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 12.1676 - mae: 1.0531 - mse: 1.8301 - val_loss: 16.1652 - val_mae: 1.7225 - val_mse: 4.8897\n",
      "Epoch 301/1000\n",
      "103/103 [==============================] - 0s 176us/sample - loss: 12.0784 - mae: 0.9726 - mse: 1.5742 - val_loss: 16.2031 - val_mae: 1.7046 - val_mse: 4.8537\n",
      "Epoch 302/1000\n",
      "103/103 [==============================] - 0s 167us/sample - loss: 12.1242 - mae: 1.0097 - mse: 1.6785 - val_loss: 15.9074 - val_mae: 1.7728 - val_mse: 5.2139\n",
      "Epoch 303/1000\n",
      "103/103 [==============================] - 0s 187us/sample - loss: 12.2220 - mae: 1.0933 - mse: 1.8898 - val_loss: 16.2944 - val_mae: 1.7057 - val_mse: 4.8529\n",
      "Epoch 304/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 12.0548 - mae: 0.9441 - mse: 1.4835 - val_loss: 16.0775 - val_mae: 1.8785 - val_mse: 5.9483\n",
      "Epoch 305/1000\n",
      "103/103 [==============================] - 0s 173us/sample - loss: 12.2667 - mae: 1.1243 - mse: 2.1679 - val_loss: 15.9567 - val_mae: 1.7061 - val_mse: 4.9536\n",
      "Epoch 306/1000\n",
      "103/103 [==============================] - 0s 172us/sample - loss: 12.0585 - mae: 1.0007 - mse: 1.6630 - val_loss: 16.4456 - val_mae: 1.6843 - val_mse: 5.0079\n",
      "Epoch 307/1000\n",
      "103/103 [==============================] - 0s 171us/sample - loss: 12.1085 - mae: 0.9812 - mse: 1.6071 - val_loss: 16.1601 - val_mae: 1.6853 - val_mse: 4.8600\n",
      "Epoch 308/1000\n",
      "103/103 [==============================] - 0s 178us/sample - loss: 12.0717 - mae: 0.9635 - mse: 1.5607 - val_loss: 16.7608 - val_mae: 1.7059 - val_mse: 4.9545\n",
      "Epoch 309/1000\n",
      "103/103 [==============================] - 0s 178us/sample - loss: 12.1683 - mae: 0.9983 - mse: 1.5855 - val_loss: 16.0342 - val_mae: 1.7161 - val_mse: 4.9535\n",
      "Epoch 310/1000\n",
      "103/103 [==============================] - 0s 188us/sample - loss: 12.1147 - mae: 0.9803 - mse: 1.6450 - val_loss: 16.1309 - val_mae: 1.6876 - val_mse: 5.0131\n",
      "Epoch 311/1000\n",
      "103/103 [==============================] - 0s 169us/sample - loss: 12.0638 - mae: 0.9880 - mse: 1.6304 - val_loss: 17.0638 - val_mae: 1.7818 - val_mse: 5.0783\n",
      "Epoch 312/1000\n",
      "103/103 [==============================] - 0s 177us/sample - loss: 12.2235 - mae: 0.9727 - mse: 1.5569 - val_loss: 16.0463 - val_mae: 1.7583 - val_mse: 5.1535\n",
      "Epoch 313/1000\n",
      "103/103 [==============================] - 0s 177us/sample - loss: 12.1991 - mae: 1.0525 - mse: 1.8170 - val_loss: 15.9515 - val_mae: 1.7282 - val_mse: 5.0655\n",
      "Epoch 314/1000\n",
      "103/103 [==============================] - 0s 199us/sample - loss: 12.0573 - mae: 0.9956 - mse: 1.6812 - val_loss: 15.9267 - val_mae: 1.7872 - val_mse: 5.3466\n",
      "Epoch 315/1000\n",
      "103/103 [==============================] - 0s 213us/sample - loss: 12.1626 - mae: 1.0753 - mse: 1.8687 - val_loss: 16.2355 - val_mae: 1.7169 - val_mse: 4.9110\n",
      "Epoch 316/1000\n",
      "103/103 [==============================] - 0s 212us/sample - loss: 12.0490 - mae: 0.9771 - mse: 1.6061 - val_loss: 16.7273 - val_mae: 1.7200 - val_mse: 4.9550\n",
      "Epoch 317/1000\n",
      "103/103 [==============================] - 0s 233us/sample - loss: 12.1897 - mae: 0.9798 - mse: 1.5954 - val_loss: 15.9952 - val_mae: 1.7272 - val_mse: 5.0966\n",
      "Epoch 318/1000\n",
      "103/103 [==============================] - 0s 242us/sample - loss: 12.0905 - mae: 1.0210 - mse: 1.7293 - val_loss: 15.9284 - val_mae: 1.7419 - val_mse: 5.1204\n",
      "Epoch 319/1000\n",
      "103/103 [==============================] - 0s 198us/sample - loss: 12.1426 - mae: 1.0578 - mse: 1.8162 - val_loss: 17.3449 - val_mae: 1.8049 - val_mse: 5.1978\n",
      "Epoch 320/1000\n",
      "103/103 [==============================] - 0s 216us/sample - loss: 12.2540 - mae: 0.9848 - mse: 1.5462 - val_loss: 16.1455 - val_mae: 1.7037 - val_mse: 4.9156\n",
      "Epoch 321/1000\n",
      "103/103 [==============================] - 0s 214us/sample - loss: 12.0207 - mae: 0.9606 - mse: 1.5513 - val_loss: 16.0000 - val_mae: 1.7361 - val_mse: 5.0446\n",
      "Epoch 322/1000\n",
      "103/103 [==============================] - 0s 188us/sample - loss: 12.1173 - mae: 0.9990 - mse: 1.6812 - val_loss: 16.6516 - val_mae: 1.7618 - val_mse: 4.9981\n",
      "Epoch 323/1000\n",
      "103/103 [==============================] - 0s 207us/sample - loss: 12.1165 - mae: 0.9415 - mse: 1.5387 - val_loss: 16.3186 - val_mae: 1.7020 - val_mse: 5.2018\n",
      "Epoch 324/1000\n",
      "103/103 [==============================] - 0s 212us/sample - loss: 12.0833 - mae: 1.0083 - mse: 1.6704 - val_loss: 16.2857 - val_mae: 1.7611 - val_mse: 5.0727\n",
      "Epoch 325/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 196us/sample - loss: 12.0718 - mae: 0.9807 - mse: 1.5997 - val_loss: 15.9124 - val_mae: 1.7386 - val_mse: 5.0958\n",
      "Epoch 326/1000\n",
      "103/103 [==============================] - 0s 197us/sample - loss: 12.0544 - mae: 1.0146 - mse: 1.7009 - val_loss: 16.6305 - val_mae: 1.7206 - val_mse: 4.9473\n",
      "Epoch 327/1000\n",
      "103/103 [==============================] - 0s 218us/sample - loss: 12.0257 - mae: 0.9578 - mse: 1.5049 - val_loss: 16.1580 - val_mae: 1.6835 - val_mse: 4.9879\n",
      "Epoch 328/1000\n",
      "103/103 [==============================] - 0s 197us/sample - loss: 12.0344 - mae: 0.9681 - mse: 1.5861 - val_loss: 16.2013 - val_mae: 1.6894 - val_mse: 4.9639\n",
      "Epoch 329/1000\n",
      "103/103 [==============================] - 0s 187us/sample - loss: 12.0772 - mae: 0.9908 - mse: 1.6233 - val_loss: 17.1898 - val_mae: 1.7765 - val_mse: 5.1217\n",
      "Epoch 330/1000\n",
      "103/103 [==============================] - 0s 212us/sample - loss: 12.2254 - mae: 0.9556 - mse: 1.5728 - val_loss: 16.2900 - val_mae: 1.6881 - val_mse: 4.9141\n",
      "Epoch 331/1000\n",
      "103/103 [==============================] - 0s 209us/sample - loss: 12.0601 - mae: 0.9694 - mse: 1.6002 - val_loss: 17.5440 - val_mae: 1.7917 - val_mse: 5.2728\n",
      "Epoch 332/1000\n",
      "103/103 [==============================] - 0s 189us/sample - loss: 12.2525 - mae: 0.9689 - mse: 1.5337 - val_loss: 16.0144 - val_mae: 1.7684 - val_mse: 5.2026\n",
      "Epoch 333/1000\n",
      "103/103 [==============================] - 0s 203us/sample - loss: 12.0546 - mae: 1.0291 - mse: 1.7802 - val_loss: 16.6692 - val_mae: 1.6967 - val_mse: 5.0326\n",
      "Epoch 334/1000\n",
      "103/103 [==============================] - 0s 221us/sample - loss: 12.1994 - mae: 1.0125 - mse: 1.6184 - val_loss: 16.2120 - val_mae: 1.7180 - val_mse: 5.2391\n",
      "Epoch 335/1000\n",
      "103/103 [==============================] - 0s 190us/sample - loss: 12.1135 - mae: 1.0105 - mse: 1.7176 - val_loss: 15.9726 - val_mae: 1.8207 - val_mse: 5.6000\n",
      "Epoch 336/1000\n",
      "103/103 [==============================] - 0s 179us/sample - loss: 12.1309 - mae: 1.0735 - mse: 1.9512 - val_loss: 16.1167 - val_mae: 1.6999 - val_mse: 4.9569\n",
      "Epoch 337/1000\n",
      "103/103 [==============================] - 0s 205us/sample - loss: 12.0114 - mae: 0.9729 - mse: 1.5951 - val_loss: 16.9222 - val_mae: 1.7459 - val_mse: 5.0228\n",
      "Epoch 338/1000\n",
      "103/103 [==============================] - 0s 218us/sample - loss: 12.2745 - mae: 0.9998 - mse: 1.6511 - val_loss: 16.2309 - val_mae: 1.7160 - val_mse: 4.9096\n",
      "Epoch 339/1000\n",
      "103/103 [==============================] - 0s 187us/sample - loss: 12.0166 - mae: 0.9751 - mse: 1.5473 - val_loss: 16.1952 - val_mae: 1.7487 - val_mse: 5.0271\n",
      "Epoch 340/1000\n",
      "103/103 [==============================] - 0s 182us/sample - loss: 12.1168 - mae: 1.0229 - mse: 1.7308 - val_loss: 16.2766 - val_mae: 1.7143 - val_mse: 4.8853\n",
      "Epoch 341/1000\n",
      "103/103 [==============================] - 0s 213us/sample - loss: 12.1037 - mae: 0.9889 - mse: 1.6077 - val_loss: 15.9863 - val_mae: 1.7048 - val_mse: 4.9588\n",
      "Epoch 342/1000\n",
      "103/103 [==============================] - 0s 211us/sample - loss: 12.1313 - mae: 1.0296 - mse: 1.7278 - val_loss: 15.9705 - val_mae: 1.7416 - val_mse: 5.3013\n",
      "Epoch 343/1000\n",
      "103/103 [==============================] - 0s 178us/sample - loss: 12.0846 - mae: 1.0228 - mse: 1.7583 - val_loss: 15.9178 - val_mae: 1.7421 - val_mse: 5.1809\n",
      "Epoch 344/1000\n",
      "103/103 [==============================] - 0s 212us/sample - loss: 12.0533 - mae: 1.0162 - mse: 1.7396 - val_loss: 16.2215 - val_mae: 1.6875 - val_mse: 4.9860\n",
      "Epoch 345/1000\n",
      "103/103 [==============================] - 0s 196us/sample - loss: 11.9969 - mae: 0.9640 - mse: 1.5609 - val_loss: 16.3341 - val_mae: 1.6840 - val_mse: 4.9510\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,442\n",
      "Trainable params: 5,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 206 samples, validate on 69 samples\n",
      "Epoch 1/1000\n",
      "206/206 [==============================] - 1s 3ms/sample - loss: 281.2152 - mae: 14.8716 - mse: 281.1350 - val_loss: 279.6716 - val_mae: 14.8013 - val_mse: 279.5794\n",
      "Epoch 2/1000\n",
      "206/206 [==============================] - 0s 81us/sample - loss: 260.9883 - mae: 14.2575 - mse: 260.8777 - val_loss: 258.4708 - val_mae: 14.1171 - val_mse: 258.3226\n",
      "Epoch 3/1000\n",
      "206/206 [==============================] - 0s 87us/sample - loss: 237.8052 - mae: 13.4714 - mse: 237.6093 - val_loss: 232.8305 - val_mae: 13.2391 - val_mse: 232.5523\n",
      "Epoch 4/1000\n",
      "206/206 [==============================] - 0s 72us/sample - loss: 210.1523 - mae: 12.4724 - mse: 209.7734 - val_loss: 203.1526 - val_mae: 12.1456 - val_mse: 202.6202\n",
      "Epoch 5/1000\n",
      "206/206 [==============================] - 0s 85us/sample - loss: 178.9395 - mae: 11.2245 - mse: 178.2143 - val_loss: 170.6669 - val_mae: 10.8024 - val_mse: 169.6838\n",
      "Epoch 6/1000\n",
      "206/206 [==============================] - 0s 108us/sample - loss: 145.7672 - mae: 9.7325 - mse: 144.4565 - val_loss: 137.9523 - val_mae: 9.2880 - val_mse: 136.2515\n",
      "Epoch 7/1000\n",
      "206/206 [==============================] - 0s 89us/sample - loss: 114.0077 - mae: 8.2280 - mse: 111.7961 - val_loss: 107.3601 - val_mae: 7.8478 - val_mse: 104.6088\n",
      "Epoch 8/1000\n",
      "206/206 [==============================] - 0s 94us/sample - loss: 86.2141 - mae: 6.8070 - mse: 82.7609 - val_loss: 83.2925 - val_mae: 6.6065 - val_mse: 79.2508\n",
      "Epoch 9/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 65.8457 - mae: 5.7188 - mse: 60.9204 - val_loss: 66.1807 - val_mae: 5.7392 - val_mse: 60.8671\n",
      "Epoch 10/1000\n",
      "206/206 [==============================] - 0s 109us/sample - loss: 52.1797 - mae: 5.0748 - mse: 45.8951 - val_loss: 53.7298 - val_mae: 5.0484 - val_mse: 47.1212\n",
      "Epoch 11/1000\n",
      "206/206 [==============================] - 0s 108us/sample - loss: 43.1551 - mae: 4.6423 - mse: 35.6741 - val_loss: 45.2695 - val_mae: 4.6476 - val_mse: 37.3423\n",
      "Epoch 12/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 38.2911 - mae: 4.3902 - mse: 29.5137 - val_loss: 41.1931 - val_mae: 4.3950 - val_mse: 32.5587\n",
      "Epoch 13/1000\n",
      "206/206 [==============================] - 0s 92us/sample - loss: 36.1465 - mae: 4.2209 - mse: 26.7725 - val_loss: 38.8440 - val_mae: 4.1791 - val_mse: 30.0760\n",
      "Epoch 14/1000\n",
      "206/206 [==============================] - 0s 93us/sample - loss: 34.5332 - mae: 4.0574 - mse: 24.9812 - val_loss: 37.5252 - val_mae: 4.0525 - val_mse: 28.9438\n",
      "Epoch 15/1000\n",
      "206/206 [==============================] - 0s 128us/sample - loss: 33.0339 - mae: 3.9200 - mse: 23.7074 - val_loss: 34.7758 - val_mae: 3.8946 - val_mse: 25.4468\n",
      "Epoch 16/1000\n",
      "206/206 [==============================] - 0s 141us/sample - loss: 31.5662 - mae: 3.7941 - mse: 21.7162 - val_loss: 33.4359 - val_mae: 3.7556 - val_mse: 24.4176\n",
      "Epoch 17/1000\n",
      "206/206 [==============================] - 0s 110us/sample - loss: 30.2039 - mae: 3.6585 - mse: 20.3678 - val_loss: 31.8013 - val_mae: 3.6464 - val_mse: 22.7062\n",
      "Epoch 18/1000\n",
      "206/206 [==============================] - 0s 89us/sample - loss: 28.6652 - mae: 3.5387 - mse: 18.8073 - val_loss: 30.5087 - val_mae: 3.5372 - val_mse: 21.6049\n",
      "Epoch 19/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 27.1238 - mae: 3.3865 - mse: 17.4491 - val_loss: 27.8923 - val_mae: 3.3000 - val_mse: 18.1979\n",
      "Epoch 20/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 25.8689 - mae: 3.2604 - mse: 15.8729 - val_loss: 26.1766 - val_mae: 3.1507 - val_mse: 16.1808\n",
      "Epoch 21/1000\n",
      "206/206 [==============================] - 0s 106us/sample - loss: 24.5121 - mae: 3.1343 - mse: 14.4787 - val_loss: 24.5998 - val_mae: 2.9464 - val_mse: 14.0794\n",
      "Epoch 22/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 114us/sample - loss: 23.3328 - mae: 2.9964 - mse: 12.9906 - val_loss: 23.5001 - val_mae: 2.8934 - val_mse: 13.5264\n",
      "Epoch 23/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 22.1328 - mae: 2.8849 - mse: 11.9560 - val_loss: 22.5725 - val_mae: 2.8362 - val_mse: 12.9394\n",
      "Epoch 24/1000\n",
      "206/206 [==============================] - 0s 93us/sample - loss: 20.9189 - mae: 2.7315 - mse: 10.7995 - val_loss: 21.5513 - val_mae: 2.7317 - val_mse: 11.8084\n",
      "Epoch 25/1000\n",
      "206/206 [==============================] - 0s 98us/sample - loss: 20.2325 - mae: 2.6479 - mse: 10.0549 - val_loss: 20.2428 - val_mae: 2.5090 - val_mse: 9.9143\n",
      "Epoch 26/1000\n",
      "206/206 [==============================] - 0s 108us/sample - loss: 19.4596 - mae: 2.5338 - mse: 9.1876 - val_loss: 19.5199 - val_mae: 2.4132 - val_mse: 9.1504\n",
      "Epoch 27/1000\n",
      "206/206 [==============================] - 0s 105us/sample - loss: 18.8127 - mae: 2.4245 - mse: 8.5475 - val_loss: 19.0657 - val_mae: 2.3136 - val_mse: 8.3624\n",
      "Epoch 28/1000\n",
      "206/206 [==============================] - 0s 87us/sample - loss: 18.2073 - mae: 2.3465 - mse: 7.7438 - val_loss: 19.1679 - val_mae: 2.4223 - val_mse: 9.4975\n",
      "Epoch 29/1000\n",
      "206/206 [==============================] - 0s 91us/sample - loss: 17.8086 - mae: 2.2659 - mse: 7.6442 - val_loss: 18.1382 - val_mae: 2.1279 - val_mse: 7.1590\n",
      "Epoch 30/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 17.6886 - mae: 2.2281 - mse: 7.1756 - val_loss: 18.6403 - val_mae: 2.3840 - val_mse: 8.9201\n",
      "Epoch 31/1000\n",
      "206/206 [==============================] - 0s 98us/sample - loss: 17.3493 - mae: 2.1722 - mse: 7.0397 - val_loss: 18.2140 - val_mae: 2.2808 - val_mse: 8.2057\n",
      "Epoch 32/1000\n",
      "206/206 [==============================] - 0s 95us/sample - loss: 17.0664 - mae: 2.1454 - mse: 6.7552 - val_loss: 17.5979 - val_mae: 2.0511 - val_mse: 6.9209\n",
      "Epoch 33/1000\n",
      "206/206 [==============================] - 0s 91us/sample - loss: 17.0055 - mae: 2.0864 - mse: 6.4715 - val_loss: 17.6426 - val_mae: 2.1121 - val_mse: 7.2413\n",
      "Epoch 34/1000\n",
      "206/206 [==============================] - 0s 111us/sample - loss: 16.7915 - mae: 2.0645 - mse: 6.3636 - val_loss: 17.5025 - val_mae: 1.9636 - val_mse: 6.3708\n",
      "Epoch 35/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 16.6995 - mae: 2.0048 - mse: 6.0755 - val_loss: 17.8348 - val_mae: 2.2122 - val_mse: 7.8200\n",
      "Epoch 36/1000\n",
      "206/206 [==============================] - 0s 116us/sample - loss: 16.7365 - mae: 2.0320 - mse: 6.2887 - val_loss: 17.9536 - val_mae: 2.2690 - val_mse: 8.0775\n",
      "Epoch 37/1000\n",
      "206/206 [==============================] - 0s 99us/sample - loss: 16.6056 - mae: 2.0430 - mse: 6.2574 - val_loss: 17.2626 - val_mae: 1.9800 - val_mse: 6.5281\n",
      "Epoch 38/1000\n",
      "206/206 [==============================] - 0s 99us/sample - loss: 16.4271 - mae: 1.9754 - mse: 5.9623 - val_loss: 17.2021 - val_mae: 1.9527 - val_mse: 6.3763\n",
      "Epoch 39/1000\n",
      "206/206 [==============================] - 0s 112us/sample - loss: 16.3458 - mae: 1.9689 - mse: 5.8315 - val_loss: 17.4190 - val_mae: 2.1153 - val_mse: 7.1988\n",
      "Epoch 40/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 16.1952 - mae: 1.9542 - mse: 5.7427 - val_loss: 17.4403 - val_mae: 2.1381 - val_mse: 7.2702\n",
      "Epoch 41/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 16.1651 - mae: 1.9422 - mse: 5.7383 - val_loss: 17.0093 - val_mae: 1.8914 - val_mse: 5.9645\n",
      "Epoch 42/1000\n",
      "206/206 [==============================] - 0s 131us/sample - loss: 16.0959 - mae: 1.9296 - mse: 5.5712 - val_loss: 17.0812 - val_mae: 1.8646 - val_mse: 5.6900\n",
      "Epoch 43/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 16.0388 - mae: 1.8941 - mse: 5.3141 - val_loss: 17.8008 - val_mae: 2.2736 - val_mse: 8.0568\n",
      "Epoch 44/1000\n",
      "206/206 [==============================] - 0s 111us/sample - loss: 15.9026 - mae: 1.9234 - mse: 5.5582 - val_loss: 16.9114 - val_mae: 1.8783 - val_mse: 5.8803\n",
      "Epoch 45/1000\n",
      "206/206 [==============================] - 0s 107us/sample - loss: 15.8317 - mae: 1.8806 - mse: 5.2265 - val_loss: 16.8469 - val_mae: 1.9257 - val_mse: 6.0799\n",
      "Epoch 46/1000\n",
      "206/206 [==============================] - 0s 99us/sample - loss: 15.6605 - mae: 1.8606 - mse: 5.1258 - val_loss: 16.7919 - val_mae: 1.9499 - val_mse: 6.2518\n",
      "Epoch 47/1000\n",
      "206/206 [==============================] - 0s 111us/sample - loss: 15.5907 - mae: 1.8387 - mse: 5.0966 - val_loss: 16.7437 - val_mae: 1.8259 - val_mse: 5.5446\n",
      "Epoch 48/1000\n",
      "206/206 [==============================] - 0s 108us/sample - loss: 15.5823 - mae: 1.8300 - mse: 4.9616 - val_loss: 17.1716 - val_mae: 2.1473 - val_mse: 7.1427\n",
      "Epoch 49/1000\n",
      "206/206 [==============================] - 0s 95us/sample - loss: 15.4287 - mae: 1.8299 - mse: 4.9317 - val_loss: 17.2362 - val_mae: 2.1819 - val_mse: 7.3334\n",
      "Epoch 50/1000\n",
      "206/206 [==============================] - 0s 110us/sample - loss: 15.3691 - mae: 1.8243 - mse: 4.9368 - val_loss: 16.5787 - val_mae: 1.9389 - val_mse: 6.0832\n",
      "Epoch 51/1000\n",
      "206/206 [==============================] - 0s 105us/sample - loss: 15.1967 - mae: 1.7607 - mse: 4.5923 - val_loss: 17.8584 - val_mae: 2.3355 - val_mse: 8.4165\n",
      "Epoch 52/1000\n",
      "206/206 [==============================] - 0s 98us/sample - loss: 15.4043 - mae: 1.8310 - mse: 5.0652 - val_loss: 16.6258 - val_mae: 1.9817 - val_mse: 6.3904\n",
      "Epoch 53/1000\n",
      "206/206 [==============================] - 0s 112us/sample - loss: 15.0586 - mae: 1.7610 - mse: 4.6238 - val_loss: 16.3085 - val_mae: 1.7483 - val_mse: 4.9846\n",
      "Epoch 54/1000\n",
      "206/206 [==============================] - 0s 112us/sample - loss: 15.0800 - mae: 1.7216 - mse: 4.4259 - val_loss: 16.3733 - val_mae: 1.8919 - val_mse: 5.8029\n",
      "Epoch 55/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 14.9950 - mae: 1.7300 - mse: 4.4601 - val_loss: 16.1762 - val_mae: 1.7313 - val_mse: 4.9763\n",
      "Epoch 56/1000\n",
      "206/206 [==============================] - 0s 108us/sample - loss: 14.7973 - mae: 1.6796 - mse: 4.2007 - val_loss: 16.1840 - val_mae: 1.7138 - val_mse: 4.8209\n",
      "Epoch 57/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 15.0473 - mae: 1.7037 - mse: 4.3407 - val_loss: 16.1156 - val_mae: 1.8187 - val_mse: 5.4858\n",
      "Epoch 58/1000\n",
      "206/206 [==============================] - 0s 111us/sample - loss: 14.6607 - mae: 1.6458 - mse: 4.0504 - val_loss: 16.4775 - val_mae: 1.9897 - val_mse: 6.3113\n",
      "Epoch 59/1000\n",
      "206/206 [==============================] - 0s 83us/sample - loss: 14.6483 - mae: 1.6596 - mse: 4.0846 - val_loss: 16.6062 - val_mae: 2.0389 - val_mse: 6.6445\n",
      "Epoch 60/1000\n",
      "206/206 [==============================] - 0s 106us/sample - loss: 14.5593 - mae: 1.6526 - mse: 4.1519 - val_loss: 16.1337 - val_mae: 1.6789 - val_mse: 4.7599\n",
      "Epoch 61/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 14.5050 - mae: 1.6032 - mse: 3.7951 - val_loss: 15.8992 - val_mae: 1.7618 - val_mse: 5.1795\n",
      "Epoch 62/1000\n",
      "206/206 [==============================] - 0s 119us/sample - loss: 14.4577 - mae: 1.6006 - mse: 3.8538 - val_loss: 16.0922 - val_mae: 1.9017 - val_mse: 5.8348\n",
      "Epoch 63/1000\n",
      "206/206 [==============================] - 0s 107us/sample - loss: 14.3537 - mae: 1.5716 - mse: 3.8094 - val_loss: 15.7392 - val_mae: 1.7342 - val_mse: 5.0211\n",
      "Epoch 64/1000\n",
      "206/206 [==============================] - 0s 108us/sample - loss: 14.2162 - mae: 1.5382 - mse: 3.6088 - val_loss: 15.7035 - val_mae: 1.7465 - val_mse: 5.0596\n",
      "Epoch 65/1000\n",
      "206/206 [==============================] - 0s 117us/sample - loss: 14.2665 - mae: 1.5643 - mse: 3.6654 - val_loss: 16.0901 - val_mae: 1.9382 - val_mse: 5.9656\n",
      "Epoch 66/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 14.0655 - mae: 1.5144 - mse: 3.5642 - val_loss: 15.7802 - val_mae: 1.7421 - val_mse: 5.0776\n",
      "Epoch 67/1000\n",
      "206/206 [==============================] - 0s 95us/sample - loss: 14.0443 - mae: 1.5017 - mse: 3.4133 - val_loss: 15.6667 - val_mae: 1.7719 - val_mse: 5.1633\n",
      "Epoch 68/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 14.0355 - mae: 1.4913 - mse: 3.3947 - val_loss: 15.8263 - val_mae: 1.8679 - val_mse: 5.5910\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 110us/sample - loss: 14.0402 - mae: 1.4885 - mse: 3.4969 - val_loss: 15.4788 - val_mae: 1.6805 - val_mse: 4.6743\n",
      "Epoch 70/1000\n",
      "206/206 [==============================] - 0s 128us/sample - loss: 13.8511 - mae: 1.4435 - mse: 3.2421 - val_loss: 15.9189 - val_mae: 1.8122 - val_mse: 5.3858\n",
      "Epoch 71/1000\n",
      "206/206 [==============================] - 0s 105us/sample - loss: 13.9220 - mae: 1.4851 - mse: 3.3455 - val_loss: 15.9378 - val_mae: 1.9386 - val_mse: 5.8321\n",
      "Epoch 72/1000\n",
      "206/206 [==============================] - 0s 116us/sample - loss: 13.8429 - mae: 1.4789 - mse: 3.3383 - val_loss: 15.2922 - val_mae: 1.6050 - val_mse: 4.2162\n",
      "Epoch 73/1000\n",
      "206/206 [==============================] - 0s 109us/sample - loss: 13.8803 - mae: 1.4400 - mse: 3.2497 - val_loss: 15.4362 - val_mae: 1.5853 - val_mse: 4.2258\n",
      "Epoch 74/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 13.8005 - mae: 1.4191 - mse: 3.0979 - val_loss: 15.6955 - val_mae: 1.8665 - val_mse: 5.4725\n",
      "Epoch 75/1000\n",
      "206/206 [==============================] - 0s 90us/sample - loss: 13.6531 - mae: 1.4031 - mse: 3.0730 - val_loss: 15.4508 - val_mae: 1.7494 - val_mse: 4.9518\n",
      "Epoch 76/1000\n",
      "206/206 [==============================] - 0s 90us/sample - loss: 13.7687 - mae: 1.4283 - mse: 3.2225 - val_loss: 15.2934 - val_mae: 1.6834 - val_mse: 4.6020\n",
      "Epoch 77/1000\n",
      "206/206 [==============================] - 0s 107us/sample - loss: 13.6406 - mae: 1.3899 - mse: 2.9736 - val_loss: 16.0370 - val_mae: 2.0133 - val_mse: 6.1367\n",
      "Epoch 78/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 13.6569 - mae: 1.4248 - mse: 3.1647 - val_loss: 15.2710 - val_mae: 1.7047 - val_mse: 4.6765\n",
      "Epoch 79/1000\n",
      "206/206 [==============================] - 0s 91us/sample - loss: 13.5199 - mae: 1.3637 - mse: 2.9024 - val_loss: 15.3172 - val_mae: 1.7141 - val_mse: 4.7129\n",
      "Epoch 80/1000\n",
      "206/206 [==============================] - 0s 94us/sample - loss: 13.4862 - mae: 1.3618 - mse: 2.8812 - val_loss: 15.3005 - val_mae: 1.7354 - val_mse: 4.8064\n",
      "Epoch 81/1000\n",
      "206/206 [==============================] - 0s 106us/sample - loss: 13.4619 - mae: 1.3514 - mse: 2.8870 - val_loss: 15.0949 - val_mae: 1.5911 - val_mse: 4.0756\n",
      "Epoch 82/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 13.5172 - mae: 1.3531 - mse: 2.8919 - val_loss: 15.3342 - val_mae: 1.5675 - val_mse: 4.0505\n",
      "Epoch 83/1000\n",
      "206/206 [==============================] - 0s 97us/sample - loss: 13.4922 - mae: 1.3323 - mse: 2.7958 - val_loss: 15.3041 - val_mae: 1.6810 - val_mse: 4.5564\n",
      "Epoch 84/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 13.3796 - mae: 1.3180 - mse: 2.7621 - val_loss: 15.1154 - val_mae: 1.6604 - val_mse: 4.3727\n",
      "Epoch 85/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 13.4127 - mae: 1.3008 - mse: 2.7153 - val_loss: 15.2556 - val_mae: 1.7467 - val_mse: 4.7659\n",
      "Epoch 86/1000\n",
      "206/206 [==============================] - 0s 117us/sample - loss: 13.3459 - mae: 1.3246 - mse: 2.7749 - val_loss: 14.9963 - val_mae: 1.6189 - val_mse: 4.1507\n",
      "Epoch 87/1000\n",
      "206/206 [==============================] - 0s 109us/sample - loss: 13.3425 - mae: 1.3046 - mse: 2.7099 - val_loss: 15.3990 - val_mae: 1.8098 - val_mse: 5.0338\n",
      "Epoch 88/1000\n",
      "206/206 [==============================] - 0s 106us/sample - loss: 13.2700 - mae: 1.3118 - mse: 2.7184 - val_loss: 15.3371 - val_mae: 1.5349 - val_mse: 3.8605\n",
      "Epoch 89/1000\n",
      "206/206 [==============================] - 0s 123us/sample - loss: 13.3653 - mae: 1.2930 - mse: 2.6709 - val_loss: 15.3851 - val_mae: 1.4985 - val_mse: 3.6587\n",
      "Epoch 90/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 13.3038 - mae: 1.2671 - mse: 2.5315 - val_loss: 15.0480 - val_mae: 1.6570 - val_mse: 4.3017\n",
      "Epoch 91/1000\n",
      "206/206 [==============================] - 0s 115us/sample - loss: 13.2106 - mae: 1.2633 - mse: 2.5580 - val_loss: 14.9475 - val_mae: 1.6090 - val_mse: 4.0524\n",
      "Epoch 92/1000\n",
      "206/206 [==============================] - 0s 105us/sample - loss: 13.2870 - mae: 1.2858 - mse: 2.6259 - val_loss: 14.8998 - val_mae: 1.5589 - val_mse: 3.8137\n",
      "Epoch 93/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 13.2282 - mae: 1.2616 - mse: 2.5417 - val_loss: 14.9163 - val_mae: 1.5667 - val_mse: 3.8514\n",
      "Epoch 94/1000\n",
      "206/206 [==============================] - 0s 115us/sample - loss: 13.1702 - mae: 1.2406 - mse: 2.5005 - val_loss: 14.8868 - val_mae: 1.5244 - val_mse: 3.6593\n",
      "Epoch 95/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 13.3078 - mae: 1.2651 - mse: 2.6236 - val_loss: 14.9360 - val_mae: 1.6431 - val_mse: 4.2087\n",
      "Epoch 96/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 13.1117 - mae: 1.2331 - mse: 2.4726 - val_loss: 14.9928 - val_mae: 1.4969 - val_mse: 3.5793\n",
      "Epoch 97/1000\n",
      "206/206 [==============================] - 0s 107us/sample - loss: 13.1329 - mae: 1.2211 - mse: 2.4026 - val_loss: 15.3201 - val_mae: 1.7910 - val_mse: 4.8890\n",
      "Epoch 98/1000\n",
      "206/206 [==============================] - 0s 98us/sample - loss: 13.1172 - mae: 1.2421 - mse: 2.5024 - val_loss: 15.1323 - val_mae: 1.5879 - val_mse: 4.0066\n",
      "Epoch 99/1000\n",
      "206/206 [==============================] - 0s 99us/sample - loss: 13.2244 - mae: 1.2689 - mse: 2.5346 - val_loss: 14.9064 - val_mae: 1.6071 - val_mse: 4.0102\n",
      "Epoch 100/1000\n",
      "206/206 [==============================] - 0s 119us/sample - loss: 13.1587 - mae: 1.2564 - mse: 2.5264 - val_loss: 14.9089 - val_mae: 1.4873 - val_mse: 3.4865\n",
      "Epoch 101/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 13.2278 - mae: 1.2429 - mse: 2.5104 - val_loss: 15.2429 - val_mae: 1.7571 - val_mse: 4.7193\n",
      "Epoch 102/1000\n",
      "206/206 [==============================] - 0s 107us/sample - loss: 13.1006 - mae: 1.2411 - mse: 2.5067 - val_loss: 14.9930 - val_mae: 1.5468 - val_mse: 3.7787\n",
      "Epoch 103/1000\n",
      "206/206 [==============================] - 0s 107us/sample - loss: 13.0479 - mae: 1.2138 - mse: 2.3780 - val_loss: 15.1342 - val_mae: 1.4436 - val_mse: 3.2411\n",
      "Epoch 104/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 13.0880 - mae: 1.1946 - mse: 2.3227 - val_loss: 14.8926 - val_mae: 1.4972 - val_mse: 3.5431\n",
      "Epoch 105/1000\n",
      "206/206 [==============================] - 0s 115us/sample - loss: 13.0739 - mae: 1.2207 - mse: 2.3934 - val_loss: 14.7846 - val_mae: 1.5190 - val_mse: 3.5957\n",
      "Epoch 106/1000\n",
      "206/206 [==============================] - 0s 115us/sample - loss: 13.0969 - mae: 1.2115 - mse: 2.4143 - val_loss: 15.0397 - val_mae: 1.6719 - val_mse: 4.3104\n",
      "Epoch 107/1000\n",
      "206/206 [==============================] - 0s 118us/sample - loss: 13.1246 - mae: 1.2374 - mse: 2.4942 - val_loss: 14.8994 - val_mae: 1.4868 - val_mse: 3.5021\n",
      "Epoch 108/1000\n",
      "206/206 [==============================] - 0s 112us/sample - loss: 12.9716 - mae: 1.1742 - mse: 2.2367 - val_loss: 14.7845 - val_mae: 1.5427 - val_mse: 3.6939\n",
      "Epoch 109/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 13.1280 - mae: 1.2245 - mse: 2.4603 - val_loss: 14.9525 - val_mae: 1.6590 - val_mse: 4.2299\n",
      "Epoch 110/1000\n",
      "206/206 [==============================] - 0s 115us/sample - loss: 13.0615 - mae: 1.2170 - mse: 2.4338 - val_loss: 14.7490 - val_mae: 1.5583 - val_mse: 3.7587\n",
      "Epoch 111/1000\n",
      "206/206 [==============================] - 0s 98us/sample - loss: 13.0274 - mae: 1.2032 - mse: 2.3700 - val_loss: 14.8641 - val_mae: 1.6460 - val_mse: 4.1522\n",
      "Epoch 112/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 13.0353 - mae: 1.1969 - mse: 2.3457 - val_loss: 14.7325 - val_mae: 1.5516 - val_mse: 3.7230\n",
      "Epoch 113/1000\n",
      "206/206 [==============================] - 0s 108us/sample - loss: 12.9313 - mae: 1.1604 - mse: 2.2052 - val_loss: 14.9942 - val_mae: 1.7397 - val_mse: 4.5590\n",
      "Epoch 114/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 13.0064 - mae: 1.2133 - mse: 2.3807 - val_loss: 14.9774 - val_mae: 1.7203 - val_mse: 4.4630\n",
      "Epoch 115/1000\n",
      "206/206 [==============================] - 0s 114us/sample - loss: 12.9886 - mae: 1.1902 - mse: 2.3168 - val_loss: 15.3465 - val_mae: 1.8792 - val_mse: 5.2013\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 126us/sample - loss: 13.0521 - mae: 1.2239 - mse: 2.4500 - val_loss: 14.9860 - val_mae: 1.7307 - val_mse: 4.5175\n",
      "Epoch 117/1000\n",
      "206/206 [==============================] - 0s 110us/sample - loss: 12.9450 - mae: 1.1752 - mse: 2.3327 - val_loss: 14.7506 - val_mae: 1.5151 - val_mse: 3.6049\n",
      "Epoch 118/1000\n",
      "206/206 [==============================] - 0s 109us/sample - loss: 12.9118 - mae: 1.1493 - mse: 2.1777 - val_loss: 14.7015 - val_mae: 1.5822 - val_mse: 3.8403\n",
      "Epoch 119/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 12.8867 - mae: 1.1590 - mse: 2.2420 - val_loss: 15.2677 - val_mae: 1.5578 - val_mse: 3.9471\n",
      "Epoch 120/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 12.9680 - mae: 1.1688 - mse: 2.2448 - val_loss: 14.9645 - val_mae: 1.7172 - val_mse: 4.4392\n",
      "Epoch 121/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.9983 - mae: 1.1857 - mse: 2.3138 - val_loss: 14.9830 - val_mae: 1.7418 - val_mse: 4.5438\n",
      "Epoch 122/1000\n",
      "206/206 [==============================] - 0s 107us/sample - loss: 12.9628 - mae: 1.1747 - mse: 2.3107 - val_loss: 14.8410 - val_mae: 1.6744 - val_mse: 4.2469\n",
      "Epoch 123/1000\n",
      "206/206 [==============================] - 0s 93us/sample - loss: 12.8893 - mae: 1.1612 - mse: 2.2281 - val_loss: 14.6731 - val_mae: 1.5178 - val_mse: 3.5864\n",
      "Epoch 124/1000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 12.9167 - mae: 1.1606 - mse: 2.2099 - val_loss: 14.9295 - val_mae: 1.6797 - val_mse: 4.3042\n",
      "Epoch 125/1000\n",
      "206/206 [==============================] - 0s 111us/sample - loss: 12.8753 - mae: 1.1608 - mse: 2.2124 - val_loss: 14.8143 - val_mae: 1.5946 - val_mse: 3.9405\n",
      "Epoch 126/1000\n",
      "206/206 [==============================] - 0s 106us/sample - loss: 12.8767 - mae: 1.1634 - mse: 2.2141 - val_loss: 14.8920 - val_mae: 1.5758 - val_mse: 3.8945\n",
      "Epoch 127/1000\n",
      "206/206 [==============================] - 0s 119us/sample - loss: 12.8522 - mae: 1.1502 - mse: 2.1589 - val_loss: 14.6109 - val_mae: 1.4704 - val_mse: 3.3721\n",
      "Epoch 128/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.9532 - mae: 1.1630 - mse: 2.2165 - val_loss: 15.0087 - val_mae: 1.7567 - val_mse: 4.6033\n",
      "Epoch 129/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.8443 - mae: 1.1649 - mse: 2.2468 - val_loss: 14.6574 - val_mae: 1.4420 - val_mse: 3.2564\n",
      "Epoch 130/1000\n",
      "206/206 [==============================] - 0s 123us/sample - loss: 12.9622 - mae: 1.1661 - mse: 2.1879 - val_loss: 14.7394 - val_mae: 1.5301 - val_mse: 3.6641\n",
      "Epoch 131/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.8579 - mae: 1.1349 - mse: 2.1277 - val_loss: 14.9623 - val_mae: 1.6606 - val_mse: 4.2545\n",
      "Epoch 132/1000\n",
      "206/206 [==============================] - 0s 94us/sample - loss: 12.7944 - mae: 1.1245 - mse: 2.1230 - val_loss: 14.9102 - val_mae: 1.7051 - val_mse: 4.3699\n",
      "Epoch 133/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.8920 - mae: 1.1701 - mse: 2.2252 - val_loss: 14.6228 - val_mae: 1.5135 - val_mse: 3.5409\n",
      "Epoch 134/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 12.8353 - mae: 1.1391 - mse: 2.1491 - val_loss: 14.6719 - val_mae: 1.5623 - val_mse: 3.7513\n",
      "Epoch 135/1000\n",
      "206/206 [==============================] - 0s 107us/sample - loss: 12.8227 - mae: 1.1337 - mse: 2.1339 - val_loss: 14.6543 - val_mae: 1.5580 - val_mse: 3.7169\n",
      "Epoch 136/1000\n",
      "206/206 [==============================] - 0s 86us/sample - loss: 12.8092 - mae: 1.1277 - mse: 2.1521 - val_loss: 14.8753 - val_mae: 1.3964 - val_mse: 3.0728\n",
      "Epoch 137/1000\n",
      "206/206 [==============================] - 0s 93us/sample - loss: 12.8057 - mae: 1.0925 - mse: 2.0040 - val_loss: 14.6998 - val_mae: 1.5564 - val_mse: 3.7488\n",
      "Epoch 138/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 12.7682 - mae: 1.0855 - mse: 2.0180 - val_loss: 14.8203 - val_mae: 1.6651 - val_mse: 4.1708\n",
      "Epoch 139/1000\n",
      "206/206 [==============================] - 0s 99us/sample - loss: 12.8026 - mae: 1.1236 - mse: 2.1374 - val_loss: 14.8661 - val_mae: 1.6195 - val_mse: 4.0510\n",
      "Epoch 140/1000\n",
      "206/206 [==============================] - 0s 94us/sample - loss: 12.7581 - mae: 1.1115 - mse: 2.0532 - val_loss: 14.6671 - val_mae: 1.5801 - val_mse: 3.8281\n",
      "Epoch 141/1000\n",
      "206/206 [==============================] - 0s 97us/sample - loss: 12.8919 - mae: 1.1607 - mse: 2.2187 - val_loss: 14.6763 - val_mae: 1.4517 - val_mse: 3.3373\n",
      "Epoch 142/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.7307 - mae: 1.1031 - mse: 2.0056 - val_loss: 14.6936 - val_mae: 1.5583 - val_mse: 3.7381\n",
      "Epoch 143/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 12.7866 - mae: 1.1198 - mse: 2.0768 - val_loss: 14.6319 - val_mae: 1.4561 - val_mse: 3.3244\n",
      "Epoch 144/1000\n",
      "206/206 [==============================] - 0s 95us/sample - loss: 12.7727 - mae: 1.1043 - mse: 2.0408 - val_loss: 14.6079 - val_mae: 1.5200 - val_mse: 3.5480\n",
      "Epoch 145/1000\n",
      "206/206 [==============================] - 0s 95us/sample - loss: 12.7819 - mae: 1.1279 - mse: 2.0908 - val_loss: 14.6670 - val_mae: 1.4375 - val_mse: 3.2891\n",
      "Epoch 146/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.7609 - mae: 1.0984 - mse: 2.0138 - val_loss: 14.5964 - val_mae: 1.4299 - val_mse: 3.2340\n",
      "Epoch 147/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.8207 - mae: 1.1211 - mse: 2.0631 - val_loss: 14.6438 - val_mae: 1.5766 - val_mse: 3.7833\n",
      "Epoch 148/1000\n",
      "206/206 [==============================] - 0s 114us/sample - loss: 12.8299 - mae: 1.1401 - mse: 2.1751 - val_loss: 14.5655 - val_mae: 1.4928 - val_mse: 3.4446\n",
      "Epoch 149/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 12.7052 - mae: 1.0910 - mse: 1.9886 - val_loss: 14.7826 - val_mae: 1.6159 - val_mse: 4.0239\n",
      "Epoch 150/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 12.7245 - mae: 1.1022 - mse: 2.0596 - val_loss: 14.6054 - val_mae: 1.4900 - val_mse: 3.4386\n",
      "Epoch 151/1000\n",
      "206/206 [==============================] - 0s 121us/sample - loss: 12.7593 - mae: 1.1305 - mse: 2.1005 - val_loss: 14.8590 - val_mae: 1.3916 - val_mse: 3.0121\n",
      "Epoch 152/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 12.8137 - mae: 1.1054 - mse: 2.0240 - val_loss: 14.6445 - val_mae: 1.4424 - val_mse: 3.2908\n",
      "Epoch 153/1000\n",
      "206/206 [==============================] - 0s 117us/sample - loss: 12.7735 - mae: 1.1076 - mse: 2.0608 - val_loss: 14.6752 - val_mae: 1.4779 - val_mse: 3.4476\n",
      "Epoch 154/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 12.8110 - mae: 1.1115 - mse: 2.0702 - val_loss: 14.7218 - val_mae: 1.5326 - val_mse: 3.6639\n",
      "Epoch 155/1000\n",
      "206/206 [==============================] - 0s 117us/sample - loss: 12.7129 - mae: 1.1016 - mse: 2.0161 - val_loss: 14.6273 - val_mae: 1.3955 - val_mse: 3.1094\n",
      "Epoch 156/1000\n",
      "206/206 [==============================] - 0s 112us/sample - loss: 12.6772 - mae: 1.0746 - mse: 1.8968 - val_loss: 14.5981 - val_mae: 1.4305 - val_mse: 3.2591\n",
      "Epoch 157/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 12.6649 - mae: 1.0899 - mse: 1.9561 - val_loss: 15.0466 - val_mae: 1.4008 - val_mse: 3.2998\n",
      "Epoch 158/1000\n",
      "206/206 [==============================] - 0s 117us/sample - loss: 12.7485 - mae: 1.0912 - mse: 1.9672 - val_loss: 14.7505 - val_mae: 1.5868 - val_mse: 3.8900\n",
      "Epoch 159/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 12.7963 - mae: 1.1293 - mse: 2.1333 - val_loss: 14.5541 - val_mae: 1.4570 - val_mse: 3.3130\n",
      "Epoch 160/1000\n",
      "206/206 [==============================] - 0s 114us/sample - loss: 12.6678 - mae: 1.0512 - mse: 1.8603 - val_loss: 15.2947 - val_mae: 1.8874 - val_mse: 5.1691\n",
      "Epoch 161/1000\n",
      "206/206 [==============================] - 0s 116us/sample - loss: 12.7695 - mae: 1.1487 - mse: 2.1948 - val_loss: 14.5591 - val_mae: 1.4797 - val_mse: 3.3999\n",
      "Epoch 162/1000\n",
      "206/206 [==============================] - 0s 108us/sample - loss: 12.6469 - mae: 1.0751 - mse: 1.8763 - val_loss: 14.9813 - val_mae: 1.7455 - val_mse: 4.5544\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 89us/sample - loss: 12.8697 - mae: 1.1517 - mse: 2.2680 - val_loss: 14.6158 - val_mae: 1.5410 - val_mse: 3.6394\n",
      "Epoch 164/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 12.6150 - mae: 1.0722 - mse: 1.9331 - val_loss: 14.6228 - val_mae: 1.3969 - val_mse: 3.1435\n",
      "Epoch 165/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.7069 - mae: 1.0812 - mse: 1.9015 - val_loss: 14.8080 - val_mae: 1.6682 - val_mse: 4.2200\n",
      "Epoch 166/1000\n",
      "206/206 [==============================] - 0s 110us/sample - loss: 12.7176 - mae: 1.1239 - mse: 2.1008 - val_loss: 14.7237 - val_mae: 1.3948 - val_mse: 3.1710\n",
      "Epoch 167/1000\n",
      "206/206 [==============================] - 0s 107us/sample - loss: 12.6403 - mae: 1.0542 - mse: 1.8707 - val_loss: 14.6540 - val_mae: 1.5329 - val_mse: 3.6273\n",
      "Epoch 168/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 12.6341 - mae: 1.0793 - mse: 1.9101 - val_loss: 14.7770 - val_mae: 1.5815 - val_mse: 3.8624\n",
      "Epoch 169/1000\n",
      "206/206 [==============================] - 0s 94us/sample - loss: 12.6565 - mae: 1.0875 - mse: 2.0237 - val_loss: 15.0980 - val_mae: 1.3782 - val_mse: 3.1440\n",
      "Epoch 170/1000\n",
      "206/206 [==============================] - 0s 94us/sample - loss: 12.8054 - mae: 1.1141 - mse: 2.0710 - val_loss: 14.6667 - val_mae: 1.4240 - val_mse: 3.2457\n",
      "Epoch 171/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.6515 - mae: 1.0800 - mse: 1.9257 - val_loss: 14.6707 - val_mae: 1.4130 - val_mse: 3.1761\n",
      "Epoch 172/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 12.6489 - mae: 1.0779 - mse: 1.9113 - val_loss: 14.6817 - val_mae: 1.4808 - val_mse: 3.4256\n",
      "Epoch 173/1000\n",
      "206/206 [==============================] - 0s 94us/sample - loss: 12.7039 - mae: 1.1215 - mse: 2.0145 - val_loss: 14.5957 - val_mae: 1.4554 - val_mse: 3.3036\n",
      "Epoch 174/1000\n",
      "206/206 [==============================] - 0s 97us/sample - loss: 12.5955 - mae: 1.0545 - mse: 1.8595 - val_loss: 14.5052 - val_mae: 1.4375 - val_mse: 3.2198\n",
      "Epoch 175/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.6272 - mae: 1.0687 - mse: 1.9278 - val_loss: 14.6261 - val_mae: 1.4850 - val_mse: 3.4300\n",
      "Epoch 176/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 12.8533 - mae: 1.1309 - mse: 2.1450 - val_loss: 14.6725 - val_mae: 1.5926 - val_mse: 3.8376\n",
      "Epoch 177/1000\n",
      "206/206 [==============================] - 0s 90us/sample - loss: 12.5993 - mae: 1.0831 - mse: 1.9331 - val_loss: 14.6707 - val_mae: 1.5978 - val_mse: 3.8587\n",
      "Epoch 178/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 12.6121 - mae: 1.0744 - mse: 1.9298 - val_loss: 14.5810 - val_mae: 1.3862 - val_mse: 3.0631\n",
      "Epoch 179/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 12.7125 - mae: 1.0854 - mse: 1.9722 - val_loss: 14.7531 - val_mae: 1.4267 - val_mse: 3.3072\n",
      "Epoch 180/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 12.6440 - mae: 1.0780 - mse: 1.9339 - val_loss: 14.5991 - val_mae: 1.4877 - val_mse: 3.4331\n",
      "Epoch 181/1000\n",
      "206/206 [==============================] - 0s 88us/sample - loss: 12.6092 - mae: 1.0523 - mse: 1.8557 - val_loss: 14.6259 - val_mae: 1.5607 - val_mse: 3.7291\n",
      "Epoch 182/1000\n",
      "206/206 [==============================] - 0s 94us/sample - loss: 12.6525 - mae: 1.0814 - mse: 1.9871 - val_loss: 14.5082 - val_mae: 1.5038 - val_mse: 3.4434\n",
      "Epoch 183/1000\n",
      "206/206 [==============================] - 0s 106us/sample - loss: 12.6831 - mae: 1.1004 - mse: 1.9607 - val_loss: 14.6300 - val_mae: 1.5597 - val_mse: 3.7115\n",
      "Epoch 184/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.5510 - mae: 1.0564 - mse: 1.8571 - val_loss: 14.6120 - val_mae: 1.5234 - val_mse: 3.5552\n",
      "Epoch 185/1000\n",
      "206/206 [==============================] - 0s 89us/sample - loss: 12.6887 - mae: 1.0870 - mse: 2.0173 - val_loss: 14.7038 - val_mae: 1.4134 - val_mse: 3.2013\n",
      "Epoch 186/1000\n",
      "206/206 [==============================] - 0s 96us/sample - loss: 12.5810 - mae: 1.0441 - mse: 1.8353 - val_loss: 14.6744 - val_mae: 1.3786 - val_mse: 3.0481\n",
      "Epoch 187/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.6727 - mae: 1.0700 - mse: 1.9029 - val_loss: 14.7371 - val_mae: 1.5550 - val_mse: 3.7330\n",
      "Epoch 188/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.6233 - mae: 1.0803 - mse: 1.9194 - val_loss: 14.6286 - val_mae: 1.3759 - val_mse: 3.0022\n",
      "Epoch 189/1000\n",
      "206/206 [==============================] - 0s 88us/sample - loss: 12.6272 - mae: 1.0382 - mse: 1.8508 - val_loss: 14.7465 - val_mae: 1.5027 - val_mse: 3.5475\n",
      "Epoch 190/1000\n",
      "206/206 [==============================] - 0s 95us/sample - loss: 12.5699 - mae: 1.0531 - mse: 1.8632 - val_loss: 14.6862 - val_mae: 1.4577 - val_mse: 3.3881\n",
      "Epoch 191/1000\n",
      "206/206 [==============================] - 0s 106us/sample - loss: 12.6005 - mae: 1.0644 - mse: 1.8865 - val_loss: 14.7163 - val_mae: 1.3702 - val_mse: 2.9628\n",
      "Epoch 192/1000\n",
      "206/206 [==============================] - 0s 106us/sample - loss: 12.6303 - mae: 1.0531 - mse: 1.8133 - val_loss: 14.9430 - val_mae: 1.7577 - val_mse: 4.5387\n",
      "Epoch 193/1000\n",
      "206/206 [==============================] - 0s 88us/sample - loss: 12.5962 - mae: 1.0872 - mse: 1.9600 - val_loss: 14.6700 - val_mae: 1.6307 - val_mse: 3.9744\n",
      "Epoch 194/1000\n",
      "206/206 [==============================] - 0s 96us/sample - loss: 12.6435 - mae: 1.0788 - mse: 1.9481 - val_loss: 14.6237 - val_mae: 1.5992 - val_mse: 3.8042\n",
      "Epoch 195/1000\n",
      "206/206 [==============================] - 0s 108us/sample - loss: 12.6629 - mae: 1.0798 - mse: 1.9488 - val_loss: 14.5022 - val_mae: 1.4349 - val_mse: 3.1690\n",
      "Epoch 196/1000\n",
      "206/206 [==============================] - 0s 109us/sample - loss: 12.6083 - mae: 1.0735 - mse: 1.8624 - val_loss: 14.5067 - val_mae: 1.4738 - val_mse: 3.3413\n",
      "Epoch 197/1000\n",
      "206/206 [==============================] - 0s 114us/sample - loss: 12.5941 - mae: 1.0616 - mse: 1.8959 - val_loss: 14.5553 - val_mae: 1.5649 - val_mse: 3.6692\n",
      "Epoch 198/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 12.6429 - mae: 1.0651 - mse: 1.9668 - val_loss: 14.7437 - val_mae: 1.6567 - val_mse: 4.1058\n",
      "Epoch 199/1000\n",
      "206/206 [==============================] - 0s 95us/sample - loss: 12.6059 - mae: 1.0706 - mse: 1.9055 - val_loss: 15.1639 - val_mae: 1.8458 - val_mse: 4.9664\n",
      "Epoch 200/1000\n",
      "206/206 [==============================] - 0s 92us/sample - loss: 12.6526 - mae: 1.1148 - mse: 2.0387 - val_loss: 15.1292 - val_mae: 1.8485 - val_mse: 4.9064\n",
      "Epoch 201/1000\n",
      "206/206 [==============================] - 0s 110us/sample - loss: 12.5665 - mae: 1.0937 - mse: 1.9793 - val_loss: 14.7748 - val_mae: 1.6721 - val_mse: 4.1686\n",
      "Epoch 202/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 12.5798 - mae: 1.0844 - mse: 1.9440 - val_loss: 14.6038 - val_mae: 1.3886 - val_mse: 3.0842\n",
      "Epoch 203/1000\n",
      "206/206 [==============================] - 0s 90us/sample - loss: 12.5862 - mae: 1.0372 - mse: 1.8048 - val_loss: 15.0458 - val_mae: 1.8124 - val_mse: 4.7645\n",
      "Epoch 204/1000\n",
      "206/206 [==============================] - 0s 94us/sample - loss: 12.6414 - mae: 1.1100 - mse: 2.0769 - val_loss: 14.5554 - val_mae: 1.4579 - val_mse: 3.3002\n",
      "Epoch 205/1000\n",
      "206/206 [==============================] - 0s 109us/sample - loss: 12.5987 - mae: 1.0663 - mse: 1.8895 - val_loss: 14.5769 - val_mae: 1.5336 - val_mse: 3.5829\n",
      "Epoch 206/1000\n",
      "206/206 [==============================] - 0s 105us/sample - loss: 12.5431 - mae: 1.0602 - mse: 1.8518 - val_loss: 14.6410 - val_mae: 1.3979 - val_mse: 3.1151\n",
      "Epoch 207/1000\n",
      "206/206 [==============================] - 0s 94us/sample - loss: 12.6238 - mae: 1.0633 - mse: 1.8752 - val_loss: 14.5186 - val_mae: 1.4252 - val_mse: 3.1551\n",
      "Epoch 208/1000\n",
      "206/206 [==============================] - 0s 107us/sample - loss: 12.5314 - mae: 1.0342 - mse: 1.7798 - val_loss: 14.5311 - val_mae: 1.4199 - val_mse: 3.1429\n",
      "Epoch 209/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 12.5652 - mae: 1.0636 - mse: 1.8647 - val_loss: 14.6011 - val_mae: 1.5629 - val_mse: 3.6557\n",
      "Epoch 210/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 93us/sample - loss: 12.5026 - mae: 1.0379 - mse: 1.7904 - val_loss: 14.6562 - val_mae: 1.5846 - val_mse: 3.7700\n",
      "Epoch 211/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.5725 - mae: 1.0522 - mse: 1.8726 - val_loss: 14.6051 - val_mae: 1.4169 - val_mse: 3.1748\n",
      "Epoch 212/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 12.6758 - mae: 1.0797 - mse: 1.9714 - val_loss: 14.5850 - val_mae: 1.5155 - val_mse: 3.4670\n",
      "Epoch 213/1000\n",
      "206/206 [==============================] - 0s 98us/sample - loss: 12.4967 - mae: 1.0459 - mse: 1.8075 - val_loss: 14.7575 - val_mae: 1.3874 - val_mse: 3.1069\n",
      "Epoch 214/1000\n",
      "206/206 [==============================] - 0s 92us/sample - loss: 12.5930 - mae: 1.0425 - mse: 1.8468 - val_loss: 14.7956 - val_mae: 1.3607 - val_mse: 3.0162\n",
      "Epoch 215/1000\n",
      "206/206 [==============================] - 0s 91us/sample - loss: 12.5694 - mae: 1.0377 - mse: 1.7826 - val_loss: 14.8476 - val_mae: 1.4625 - val_mse: 3.3821\n",
      "Epoch 216/1000\n",
      "206/206 [==============================] - 0s 110us/sample - loss: 12.4879 - mae: 1.0222 - mse: 1.7357 - val_loss: 14.8084 - val_mae: 1.6697 - val_mse: 4.1424\n",
      "Epoch 217/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 12.5404 - mae: 1.0541 - mse: 1.8180 - val_loss: 14.7297 - val_mae: 1.5966 - val_mse: 3.8642\n",
      "Epoch 218/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 12.5783 - mae: 1.0766 - mse: 1.8704 - val_loss: 14.5942 - val_mae: 1.5399 - val_mse: 3.5762\n",
      "Epoch 219/1000\n",
      "206/206 [==============================] - 0s 93us/sample - loss: 12.5329 - mae: 1.0442 - mse: 1.8268 - val_loss: 14.5517 - val_mae: 1.4439 - val_mse: 3.2330\n",
      "Epoch 220/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.5475 - mae: 1.0378 - mse: 1.8076 - val_loss: 14.5940 - val_mae: 1.5714 - val_mse: 3.6905\n",
      "Epoch 221/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.4980 - mae: 1.0499 - mse: 1.8186 - val_loss: 14.5813 - val_mae: 1.4193 - val_mse: 3.1787\n",
      "Epoch 222/1000\n",
      "206/206 [==============================] - 0s 90us/sample - loss: 12.5575 - mae: 1.0459 - mse: 1.8017 - val_loss: 14.8724 - val_mae: 1.5864 - val_mse: 3.9007\n",
      "Epoch 223/1000\n",
      "206/206 [==============================] - 0s 97us/sample - loss: 12.5291 - mae: 1.0377 - mse: 1.8156 - val_loss: 14.5382 - val_mae: 1.5203 - val_mse: 3.4791\n",
      "Epoch 224/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.5800 - mae: 1.0519 - mse: 1.8347 - val_loss: 14.5425 - val_mae: 1.4638 - val_mse: 3.2947\n",
      "Epoch 225/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.5549 - mae: 1.0687 - mse: 1.8600 - val_loss: 14.6186 - val_mae: 1.3972 - val_mse: 3.0996\n",
      "Epoch 226/1000\n",
      "206/206 [==============================] - 0s 91us/sample - loss: 12.5536 - mae: 1.0472 - mse: 1.7805 - val_loss: 14.8947 - val_mae: 1.7299 - val_mse: 4.4105\n",
      "Epoch 227/1000\n",
      "206/206 [==============================] - 0s 90us/sample - loss: 12.4653 - mae: 1.0533 - mse: 1.8804 - val_loss: 14.8194 - val_mae: 1.3451 - val_mse: 2.9660\n",
      "Epoch 228/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.5750 - mae: 1.0359 - mse: 1.7912 - val_loss: 14.8230 - val_mae: 1.6871 - val_mse: 4.1777\n",
      "Epoch 229/1000\n",
      "206/206 [==============================] - 0s 98us/sample - loss: 12.5406 - mae: 1.0467 - mse: 1.8622 - val_loss: 14.5662 - val_mae: 1.4316 - val_mse: 3.1875\n",
      "Epoch 230/1000\n",
      "206/206 [==============================] - 0s 117us/sample - loss: 12.5202 - mae: 1.0386 - mse: 1.8109 - val_loss: 14.5872 - val_mae: 1.5337 - val_mse: 3.5270\n",
      "Epoch 231/1000\n",
      "206/206 [==============================] - 0s 103us/sample - loss: 12.4832 - mae: 1.0355 - mse: 1.7764 - val_loss: 14.6707 - val_mae: 1.6197 - val_mse: 3.9170\n",
      "Epoch 232/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 12.4837 - mae: 1.0240 - mse: 1.7970 - val_loss: 14.7740 - val_mae: 1.6237 - val_mse: 3.9947\n",
      "Epoch 233/1000\n",
      "206/206 [==============================] - 0s 97us/sample - loss: 12.6036 - mae: 1.0927 - mse: 1.9385 - val_loss: 14.4907 - val_mae: 1.4861 - val_mse: 3.3637\n",
      "Epoch 234/1000\n",
      "206/206 [==============================] - 0s 111us/sample - loss: 12.5134 - mae: 1.0454 - mse: 1.8105 - val_loss: 14.5973 - val_mae: 1.3941 - val_mse: 3.0897\n",
      "Epoch 235/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.5462 - mae: 1.0415 - mse: 1.8228 - val_loss: 14.6166 - val_mae: 1.4308 - val_mse: 3.2031\n",
      "Epoch 236/1000\n",
      "206/206 [==============================] - 0s 153us/sample - loss: 12.5293 - mae: 1.0383 - mse: 1.7963 - val_loss: 14.5662 - val_mae: 1.5420 - val_mse: 3.5941\n",
      "Epoch 237/1000\n",
      "206/206 [==============================] - 0s 173us/sample - loss: 12.5222 - mae: 1.0511 - mse: 1.8203 - val_loss: 14.5744 - val_mae: 1.3808 - val_mse: 3.0290\n",
      "Epoch 238/1000\n",
      "206/206 [==============================] - 0s 193us/sample - loss: 12.5508 - mae: 1.0457 - mse: 1.8068 - val_loss: 14.7722 - val_mae: 1.3456 - val_mse: 2.9565\n",
      "Epoch 239/1000\n",
      "206/206 [==============================] - 0s 116us/sample - loss: 12.5090 - mae: 1.0055 - mse: 1.7179 - val_loss: 14.5395 - val_mae: 1.3956 - val_mse: 3.0663\n",
      "Epoch 240/1000\n",
      "206/206 [==============================] - 0s 155us/sample - loss: 12.4986 - mae: 1.0179 - mse: 1.7453 - val_loss: 14.6643 - val_mae: 1.6494 - val_mse: 3.9638\n",
      "Epoch 241/1000\n",
      "206/206 [==============================] - 0s 133us/sample - loss: 12.4625 - mae: 1.0222 - mse: 1.7771 - val_loss: 14.6906 - val_mae: 1.6371 - val_mse: 4.0006\n",
      "Epoch 242/1000\n",
      "206/206 [==============================] - 0s 143us/sample - loss: 12.5265 - mae: 1.0554 - mse: 1.8548 - val_loss: 14.5237 - val_mae: 1.5270 - val_mse: 3.4998\n",
      "Epoch 243/1000\n",
      "206/206 [==============================] - 0s 118us/sample - loss: 12.5361 - mae: 1.0596 - mse: 1.8552 - val_loss: 14.7463 - val_mae: 1.6362 - val_mse: 4.0192\n",
      "Epoch 244/1000\n",
      "206/206 [==============================] - 0s 119us/sample - loss: 12.4563 - mae: 1.0403 - mse: 1.8004 - val_loss: 14.5420 - val_mae: 1.4796 - val_mse: 3.3283\n",
      "Epoch 245/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 12.4824 - mae: 1.0314 - mse: 1.7431 - val_loss: 14.6517 - val_mae: 1.6309 - val_mse: 3.9494\n",
      "Epoch 246/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.5281 - mae: 1.0569 - mse: 1.8396 - val_loss: 14.6666 - val_mae: 1.6333 - val_mse: 3.9614\n",
      "Epoch 247/1000\n",
      "206/206 [==============================] - 0s 112us/sample - loss: 12.4690 - mae: 1.0359 - mse: 1.7999 - val_loss: 14.6168 - val_mae: 1.3286 - val_mse: 2.8594\n",
      "Epoch 248/1000\n",
      "206/206 [==============================] - 0s 98us/sample - loss: 12.4562 - mae: 1.0020 - mse: 1.6494 - val_loss: 14.5497 - val_mae: 1.5687 - val_mse: 3.6931\n",
      "Epoch 249/1000\n",
      "206/206 [==============================] - 0s 98us/sample - loss: 12.5321 - mae: 1.0570 - mse: 1.8439 - val_loss: 14.6413 - val_mae: 1.3439 - val_mse: 2.9092\n",
      "Epoch 250/1000\n",
      "206/206 [==============================] - 0s 112us/sample - loss: 12.5006 - mae: 1.0216 - mse: 1.6913 - val_loss: 14.5228 - val_mae: 1.5330 - val_mse: 3.5175\n",
      "Epoch 251/1000\n",
      "206/206 [==============================] - 0s 107us/sample - loss: 12.5336 - mae: 1.0706 - mse: 1.8752 - val_loss: 14.4927 - val_mae: 1.4094 - val_mse: 3.1012\n",
      "Epoch 252/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 12.4345 - mae: 1.0081 - mse: 1.6919 - val_loss: 14.5752 - val_mae: 1.5764 - val_mse: 3.6786\n",
      "Epoch 253/1000\n",
      "206/206 [==============================] - 0s 108us/sample - loss: 12.4883 - mae: 1.0208 - mse: 1.7859 - val_loss: 14.7920 - val_mae: 1.7068 - val_mse: 4.2428\n",
      "Epoch 254/1000\n",
      "206/206 [==============================] - 0s 105us/sample - loss: 12.4651 - mae: 1.0379 - mse: 1.8117 - val_loss: 14.5843 - val_mae: 1.5060 - val_mse: 3.4392\n",
      "Epoch 255/1000\n",
      "206/206 [==============================] - 0s 105us/sample - loss: 12.3966 - mae: 1.0197 - mse: 1.7163 - val_loss: 14.9198 - val_mae: 1.3514 - val_mse: 3.0255\n",
      "Epoch 256/1000\n",
      "206/206 [==============================] - 0s 87us/sample - loss: 12.5651 - mae: 1.0498 - mse: 1.7914 - val_loss: 14.6531 - val_mae: 1.4193 - val_mse: 3.1699\n",
      "Epoch 257/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 96us/sample - loss: 12.4893 - mae: 1.0270 - mse: 1.7591 - val_loss: 14.7411 - val_mae: 1.3311 - val_mse: 2.9009\n",
      "Epoch 258/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.4533 - mae: 1.0043 - mse: 1.6773 - val_loss: 14.6871 - val_mae: 1.3599 - val_mse: 2.9948\n",
      "Epoch 259/1000\n",
      "206/206 [==============================] - 0s 97us/sample - loss: 12.4112 - mae: 0.9913 - mse: 1.6080 - val_loss: 15.1399 - val_mae: 1.8117 - val_mse: 4.8264\n",
      "Epoch 260/1000\n",
      "206/206 [==============================] - 0s 94us/sample - loss: 12.5004 - mae: 1.0770 - mse: 1.9284 - val_loss: 14.8210 - val_mae: 1.3525 - val_mse: 3.0120\n",
      "Epoch 261/1000\n",
      "206/206 [==============================] - 0s 96us/sample - loss: 12.5133 - mae: 1.0113 - mse: 1.7183 - val_loss: 14.7146 - val_mae: 1.6644 - val_mse: 4.0381\n",
      "Epoch 262/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.4434 - mae: 1.0179 - mse: 1.7249 - val_loss: 14.5781 - val_mae: 1.5612 - val_mse: 3.6307\n",
      "Epoch 263/1000\n",
      "206/206 [==============================] - 0s 99us/sample - loss: 12.4048 - mae: 1.0214 - mse: 1.7070 - val_loss: 14.4637 - val_mae: 1.4538 - val_mse: 3.2318\n",
      "Epoch 264/1000\n",
      "206/206 [==============================] - 0s 92us/sample - loss: 12.4087 - mae: 1.0150 - mse: 1.7004 - val_loss: 14.6727 - val_mae: 1.3320 - val_mse: 2.8803\n",
      "Epoch 265/1000\n",
      "206/206 [==============================] - 0s 91us/sample - loss: 12.4651 - mae: 1.0122 - mse: 1.6717 - val_loss: 14.4783 - val_mae: 1.5160 - val_mse: 3.4343\n",
      "Epoch 266/1000\n",
      "206/206 [==============================] - 0s 105us/sample - loss: 12.4584 - mae: 1.0182 - mse: 1.7319 - val_loss: 14.7054 - val_mae: 1.6702 - val_mse: 4.1234\n",
      "Epoch 267/1000\n",
      "206/206 [==============================] - 0s 124us/sample - loss: 12.4214 - mae: 1.0315 - mse: 1.7884 - val_loss: 14.8358 - val_mae: 1.3212 - val_mse: 2.8820\n",
      "Epoch 268/1000\n",
      "206/206 [==============================] - 0s 136us/sample - loss: 12.5469 - mae: 1.0319 - mse: 1.7300 - val_loss: 14.6479 - val_mae: 1.4310 - val_mse: 3.2011\n",
      "Epoch 269/1000\n",
      "206/206 [==============================] - 0s 143us/sample - loss: 12.5238 - mae: 1.0355 - mse: 1.7907 - val_loss: 14.5585 - val_mae: 1.5536 - val_mse: 3.5961\n",
      "Epoch 270/1000\n",
      "206/206 [==============================] - 0s 173us/sample - loss: 12.4328 - mae: 1.0274 - mse: 1.7468 - val_loss: 14.5617 - val_mae: 1.4252 - val_mse: 3.1569\n",
      "Epoch 271/1000\n",
      "206/206 [==============================] - 0s 134us/sample - loss: 12.4170 - mae: 1.0027 - mse: 1.6457 - val_loss: 14.5102 - val_mae: 1.4036 - val_mse: 3.0894\n",
      "Epoch 272/1000\n",
      "206/206 [==============================] - 0s 142us/sample - loss: 12.3884 - mae: 0.9930 - mse: 1.6700 - val_loss: 14.6559 - val_mae: 1.3916 - val_mse: 3.0810\n",
      "Epoch 273/1000\n",
      "206/206 [==============================] - 0s 160us/sample - loss: 12.5575 - mae: 1.0503 - mse: 1.8148 - val_loss: 14.5692 - val_mae: 1.4727 - val_mse: 3.3212\n",
      "Epoch 274/1000\n",
      "206/206 [==============================] - 0s 157us/sample - loss: 12.3611 - mae: 0.9880 - mse: 1.6398 - val_loss: 14.5376 - val_mae: 1.3863 - val_mse: 3.0355\n",
      "Epoch 275/1000\n",
      "206/206 [==============================] - 0s 158us/sample - loss: 12.4828 - mae: 1.0243 - mse: 1.7214 - val_loss: 14.6558 - val_mae: 1.4412 - val_mse: 3.2440\n",
      "Epoch 276/1000\n",
      "206/206 [==============================] - 0s 118us/sample - loss: 12.4120 - mae: 1.0016 - mse: 1.6448 - val_loss: 14.5123 - val_mae: 1.5387 - val_mse: 3.5245\n",
      "Epoch 277/1000\n",
      "206/206 [==============================] - 0s 88us/sample - loss: 12.4100 - mae: 1.0042 - mse: 1.7091 - val_loss: 14.5980 - val_mae: 1.4833 - val_mse: 3.3781\n",
      "Epoch 278/1000\n",
      "206/206 [==============================] - 0s 96us/sample - loss: 12.4729 - mae: 1.0120 - mse: 1.7078 - val_loss: 14.7375 - val_mae: 1.6360 - val_mse: 3.9931\n",
      "Epoch 279/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 12.4424 - mae: 1.0372 - mse: 1.7879 - val_loss: 14.5303 - val_mae: 1.4249 - val_mse: 3.1464\n",
      "Epoch 280/1000\n",
      "206/206 [==============================] - 0s 97us/sample - loss: 12.3763 - mae: 0.9824 - mse: 1.6332 - val_loss: 14.6833 - val_mae: 1.3931 - val_mse: 3.0804\n",
      "Epoch 281/1000\n",
      "206/206 [==============================] - 0s 110us/sample - loss: 12.5620 - mae: 1.0628 - mse: 1.8670 - val_loss: 14.5573 - val_mae: 1.3850 - val_mse: 3.0370\n",
      "Epoch 282/1000\n",
      "206/206 [==============================] - 0s 100us/sample - loss: 12.3717 - mae: 0.9781 - mse: 1.6218 - val_loss: 14.5303 - val_mae: 1.3894 - val_mse: 3.0456\n",
      "Epoch 283/1000\n",
      "206/206 [==============================] - 0s 94us/sample - loss: 12.4482 - mae: 1.0139 - mse: 1.7145 - val_loss: 14.6691 - val_mae: 1.3569 - val_mse: 2.9873\n",
      "Epoch 284/1000\n",
      "206/206 [==============================] - 0s 105us/sample - loss: 12.4288 - mae: 1.0051 - mse: 1.6547 - val_loss: 14.6698 - val_mae: 1.5896 - val_mse: 3.8082\n",
      "Epoch 285/1000\n",
      "206/206 [==============================] - 0s 107us/sample - loss: 12.4356 - mae: 1.0094 - mse: 1.7305 - val_loss: 14.7061 - val_mae: 1.4194 - val_mse: 3.1866\n",
      "Epoch 286/1000\n",
      "206/206 [==============================] - 0s 97us/sample - loss: 12.3560 - mae: 0.9756 - mse: 1.5533 - val_loss: 14.7141 - val_mae: 1.6811 - val_mse: 4.0765\n",
      "Epoch 287/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.4081 - mae: 1.0189 - mse: 1.7403 - val_loss: 14.4698 - val_mae: 1.5050 - val_mse: 3.3822\n",
      "Epoch 288/1000\n",
      "206/206 [==============================] - 0s 120us/sample - loss: 12.4743 - mae: 1.0213 - mse: 1.7626 - val_loss: 14.4594 - val_mae: 1.5014 - val_mse: 3.3839\n",
      "Epoch 289/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.4481 - mae: 1.0274 - mse: 1.7494 - val_loss: 14.5216 - val_mae: 1.5373 - val_mse: 3.5457\n",
      "Epoch 290/1000\n",
      "206/206 [==============================] - 0s 118us/sample - loss: 12.4464 - mae: 1.0375 - mse: 1.7748 - val_loss: 14.7347 - val_mae: 1.3080 - val_mse: 2.8195\n",
      "Epoch 291/1000\n",
      "206/206 [==============================] - 0s 99us/sample - loss: 12.4245 - mae: 0.9906 - mse: 1.6177 - val_loss: 14.4893 - val_mae: 1.5338 - val_mse: 3.4948\n",
      "Epoch 292/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.3771 - mae: 1.0013 - mse: 1.6606 - val_loss: 14.5959 - val_mae: 1.6179 - val_mse: 3.8935\n",
      "Epoch 293/1000\n",
      "206/206 [==============================] - 0s 88us/sample - loss: 12.5416 - mae: 1.0794 - mse: 1.8669 - val_loss: 14.4631 - val_mae: 1.5216 - val_mse: 3.4708\n",
      "Epoch 294/1000\n",
      "206/206 [==============================] - 0s 140us/sample - loss: 12.3363 - mae: 0.9797 - mse: 1.6247 - val_loss: 14.6154 - val_mae: 1.5786 - val_mse: 3.7482\n",
      "Epoch 295/1000\n",
      "206/206 [==============================] - 0s 121us/sample - loss: 12.3487 - mae: 1.0063 - mse: 1.6743 - val_loss: 14.5004 - val_mae: 1.5212 - val_mse: 3.4659\n",
      "Epoch 296/1000\n",
      "206/206 [==============================] - 0s 123us/sample - loss: 12.3526 - mae: 0.9796 - mse: 1.6133 - val_loss: 14.7598 - val_mae: 1.6907 - val_mse: 4.1851\n",
      "Epoch 297/1000\n",
      "206/206 [==============================] - 0s 163us/sample - loss: 12.4378 - mae: 1.0131 - mse: 1.7410 - val_loss: 14.8476 - val_mae: 1.7306 - val_mse: 4.3833\n",
      "Epoch 298/1000\n",
      "206/206 [==============================] - 0s 174us/sample - loss: 12.3909 - mae: 1.0241 - mse: 1.7501 - val_loss: 14.5497 - val_mae: 1.5699 - val_mse: 3.6533\n",
      "Epoch 299/1000\n",
      "206/206 [==============================] - 0s 168us/sample - loss: 12.4635 - mae: 1.0175 - mse: 1.7504 - val_loss: 14.6581 - val_mae: 1.5305 - val_mse: 3.5573\n",
      "Epoch 300/1000\n",
      "206/206 [==============================] - 0s 118us/sample - loss: 12.3136 - mae: 0.9759 - mse: 1.5913 - val_loss: 14.5458 - val_mae: 1.4613 - val_mse: 3.2662\n",
      "Epoch 301/1000\n",
      "206/206 [==============================] - 0s 114us/sample - loss: 12.4014 - mae: 1.0014 - mse: 1.6212 - val_loss: 14.9263 - val_mae: 1.7552 - val_mse: 4.4843\n",
      "Epoch 302/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.3744 - mae: 1.0205 - mse: 1.7072 - val_loss: 14.7261 - val_mae: 1.5495 - val_mse: 3.6679\n",
      "Epoch 303/1000\n",
      "206/206 [==============================] - 0s 119us/sample - loss: 12.3321 - mae: 0.9755 - mse: 1.6010 - val_loss: 14.8939 - val_mae: 1.6573 - val_mse: 4.1307\n",
      "Epoch 304/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 101us/sample - loss: 12.4229 - mae: 1.0277 - mse: 1.7244 - val_loss: 14.4711 - val_mae: 1.4354 - val_mse: 3.1614\n",
      "Epoch 305/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 12.3512 - mae: 0.9783 - mse: 1.6097 - val_loss: 14.5794 - val_mae: 1.4227 - val_mse: 3.1689\n",
      "Epoch 306/1000\n",
      "206/206 [==============================] - 0s 111us/sample - loss: 12.3248 - mae: 0.9723 - mse: 1.5879 - val_loss: 14.5504 - val_mae: 1.5255 - val_mse: 3.4918\n",
      "Epoch 307/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 12.3503 - mae: 0.9938 - mse: 1.6032 - val_loss: 14.5260 - val_mae: 1.4516 - val_mse: 3.2386\n",
      "Epoch 308/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.3981 - mae: 1.0012 - mse: 1.6634 - val_loss: 14.5422 - val_mae: 1.5774 - val_mse: 3.6806\n",
      "Epoch 309/1000\n",
      "206/206 [==============================] - 0s 105us/sample - loss: 12.3163 - mae: 0.9842 - mse: 1.6187 - val_loss: 14.4250 - val_mae: 1.4812 - val_mse: 3.3085\n",
      "Epoch 310/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.3485 - mae: 0.9721 - mse: 1.5994 - val_loss: 14.9014 - val_mae: 1.7532 - val_mse: 4.4828\n",
      "Epoch 311/1000\n",
      "206/206 [==============================] - 0s 97us/sample - loss: 12.3831 - mae: 1.0275 - mse: 1.7341 - val_loss: 14.4952 - val_mae: 1.5337 - val_mse: 3.4972\n",
      "Epoch 312/1000\n",
      "206/206 [==============================] - 0s 118us/sample - loss: 12.3396 - mae: 0.9801 - mse: 1.6142 - val_loss: 14.5286 - val_mae: 1.5436 - val_mse: 3.5453\n",
      "Epoch 313/1000\n",
      "206/206 [==============================] - 0s 108us/sample - loss: 12.3328 - mae: 1.0000 - mse: 1.6416 - val_loss: 14.8486 - val_mae: 1.3347 - val_mse: 2.9343\n",
      "Epoch 314/1000\n",
      "206/206 [==============================] - 0s 118us/sample - loss: 12.3873 - mae: 1.0087 - mse: 1.6578 - val_loss: 14.5791 - val_mae: 1.4523 - val_mse: 3.2328\n",
      "Epoch 315/1000\n",
      "206/206 [==============================] - 0s 124us/sample - loss: 12.3090 - mae: 0.9734 - mse: 1.5757 - val_loss: 14.5877 - val_mae: 1.4264 - val_mse: 3.1551\n",
      "Epoch 316/1000\n",
      "206/206 [==============================] - 0s 155us/sample - loss: 12.5087 - mae: 1.0076 - mse: 1.7322 - val_loss: 14.5265 - val_mae: 1.4042 - val_mse: 3.0732\n",
      "Epoch 317/1000\n",
      "206/206 [==============================] - 0s 157us/sample - loss: 12.3003 - mae: 0.9550 - mse: 1.5321 - val_loss: 14.4836 - val_mae: 1.4065 - val_mse: 3.0758\n",
      "Epoch 318/1000\n",
      "206/206 [==============================] - 0s 134us/sample - loss: 12.3614 - mae: 0.9735 - mse: 1.6042 - val_loss: 14.4564 - val_mae: 1.4460 - val_mse: 3.1908\n",
      "Epoch 319/1000\n",
      "206/206 [==============================] - 0s 168us/sample - loss: 12.3551 - mae: 0.9792 - mse: 1.6151 - val_loss: 14.5143 - val_mae: 1.4484 - val_mse: 3.2223\n",
      "Epoch 320/1000\n",
      "206/206 [==============================] - 0s 156us/sample - loss: 12.3267 - mae: 0.9642 - mse: 1.5331 - val_loss: 15.3070 - val_mae: 1.9382 - val_mse: 5.2291\n",
      "Epoch 321/1000\n",
      "206/206 [==============================] - 0s 119us/sample - loss: 12.4308 - mae: 1.0869 - mse: 1.8985 - val_loss: 14.8358 - val_mae: 1.3355 - val_mse: 2.9500\n",
      "Epoch 322/1000\n",
      "206/206 [==============================] - 0s 80us/sample - loss: 12.3561 - mae: 0.9785 - mse: 1.5554 - val_loss: 14.6277 - val_mae: 1.5144 - val_mse: 3.4872\n",
      "Epoch 323/1000\n",
      "206/206 [==============================] - 0s 92us/sample - loss: 12.3173 - mae: 0.9772 - mse: 1.5836 - val_loss: 14.7729 - val_mae: 1.7047 - val_mse: 4.2240\n",
      "Epoch 324/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.4607 - mae: 1.0563 - mse: 1.8340 - val_loss: 14.6258 - val_mae: 1.4578 - val_mse: 3.2698\n",
      "Epoch 325/1000\n",
      "206/206 [==============================] - 0s 98us/sample - loss: 12.3167 - mae: 0.9875 - mse: 1.5933 - val_loss: 14.7343 - val_mae: 1.3095 - val_mse: 2.8444\n",
      "Epoch 326/1000\n",
      "206/206 [==============================] - 0s 115us/sample - loss: 12.4316 - mae: 0.9827 - mse: 1.6094 - val_loss: 14.4930 - val_mae: 1.4304 - val_mse: 3.1452\n",
      "Epoch 327/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.3386 - mae: 0.9727 - mse: 1.6105 - val_loss: 14.7697 - val_mae: 1.5174 - val_mse: 3.5425\n",
      "Epoch 328/1000\n",
      "206/206 [==============================] - 0s 102us/sample - loss: 12.3989 - mae: 1.0163 - mse: 1.6853 - val_loss: 14.5501 - val_mae: 1.5566 - val_mse: 3.5839\n",
      "Epoch 329/1000\n",
      "206/206 [==============================] - 0s 92us/sample - loss: 12.3443 - mae: 0.9889 - mse: 1.6368 - val_loss: 14.5432 - val_mae: 1.3752 - val_mse: 2.9845\n",
      "Epoch 330/1000\n",
      "206/206 [==============================] - 0s 133us/sample - loss: 12.2868 - mae: 0.9436 - mse: 1.4998 - val_loss: 14.6105 - val_mae: 1.4244 - val_mse: 3.1634\n",
      "Epoch 331/1000\n",
      "206/206 [==============================] - 0s 161us/sample - loss: 12.4174 - mae: 0.9911 - mse: 1.6324 - val_loss: 14.4720 - val_mae: 1.5088 - val_mse: 3.3953\n",
      "Epoch 332/1000\n",
      "206/206 [==============================] - 0s 122us/sample - loss: 12.3405 - mae: 0.9872 - mse: 1.6517 - val_loss: 14.4339 - val_mae: 1.5068 - val_mse: 3.3886\n",
      "Epoch 333/1000\n",
      "206/206 [==============================] - 0s 115us/sample - loss: 12.3128 - mae: 0.9885 - mse: 1.6201 - val_loss: 14.4494 - val_mae: 1.4335 - val_mse: 3.1512\n",
      "Epoch 334/1000\n",
      "206/206 [==============================] - 0s 166us/sample - loss: 12.2699 - mae: 0.9509 - mse: 1.5112 - val_loss: 14.5431 - val_mae: 1.4627 - val_mse: 3.2880\n",
      "Epoch 335/1000\n",
      "206/206 [==============================] - 0s 171us/sample - loss: 12.3401 - mae: 0.9887 - mse: 1.6120 - val_loss: 14.6051 - val_mae: 1.6167 - val_mse: 3.8333\n",
      "Epoch 336/1000\n",
      "206/206 [==============================] - 0s 117us/sample - loss: 12.3661 - mae: 0.9972 - mse: 1.6578 - val_loss: 14.6316 - val_mae: 1.3923 - val_mse: 3.0634\n",
      "Epoch 337/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 12.3664 - mae: 0.9790 - mse: 1.5791 - val_loss: 14.9147 - val_mae: 1.7536 - val_mse: 4.4582\n",
      "Epoch 338/1000\n",
      "206/206 [==============================] - 0s 106us/sample - loss: 12.3575 - mae: 1.0225 - mse: 1.7568 - val_loss: 14.6555 - val_mae: 1.3400 - val_mse: 2.9166\n",
      "Epoch 339/1000\n",
      "206/206 [==============================] - 0s 101us/sample - loss: 12.2908 - mae: 0.9480 - mse: 1.5038 - val_loss: 14.4944 - val_mae: 1.3965 - val_mse: 3.0466\n",
      "Epoch 340/1000\n",
      "206/206 [==============================] - 0s 98us/sample - loss: 12.3266 - mae: 0.9806 - mse: 1.5889 - val_loss: 14.6044 - val_mae: 1.5967 - val_mse: 3.7474\n",
      "Epoch 341/1000\n",
      "206/206 [==============================] - 0s 115us/sample - loss: 12.3885 - mae: 1.0131 - mse: 1.7092 - val_loss: 14.5758 - val_mae: 1.4905 - val_mse: 3.3754\n",
      "Epoch 342/1000\n",
      "206/206 [==============================] - 0s 131us/sample - loss: 12.2904 - mae: 0.9707 - mse: 1.5610 - val_loss: 14.6231 - val_mae: 1.3342 - val_mse: 2.8913\n",
      "Epoch 343/1000\n",
      "206/206 [==============================] - 0s 180us/sample - loss: 12.3187 - mae: 0.9430 - mse: 1.4908 - val_loss: 14.6637 - val_mae: 1.6376 - val_mse: 3.9673\n",
      "Epoch 344/1000\n",
      "206/206 [==============================] - 0s 148us/sample - loss: 12.3279 - mae: 0.9898 - mse: 1.6515 - val_loss: 14.5227 - val_mae: 1.5738 - val_mse: 3.6869\n",
      "Epoch 345/1000\n",
      "206/206 [==============================] - 0s 119us/sample - loss: 12.2777 - mae: 0.9735 - mse: 1.5823 - val_loss: 14.4454 - val_mae: 1.4344 - val_mse: 3.1595\n",
      "Epoch 346/1000\n",
      "206/206 [==============================] - 0s 128us/sample - loss: 12.4274 - mae: 0.9996 - mse: 1.6784 - val_loss: 14.6709 - val_mae: 1.6378 - val_mse: 3.9682\n",
      "Epoch 347/1000\n",
      "206/206 [==============================] - 0s 120us/sample - loss: 12.3243 - mae: 1.0006 - mse: 1.6933 - val_loss: 14.5421 - val_mae: 1.5463 - val_mse: 3.5620\n",
      "Epoch 348/1000\n",
      "206/206 [==============================] - 0s 142us/sample - loss: 12.3239 - mae: 0.9786 - mse: 1.5866 - val_loss: 14.6186 - val_mae: 1.6329 - val_mse: 3.8999\n",
      "Epoch 349/1000\n",
      "206/206 [==============================] - 0s 107us/sample - loss: 12.2786 - mae: 0.9801 - mse: 1.5786 - val_loss: 14.8177 - val_mae: 1.7303 - val_mse: 4.3309\n",
      "Epoch 350/1000\n",
      "206/206 [==============================] - 0s 118us/sample - loss: 12.3043 - mae: 0.9984 - mse: 1.6306 - val_loss: 14.5509 - val_mae: 1.5542 - val_mse: 3.6236\n",
      "Epoch 351/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/206 [==============================] - 0s 102us/sample - loss: 12.2938 - mae: 0.9988 - mse: 1.6299 - val_loss: 14.5053 - val_mae: 1.3349 - val_mse: 2.8626\n",
      "Epoch 352/1000\n",
      "206/206 [==============================] - 0s 111us/sample - loss: 12.2791 - mae: 0.9344 - mse: 1.4883 - val_loss: 14.5997 - val_mae: 1.6177 - val_mse: 3.8504\n",
      "Epoch 353/1000\n",
      "206/206 [==============================] - 0s 104us/sample - loss: 12.3826 - mae: 1.0140 - mse: 1.7045 - val_loss: 14.5167 - val_mae: 1.3863 - val_mse: 3.0132\n",
      "Epoch 354/1000\n",
      "206/206 [==============================] - 0s 99us/sample - loss: 12.3209 - mae: 0.9764 - mse: 1.5766 - val_loss: 14.5799 - val_mae: 1.5396 - val_mse: 3.5419\n",
      "Epoch 355/1000\n",
      "206/206 [==============================] - 0s 94us/sample - loss: 12.2622 - mae: 0.9669 - mse: 1.5585 - val_loss: 14.5434 - val_mae: 1.4544 - val_mse: 3.2346\n",
      "Epoch 356/1000\n",
      "206/206 [==============================] - 0s 140us/sample - loss: 12.3146 - mae: 0.9722 - mse: 1.5635 - val_loss: 14.7269 - val_mae: 1.6826 - val_mse: 4.0703\n",
      "Epoch 357/1000\n",
      "206/206 [==============================] - 0s 150us/sample - loss: 12.3338 - mae: 1.0012 - mse: 1.6817 - val_loss: 14.4443 - val_mae: 1.3822 - val_mse: 2.9947\n",
      "Epoch 358/1000\n",
      "206/206 [==============================] - 0s 151us/sample - loss: 12.2527 - mae: 0.9406 - mse: 1.5049 - val_loss: 14.5049 - val_mae: 1.3402 - val_mse: 2.8819\n",
      "Epoch 359/1000\n",
      "206/206 [==============================] - 0s 156us/sample - loss: 12.2896 - mae: 0.9535 - mse: 1.5036 - val_loss: 14.4708 - val_mae: 1.4185 - val_mse: 3.1271\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,442\n",
      "Trainable params: 5,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 309 samples, validate on 103 samples\n",
      "Epoch 1/1000\n",
      "309/309 [==============================] - 1s 3ms/sample - loss: 258.4884 - mae: 14.2087 - mse: 258.3792 - val_loss: 261.9558 - val_mae: 14.2371 - val_mse: 261.7855\n",
      "Epoch 2/1000\n",
      "309/309 [==============================] - 0s 62us/sample - loss: 217.1303 - mae: 12.8583 - mse: 216.8476 - val_loss: 215.7673 - val_mae: 12.7279 - val_mse: 215.3018\n",
      "Epoch 3/1000\n",
      "309/309 [==============================] - 0s 85us/sample - loss: 170.0512 - mae: 11.0975 - mse: 169.2988 - val_loss: 163.9871 - val_mae: 10.7618 - val_mse: 162.8348\n",
      "Epoch 4/1000\n",
      "309/309 [==============================] - 0s 80us/sample - loss: 120.8835 - mae: 8.8740 - mse: 119.1522 - val_loss: 113.1686 - val_mae: 8.4004 - val_mse: 110.7135\n",
      "Epoch 5/1000\n",
      "309/309 [==============================] - 0s 88us/sample - loss: 78.3243 - mae: 6.6068 - mse: 74.9147 - val_loss: 73.4193 - val_mae: 6.2369 - val_mse: 69.0021\n",
      "Epoch 6/1000\n",
      "309/309 [==============================] - 0s 79us/sample - loss: 50.4803 - mae: 4.8977 - mse: 44.8119 - val_loss: 50.2733 - val_mae: 4.9430 - val_mse: 43.7408\n",
      "Epoch 7/1000\n",
      "309/309 [==============================] - 0s 68us/sample - loss: 37.4554 - mae: 4.2111 - mse: 29.7696 - val_loss: 38.9643 - val_mae: 4.2753 - val_mse: 30.7453\n",
      "Epoch 8/1000\n",
      "309/309 [==============================] - 0s 70us/sample - loss: 32.7558 - mae: 3.8998 - mse: 23.7196 - val_loss: 35.1436 - val_mae: 3.9602 - val_mse: 26.4272\n",
      "Epoch 9/1000\n",
      "309/309 [==============================] - 0s 87us/sample - loss: 30.6717 - mae: 3.6819 - mse: 21.2731 - val_loss: 32.2643 - val_mae: 3.7449 - val_mse: 23.0449\n",
      "Epoch 10/1000\n",
      "309/309 [==============================] - 0s 77us/sample - loss: 28.4826 - mae: 3.4923 - mse: 19.0232 - val_loss: 29.0369 - val_mae: 3.4721 - val_mse: 18.8096\n",
      "Epoch 11/1000\n",
      "309/309 [==============================] - 0s 92us/sample - loss: 26.5027 - mae: 3.3166 - mse: 16.6968 - val_loss: 27.4844 - val_mae: 3.3243 - val_mse: 17.7538\n",
      "Epoch 12/1000\n",
      "309/309 [==============================] - 0s 84us/sample - loss: 24.5077 - mae: 3.0997 - mse: 14.7098 - val_loss: 25.9572 - val_mae: 3.1955 - val_mse: 16.3500\n",
      "Epoch 13/1000\n",
      "309/309 [==============================] - 0s 85us/sample - loss: 22.5832 - mae: 2.9121 - mse: 12.7917 - val_loss: 24.0451 - val_mae: 3.0064 - val_mse: 14.3131\n",
      "Epoch 14/1000\n",
      "309/309 [==============================] - 0s 93us/sample - loss: 20.8257 - mae: 2.6899 - mse: 11.0322 - val_loss: 21.7193 - val_mae: 2.7053 - val_mse: 10.8970\n",
      "Epoch 15/1000\n",
      "309/309 [==============================] - 0s 88us/sample - loss: 19.3636 - mae: 2.5015 - mse: 9.2732 - val_loss: 20.9198 - val_mae: 2.6729 - val_mse: 10.9764\n",
      "Epoch 16/1000\n",
      "309/309 [==============================] - 0s 66us/sample - loss: 18.3589 - mae: 2.3512 - mse: 8.3300 - val_loss: 19.3792 - val_mae: 2.3987 - val_mse: 8.7674\n",
      "Epoch 17/1000\n",
      "309/309 [==============================] - 0s 74us/sample - loss: 17.5351 - mae: 2.2090 - mse: 7.4108 - val_loss: 18.7733 - val_mae: 2.3396 - val_mse: 8.2960\n",
      "Epoch 18/1000\n",
      "309/309 [==============================] - 0s 91us/sample - loss: 17.0350 - mae: 2.1310 - mse: 6.9437 - val_loss: 18.4645 - val_mae: 2.0651 - val_mse: 6.5560\n",
      "Epoch 19/1000\n",
      "309/309 [==============================] - 0s 79us/sample - loss: 16.7694 - mae: 2.0682 - mse: 6.4507 - val_loss: 17.7733 - val_mae: 2.0704 - val_mse: 6.7259\n",
      "Epoch 20/1000\n",
      "309/309 [==============================] - 0s 83us/sample - loss: 16.4884 - mae: 2.0110 - mse: 6.2401 - val_loss: 17.7663 - val_mae: 2.1544 - val_mse: 7.1067\n",
      "Epoch 21/1000\n",
      "309/309 [==============================] - 0s 82us/sample - loss: 16.4582 - mae: 2.0238 - mse: 6.2290 - val_loss: 17.5465 - val_mae: 2.0865 - val_mse: 6.8748\n",
      "Epoch 22/1000\n",
      "309/309 [==============================] - 0s 82us/sample - loss: 16.2863 - mae: 1.9929 - mse: 6.0338 - val_loss: 17.5519 - val_mae: 2.1125 - val_mse: 7.0403\n",
      "Epoch 23/1000\n",
      "309/309 [==============================] - 0s 89us/sample - loss: 16.1702 - mae: 1.9799 - mse: 6.0034 - val_loss: 17.3288 - val_mae: 1.8858 - val_mse: 5.5719\n",
      "Epoch 24/1000\n",
      "309/309 [==============================] - 0s 76us/sample - loss: 16.1360 - mae: 1.9477 - mse: 5.8203 - val_loss: 17.0877 - val_mae: 1.9482 - val_mse: 5.8826\n",
      "Epoch 25/1000\n",
      "309/309 [==============================] - 0s 91us/sample - loss: 15.8259 - mae: 1.9117 - mse: 5.5596 - val_loss: 17.0286 - val_mae: 1.8719 - val_mse: 5.4076\n",
      "Epoch 26/1000\n",
      "309/309 [==============================] - 0s 78us/sample - loss: 15.9382 - mae: 1.9197 - mse: 5.6052 - val_loss: 16.8903 - val_mae: 1.9382 - val_mse: 5.8595\n",
      "Epoch 27/1000\n",
      "309/309 [==============================] - 0s 83us/sample - loss: 15.6685 - mae: 1.8654 - mse: 5.3324 - val_loss: 17.3058 - val_mae: 2.1213 - val_mse: 6.9970\n",
      "Epoch 28/1000\n",
      "309/309 [==============================] - 0s 89us/sample - loss: 15.5767 - mae: 1.8825 - mse: 5.3637 - val_loss: 16.7667 - val_mae: 1.8360 - val_mse: 5.4893\n",
      "Epoch 29/1000\n",
      "309/309 [==============================] - 0s 79us/sample - loss: 15.5208 - mae: 1.8293 - mse: 5.2252 - val_loss: 16.6344 - val_mae: 1.8592 - val_mse: 5.4673\n",
      "Epoch 30/1000\n",
      "309/309 [==============================] - 0s 90us/sample - loss: 15.3475 - mae: 1.8154 - mse: 5.0295 - val_loss: 16.5593 - val_mae: 1.8670 - val_mse: 5.4793\n",
      "Epoch 31/1000\n",
      "309/309 [==============================] - 0s 79us/sample - loss: 15.1822 - mae: 1.7860 - mse: 4.8981 - val_loss: 16.4861 - val_mae: 1.8555 - val_mse: 5.2372\n",
      "Epoch 32/1000\n",
      "309/309 [==============================] - 0s 82us/sample - loss: 15.1215 - mae: 1.7812 - mse: 4.7820 - val_loss: 16.3884 - val_mae: 1.8407 - val_mse: 5.3571\n",
      "Epoch 33/1000\n",
      "309/309 [==============================] - 0s 89us/sample - loss: 14.9795 - mae: 1.7418 - mse: 4.7092 - val_loss: 16.5571 - val_mae: 1.7539 - val_mse: 4.6200\n",
      "Epoch 34/1000\n",
      "309/309 [==============================] - 0s 84us/sample - loss: 14.8949 - mae: 1.7332 - mse: 4.5193 - val_loss: 16.2282 - val_mae: 1.8541 - val_mse: 5.2131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/1000\n",
      "309/309 [==============================] - 0s 91us/sample - loss: 14.8546 - mae: 1.7195 - mse: 4.5248 - val_loss: 16.3332 - val_mae: 1.9338 - val_mse: 5.6490\n",
      "Epoch 36/1000\n",
      "309/309 [==============================] - 0s 86us/sample - loss: 14.6084 - mae: 1.6698 - mse: 4.3040 - val_loss: 16.1016 - val_mae: 1.8439 - val_mse: 5.1905\n",
      "Epoch 37/1000\n",
      "309/309 [==============================] - 0s 77us/sample - loss: 14.5470 - mae: 1.6665 - mse: 4.2400 - val_loss: 15.9932 - val_mae: 1.8310 - val_mse: 5.0716\n",
      "Epoch 38/1000\n",
      "309/309 [==============================] - 0s 88us/sample - loss: 14.5026 - mae: 1.6529 - mse: 4.1955 - val_loss: 15.8897 - val_mae: 1.7921 - val_mse: 4.9172\n",
      "Epoch 39/1000\n",
      "309/309 [==============================] - 0s 77us/sample - loss: 14.3620 - mae: 1.6179 - mse: 4.0566 - val_loss: 15.7754 - val_mae: 1.6828 - val_mse: 4.3371\n",
      "Epoch 40/1000\n",
      "309/309 [==============================] - 0s 87us/sample - loss: 14.2691 - mae: 1.5997 - mse: 3.8943 - val_loss: 15.8608 - val_mae: 1.8198 - val_mse: 5.0679\n",
      "Epoch 41/1000\n",
      "309/309 [==============================] - 0s 79us/sample - loss: 14.1995 - mae: 1.5918 - mse: 3.8630 - val_loss: 15.8954 - val_mae: 1.8589 - val_mse: 5.2658\n",
      "Epoch 42/1000\n",
      "309/309 [==============================] - 0s 80us/sample - loss: 14.0185 - mae: 1.5539 - mse: 3.7126 - val_loss: 15.5767 - val_mae: 1.7163 - val_mse: 4.4736\n",
      "Epoch 43/1000\n",
      "309/309 [==============================] - 0s 96us/sample - loss: 13.8994 - mae: 1.5215 - mse: 3.5580 - val_loss: 15.4778 - val_mae: 1.6638 - val_mse: 4.2193\n",
      "Epoch 44/1000\n",
      "309/309 [==============================] - 0s 67us/sample - loss: 13.7908 - mae: 1.5000 - mse: 3.4659 - val_loss: 15.4935 - val_mae: 1.5905 - val_mse: 3.7828\n",
      "Epoch 45/1000\n",
      "309/309 [==============================] - 0s 85us/sample - loss: 13.7867 - mae: 1.4777 - mse: 3.4035 - val_loss: 15.5261 - val_mae: 1.5940 - val_mse: 3.7546\n",
      "Epoch 46/1000\n",
      "309/309 [==============================] - 0s 76us/sample - loss: 13.7115 - mae: 1.4665 - mse: 3.2971 - val_loss: 15.3415 - val_mae: 1.6289 - val_mse: 3.9411\n",
      "Epoch 47/1000\n",
      "309/309 [==============================] - 0s 93us/sample - loss: 13.6653 - mae: 1.4367 - mse: 3.2607 - val_loss: 15.5275 - val_mae: 1.8036 - val_mse: 4.8183\n",
      "Epoch 48/1000\n",
      "309/309 [==============================] - 0s 77us/sample - loss: 13.5810 - mae: 1.4388 - mse: 3.2535 - val_loss: 15.3290 - val_mae: 1.6754 - val_mse: 4.4280\n",
      "Epoch 49/1000\n",
      "309/309 [==============================] - 0s 84us/sample - loss: 13.4349 - mae: 1.3977 - mse: 3.1038 - val_loss: 15.2638 - val_mae: 1.5237 - val_mse: 3.4840\n",
      "Epoch 50/1000\n",
      "309/309 [==============================] - 0s 82us/sample - loss: 13.4541 - mae: 1.3808 - mse: 2.9974 - val_loss: 15.1728 - val_mae: 1.6424 - val_mse: 4.1186\n",
      "Epoch 51/1000\n",
      "309/309 [==============================] - 0s 81us/sample - loss: 13.3474 - mae: 1.3646 - mse: 2.9786 - val_loss: 15.1408 - val_mae: 1.6184 - val_mse: 3.8510\n",
      "Epoch 52/1000\n",
      "309/309 [==============================] - 0s 88us/sample - loss: 13.2512 - mae: 1.3400 - mse: 2.8677 - val_loss: 15.1104 - val_mae: 1.5049 - val_mse: 3.4389\n",
      "Epoch 53/1000\n",
      "309/309 [==============================] - 0s 76us/sample - loss: 13.3743 - mae: 1.3525 - mse: 2.9407 - val_loss: 15.2242 - val_mae: 1.6940 - val_mse: 4.4559\n",
      "Epoch 54/1000\n",
      "309/309 [==============================] - 0s 93us/sample - loss: 13.1620 - mae: 1.3217 - mse: 2.8127 - val_loss: 15.0042 - val_mae: 1.5165 - val_mse: 3.4862\n",
      "Epoch 55/1000\n",
      "309/309 [==============================] - 0s 86us/sample - loss: 13.1305 - mae: 1.3063 - mse: 2.7175 - val_loss: 15.0843 - val_mae: 1.5036 - val_mse: 3.3802\n",
      "Epoch 56/1000\n",
      "309/309 [==============================] - 0s 83us/sample - loss: 13.0844 - mae: 1.2931 - mse: 2.6397 - val_loss: 15.0674 - val_mae: 1.6166 - val_mse: 4.0902\n",
      "Epoch 57/1000\n",
      "309/309 [==============================] - 0s 91us/sample - loss: 13.1402 - mae: 1.2994 - mse: 2.7145 - val_loss: 15.2168 - val_mae: 1.7289 - val_mse: 4.4924\n",
      "Epoch 58/1000\n",
      "309/309 [==============================] - 0s 76us/sample - loss: 13.0400 - mae: 1.2815 - mse: 2.6483 - val_loss: 15.1076 - val_mae: 1.6774 - val_mse: 4.2230\n",
      "Epoch 59/1000\n",
      "309/309 [==============================] - 0s 90us/sample - loss: 12.9532 - mae: 1.2534 - mse: 2.5575 - val_loss: 14.9391 - val_mae: 1.5403 - val_mse: 3.7024\n",
      "Epoch 60/1000\n",
      "309/309 [==============================] - 0s 86us/sample - loss: 12.9424 - mae: 1.2420 - mse: 2.5261 - val_loss: 14.9777 - val_mae: 1.4785 - val_mse: 3.3256\n",
      "Epoch 61/1000\n",
      "309/309 [==============================] - 0s 82us/sample - loss: 12.9055 - mae: 1.2194 - mse: 2.4233 - val_loss: 15.3789 - val_mae: 1.7981 - val_mse: 4.8779\n",
      "Epoch 62/1000\n",
      "309/309 [==============================] - 0s 91us/sample - loss: 12.8676 - mae: 1.2197 - mse: 2.4969 - val_loss: 15.2351 - val_mae: 1.6117 - val_mse: 3.8633\n",
      "Epoch 63/1000\n",
      "309/309 [==============================] - 0s 81us/sample - loss: 12.9295 - mae: 1.2123 - mse: 2.4537 - val_loss: 15.4122 - val_mae: 1.8041 - val_mse: 4.9440\n",
      "Epoch 64/1000\n",
      "309/309 [==============================] - 0s 81us/sample - loss: 12.8909 - mae: 1.2285 - mse: 2.5165 - val_loss: 15.2085 - val_mae: 1.7164 - val_mse: 4.4276\n",
      "Epoch 65/1000\n",
      "309/309 [==============================] - 0s 89us/sample - loss: 12.8203 - mae: 1.2065 - mse: 2.3958 - val_loss: 15.2480 - val_mae: 1.7130 - val_mse: 4.3939\n",
      "Epoch 66/1000\n",
      "309/309 [==============================] - 0s 76us/sample - loss: 12.7641 - mae: 1.1915 - mse: 2.3493 - val_loss: 14.9102 - val_mae: 1.5542 - val_mse: 3.7034\n",
      "Epoch 67/1000\n",
      "309/309 [==============================] - 0s 93us/sample - loss: 12.8408 - mae: 1.2029 - mse: 2.3557 - val_loss: 14.9295 - val_mae: 1.5559 - val_mse: 3.7211\n",
      "Epoch 68/1000\n",
      "309/309 [==============================] - 0s 85us/sample - loss: 12.7317 - mae: 1.1752 - mse: 2.2858 - val_loss: 14.8469 - val_mae: 1.5200 - val_mse: 3.6366\n",
      "Epoch 69/1000\n",
      "309/309 [==============================] - 0s 82us/sample - loss: 12.6884 - mae: 1.1636 - mse: 2.2198 - val_loss: 14.8879 - val_mae: 1.5819 - val_mse: 3.8670\n",
      "Epoch 70/1000\n",
      "309/309 [==============================] - 0s 88us/sample - loss: 12.7480 - mae: 1.1894 - mse: 2.3226 - val_loss: 14.8541 - val_mae: 1.4131 - val_mse: 3.1413\n",
      "Epoch 71/1000\n",
      "309/309 [==============================] - 0s 80us/sample - loss: 12.7361 - mae: 1.1641 - mse: 2.2258 - val_loss: 15.0994 - val_mae: 1.6804 - val_mse: 4.3203\n",
      "Epoch 72/1000\n",
      "309/309 [==============================] - 0s 89us/sample - loss: 12.6519 - mae: 1.1514 - mse: 2.2296 - val_loss: 14.9859 - val_mae: 1.6251 - val_mse: 4.0804\n",
      "Epoch 73/1000\n",
      "309/309 [==============================] - 0s 86us/sample - loss: 12.6416 - mae: 1.1511 - mse: 2.1831 - val_loss: 15.2556 - val_mae: 1.7475 - val_mse: 4.6833\n",
      "Epoch 74/1000\n",
      "309/309 [==============================] - 0s 87us/sample - loss: 12.7232 - mae: 1.1751 - mse: 2.3095 - val_loss: 15.0509 - val_mae: 1.6333 - val_mse: 4.0932\n",
      "Epoch 75/1000\n",
      "309/309 [==============================] - 0s 89us/sample - loss: 12.5654 - mae: 1.1466 - mse: 2.1369 - val_loss: 14.9316 - val_mae: 1.4567 - val_mse: 3.3619\n",
      "Epoch 76/1000\n",
      "309/309 [==============================] - 0s 86us/sample - loss: 12.6516 - mae: 1.1393 - mse: 2.1620 - val_loss: 14.9559 - val_mae: 1.6110 - val_mse: 4.0356\n",
      "Epoch 77/1000\n",
      "309/309 [==============================] - 0s 86us/sample - loss: 12.5539 - mae: 1.1332 - mse: 2.0991 - val_loss: 14.9310 - val_mae: 1.5867 - val_mse: 3.9204\n",
      "Epoch 78/1000\n",
      "309/309 [==============================] - 0s 88us/sample - loss: 12.6396 - mae: 1.1426 - mse: 2.1890 - val_loss: 14.9564 - val_mae: 1.5943 - val_mse: 3.9530\n",
      "Epoch 79/1000\n",
      "309/309 [==============================] - 0s 88us/sample - loss: 12.6614 - mae: 1.1585 - mse: 2.2118 - val_loss: 14.8773 - val_mae: 1.4965 - val_mse: 3.5187\n",
      "Epoch 80/1000\n",
      "309/309 [==============================] - 0s 89us/sample - loss: 12.5023 - mae: 1.1046 - mse: 2.0387 - val_loss: 14.7988 - val_mae: 1.4997 - val_mse: 3.5522\n",
      "Epoch 81/1000\n",
      "309/309 [==============================] - 0s 89us/sample - loss: 12.5827 - mae: 1.1410 - mse: 2.1515 - val_loss: 14.9618 - val_mae: 1.3696 - val_mse: 3.0399\n",
      "Epoch 82/1000\n",
      "309/309 [==============================] - 0s 94us/sample - loss: 12.5217 - mae: 1.0963 - mse: 1.9994 - val_loss: 14.8261 - val_mae: 1.4909 - val_mse: 3.5306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/1000\n",
      "309/309 [==============================] - 0s 82us/sample - loss: 12.4935 - mae: 1.0997 - mse: 2.0332 - val_loss: 14.9303 - val_mae: 1.4665 - val_mse: 3.4489\n",
      "Epoch 84/1000\n",
      "309/309 [==============================] - 0s 88us/sample - loss: 12.5475 - mae: 1.1156 - mse: 2.0712 - val_loss: 14.8262 - val_mae: 1.4444 - val_mse: 3.3630\n",
      "Epoch 85/1000\n",
      "309/309 [==============================] - 0s 91us/sample - loss: 12.4835 - mae: 1.0980 - mse: 2.0037 - val_loss: 14.8459 - val_mae: 1.5283 - val_mse: 3.7134\n",
      "Epoch 86/1000\n",
      "309/309 [==============================] - 0s 82us/sample - loss: 12.5331 - mae: 1.1227 - mse: 2.0830 - val_loss: 14.8557 - val_mae: 1.4354 - val_mse: 3.3436\n",
      "Epoch 87/1000\n",
      "309/309 [==============================] - 0s 89us/sample - loss: 12.4877 - mae: 1.0986 - mse: 1.9978 - val_loss: 14.8509 - val_mae: 1.4913 - val_mse: 3.5646\n",
      "Epoch 88/1000\n",
      "309/309 [==============================] - 0s 83us/sample - loss: 12.4069 - mae: 1.0806 - mse: 1.9529 - val_loss: 14.8806 - val_mae: 1.4702 - val_mse: 3.4846\n",
      "Epoch 89/1000\n",
      "309/309 [==============================] - 0s 78us/sample - loss: 12.4615 - mae: 1.0849 - mse: 1.9689 - val_loss: 15.1213 - val_mae: 1.6532 - val_mse: 4.2843\n",
      "Epoch 90/1000\n",
      "309/309 [==============================] - 0s 85us/sample - loss: 12.4283 - mae: 1.0941 - mse: 1.9941 - val_loss: 14.7855 - val_mae: 1.4294 - val_mse: 3.3392\n",
      "Epoch 91/1000\n",
      "309/309 [==============================] - 0s 78us/sample - loss: 12.4878 - mae: 1.0996 - mse: 2.0108 - val_loss: 14.7944 - val_mae: 1.4469 - val_mse: 3.4110\n",
      "Epoch 92/1000\n",
      "309/309 [==============================] - 0s 86us/sample - loss: 12.4366 - mae: 1.0888 - mse: 1.9681 - val_loss: 14.9066 - val_mae: 1.3722 - val_mse: 3.1233\n",
      "Epoch 93/1000\n",
      "309/309 [==============================] - 0s 77us/sample - loss: 12.4290 - mae: 1.0885 - mse: 1.9419 - val_loss: 14.8743 - val_mae: 1.3772 - val_mse: 3.1357\n",
      "Epoch 94/1000\n",
      "309/309 [==============================] - 0s 89us/sample - loss: 12.4063 - mae: 1.0608 - mse: 1.8914 - val_loss: 14.8318 - val_mae: 1.4663 - val_mse: 3.5037\n",
      "Epoch 95/1000\n",
      "309/309 [==============================] - 0s 80us/sample - loss: 12.4321 - mae: 1.0729 - mse: 1.9557 - val_loss: 14.8951 - val_mae: 1.3976 - val_mse: 3.2518\n",
      "Epoch 96/1000\n",
      "309/309 [==============================] - 0s 81us/sample - loss: 12.4104 - mae: 1.0807 - mse: 1.9324 - val_loss: 14.9329 - val_mae: 1.3878 - val_mse: 3.2154\n",
      "Epoch 97/1000\n",
      "309/309 [==============================] - 0s 82us/sample - loss: 12.3913 - mae: 1.0695 - mse: 1.9101 - val_loss: 14.9181 - val_mae: 1.3892 - val_mse: 3.2334\n",
      "Epoch 98/1000\n",
      "309/309 [==============================] - 0s 84us/sample - loss: 12.3535 - mae: 1.0632 - mse: 1.8870 - val_loss: 15.1670 - val_mae: 1.3252 - val_mse: 2.9765\n",
      "Epoch 99/1000\n",
      "309/309 [==============================] - 0s 87us/sample - loss: 12.4505 - mae: 1.0681 - mse: 1.8919 - val_loss: 14.9074 - val_mae: 1.4916 - val_mse: 3.6420\n",
      "Epoch 100/1000\n",
      "309/309 [==============================] - 0s 75us/sample - loss: 12.3201 - mae: 1.0583 - mse: 1.8422 - val_loss: 14.9585 - val_mae: 1.5018 - val_mse: 3.6993\n",
      "Epoch 101/1000\n",
      "309/309 [==============================] - 0s 90us/sample - loss: 12.3512 - mae: 1.0581 - mse: 1.8573 - val_loss: 15.1315 - val_mae: 1.6030 - val_mse: 4.1424\n",
      "Epoch 102/1000\n",
      "309/309 [==============================] - 0s 79us/sample - loss: 12.3477 - mae: 1.0717 - mse: 1.8854 - val_loss: 15.1736 - val_mae: 1.5613 - val_mse: 3.9987\n",
      "Epoch 103/1000\n",
      "309/309 [==============================] - 0s 84us/sample - loss: 12.4303 - mae: 1.0696 - mse: 1.9258 - val_loss: 14.9117 - val_mae: 1.4112 - val_mse: 3.3608\n",
      "Epoch 104/1000\n",
      "309/309 [==============================] - 0s 82us/sample - loss: 12.2870 - mae: 1.0276 - mse: 1.8010 - val_loss: 14.8546 - val_mae: 1.4504 - val_mse: 3.4842\n",
      "Epoch 105/1000\n",
      "309/309 [==============================] - 0s 82us/sample - loss: 12.2965 - mae: 1.0499 - mse: 1.8067 - val_loss: 14.9427 - val_mae: 1.5574 - val_mse: 3.9121\n",
      "Epoch 106/1000\n",
      "309/309 [==============================] - 0s 95us/sample - loss: 12.3529 - mae: 1.0527 - mse: 1.8636 - val_loss: 14.9352 - val_mae: 1.4834 - val_mse: 3.6572\n",
      "Epoch 107/1000\n",
      "309/309 [==============================] - 0s 79us/sample - loss: 12.3171 - mae: 1.0585 - mse: 1.8684 - val_loss: 15.0866 - val_mae: 1.3205 - val_mse: 2.9320\n",
      "Epoch 108/1000\n",
      "309/309 [==============================] - 0s 83us/sample - loss: 12.3122 - mae: 1.0452 - mse: 1.7797 - val_loss: 14.9438 - val_mae: 1.3916 - val_mse: 3.3167\n",
      "Epoch 109/1000\n",
      "309/309 [==============================] - 0s 87us/sample - loss: 12.3454 - mae: 1.0417 - mse: 1.8226 - val_loss: 15.0747 - val_mae: 1.5846 - val_mse: 4.0771\n",
      "Epoch 110/1000\n",
      "309/309 [==============================] - 0s 80us/sample - loss: 12.2829 - mae: 1.0385 - mse: 1.8167 - val_loss: 15.0946 - val_mae: 1.5667 - val_mse: 4.0244\n",
      "Epoch 111/1000\n",
      "309/309 [==============================] - 0s 92us/sample - loss: 12.3017 - mae: 1.0546 - mse: 1.8350 - val_loss: 15.0194 - val_mae: 1.3580 - val_mse: 3.2046\n",
      "Epoch 112/1000\n",
      "309/309 [==============================] - 0s 78us/sample - loss: 12.2461 - mae: 1.0198 - mse: 1.7346 - val_loss: 14.8980 - val_mae: 1.4009 - val_mse: 3.3567\n",
      "Epoch 113/1000\n",
      "309/309 [==============================] - 0s 83us/sample - loss: 12.3106 - mae: 1.0337 - mse: 1.7985 - val_loss: 15.2163 - val_mae: 1.6780 - val_mse: 4.4761\n",
      "Epoch 114/1000\n",
      "309/309 [==============================] - 0s 85us/sample - loss: 12.2151 - mae: 1.0442 - mse: 1.7624 - val_loss: 15.0597 - val_mae: 1.5783 - val_mse: 4.0639\n",
      "Epoch 115/1000\n",
      "309/309 [==============================] - 0s 81us/sample - loss: 12.3732 - mae: 1.0525 - mse: 1.8862 - val_loss: 14.9116 - val_mae: 1.4063 - val_mse: 3.3831\n",
      "Epoch 116/1000\n",
      "309/309 [==============================] - 0s 91us/sample - loss: 12.2392 - mae: 1.0295 - mse: 1.7406 - val_loss: 14.8863 - val_mae: 1.4510 - val_mse: 3.5493\n",
      "Epoch 117/1000\n",
      "309/309 [==============================] - 0s 78us/sample - loss: 12.2245 - mae: 1.0212 - mse: 1.7269 - val_loss: 15.0797 - val_mae: 1.5963 - val_mse: 4.1389\n",
      "Epoch 118/1000\n",
      "309/309 [==============================] - 0s 89us/sample - loss: 12.2922 - mae: 1.0550 - mse: 1.8255 - val_loss: 14.8982 - val_mae: 1.3760 - val_mse: 3.2750\n",
      "Epoch 119/1000\n",
      "309/309 [==============================] - 0s 86us/sample - loss: 12.2131 - mae: 1.0204 - mse: 1.7180 - val_loss: 15.0867 - val_mae: 1.4538 - val_mse: 3.6493\n",
      "Epoch 120/1000\n",
      "309/309 [==============================] - 0s 77us/sample - loss: 12.3659 - mae: 1.0617 - mse: 1.8922 - val_loss: 14.9963 - val_mae: 1.3420 - val_mse: 3.1613\n",
      "Epoch 121/1000\n",
      "309/309 [==============================] - 0s 87us/sample - loss: 12.2200 - mae: 1.0111 - mse: 1.7026 - val_loss: 14.9735 - val_mae: 1.4400 - val_mse: 3.5610\n",
      "Epoch 122/1000\n",
      "309/309 [==============================] - 0s 80us/sample - loss: 12.2799 - mae: 1.0429 - mse: 1.7881 - val_loss: 14.9154 - val_mae: 1.4129 - val_mse: 3.4124\n",
      "Epoch 123/1000\n",
      "309/309 [==============================] - 0s 90us/sample - loss: 12.2013 - mae: 0.9979 - mse: 1.6606 - val_loss: 15.8095 - val_mae: 1.8694 - val_mse: 5.4430\n",
      "Epoch 124/1000\n",
      "309/309 [==============================] - 0s 87us/sample - loss: 12.3005 - mae: 1.0524 - mse: 1.8840 - val_loss: 15.1492 - val_mae: 1.5987 - val_mse: 4.1799\n",
      "Epoch 125/1000\n",
      "309/309 [==============================] - 0s 79us/sample - loss: 12.2497 - mae: 1.0469 - mse: 1.8029 - val_loss: 15.0770 - val_mae: 1.3618 - val_mse: 3.3062\n",
      "Epoch 126/1000\n",
      "309/309 [==============================] - 0s 91us/sample - loss: 12.2137 - mae: 1.0152 - mse: 1.6892 - val_loss: 14.9445 - val_mae: 1.4604 - val_mse: 3.6259\n",
      "Epoch 127/1000\n",
      "309/309 [==============================] - 0s 81us/sample - loss: 12.2309 - mae: 1.0208 - mse: 1.7449 - val_loss: 14.9842 - val_mae: 1.4049 - val_mse: 3.4564\n",
      "Epoch 128/1000\n",
      "309/309 [==============================] - 0s 69us/sample - loss: 12.1643 - mae: 1.0065 - mse: 1.6717 - val_loss: 14.9610 - val_mae: 1.4283 - val_mse: 3.5319\n",
      "Epoch 129/1000\n",
      "309/309 [==============================] - 0s 97us/sample - loss: 12.2144 - mae: 1.0124 - mse: 1.7088 - val_loss: 15.1125 - val_mae: 1.5223 - val_mse: 3.9263\n",
      "Epoch 130/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 101us/sample - loss: 12.2255 - mae: 1.0174 - mse: 1.7495 - val_loss: 14.9570 - val_mae: 1.3590 - val_mse: 3.2127\n",
      "Epoch 131/1000\n",
      "309/309 [==============================] - 0s 105us/sample - loss: 12.1521 - mae: 0.9847 - mse: 1.6274 - val_loss: 15.1977 - val_mae: 1.6329 - val_mse: 4.3208\n",
      "Epoch 132/1000\n",
      "309/309 [==============================] - 0s 112us/sample - loss: 12.2096 - mae: 1.0294 - mse: 1.7553 - val_loss: 14.9388 - val_mae: 1.3744 - val_mse: 3.2818\n",
      "Epoch 133/1000\n",
      "309/309 [==============================] - 0s 117us/sample - loss: 12.2074 - mae: 1.0146 - mse: 1.7073 - val_loss: 14.9917 - val_mae: 1.4955 - val_mse: 3.7582\n",
      "Epoch 134/1000\n",
      "309/309 [==============================] - 0s 119us/sample - loss: 12.2361 - mae: 1.0214 - mse: 1.7143 - val_loss: 15.3949 - val_mae: 1.7083 - val_mse: 4.6896\n",
      "Epoch 135/1000\n",
      "309/309 [==============================] - 0s 144us/sample - loss: 12.1967 - mae: 1.0312 - mse: 1.7783 - val_loss: 15.0925 - val_mae: 1.3387 - val_mse: 3.2237\n",
      "Epoch 136/1000\n",
      "309/309 [==============================] - 0s 106us/sample - loss: 12.1963 - mae: 0.9957 - mse: 1.6658 - val_loss: 15.0324 - val_mae: 1.4912 - val_mse: 3.7965\n",
      "Epoch 137/1000\n",
      "309/309 [==============================] - 0s 64us/sample - loss: 12.1239 - mae: 1.0091 - mse: 1.6665 - val_loss: 15.3358 - val_mae: 1.3024 - val_mse: 3.0061\n",
      "Epoch 138/1000\n",
      "309/309 [==============================] - 0s 94us/sample - loss: 12.2398 - mae: 1.0029 - mse: 1.6742 - val_loss: 15.0711 - val_mae: 1.5384 - val_mse: 3.9831\n",
      "Epoch 139/1000\n",
      "309/309 [==============================] - 0s 79us/sample - loss: 12.1787 - mae: 1.0142 - mse: 1.6992 - val_loss: 15.1200 - val_mae: 1.5568 - val_mse: 4.0608\n",
      "Epoch 140/1000\n",
      "309/309 [==============================] - 0s 89us/sample - loss: 12.1223 - mae: 0.9864 - mse: 1.6390 - val_loss: 15.1300 - val_mae: 1.5978 - val_mse: 4.1252\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,442\n",
      "Trainable params: 5,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 412 samples, validate on 137 samples\n",
      "Epoch 1/1000\n",
      "412/412 [==============================] - 1s 1ms/sample - loss: 264.6136 - mae: 14.3350 - mse: 264.5146 - val_loss: 238.6475 - val_mae: 13.6081 - val_mse: 238.4955\n",
      "Epoch 2/1000\n",
      "412/412 [==============================] - 0s 62us/sample - loss: 222.1655 - mae: 12.9893 - mse: 221.8925 - val_loss: 193.6711 - val_mae: 11.9968 - val_mse: 193.2117\n",
      "Epoch 3/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 170.5765 - mae: 11.0036 - mse: 169.7629 - val_loss: 141.0181 - val_mae: 9.7303 - val_mse: 139.7512\n",
      "Epoch 4/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 115.4550 - mae: 8.3751 - mse: 113.3750 - val_loss: 91.0310 - val_mae: 7.1168 - val_mse: 88.1135\n",
      "Epoch 5/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 70.4486 - mae: 5.9651 - mse: 66.1418 - val_loss: 57.6051 - val_mae: 5.0866 - val_mse: 52.2713\n",
      "Epoch 6/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 46.1288 - mae: 4.6743 - mse: 39.2201 - val_loss: 42.9317 - val_mae: 4.5379 - val_mse: 35.3535\n",
      "Epoch 7/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 37.2076 - mae: 4.1879 - mse: 28.3381 - val_loss: 38.5842 - val_mae: 4.3119 - val_mse: 30.1234\n",
      "Epoch 8/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 34.0722 - mae: 3.9186 - mse: 24.6806 - val_loss: 35.0807 - val_mae: 4.0857 - val_mse: 25.7532\n",
      "Epoch 9/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 31.4603 - mae: 3.7154 - mse: 21.6323 - val_loss: 32.0831 - val_mae: 3.8339 - val_mse: 23.3379\n",
      "Epoch 10/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 28.8163 - mae: 3.4784 - mse: 19.1271 - val_loss: 28.7838 - val_mae: 3.5747 - val_mse: 19.3555\n",
      "Epoch 11/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 26.4175 - mae: 3.2748 - mse: 16.5198 - val_loss: 25.9703 - val_mae: 3.3255 - val_mse: 16.5739\n",
      "Epoch 12/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 24.0420 - mae: 3.0565 - mse: 14.1156 - val_loss: 23.4102 - val_mae: 3.0620 - val_mse: 13.7344\n",
      "Epoch 13/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 21.9476 - mae: 2.8249 - mse: 11.8960 - val_loss: 21.1404 - val_mae: 2.8013 - val_mse: 11.4266\n",
      "Epoch 14/1000\n",
      "412/412 [==============================] - 0s 57us/sample - loss: 19.9781 - mae: 2.5838 - mse: 9.7973 - val_loss: 19.6346 - val_mae: 2.5674 - val_mse: 10.3836\n",
      "Epoch 15/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 18.5550 - mae: 2.3825 - mse: 8.4039 - val_loss: 17.9208 - val_mae: 2.3200 - val_mse: 8.1838\n",
      "Epoch 16/1000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 17.5507 - mae: 2.2029 - mse: 7.2680 - val_loss: 17.2592 - val_mae: 2.1737 - val_mse: 7.6372\n",
      "Epoch 17/1000\n",
      "412/412 [==============================] - 0s 89us/sample - loss: 16.7977 - mae: 2.0575 - mse: 6.4786 - val_loss: 16.6411 - val_mae: 2.0366 - val_mse: 6.7085\n",
      "Epoch 18/1000\n",
      "412/412 [==============================] - 0s 107us/sample - loss: 16.4038 - mae: 1.9524 - mse: 6.0093 - val_loss: 16.3616 - val_mae: 1.9986 - val_mse: 6.5654\n",
      "Epoch 19/1000\n",
      "412/412 [==============================] - 0s 88us/sample - loss: 16.0986 - mae: 1.8824 - mse: 5.6786 - val_loss: 16.2454 - val_mae: 1.9890 - val_mse: 6.5424\n",
      "Epoch 20/1000\n",
      "412/412 [==============================] - 0s 90us/sample - loss: 15.9287 - mae: 1.8524 - mse: 5.5106 - val_loss: 16.0727 - val_mae: 1.8571 - val_mse: 5.7700\n",
      "Epoch 21/1000\n",
      "412/412 [==============================] - 0s 102us/sample - loss: 15.7903 - mae: 1.8188 - mse: 5.3308 - val_loss: 15.8435 - val_mae: 1.8416 - val_mse: 5.5560\n",
      "Epoch 22/1000\n",
      "412/412 [==============================] - 0s 83us/sample - loss: 15.6340 - mae: 1.7824 - mse: 5.1075 - val_loss: 16.2095 - val_mae: 2.0478 - val_mse: 6.8664\n",
      "Epoch 23/1000\n",
      "412/412 [==============================] - 0s 82us/sample - loss: 15.4784 - mae: 1.7830 - mse: 5.0825 - val_loss: 15.5807 - val_mae: 1.8393 - val_mse: 5.4570\n",
      "Epoch 24/1000\n",
      "412/412 [==============================] - 0s 83us/sample - loss: 15.3517 - mae: 1.7521 - mse: 4.8968 - val_loss: 15.5652 - val_mae: 1.7755 - val_mse: 5.1146\n",
      "Epoch 25/1000\n",
      "412/412 [==============================] - 0s 91us/sample - loss: 15.1972 - mae: 1.7221 - mse: 4.6982 - val_loss: 15.4299 - val_mae: 1.7861 - val_mse: 5.2187\n",
      "Epoch 26/1000\n",
      "412/412 [==============================] - 0s 102us/sample - loss: 15.0972 - mae: 1.6903 - mse: 4.5856 - val_loss: 15.3781 - val_mae: 1.8460 - val_mse: 5.5389\n",
      "Epoch 27/1000\n",
      "412/412 [==============================] - 0s 86us/sample - loss: 14.9711 - mae: 1.6827 - mse: 4.4924 - val_loss: 15.2142 - val_mae: 1.7624 - val_mse: 5.0748\n",
      "Epoch 28/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 14.7992 - mae: 1.6418 - mse: 4.2658 - val_loss: 15.5742 - val_mae: 1.9403 - val_mse: 6.1572\n",
      "Epoch 29/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 14.7082 - mae: 1.6198 - mse: 4.2201 - val_loss: 15.2159 - val_mae: 1.8683 - val_mse: 5.5754\n",
      "Epoch 30/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 14.6321 - mae: 1.6293 - mse: 4.1759 - val_loss: 14.9361 - val_mae: 1.6836 - val_mse: 4.6296\n",
      "Epoch 31/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 14.4348 - mae: 1.5736 - mse: 3.9041 - val_loss: 14.9431 - val_mae: 1.7130 - val_mse: 4.8801\n",
      "Epoch 32/1000\n",
      "412/412 [==============================] - 0s 70us/sample - loss: 14.3817 - mae: 1.5518 - mse: 3.8165 - val_loss: 15.3984 - val_mae: 1.9128 - val_mse: 6.0372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 14.2556 - mae: 1.5436 - mse: 3.7826 - val_loss: 15.0302 - val_mae: 1.7805 - val_mse: 5.3353\n",
      "Epoch 34/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 14.1156 - mae: 1.4947 - mse: 3.5831 - val_loss: 15.1988 - val_mae: 1.9126 - val_mse: 5.8464\n",
      "Epoch 35/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 14.0146 - mae: 1.4758 - mse: 3.5206 - val_loss: 14.8526 - val_mae: 1.7822 - val_mse: 5.2157\n",
      "Epoch 36/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 13.9250 - mae: 1.4526 - mse: 3.4175 - val_loss: 14.6193 - val_mae: 1.6788 - val_mse: 4.6583\n",
      "Epoch 37/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 13.8188 - mae: 1.4241 - mse: 3.2879 - val_loss: 14.5017 - val_mae: 1.6479 - val_mse: 4.4574\n",
      "Epoch 38/1000\n",
      "412/412 [==============================] - 0s 50us/sample - loss: 13.7492 - mae: 1.4078 - mse: 3.2043 - val_loss: 14.4201 - val_mae: 1.6491 - val_mse: 4.4202\n",
      "Epoch 39/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 13.6578 - mae: 1.3811 - mse: 3.0974 - val_loss: 14.3778 - val_mae: 1.6590 - val_mse: 4.4446\n",
      "Epoch 40/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 13.5100 - mae: 1.3557 - mse: 2.9795 - val_loss: 14.3927 - val_mae: 1.5533 - val_mse: 4.0165\n",
      "Epoch 41/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 13.4665 - mae: 1.3169 - mse: 2.8882 - val_loss: 14.2496 - val_mae: 1.6480 - val_mse: 4.3137\n",
      "Epoch 42/1000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 13.3836 - mae: 1.3107 - mse: 2.8195 - val_loss: 14.2630 - val_mae: 1.6896 - val_mse: 4.4138\n",
      "Epoch 43/1000\n",
      "412/412 [==============================] - 0s 110us/sample - loss: 13.3207 - mae: 1.2935 - mse: 2.7634 - val_loss: 14.1333 - val_mae: 1.6256 - val_mse: 4.0954\n",
      "Epoch 44/1000\n",
      "412/412 [==============================] - 0s 100us/sample - loss: 13.2284 - mae: 1.2653 - mse: 2.6809 - val_loss: 14.0408 - val_mae: 1.5268 - val_mse: 3.6382\n",
      "Epoch 45/1000\n",
      "412/412 [==============================] - 0s 121us/sample - loss: 13.1966 - mae: 1.2467 - mse: 2.5873 - val_loss: 14.0858 - val_mae: 1.6202 - val_mse: 4.0166\n",
      "Epoch 46/1000\n",
      "412/412 [==============================] - 0s 123us/sample - loss: 13.1541 - mae: 1.2477 - mse: 2.5818 - val_loss: 13.9855 - val_mae: 1.5577 - val_mse: 3.8130\n",
      "Epoch 47/1000\n",
      "412/412 [==============================] - 0s 106us/sample - loss: 13.1180 - mae: 1.2270 - mse: 2.5120 - val_loss: 14.1067 - val_mae: 1.6393 - val_mse: 4.2495\n",
      "Epoch 48/1000\n",
      "412/412 [==============================] - 0s 85us/sample - loss: 13.0461 - mae: 1.2206 - mse: 2.4774 - val_loss: 13.9109 - val_mae: 1.5132 - val_mse: 3.5996\n",
      "Epoch 49/1000\n",
      "412/412 [==============================] - 0s 121us/sample - loss: 13.0528 - mae: 1.2048 - mse: 2.4532 - val_loss: 13.9408 - val_mae: 1.5820 - val_mse: 3.9117\n",
      "Epoch 50/1000\n",
      "412/412 [==============================] - 0s 60us/sample - loss: 13.0038 - mae: 1.2040 - mse: 2.4103 - val_loss: 13.8954 - val_mae: 1.5713 - val_mse: 3.8132\n",
      "Epoch 51/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.9584 - mae: 1.1978 - mse: 2.3534 - val_loss: 13.8887 - val_mae: 1.5497 - val_mse: 3.7670\n",
      "Epoch 52/1000\n",
      "412/412 [==============================] - 0s 69us/sample - loss: 12.9359 - mae: 1.1809 - mse: 2.3460 - val_loss: 13.8515 - val_mae: 1.4644 - val_mse: 3.3514\n",
      "Epoch 53/1000\n",
      "412/412 [==============================] - 0s 70us/sample - loss: 12.8751 - mae: 1.1548 - mse: 2.2295 - val_loss: 14.0944 - val_mae: 1.6970 - val_mse: 4.4181\n",
      "Epoch 54/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.9793 - mae: 1.2012 - mse: 2.4188 - val_loss: 13.7982 - val_mae: 1.5041 - val_mse: 3.4800\n",
      "Epoch 55/1000\n",
      "412/412 [==============================] - 0s 69us/sample - loss: 12.8468 - mae: 1.1623 - mse: 2.2256 - val_loss: 13.7633 - val_mae: 1.5156 - val_mse: 3.5646\n",
      "Epoch 56/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.9443 - mae: 1.1990 - mse: 2.3546 - val_loss: 13.7852 - val_mae: 1.4170 - val_mse: 3.1221\n",
      "Epoch 57/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 12.8037 - mae: 1.1435 - mse: 2.1582 - val_loss: 13.7448 - val_mae: 1.5115 - val_mse: 3.4945\n",
      "Epoch 58/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 12.7947 - mae: 1.1474 - mse: 2.1546 - val_loss: 13.9617 - val_mae: 1.6343 - val_mse: 4.1754\n",
      "Epoch 59/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.8688 - mae: 1.1797 - mse: 2.2628 - val_loss: 13.6952 - val_mae: 1.5066 - val_mse: 3.5163\n",
      "Epoch 60/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.7508 - mae: 1.1325 - mse: 2.1238 - val_loss: 13.7216 - val_mae: 1.5376 - val_mse: 3.6648\n",
      "Epoch 61/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.7918 - mae: 1.1491 - mse: 2.1880 - val_loss: 13.6549 - val_mae: 1.4631 - val_mse: 3.3217\n",
      "Epoch 62/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.7833 - mae: 1.1430 - mse: 2.1577 - val_loss: 13.6439 - val_mae: 1.4178 - val_mse: 3.1350\n",
      "Epoch 63/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.7669 - mae: 1.1390 - mse: 2.1208 - val_loss: 13.6341 - val_mae: 1.4571 - val_mse: 3.3287\n",
      "Epoch 64/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 12.7106 - mae: 1.1350 - mse: 2.0951 - val_loss: 13.6172 - val_mae: 1.4012 - val_mse: 3.0853\n",
      "Epoch 65/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.7175 - mae: 1.1178 - mse: 2.0559 - val_loss: 13.7011 - val_mae: 1.5544 - val_mse: 3.7485\n",
      "Epoch 66/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.6921 - mae: 1.1211 - mse: 2.0621 - val_loss: 13.7393 - val_mae: 1.5596 - val_mse: 3.8095\n",
      "Epoch 67/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.6875 - mae: 1.1143 - mse: 2.0571 - val_loss: 13.7498 - val_mae: 1.5805 - val_mse: 3.8944\n",
      "Epoch 68/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.7163 - mae: 1.1492 - mse: 2.1342 - val_loss: 13.6734 - val_mae: 1.3378 - val_mse: 2.8630\n",
      "Epoch 69/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.6591 - mae: 1.1052 - mse: 1.9938 - val_loss: 13.5483 - val_mae: 1.4099 - val_mse: 3.1477\n",
      "Epoch 70/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 12.7144 - mae: 1.1161 - mse: 2.0773 - val_loss: 13.5552 - val_mae: 1.3786 - val_mse: 2.9999\n",
      "Epoch 71/1000\n",
      "412/412 [==============================] - 0s 57us/sample - loss: 12.6434 - mae: 1.0949 - mse: 1.9599 - val_loss: 13.7905 - val_mae: 1.6178 - val_mse: 4.0594\n",
      "Epoch 72/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.6385 - mae: 1.1164 - mse: 2.0592 - val_loss: 13.5243 - val_mae: 1.3587 - val_mse: 2.9238\n",
      "Epoch 73/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.6408 - mae: 1.0918 - mse: 1.9810 - val_loss: 13.5211 - val_mae: 1.4466 - val_mse: 3.3076\n",
      "Epoch 74/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 12.6747 - mae: 1.1044 - mse: 2.0478 - val_loss: 13.4910 - val_mae: 1.4067 - val_mse: 3.1152\n",
      "Epoch 75/1000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 12.6045 - mae: 1.0928 - mse: 1.9754 - val_loss: 13.5263 - val_mae: 1.3221 - val_mse: 2.8162\n",
      "Epoch 76/1000\n",
      "412/412 [==============================] - 0s 110us/sample - loss: 12.6392 - mae: 1.0852 - mse: 1.9513 - val_loss: 13.6351 - val_mae: 1.5574 - val_mse: 3.7880\n",
      "Epoch 77/1000\n",
      "412/412 [==============================] - 0s 92us/sample - loss: 12.5835 - mae: 1.0874 - mse: 1.9534 - val_loss: 13.5026 - val_mae: 1.4774 - val_mse: 3.4239\n",
      "Epoch 78/1000\n",
      "412/412 [==============================] - 0s 96us/sample - loss: 12.6110 - mae: 1.0890 - mse: 1.9780 - val_loss: 13.4952 - val_mae: 1.4308 - val_mse: 3.2129\n",
      "Epoch 79/1000\n",
      "412/412 [==============================] - 0s 83us/sample - loss: 12.5914 - mae: 1.0807 - mse: 1.9485 - val_loss: 13.4602 - val_mae: 1.4508 - val_mse: 3.3013\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 83us/sample - loss: 12.5789 - mae: 1.1012 - mse: 1.9896 - val_loss: 13.8555 - val_mae: 1.2767 - val_mse: 2.6342\n",
      "Epoch 81/1000\n",
      "412/412 [==============================] - 0s 105us/sample - loss: 12.6010 - mae: 1.0580 - mse: 1.8654 - val_loss: 13.5833 - val_mae: 1.5504 - val_mse: 3.7567\n",
      "Epoch 82/1000\n",
      "412/412 [==============================] - 0s 106us/sample - loss: 12.6096 - mae: 1.0951 - mse: 1.9817 - val_loss: 13.4680 - val_mae: 1.4807 - val_mse: 3.4542\n",
      "Epoch 83/1000\n",
      "412/412 [==============================] - 0s 100us/sample - loss: 12.5361 - mae: 1.0678 - mse: 1.8963 - val_loss: 13.4469 - val_mae: 1.4479 - val_mse: 3.3307\n",
      "Epoch 84/1000\n",
      "412/412 [==============================] - 0s 61us/sample - loss: 12.5192 - mae: 1.0603 - mse: 1.8742 - val_loss: 13.4248 - val_mae: 1.4618 - val_mse: 3.3689\n",
      "Epoch 85/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.5949 - mae: 1.0827 - mse: 1.9573 - val_loss: 13.3907 - val_mae: 1.4251 - val_mse: 3.2076\n",
      "Epoch 86/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.5675 - mae: 1.0764 - mse: 1.9312 - val_loss: 13.3372 - val_mae: 1.3810 - val_mse: 3.0447\n",
      "Epoch 87/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 12.5633 - mae: 1.0693 - mse: 1.8843 - val_loss: 13.5268 - val_mae: 1.5366 - val_mse: 3.7016\n",
      "Epoch 88/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.5034 - mae: 1.0692 - mse: 1.8983 - val_loss: 13.3439 - val_mae: 1.3053 - val_mse: 2.7664\n",
      "Epoch 89/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.5035 - mae: 1.0385 - mse: 1.8291 - val_loss: 13.4830 - val_mae: 1.4783 - val_mse: 3.4299\n",
      "Epoch 90/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 12.5024 - mae: 1.0601 - mse: 1.8917 - val_loss: 13.5163 - val_mae: 1.2464 - val_mse: 2.5612\n",
      "Epoch 91/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.5986 - mae: 1.0693 - mse: 1.9317 - val_loss: 13.2961 - val_mae: 1.3252 - val_mse: 2.8498\n",
      "Epoch 92/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 12.4728 - mae: 1.0359 - mse: 1.8075 - val_loss: 13.3131 - val_mae: 1.3946 - val_mse: 3.1149\n",
      "Epoch 93/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.5632 - mae: 1.0610 - mse: 1.9143 - val_loss: 13.3591 - val_mae: 1.4310 - val_mse: 3.2590\n",
      "Epoch 94/1000\n",
      "412/412 [==============================] - 0s 59us/sample - loss: 12.4901 - mae: 1.0537 - mse: 1.8711 - val_loss: 13.3702 - val_mae: 1.2861 - val_mse: 2.7195\n",
      "Epoch 95/1000\n",
      "412/412 [==============================] - 0s 67us/sample - loss: 12.5113 - mae: 1.0450 - mse: 1.8290 - val_loss: 13.3699 - val_mae: 1.4435 - val_mse: 3.3142\n",
      "Epoch 96/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 12.4643 - mae: 1.0470 - mse: 1.8419 - val_loss: 13.3952 - val_mae: 1.2937 - val_mse: 2.7471\n",
      "Epoch 97/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 12.4619 - mae: 1.0397 - mse: 1.8051 - val_loss: 13.3167 - val_mae: 1.2624 - val_mse: 2.6275\n",
      "Epoch 98/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.5649 - mae: 1.0579 - mse: 1.8602 - val_loss: 13.4029 - val_mae: 1.4826 - val_mse: 3.4909\n",
      "Epoch 99/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 12.5003 - mae: 1.0609 - mse: 1.8795 - val_loss: 13.2578 - val_mae: 1.3722 - val_mse: 3.0311\n",
      "Epoch 100/1000\n",
      "412/412 [==============================] - 0s 53us/sample - loss: 12.4623 - mae: 1.0345 - mse: 1.8073 - val_loss: 13.2569 - val_mae: 1.3584 - val_mse: 2.9944\n",
      "Epoch 101/1000\n",
      "412/412 [==============================] - 0s 109us/sample - loss: 12.5025 - mae: 1.0382 - mse: 1.8328 - val_loss: 13.3662 - val_mae: 1.4652 - val_mse: 3.4166\n",
      "Epoch 102/1000\n",
      "412/412 [==============================] - 0s 89us/sample - loss: 12.4567 - mae: 1.0315 - mse: 1.8087 - val_loss: 13.3237 - val_mae: 1.4438 - val_mse: 3.3185\n",
      "Epoch 103/1000\n",
      "412/412 [==============================] - 0s 102us/sample - loss: 12.5238 - mae: 1.0597 - mse: 1.8988 - val_loss: 13.2634 - val_mae: 1.2667 - val_mse: 2.6414\n",
      "Epoch 104/1000\n",
      "412/412 [==============================] - 0s 91us/sample - loss: 12.4571 - mae: 1.0269 - mse: 1.7771 - val_loss: 13.2337 - val_mae: 1.3661 - val_mse: 3.0112\n",
      "Epoch 105/1000\n",
      "412/412 [==============================] - 0s 94us/sample - loss: 12.4459 - mae: 1.0283 - mse: 1.7756 - val_loss: 13.3358 - val_mae: 1.4432 - val_mse: 3.3067\n",
      "Epoch 106/1000\n",
      "412/412 [==============================] - 0s 94us/sample - loss: 12.5001 - mae: 1.0485 - mse: 1.8775 - val_loss: 13.2903 - val_mae: 1.2399 - val_mse: 2.5648\n",
      "Epoch 107/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.4744 - mae: 1.0367 - mse: 1.8013 - val_loss: 13.2613 - val_mae: 1.3113 - val_mse: 2.8075\n",
      "Epoch 108/1000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 12.3946 - mae: 1.0111 - mse: 1.7308 - val_loss: 13.2156 - val_mae: 1.3412 - val_mse: 2.9362\n",
      "Epoch 109/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.4176 - mae: 1.0205 - mse: 1.7818 - val_loss: 13.2673 - val_mae: 1.2707 - val_mse: 2.6626\n",
      "Epoch 110/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.4643 - mae: 1.0380 - mse: 1.7849 - val_loss: 13.2306 - val_mae: 1.3858 - val_mse: 3.0982\n",
      "Epoch 111/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.4258 - mae: 1.0229 - mse: 1.7727 - val_loss: 13.2204 - val_mae: 1.3763 - val_mse: 3.0663\n",
      "Epoch 112/1000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 12.4604 - mae: 1.0385 - mse: 1.8119 - val_loss: 13.2013 - val_mae: 1.3410 - val_mse: 2.9314\n",
      "Epoch 113/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 12.4081 - mae: 1.0263 - mse: 1.7537 - val_loss: 13.2440 - val_mae: 1.3302 - val_mse: 2.8828\n",
      "Epoch 114/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.4467 - mae: 1.0201 - mse: 1.7694 - val_loss: 13.3839 - val_mae: 1.4955 - val_mse: 3.5672\n",
      "Epoch 115/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.4094 - mae: 1.0329 - mse: 1.7985 - val_loss: 13.2042 - val_mae: 1.2407 - val_mse: 2.5741\n",
      "Epoch 116/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 12.4453 - mae: 1.0267 - mse: 1.7786 - val_loss: 13.1803 - val_mae: 1.2523 - val_mse: 2.6197\n",
      "Epoch 117/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.3844 - mae: 1.0093 - mse: 1.7196 - val_loss: 13.1471 - val_mae: 1.3107 - val_mse: 2.8204\n",
      "Epoch 118/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.4039 - mae: 1.0152 - mse: 1.7312 - val_loss: 13.1770 - val_mae: 1.3300 - val_mse: 2.9026\n",
      "Epoch 119/1000\n",
      "412/412 [==============================] - 0s 53us/sample - loss: 12.4505 - mae: 1.0302 - mse: 1.8046 - val_loss: 13.1564 - val_mae: 1.3066 - val_mse: 2.8030\n",
      "Epoch 120/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.3830 - mae: 1.0075 - mse: 1.7165 - val_loss: 13.2256 - val_mae: 1.3625 - val_mse: 3.0323\n",
      "Epoch 121/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 12.4088 - mae: 1.0152 - mse: 1.7415 - val_loss: 13.3905 - val_mae: 1.5001 - val_mse: 3.5882\n",
      "Epoch 122/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 12.4058 - mae: 1.0228 - mse: 1.7708 - val_loss: 13.1877 - val_mae: 1.3520 - val_mse: 2.9758\n",
      "Epoch 123/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.4102 - mae: 1.0318 - mse: 1.7795 - val_loss: 13.2508 - val_mae: 1.2165 - val_mse: 2.4996\n",
      "Epoch 124/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 12.3863 - mae: 1.0157 - mse: 1.7294 - val_loss: 13.2709 - val_mae: 1.2054 - val_mse: 2.4623\n",
      "Epoch 125/1000\n",
      "412/412 [==============================] - 0s 59us/sample - loss: 12.3609 - mae: 0.9918 - mse: 1.6667 - val_loss: 13.1835 - val_mae: 1.3727 - val_mse: 3.0469\n",
      "Epoch 126/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 12.3422 - mae: 1.0070 - mse: 1.7108 - val_loss: 13.2016 - val_mae: 1.2277 - val_mse: 2.5416\n",
      "Epoch 127/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 78us/sample - loss: 12.3612 - mae: 1.0046 - mse: 1.6974 - val_loss: 13.1502 - val_mae: 1.2538 - val_mse: 2.6246\n",
      "Epoch 128/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.3455 - mae: 0.9928 - mse: 1.6731 - val_loss: 13.1486 - val_mae: 1.3210 - val_mse: 2.8747\n",
      "Epoch 129/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 12.3794 - mae: 1.0090 - mse: 1.7187 - val_loss: 13.1989 - val_mae: 1.3888 - val_mse: 3.1190\n",
      "Epoch 130/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 12.3732 - mae: 1.0260 - mse: 1.7386 - val_loss: 13.1370 - val_mae: 1.2543 - val_mse: 2.6237\n",
      "Epoch 131/1000\n",
      "412/412 [==============================] - 0s 53us/sample - loss: 12.3377 - mae: 0.9932 - mse: 1.6873 - val_loss: 13.4498 - val_mae: 1.2381 - val_mse: 2.5714\n",
      "Epoch 132/1000\n",
      "412/412 [==============================] - 0s 105us/sample - loss: 12.3959 - mae: 1.0057 - mse: 1.7158 - val_loss: 13.1125 - val_mae: 1.2974 - val_mse: 2.7685\n",
      "Epoch 133/1000\n",
      "412/412 [==============================] - 0s 100us/sample - loss: 12.3438 - mae: 1.0050 - mse: 1.6950 - val_loss: 13.2224 - val_mae: 1.2288 - val_mse: 2.5405\n",
      "Epoch 134/1000\n",
      "412/412 [==============================] - 0s 112us/sample - loss: 12.3353 - mae: 0.9956 - mse: 1.6607 - val_loss: 13.2112 - val_mae: 1.3003 - val_mse: 2.7868\n",
      "Epoch 135/1000\n",
      "412/412 [==============================] - 0s 119us/sample - loss: 12.3488 - mae: 1.0080 - mse: 1.7050 - val_loss: 13.2084 - val_mae: 1.1921 - val_mse: 2.4253\n",
      "Epoch 136/1000\n",
      "412/412 [==============================] - 0s 102us/sample - loss: 12.3790 - mae: 1.0045 - mse: 1.7035 - val_loss: 13.2168 - val_mae: 1.2279 - val_mse: 2.5406\n",
      "Epoch 137/1000\n",
      "412/412 [==============================] - 0s 90us/sample - loss: 12.3458 - mae: 0.9974 - mse: 1.6930 - val_loss: 13.2900 - val_mae: 1.1786 - val_mse: 2.3760\n",
      "Epoch 138/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.3555 - mae: 0.9912 - mse: 1.6638 - val_loss: 13.1358 - val_mae: 1.2948 - val_mse: 2.7639\n",
      "Epoch 139/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.3258 - mae: 0.9925 - mse: 1.6589 - val_loss: 13.1397 - val_mae: 1.3603 - val_mse: 3.0021\n",
      "Epoch 140/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.3308 - mae: 1.0087 - mse: 1.6837 - val_loss: 13.0779 - val_mae: 1.2812 - val_mse: 2.7002\n",
      "Epoch 141/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.3727 - mae: 1.0045 - mse: 1.6982 - val_loss: 13.1412 - val_mae: 1.3688 - val_mse: 3.0134\n",
      "Epoch 142/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 12.3235 - mae: 1.0010 - mse: 1.6811 - val_loss: 13.1124 - val_mae: 1.2200 - val_mse: 2.5133\n",
      "Epoch 143/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.3166 - mae: 0.9845 - mse: 1.6469 - val_loss: 13.2774 - val_mae: 1.3100 - val_mse: 2.8118\n",
      "Epoch 144/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.3339 - mae: 1.0007 - mse: 1.6652 - val_loss: 13.1627 - val_mae: 1.3816 - val_mse: 3.0555\n",
      "Epoch 145/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.3431 - mae: 0.9968 - mse: 1.6864 - val_loss: 13.1576 - val_mae: 1.3728 - val_mse: 3.0655\n",
      "Epoch 146/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.3518 - mae: 1.0006 - mse: 1.7000 - val_loss: 13.1198 - val_mae: 1.3319 - val_mse: 2.9015\n",
      "Epoch 147/1000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 12.3224 - mae: 0.9888 - mse: 1.6877 - val_loss: 13.1337 - val_mae: 1.2127 - val_mse: 2.4950\n",
      "Epoch 148/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.2994 - mae: 0.9800 - mse: 1.6375 - val_loss: 13.0973 - val_mae: 1.2299 - val_mse: 2.5478\n",
      "Epoch 149/1000\n",
      "412/412 [==============================] - 0s 79us/sample - loss: 12.3625 - mae: 1.0124 - mse: 1.7070 - val_loss: 13.1586 - val_mae: 1.2079 - val_mse: 2.4781\n",
      "Epoch 150/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.3059 - mae: 0.9714 - mse: 1.6162 - val_loss: 13.1278 - val_mae: 1.3530 - val_mse: 2.9712\n",
      "Epoch 151/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 12.3293 - mae: 0.9921 - mse: 1.6754 - val_loss: 13.1334 - val_mae: 1.3679 - val_mse: 3.0323\n",
      "Epoch 152/1000\n",
      "412/412 [==============================] - 0s 79us/sample - loss: 12.3196 - mae: 0.9918 - mse: 1.6557 - val_loss: 13.2809 - val_mae: 1.4250 - val_mse: 3.3144\n",
      "Epoch 153/1000\n",
      "412/412 [==============================] - 0s 80us/sample - loss: 12.2725 - mae: 0.9926 - mse: 1.6396 - val_loss: 13.0629 - val_mae: 1.2555 - val_mse: 2.6167\n",
      "Epoch 154/1000\n",
      "412/412 [==============================] - 0s 83us/sample - loss: 12.3277 - mae: 1.0044 - mse: 1.7121 - val_loss: 13.6149 - val_mae: 1.1602 - val_mse: 2.3086\n",
      "Epoch 155/1000\n",
      "412/412 [==============================] - 0s 86us/sample - loss: 12.3753 - mae: 0.9857 - mse: 1.6444 - val_loss: 13.1167 - val_mae: 1.2874 - val_mse: 2.7414\n",
      "Epoch 156/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 12.2562 - mae: 0.9775 - mse: 1.5951 - val_loss: 13.1289 - val_mae: 1.2673 - val_mse: 2.6741\n",
      "Epoch 157/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.3372 - mae: 1.0044 - mse: 1.6666 - val_loss: 13.3204 - val_mae: 1.3626 - val_mse: 3.0254\n",
      "Epoch 158/1000\n",
      "412/412 [==============================] - 0s 80us/sample - loss: 12.2932 - mae: 0.9882 - mse: 1.6448 - val_loss: 13.0788 - val_mae: 1.2697 - val_mse: 2.6550\n",
      "Epoch 159/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.3030 - mae: 0.9879 - mse: 1.6354 - val_loss: 13.0686 - val_mae: 1.3110 - val_mse: 2.8120\n",
      "Epoch 160/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 12.2709 - mae: 0.9874 - mse: 1.6393 - val_loss: 13.2713 - val_mae: 1.1580 - val_mse: 2.3289\n",
      "Epoch 161/1000\n",
      "412/412 [==============================] - 0s 79us/sample - loss: 12.3397 - mae: 0.9916 - mse: 1.6512 - val_loss: 13.1770 - val_mae: 1.3518 - val_mse: 2.9947\n",
      "Epoch 162/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.2973 - mae: 0.9832 - mse: 1.6606 - val_loss: 13.0928 - val_mae: 1.1914 - val_mse: 2.4225\n",
      "Epoch 163/1000\n",
      "412/412 [==============================] - 0s 80us/sample - loss: 12.3313 - mae: 0.9952 - mse: 1.6640 - val_loss: 13.0926 - val_mae: 1.1902 - val_mse: 2.4233\n",
      "Epoch 164/1000\n",
      "412/412 [==============================] - 0s 81us/sample - loss: 12.2988 - mae: 0.9743 - mse: 1.6181 - val_loss: 13.1243 - val_mae: 1.2790 - val_mse: 2.7039\n",
      "Epoch 165/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.2829 - mae: 0.9955 - mse: 1.6267 - val_loss: 13.0431 - val_mae: 1.2293 - val_mse: 2.5338\n",
      "Epoch 166/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 12.2910 - mae: 0.9787 - mse: 1.6398 - val_loss: 13.1920 - val_mae: 1.1639 - val_mse: 2.3475\n",
      "Epoch 167/1000\n",
      "412/412 [==============================] - 0s 54us/sample - loss: 12.2741 - mae: 0.9708 - mse: 1.5872 - val_loss: 13.0482 - val_mae: 1.2846 - val_mse: 2.6973\n",
      "Epoch 168/1000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 12.3587 - mae: 1.0232 - mse: 1.7068 - val_loss: 13.1139 - val_mae: 1.1930 - val_mse: 2.4375\n",
      "Epoch 169/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 12.2775 - mae: 0.9763 - mse: 1.5911 - val_loss: 13.0533 - val_mae: 1.3233 - val_mse: 2.8402\n",
      "Epoch 170/1000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 12.2889 - mae: 0.9748 - mse: 1.6275 - val_loss: 13.0760 - val_mae: 1.3498 - val_mse: 2.9528\n",
      "Epoch 171/1000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 12.2741 - mae: 0.9806 - mse: 1.6168 - val_loss: 13.0554 - val_mae: 1.3330 - val_mse: 2.8716\n",
      "Epoch 172/1000\n",
      "412/412 [==============================] - 0s 66us/sample - loss: 12.2655 - mae: 0.9864 - mse: 1.6118 - val_loss: 13.1054 - val_mae: 1.2835 - val_mse: 2.7328\n",
      "Epoch 173/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 12.2557 - mae: 0.9764 - mse: 1.6038 - val_loss: 13.1077 - val_mae: 1.1669 - val_mse: 2.3530\n",
      "Epoch 174/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 59us/sample - loss: 12.2829 - mae: 0.9729 - mse: 1.6072 - val_loss: 13.0517 - val_mae: 1.2182 - val_mse: 2.5051\n",
      "Epoch 175/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.2366 - mae: 0.9699 - mse: 1.5711 - val_loss: 13.0127 - val_mae: 1.2362 - val_mse: 2.5559\n",
      "Epoch 176/1000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 12.2983 - mae: 0.9937 - mse: 1.6487 - val_loss: 13.1194 - val_mae: 1.1568 - val_mse: 2.3159\n",
      "Epoch 177/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.2467 - mae: 0.9586 - mse: 1.5569 - val_loss: 13.1449 - val_mae: 1.2862 - val_mse: 2.7270\n",
      "Epoch 178/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.2741 - mae: 0.9842 - mse: 1.6257 - val_loss: 13.0598 - val_mae: 1.1937 - val_mse: 2.4245\n",
      "Epoch 179/1000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 12.2735 - mae: 0.9792 - mse: 1.5856 - val_loss: 13.0548 - val_mae: 1.3520 - val_mse: 2.9349\n",
      "Epoch 180/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.2414 - mae: 0.9695 - mse: 1.5734 - val_loss: 13.2334 - val_mae: 1.4738 - val_mse: 3.4241\n",
      "Epoch 181/1000\n",
      "412/412 [==============================] - 0s 81us/sample - loss: 12.2188 - mae: 0.9727 - mse: 1.6004 - val_loss: 13.0910 - val_mae: 1.1731 - val_mse: 2.3527\n",
      "Epoch 182/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 12.2673 - mae: 0.9755 - mse: 1.5803 - val_loss: 13.0307 - val_mae: 1.3170 - val_mse: 2.8369\n",
      "Epoch 183/1000\n",
      "412/412 [==============================] - 0s 80us/sample - loss: 12.2474 - mae: 0.9825 - mse: 1.6224 - val_loss: 13.4215 - val_mae: 1.1587 - val_mse: 2.3400\n",
      "Epoch 184/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.2819 - mae: 0.9726 - mse: 1.5771 - val_loss: 13.0413 - val_mae: 1.2718 - val_mse: 2.6862\n",
      "Epoch 185/1000\n",
      "412/412 [==============================] - 0s 79us/sample - loss: 12.2523 - mae: 0.9768 - mse: 1.6133 - val_loss: 13.0250 - val_mae: 1.2141 - val_mse: 2.4781\n",
      "Epoch 186/1000\n",
      "412/412 [==============================] - 0s 58us/sample - loss: 12.2716 - mae: 0.9812 - mse: 1.6146 - val_loss: 13.1158 - val_mae: 1.1927 - val_mse: 2.4286\n",
      "Epoch 187/1000\n",
      "412/412 [==============================] - 0s 61us/sample - loss: 12.2562 - mae: 0.9641 - mse: 1.5998 - val_loss: 13.2526 - val_mae: 1.1561 - val_mse: 2.3183\n",
      "Epoch 188/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.2570 - mae: 0.9656 - mse: 1.5593 - val_loss: 13.0500 - val_mae: 1.3292 - val_mse: 2.8889\n",
      "Epoch 189/1000\n",
      "412/412 [==============================] - 0s 54us/sample - loss: 12.2351 - mae: 0.9732 - mse: 1.5902 - val_loss: 12.9967 - val_mae: 1.2299 - val_mse: 2.5392\n",
      "Epoch 190/1000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 12.2615 - mae: 0.9717 - mse: 1.5822 - val_loss: 13.0802 - val_mae: 1.3414 - val_mse: 2.9519\n",
      "Epoch 191/1000\n",
      "412/412 [==============================] - 0s 70us/sample - loss: 12.2253 - mae: 0.9599 - mse: 1.5653 - val_loss: 13.0800 - val_mae: 1.3793 - val_mse: 3.0298\n",
      "Epoch 192/1000\n",
      "412/412 [==============================] - 0s 57us/sample - loss: 12.2512 - mae: 0.9685 - mse: 1.5829 - val_loss: 13.1115 - val_mae: 1.4137 - val_mse: 3.1385\n",
      "Epoch 193/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.2318 - mae: 0.9728 - mse: 1.5799 - val_loss: 13.0080 - val_mae: 1.2914 - val_mse: 2.7413\n",
      "Epoch 194/1000\n",
      "412/412 [==============================] - 0s 54us/sample - loss: 12.2474 - mae: 0.9718 - mse: 1.5803 - val_loss: 13.0054 - val_mae: 1.2842 - val_mse: 2.7207\n",
      "Epoch 195/1000\n",
      "412/412 [==============================] - 0s 65us/sample - loss: 12.2505 - mae: 0.9786 - mse: 1.6019 - val_loss: 13.0266 - val_mae: 1.2313 - val_mse: 2.5244\n",
      "Epoch 196/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.2586 - mae: 0.9632 - mse: 1.5806 - val_loss: 13.0203 - val_mae: 1.2967 - val_mse: 2.7711\n",
      "Epoch 197/1000\n",
      "412/412 [==============================] - 0s 57us/sample - loss: 12.2408 - mae: 0.9733 - mse: 1.5935 - val_loss: 12.9932 - val_mae: 1.2031 - val_mse: 2.4440\n",
      "Epoch 198/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.2445 - mae: 0.9696 - mse: 1.5775 - val_loss: 13.0979 - val_mae: 1.1996 - val_mse: 2.4468\n",
      "Epoch 199/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.2312 - mae: 0.9613 - mse: 1.5703 - val_loss: 13.0646 - val_mae: 1.2016 - val_mse: 2.4466\n",
      "Epoch 200/1000\n",
      "412/412 [==============================] - 0s 59us/sample - loss: 12.2185 - mae: 0.9578 - mse: 1.5347 - val_loss: 12.9835 - val_mae: 1.2454 - val_mse: 2.5872\n",
      "Epoch 201/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.2163 - mae: 0.9597 - mse: 1.5747 - val_loss: 13.3190 - val_mae: 1.1558 - val_mse: 2.3455\n",
      "Epoch 202/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.2479 - mae: 0.9667 - mse: 1.5494 - val_loss: 12.9781 - val_mae: 1.2492 - val_mse: 2.5920\n",
      "Epoch 203/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.2320 - mae: 0.9622 - mse: 1.5724 - val_loss: 13.0362 - val_mae: 1.2031 - val_mse: 2.4580\n",
      "Epoch 204/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.1765 - mae: 0.9435 - mse: 1.5186 - val_loss: 13.1883 - val_mae: 1.1694 - val_mse: 2.3488\n",
      "Epoch 205/1000\n",
      "412/412 [==============================] - 0s 59us/sample - loss: 12.2007 - mae: 0.9468 - mse: 1.5104 - val_loss: 12.9799 - val_mae: 1.2845 - val_mse: 2.7080\n",
      "Epoch 206/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.2391 - mae: 0.9667 - mse: 1.5711 - val_loss: 13.0218 - val_mae: 1.2055 - val_mse: 2.4653\n",
      "Epoch 207/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.2169 - mae: 0.9555 - mse: 1.5500 - val_loss: 13.1220 - val_mae: 1.2060 - val_mse: 2.4617\n",
      "Epoch 208/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 12.1698 - mae: 0.9414 - mse: 1.4948 - val_loss: 12.9771 - val_mae: 1.2364 - val_mse: 2.5442\n",
      "Epoch 209/1000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 12.2254 - mae: 0.9684 - mse: 1.5570 - val_loss: 13.0051 - val_mae: 1.1738 - val_mse: 2.3690\n",
      "Epoch 210/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.1961 - mae: 0.9519 - mse: 1.5230 - val_loss: 12.9913 - val_mae: 1.1874 - val_mse: 2.4141\n",
      "Epoch 211/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.1976 - mae: 0.9437 - mse: 1.5126 - val_loss: 13.0007 - val_mae: 1.3212 - val_mse: 2.8154\n",
      "Epoch 212/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.1836 - mae: 0.9626 - mse: 1.5344 - val_loss: 13.0134 - val_mae: 1.1788 - val_mse: 2.3770\n",
      "Epoch 213/1000\n",
      "412/412 [==============================] - 0s 60us/sample - loss: 12.2089 - mae: 0.9589 - mse: 1.5515 - val_loss: 13.0763 - val_mae: 1.1546 - val_mse: 2.3059\n",
      "Epoch 214/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.1653 - mae: 0.9517 - mse: 1.5043 - val_loss: 13.1371 - val_mae: 1.1292 - val_mse: 2.2197\n",
      "Epoch 215/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.2118 - mae: 0.9504 - mse: 1.5245 - val_loss: 12.9889 - val_mae: 1.2390 - val_mse: 2.5683\n",
      "Epoch 216/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.1757 - mae: 0.9534 - mse: 1.5176 - val_loss: 12.9951 - val_mae: 1.1671 - val_mse: 2.3498\n",
      "Epoch 217/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.2072 - mae: 0.9434 - mse: 1.5175 - val_loss: 13.0649 - val_mae: 1.3784 - val_mse: 3.0702\n",
      "Epoch 218/1000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 12.1515 - mae: 0.9561 - mse: 1.5271 - val_loss: 13.2714 - val_mae: 1.1212 - val_mse: 2.2025\n",
      "Epoch 219/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 12.2234 - mae: 0.9569 - mse: 1.5516 - val_loss: 13.1684 - val_mae: 1.1327 - val_mse: 2.2350\n",
      "Epoch 220/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.1701 - mae: 0.9352 - mse: 1.4631 - val_loss: 13.0840 - val_mae: 1.3044 - val_mse: 2.8040\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 78us/sample - loss: 12.2131 - mae: 0.9578 - mse: 1.5476 - val_loss: 13.0761 - val_mae: 1.3109 - val_mse: 2.8377\n",
      "Epoch 222/1000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 12.2003 - mae: 0.9689 - mse: 1.5654 - val_loss: 13.1918 - val_mae: 1.1592 - val_mse: 2.3404\n",
      "Epoch 223/1000\n",
      "412/412 [==============================] - 0s 70us/sample - loss: 12.1588 - mae: 0.9285 - mse: 1.4785 - val_loss: 13.1357 - val_mae: 1.2077 - val_mse: 2.4907\n",
      "Epoch 224/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 12.2162 - mae: 0.9642 - mse: 1.5549 - val_loss: 13.0548 - val_mae: 1.1637 - val_mse: 2.3331\n",
      "Epoch 225/1000\n",
      "412/412 [==============================] - 0s 70us/sample - loss: 12.1547 - mae: 0.9439 - mse: 1.4740 - val_loss: 13.0006 - val_mae: 1.2128 - val_mse: 2.4951\n",
      "Epoch 226/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.1838 - mae: 0.9469 - mse: 1.5090 - val_loss: 13.0237 - val_mae: 1.3103 - val_mse: 2.8408\n",
      "Epoch 227/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.1999 - mae: 0.9726 - mse: 1.5647 - val_loss: 13.1452 - val_mae: 1.1289 - val_mse: 2.2483\n",
      "Epoch 228/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.1365 - mae: 0.9339 - mse: 1.4704 - val_loss: 13.2183 - val_mae: 1.1091 - val_mse: 2.1729\n",
      "Epoch 229/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.2190 - mae: 0.9490 - mse: 1.5143 - val_loss: 12.9544 - val_mae: 1.2717 - val_mse: 2.6756\n",
      "Epoch 230/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 12.1578 - mae: 0.9566 - mse: 1.5111 - val_loss: 13.0690 - val_mae: 1.1541 - val_mse: 2.3185\n",
      "Epoch 231/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.2077 - mae: 0.9606 - mse: 1.5414 - val_loss: 13.0430 - val_mae: 1.1463 - val_mse: 2.2994\n",
      "Epoch 232/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.1508 - mae: 0.9514 - mse: 1.4982 - val_loss: 13.4399 - val_mae: 1.1146 - val_mse: 2.1983\n",
      "Epoch 233/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.2034 - mae: 0.9379 - mse: 1.4890 - val_loss: 12.9597 - val_mae: 1.2637 - val_mse: 2.6258\n",
      "Epoch 234/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 12.1505 - mae: 0.9566 - mse: 1.5036 - val_loss: 13.0396 - val_mae: 1.1594 - val_mse: 2.3304\n",
      "Epoch 235/1000\n",
      "412/412 [==============================] - 0s 79us/sample - loss: 12.1617 - mae: 0.9499 - mse: 1.5038 - val_loss: 13.3342 - val_mae: 1.1163 - val_mse: 2.2088\n",
      "Epoch 236/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.1613 - mae: 0.9317 - mse: 1.4639 - val_loss: 12.9554 - val_mae: 1.2640 - val_mse: 2.6396\n",
      "Epoch 237/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 12.1343 - mae: 0.9354 - mse: 1.4722 - val_loss: 12.9871 - val_mae: 1.1791 - val_mse: 2.4038\n",
      "Epoch 238/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.1673 - mae: 0.9457 - mse: 1.5017 - val_loss: 13.0198 - val_mae: 1.1558 - val_mse: 2.3230\n",
      "Epoch 239/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.1875 - mae: 0.9438 - mse: 1.5078 - val_loss: 13.0025 - val_mae: 1.2031 - val_mse: 2.4745\n",
      "Epoch 240/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.1143 - mae: 0.9205 - mse: 1.4358 - val_loss: 12.9802 - val_mae: 1.2888 - val_mse: 2.7454\n",
      "Epoch 241/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.1707 - mae: 0.9451 - mse: 1.5300 - val_loss: 13.0399 - val_mae: 1.1311 - val_mse: 2.2545\n",
      "Epoch 242/1000\n",
      "412/412 [==============================] - 0s 79us/sample - loss: 12.1895 - mae: 0.9370 - mse: 1.4639 - val_loss: 13.1047 - val_mae: 1.4307 - val_mse: 3.1901\n",
      "Epoch 243/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.1063 - mae: 0.9414 - mse: 1.4996 - val_loss: 13.1656 - val_mae: 1.1030 - val_mse: 2.1682\n",
      "Epoch 244/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.1935 - mae: 0.9440 - mse: 1.5125 - val_loss: 12.9714 - val_mae: 1.1473 - val_mse: 2.2929\n",
      "Epoch 245/1000\n",
      "412/412 [==============================] - 0s 57us/sample - loss: 12.1525 - mae: 0.9321 - mse: 1.4629 - val_loss: 12.9864 - val_mae: 1.2841 - val_mse: 2.7438\n",
      "Epoch 246/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.0972 - mae: 0.9209 - mse: 1.4421 - val_loss: 13.1689 - val_mae: 1.2336 - val_mse: 2.5835\n",
      "Epoch 247/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.1526 - mae: 0.9565 - mse: 1.5148 - val_loss: 13.3173 - val_mae: 1.0991 - val_mse: 2.1527\n",
      "Epoch 248/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.1522 - mae: 0.9241 - mse: 1.4356 - val_loss: 12.9544 - val_mae: 1.2936 - val_mse: 2.7528\n",
      "Epoch 249/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.1119 - mae: 0.9356 - mse: 1.4792 - val_loss: 13.1026 - val_mae: 1.1333 - val_mse: 2.2547\n",
      "Epoch 250/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 12.1367 - mae: 0.9252 - mse: 1.4395 - val_loss: 12.9551 - val_mae: 1.2468 - val_mse: 2.6126\n",
      "Epoch 251/1000\n",
      "412/412 [==============================] - 0s 82us/sample - loss: 12.0917 - mae: 0.9372 - mse: 1.4475 - val_loss: 13.1140 - val_mae: 1.1057 - val_mse: 2.1739\n",
      "Epoch 252/1000\n",
      "412/412 [==============================] - 0s 54us/sample - loss: 12.1696 - mae: 0.9317 - mse: 1.4814 - val_loss: 12.9369 - val_mae: 1.2038 - val_mse: 2.4561\n",
      "Epoch 253/1000\n",
      "412/412 [==============================] - 0s 107us/sample - loss: 12.1296 - mae: 0.9231 - mse: 1.4537 - val_loss: 12.9380 - val_mae: 1.2314 - val_mse: 2.5399\n",
      "Epoch 254/1000\n",
      "412/412 [==============================] - 0s 95us/sample - loss: 12.0873 - mae: 0.9203 - mse: 1.4225 - val_loss: 12.9355 - val_mae: 1.2047 - val_mse: 2.4536\n",
      "Epoch 255/1000\n",
      "412/412 [==============================] - 0s 98us/sample - loss: 12.1458 - mae: 0.9370 - mse: 1.4655 - val_loss: 12.9753 - val_mae: 1.2572 - val_mse: 2.6599\n",
      "Epoch 256/1000\n",
      "412/412 [==============================] - 0s 93us/sample - loss: 12.1062 - mae: 0.9295 - mse: 1.4513 - val_loss: 12.9985 - val_mae: 1.1715 - val_mse: 2.3770\n",
      "Epoch 257/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.1052 - mae: 0.9231 - mse: 1.4410 - val_loss: 13.0841 - val_mae: 1.1681 - val_mse: 2.3800\n",
      "Epoch 258/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.1729 - mae: 0.9337 - mse: 1.4816 - val_loss: 12.9490 - val_mae: 1.2799 - val_mse: 2.7133\n",
      "Epoch 259/1000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 12.0965 - mae: 0.9232 - mse: 1.4333 - val_loss: 12.9342 - val_mae: 1.2089 - val_mse: 2.5025\n",
      "Epoch 260/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.0989 - mae: 0.9213 - mse: 1.4111 - val_loss: 13.0804 - val_mae: 1.3502 - val_mse: 3.0211\n",
      "Epoch 261/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.1545 - mae: 0.9511 - mse: 1.4924 - val_loss: 12.9985 - val_mae: 1.3132 - val_mse: 2.8546\n",
      "Epoch 262/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.0977 - mae: 0.9305 - mse: 1.4439 - val_loss: 12.9292 - val_mae: 1.2571 - val_mse: 2.6222\n",
      "Epoch 263/1000\n",
      "412/412 [==============================] - 0s 93us/sample - loss: 12.1316 - mae: 0.9310 - mse: 1.4767 - val_loss: 12.9901 - val_mae: 1.1673 - val_mse: 2.3634\n",
      "Epoch 264/1000\n",
      "412/412 [==============================] - 0s 108us/sample - loss: 12.0848 - mae: 0.9127 - mse: 1.4093 - val_loss: 12.9537 - val_mae: 1.1546 - val_mse: 2.3245\n",
      "Epoch 265/1000\n",
      "412/412 [==============================] - 0s 88us/sample - loss: 12.0779 - mae: 0.9170 - mse: 1.4191 - val_loss: 13.1338 - val_mae: 1.0952 - val_mse: 2.1670\n",
      "Epoch 266/1000\n",
      "412/412 [==============================] - 0s 99us/sample - loss: 12.1034 - mae: 0.9205 - mse: 1.4158 - val_loss: 12.9647 - val_mae: 1.1499 - val_mse: 2.3175\n",
      "Epoch 267/1000\n",
      "412/412 [==============================] - 0s 95us/sample - loss: 12.0888 - mae: 0.9246 - mse: 1.4212 - val_loss: 13.2614 - val_mae: 1.1377 - val_mse: 2.3202\n",
      "Epoch 268/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 90us/sample - loss: 12.1031 - mae: 0.9177 - mse: 1.4276 - val_loss: 13.3254 - val_mae: 1.2126 - val_mse: 2.5456\n",
      "Epoch 269/1000\n",
      "412/412 [==============================] - 0s 66us/sample - loss: 12.1591 - mae: 0.9317 - mse: 1.4683 - val_loss: 12.9369 - val_mae: 1.2760 - val_mse: 2.6933\n",
      "Epoch 270/1000\n",
      "412/412 [==============================] - 0s 92us/sample - loss: 12.1116 - mae: 0.9413 - mse: 1.4768 - val_loss: 13.1902 - val_mae: 1.1023 - val_mse: 2.1857\n",
      "Epoch 271/1000\n",
      "412/412 [==============================] - 0s 109us/sample - loss: 12.1211 - mae: 0.9114 - mse: 1.4060 - val_loss: 12.9269 - val_mae: 1.2358 - val_mse: 2.5804\n",
      "Epoch 272/1000\n",
      "412/412 [==============================] - 0s 90us/sample - loss: 12.0888 - mae: 0.9208 - mse: 1.4192 - val_loss: 12.9136 - val_mae: 1.2535 - val_mse: 2.6173\n",
      "Epoch 273/1000\n",
      "412/412 [==============================] - 0s 108us/sample - loss: 12.0860 - mae: 0.9065 - mse: 1.3877 - val_loss: 13.2453 - val_mae: 1.5200 - val_mse: 3.5339\n",
      "Epoch 274/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.1193 - mae: 0.9395 - mse: 1.4780 - val_loss: 13.1311 - val_mae: 1.3244 - val_mse: 2.9686\n",
      "Epoch 275/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 12.1106 - mae: 0.9373 - mse: 1.4888 - val_loss: 13.2235 - val_mae: 1.0822 - val_mse: 2.1182\n",
      "Epoch 276/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 12.1226 - mae: 0.9049 - mse: 1.4078 - val_loss: 13.0732 - val_mae: 1.2493 - val_mse: 2.6480\n",
      "Epoch 277/1000\n",
      "412/412 [==============================] - 0s 96us/sample - loss: 12.0828 - mae: 0.9152 - mse: 1.4111 - val_loss: 12.9110 - val_mae: 1.2482 - val_mse: 2.5864\n",
      "Epoch 278/1000\n",
      "412/412 [==============================] - 0s 101us/sample - loss: 12.0857 - mae: 0.9159 - mse: 1.4104 - val_loss: 12.9385 - val_mae: 1.2497 - val_mse: 2.6346\n",
      "Epoch 279/1000\n",
      "412/412 [==============================] - 0s 99us/sample - loss: 12.1573 - mae: 0.9383 - mse: 1.4906 - val_loss: 13.0149 - val_mae: 1.2238 - val_mse: 2.5744\n",
      "Epoch 280/1000\n",
      "412/412 [==============================] - 0s 100us/sample - loss: 12.0981 - mae: 0.9244 - mse: 1.4610 - val_loss: 13.1159 - val_mae: 1.0834 - val_mse: 2.1378\n",
      "Epoch 281/1000\n",
      "412/412 [==============================] - 0s 67us/sample - loss: 12.0906 - mae: 0.9033 - mse: 1.3843 - val_loss: 12.9148 - val_mae: 1.2052 - val_mse: 2.4872\n",
      "Epoch 282/1000\n",
      "412/412 [==============================] - 0s 66us/sample - loss: 12.0986 - mae: 0.9189 - mse: 1.4243 - val_loss: 12.9279 - val_mae: 1.1551 - val_mse: 2.3242\n",
      "Epoch 283/1000\n",
      "412/412 [==============================] - 0s 97us/sample - loss: 12.0808 - mae: 0.8933 - mse: 1.3891 - val_loss: 12.9457 - val_mae: 1.2830 - val_mse: 2.7410\n",
      "Epoch 284/1000\n",
      "412/412 [==============================] - 0s 100us/sample - loss: 12.1269 - mae: 0.9281 - mse: 1.4773 - val_loss: 12.9933 - val_mae: 1.1451 - val_mse: 2.3040\n",
      "Epoch 285/1000\n",
      "412/412 [==============================] - 0s 94us/sample - loss: 12.0726 - mae: 0.9033 - mse: 1.3785 - val_loss: 12.8944 - val_mae: 1.2473 - val_mse: 2.5817\n",
      "Epoch 286/1000\n",
      "412/412 [==============================] - 0s 102us/sample - loss: 12.0433 - mae: 0.9053 - mse: 1.3876 - val_loss: 13.0037 - val_mae: 1.1305 - val_mse: 2.2630\n",
      "Epoch 287/1000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 12.1045 - mae: 0.9183 - mse: 1.4054 - val_loss: 12.9499 - val_mae: 1.2607 - val_mse: 2.6880\n",
      "Epoch 288/1000\n",
      "412/412 [==============================] - 0s 69us/sample - loss: 12.0711 - mae: 0.9126 - mse: 1.3991 - val_loss: 12.9071 - val_mae: 1.2332 - val_mse: 2.5785\n",
      "Epoch 289/1000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 12.0276 - mae: 0.8978 - mse: 1.3560 - val_loss: 12.9482 - val_mae: 1.2349 - val_mse: 2.6127\n",
      "Epoch 290/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.1145 - mae: 0.9293 - mse: 1.4491 - val_loss: 12.9166 - val_mae: 1.1626 - val_mse: 2.3574\n",
      "Epoch 291/1000\n",
      "412/412 [==============================] - 0s 51us/sample - loss: 12.0677 - mae: 0.9049 - mse: 1.4026 - val_loss: 12.9812 - val_mae: 1.1185 - val_mse: 2.2437\n",
      "Epoch 292/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.1103 - mae: 0.9211 - mse: 1.4443 - val_loss: 13.0161 - val_mae: 1.1006 - val_mse: 2.1930\n",
      "Epoch 293/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.0356 - mae: 0.8930 - mse: 1.3453 - val_loss: 12.9254 - val_mae: 1.1441 - val_mse: 2.2946\n",
      "Epoch 294/1000\n",
      "412/412 [==============================] - 0s 96us/sample - loss: 12.0792 - mae: 0.9147 - mse: 1.3957 - val_loss: 12.8888 - val_mae: 1.1994 - val_mse: 2.4584\n",
      "Epoch 295/1000\n",
      "412/412 [==============================] - 0s 112us/sample - loss: 12.0502 - mae: 0.9170 - mse: 1.4009 - val_loss: 13.1149 - val_mae: 1.0861 - val_mse: 2.1605\n",
      "Epoch 296/1000\n",
      "412/412 [==============================] - 0s 106us/sample - loss: 12.0368 - mae: 0.8921 - mse: 1.3511 - val_loss: 13.2988 - val_mae: 1.1330 - val_mse: 2.3265\n",
      "Epoch 297/1000\n",
      "412/412 [==============================] - 0s 98us/sample - loss: 12.0846 - mae: 0.8873 - mse: 1.3782 - val_loss: 13.0257 - val_mae: 1.2776 - val_mse: 2.7781\n",
      "Epoch 298/1000\n",
      "412/412 [==============================] - 0s 96us/sample - loss: 12.0490 - mae: 0.9210 - mse: 1.3879 - val_loss: 12.9241 - val_mae: 1.1614 - val_mse: 2.3307\n",
      "Epoch 299/1000\n",
      "412/412 [==============================] - 0s 53us/sample - loss: 12.0235 - mae: 0.8840 - mse: 1.3459 - val_loss: 12.9802 - val_mae: 1.1995 - val_mse: 2.5003\n",
      "Epoch 300/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.0570 - mae: 0.9002 - mse: 1.3891 - val_loss: 12.9990 - val_mae: 1.1057 - val_mse: 2.2225\n",
      "Epoch 301/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 12.0195 - mae: 0.8809 - mse: 1.3224 - val_loss: 12.9026 - val_mae: 1.2480 - val_mse: 2.6294\n",
      "Epoch 302/1000\n",
      "412/412 [==============================] - 0s 52us/sample - loss: 12.0828 - mae: 0.9112 - mse: 1.4044 - val_loss: 12.9124 - val_mae: 1.2692 - val_mse: 2.6779\n",
      "Epoch 303/1000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 12.0701 - mae: 0.9077 - mse: 1.3984 - val_loss: 12.9454 - val_mae: 1.2685 - val_mse: 2.7107\n",
      "Epoch 304/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 12.0330 - mae: 0.9028 - mse: 1.3653 - val_loss: 12.9022 - val_mae: 1.2602 - val_mse: 2.5893\n",
      "Epoch 305/1000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 12.0272 - mae: 0.9080 - mse: 1.3600 - val_loss: 12.8881 - val_mae: 1.1951 - val_mse: 2.4220\n",
      "Epoch 306/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.0334 - mae: 0.8979 - mse: 1.3596 - val_loss: 12.9120 - val_mae: 1.1834 - val_mse: 2.4365\n",
      "Epoch 307/1000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 12.0219 - mae: 0.8805 - mse: 1.3283 - val_loss: 13.0188 - val_mae: 1.3079 - val_mse: 2.8840\n",
      "Epoch 308/1000\n",
      "412/412 [==============================] - 0s 66us/sample - loss: 12.0609 - mae: 0.9092 - mse: 1.4080 - val_loss: 13.0389 - val_mae: 1.0828 - val_mse: 2.1727\n",
      "Epoch 309/1000\n",
      "412/412 [==============================] - 0s 69us/sample - loss: 11.9935 - mae: 0.8831 - mse: 1.3104 - val_loss: 13.0976 - val_mae: 1.1211 - val_mse: 2.2755\n",
      "Epoch 310/1000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 12.0414 - mae: 0.8993 - mse: 1.3769 - val_loss: 13.1104 - val_mae: 1.0811 - val_mse: 2.1493\n",
      "Epoch 311/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 12.0534 - mae: 0.9019 - mse: 1.3743 - val_loss: 13.0530 - val_mae: 1.0764 - val_mse: 2.1266\n",
      "Epoch 312/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.0302 - mae: 0.8909 - mse: 1.3386 - val_loss: 13.0671 - val_mae: 1.0823 - val_mse: 2.1694\n",
      "Epoch 313/1000\n",
      "412/412 [==============================] - 0s 54us/sample - loss: 12.0469 - mae: 0.8989 - mse: 1.3701 - val_loss: 13.0327 - val_mae: 1.0768 - val_mse: 2.1454\n",
      "Epoch 314/1000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 12.0271 - mae: 0.8849 - mse: 1.3302 - val_loss: 12.9102 - val_mae: 1.1512 - val_mse: 2.3285\n",
      "Epoch 315/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 73us/sample - loss: 12.0483 - mae: 0.9039 - mse: 1.3624 - val_loss: 12.8869 - val_mae: 1.2235 - val_mse: 2.5064\n",
      "Epoch 316/1000\n",
      "412/412 [==============================] - 0s 57us/sample - loss: 11.9968 - mae: 0.8933 - mse: 1.3218 - val_loss: 12.9021 - val_mae: 1.1637 - val_mse: 2.3731\n",
      "Epoch 317/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.0311 - mae: 0.8958 - mse: 1.3538 - val_loss: 12.9892 - val_mae: 1.1599 - val_mse: 2.3908\n",
      "Epoch 318/1000\n",
      "412/412 [==============================] - 0s 79us/sample - loss: 12.0551 - mae: 0.9037 - mse: 1.3670 - val_loss: 12.9056 - val_mae: 1.1781 - val_mse: 2.4256\n",
      "Epoch 319/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 11.9667 - mae: 0.8790 - mse: 1.2914 - val_loss: 13.0592 - val_mae: 1.1817 - val_mse: 2.4730\n",
      "Epoch 320/1000\n",
      "412/412 [==============================] - 0s 53us/sample - loss: 12.0078 - mae: 0.8923 - mse: 1.3365 - val_loss: 12.9525 - val_mae: 1.1063 - val_mse: 2.2280\n",
      "Epoch 321/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 12.0325 - mae: 0.8981 - mse: 1.3614 - val_loss: 13.1489 - val_mae: 1.0642 - val_mse: 2.1085\n",
      "Epoch 322/1000\n",
      "412/412 [==============================] - 0s 79us/sample - loss: 12.0318 - mae: 0.8729 - mse: 1.3107 - val_loss: 12.9870 - val_mae: 1.3195 - val_mse: 2.9090\n",
      "Epoch 323/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 11.9973 - mae: 0.8968 - mse: 1.3517 - val_loss: 13.0284 - val_mae: 1.0783 - val_mse: 2.1451\n",
      "Epoch 324/1000\n",
      "412/412 [==============================] - 0s 53us/sample - loss: 12.0221 - mae: 0.8947 - mse: 1.3384 - val_loss: 12.9226 - val_mae: 1.1239 - val_mse: 2.2561\n",
      "Epoch 325/1000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 12.0129 - mae: 0.8933 - mse: 1.3290 - val_loss: 12.9025 - val_mae: 1.1604 - val_mse: 2.3708\n",
      "Epoch 326/1000\n",
      "412/412 [==============================] - 0s 71us/sample - loss: 12.0069 - mae: 0.8909 - mse: 1.3384 - val_loss: 13.1253 - val_mae: 1.0715 - val_mse: 2.1469\n",
      "Epoch 327/1000\n",
      "412/412 [==============================] - 0s 58us/sample - loss: 12.0048 - mae: 0.8776 - mse: 1.3140 - val_loss: 12.9114 - val_mae: 1.1395 - val_mse: 2.2998\n",
      "Epoch 328/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.0592 - mae: 0.8976 - mse: 1.3845 - val_loss: 13.0387 - val_mae: 1.0783 - val_mse: 2.1658\n",
      "Epoch 329/1000\n",
      "412/412 [==============================] - 0s 54us/sample - loss: 12.0166 - mae: 0.8859 - mse: 1.3460 - val_loss: 13.2329 - val_mae: 1.0601 - val_mse: 2.1010\n",
      "Epoch 330/1000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 11.9809 - mae: 0.8688 - mse: 1.2647 - val_loss: 13.0092 - val_mae: 1.1408 - val_mse: 2.3437\n",
      "Epoch 331/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 12.0296 - mae: 0.8985 - mse: 1.3490 - val_loss: 12.9988 - val_mae: 1.1279 - val_mse: 2.3055\n",
      "Epoch 332/1000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 11.9838 - mae: 0.8532 - mse: 1.2612 - val_loss: 13.0912 - val_mae: 1.3778 - val_mse: 3.1393\n",
      "Epoch 333/1000\n",
      "412/412 [==============================] - 0s 79us/sample - loss: 11.9949 - mae: 0.8978 - mse: 1.3612 - val_loss: 13.0503 - val_mae: 1.0759 - val_mse: 2.1559\n",
      "Epoch 334/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 11.9790 - mae: 0.8765 - mse: 1.2998 - val_loss: 13.1404 - val_mae: 1.1320 - val_mse: 2.3301\n",
      "Epoch 335/1000\n",
      "412/412 [==============================] - 0s 79us/sample - loss: 12.0292 - mae: 0.8803 - mse: 1.3312 - val_loss: 13.0402 - val_mae: 1.1861 - val_mse: 2.4891\n",
      "Epoch 336/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 11.9619 - mae: 0.8705 - mse: 1.2870 - val_loss: 13.0124 - val_mae: 1.0782 - val_mse: 2.1719\n",
      "Epoch 337/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 11.9923 - mae: 0.8759 - mse: 1.3035 - val_loss: 12.9555 - val_mae: 1.1004 - val_mse: 2.2240\n",
      "Epoch 338/1000\n",
      "412/412 [==============================] - 0s 52us/sample - loss: 12.0135 - mae: 0.8864 - mse: 1.3238 - val_loss: 12.9999 - val_mae: 1.1613 - val_mse: 2.4147\n",
      "Epoch 339/1000\n",
      "412/412 [==============================] - 0s 66us/sample - loss: 12.0059 - mae: 0.8739 - mse: 1.2975 - val_loss: 13.0282 - val_mae: 1.2632 - val_mse: 2.7686\n",
      "Epoch 340/1000\n",
      "412/412 [==============================] - 0s 72us/sample - loss: 11.9546 - mae: 0.8799 - mse: 1.3145 - val_loss: 13.1011 - val_mae: 1.0552 - val_mse: 2.0863\n",
      "Epoch 341/1000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 11.9740 - mae: 0.8558 - mse: 1.2599 - val_loss: 12.9070 - val_mae: 1.2455 - val_mse: 2.6049\n",
      "Epoch 342/1000\n",
      "412/412 [==============================] - 0s 81us/sample - loss: 11.9889 - mae: 0.8864 - mse: 1.3267 - val_loss: 13.1239 - val_mae: 1.0899 - val_mse: 2.2206\n",
      "Epoch 343/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 11.9757 - mae: 0.8688 - mse: 1.2885 - val_loss: 13.0553 - val_mae: 1.0725 - val_mse: 2.1669\n",
      "Epoch 344/1000\n",
      "412/412 [==============================] - 0s 81us/sample - loss: 12.0046 - mae: 0.8870 - mse: 1.3198 - val_loss: 12.9564 - val_mae: 1.0950 - val_mse: 2.2120\n",
      "Epoch 345/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 11.9625 - mae: 0.8602 - mse: 1.2649 - val_loss: 12.9292 - val_mae: 1.2199 - val_mse: 2.5761\n",
      "Epoch 346/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 12.0107 - mae: 0.8752 - mse: 1.3212 - val_loss: 12.9825 - val_mae: 1.2990 - val_mse: 2.8456\n",
      "Epoch 347/1000\n",
      "412/412 [==============================] - 0s 52us/sample - loss: 11.9996 - mae: 0.8935 - mse: 1.3388 - val_loss: 12.9010 - val_mae: 1.1790 - val_mse: 2.4048\n",
      "Epoch 348/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 11.9962 - mae: 0.8816 - mse: 1.3294 - val_loss: 12.8931 - val_mae: 1.1700 - val_mse: 2.3932\n",
      "Epoch 349/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 11.9347 - mae: 0.8623 - mse: 1.2536 - val_loss: 12.9429 - val_mae: 1.1530 - val_mse: 2.3793\n",
      "Epoch 350/1000\n",
      "412/412 [==============================] - 0s 52us/sample - loss: 11.9807 - mae: 0.8835 - mse: 1.3101 - val_loss: 13.1378 - val_mae: 1.0762 - val_mse: 2.1820\n",
      "Epoch 351/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 11.9794 - mae: 0.8645 - mse: 1.2699 - val_loss: 13.0221 - val_mae: 1.2094 - val_mse: 2.5967\n",
      "Epoch 352/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 11.9542 - mae: 0.8582 - mse: 1.2673 - val_loss: 12.9386 - val_mae: 1.2928 - val_mse: 2.7926\n",
      "Epoch 353/1000\n",
      "412/412 [==============================] - 0s 80us/sample - loss: 11.9708 - mae: 0.8757 - mse: 1.3137 - val_loss: 12.9435 - val_mae: 1.1081 - val_mse: 2.2319\n",
      "Epoch 354/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 11.9439 - mae: 0.8576 - mse: 1.2278 - val_loss: 13.0454 - val_mae: 1.3596 - val_mse: 3.0615\n",
      "Epoch 355/1000\n",
      "412/412 [==============================] - 0s 53us/sample - loss: 11.9724 - mae: 0.8753 - mse: 1.3238 - val_loss: 12.9259 - val_mae: 1.1282 - val_mse: 2.3018\n",
      "Epoch 356/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 11.9697 - mae: 0.8650 - mse: 1.2704 - val_loss: 12.9056 - val_mae: 1.2175 - val_mse: 2.5571\n",
      "Epoch 357/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 11.9846 - mae: 0.8703 - mse: 1.2880 - val_loss: 12.9605 - val_mae: 1.2981 - val_mse: 2.8195\n",
      "Epoch 358/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 11.9695 - mae: 0.8761 - mse: 1.3060 - val_loss: 12.9200 - val_mae: 1.1323 - val_mse: 2.3144\n",
      "Epoch 359/1000\n",
      "412/412 [==============================] - 0s 52us/sample - loss: 12.0001 - mae: 0.8830 - mse: 1.3088 - val_loss: 12.9010 - val_mae: 1.2323 - val_mse: 2.5854\n",
      "Epoch 360/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 11.9187 - mae: 0.8617 - mse: 1.2466 - val_loss: 12.8858 - val_mae: 1.1941 - val_mse: 2.4628\n",
      "Epoch 361/1000\n",
      "412/412 [==============================] - 0s 77us/sample - loss: 12.0100 - mae: 0.8881 - mse: 1.3195 - val_loss: 12.8893 - val_mae: 1.2203 - val_mse: 2.5536\n",
      "Epoch 362/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 75us/sample - loss: 11.9131 - mae: 0.8588 - mse: 1.2472 - val_loss: 13.0188 - val_mae: 1.0801 - val_mse: 2.2076\n",
      "Epoch 363/1000\n",
      "412/412 [==============================] - 0s 53us/sample - loss: 11.9518 - mae: 0.8537 - mse: 1.2438 - val_loss: 13.0796 - val_mae: 1.3490 - val_mse: 3.0626\n",
      "Epoch 364/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 11.9843 - mae: 0.8878 - mse: 1.3299 - val_loss: 13.0074 - val_mae: 1.2154 - val_mse: 2.6162\n",
      "Epoch 365/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 11.9393 - mae: 0.8590 - mse: 1.2601 - val_loss: 13.0192 - val_mae: 1.1832 - val_mse: 2.5243\n",
      "Epoch 366/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 11.9742 - mae: 0.8624 - mse: 1.2893 - val_loss: 12.9477 - val_mae: 1.1409 - val_mse: 2.3660\n",
      "Epoch 367/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 11.9236 - mae: 0.8558 - mse: 1.2397 - val_loss: 12.9003 - val_mae: 1.1410 - val_mse: 2.3484\n",
      "Epoch 368/1000\n",
      "412/412 [==============================] - 0s 54us/sample - loss: 11.9480 - mae: 0.8624 - mse: 1.2636 - val_loss: 12.9773 - val_mae: 1.1095 - val_mse: 2.2665\n",
      "Epoch 369/1000\n",
      "412/412 [==============================] - 0s 62us/sample - loss: 11.9821 - mae: 0.8790 - mse: 1.3107 - val_loss: 13.1029 - val_mae: 1.0449 - val_mse: 2.1017\n",
      "Epoch 370/1000\n",
      "412/412 [==============================] - 0s 68us/sample - loss: 11.9859 - mae: 0.8659 - mse: 1.2934 - val_loss: 13.0959 - val_mae: 1.0801 - val_mse: 2.2090\n",
      "Epoch 371/1000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 11.9028 - mae: 0.8476 - mse: 1.2077 - val_loss: 13.1958 - val_mae: 1.1572 - val_mse: 2.4450\n",
      "Epoch 372/1000\n",
      "412/412 [==============================] - 0s 70us/sample - loss: 11.9616 - mae: 0.8544 - mse: 1.2624 - val_loss: 12.9051 - val_mae: 1.2514 - val_mse: 2.6533\n",
      "Epoch 373/1000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 11.9195 - mae: 0.8740 - mse: 1.2867 - val_loss: 13.5094 - val_mae: 1.0558 - val_mse: 2.1467\n",
      "Epoch 374/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 11.9521 - mae: 0.8482 - mse: 1.2276 - val_loss: 12.9955 - val_mae: 1.1541 - val_mse: 2.4224\n",
      "Epoch 375/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 11.9257 - mae: 0.8532 - mse: 1.2551 - val_loss: 13.2106 - val_mae: 1.0848 - val_mse: 2.2470\n",
      "Epoch 376/1000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 11.9200 - mae: 0.8597 - mse: 1.2385 - val_loss: 13.2607 - val_mae: 1.0397 - val_mse: 2.0981\n",
      "Epoch 377/1000\n",
      "412/412 [==============================] - 0s 64us/sample - loss: 11.9800 - mae: 0.8673 - mse: 1.2961 - val_loss: 13.0564 - val_mae: 1.0548 - val_mse: 2.1147\n",
      "Epoch 378/1000\n",
      "412/412 [==============================] - 0s 70us/sample - loss: 11.9483 - mae: 0.8589 - mse: 1.2435 - val_loss: 12.9417 - val_mae: 1.1283 - val_mse: 2.3321\n",
      "Epoch 379/1000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 11.9782 - mae: 0.8733 - mse: 1.2833 - val_loss: 12.9341 - val_mae: 1.1890 - val_mse: 2.5137\n",
      "Epoch 380/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 11.9225 - mae: 0.8610 - mse: 1.2268 - val_loss: 12.9739 - val_mae: 1.2682 - val_mse: 2.7729\n",
      "Epoch 381/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 11.8966 - mae: 0.8563 - mse: 1.2403 - val_loss: 13.1351 - val_mae: 1.1483 - val_mse: 2.4390\n",
      "Epoch 382/1000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 11.9375 - mae: 0.8583 - mse: 1.2726 - val_loss: 13.1491 - val_mae: 1.0528 - val_mse: 2.1588\n",
      "Epoch 383/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 11.9796 - mae: 0.8688 - mse: 1.2832 - val_loss: 12.9244 - val_mae: 1.1228 - val_mse: 2.3096\n",
      "Epoch 384/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 11.9223 - mae: 0.8581 - mse: 1.2537 - val_loss: 13.0937 - val_mae: 1.0904 - val_mse: 2.2513\n",
      "Epoch 385/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 11.9255 - mae: 0.8584 - mse: 1.2395 - val_loss: 13.1085 - val_mae: 1.0836 - val_mse: 2.2298\n",
      "Epoch 386/1000\n",
      "412/412 [==============================] - 0s 52us/sample - loss: 11.9574 - mae: 0.8566 - mse: 1.2586 - val_loss: 12.9437 - val_mae: 1.1313 - val_mse: 2.3547\n",
      "Epoch 387/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 11.9010 - mae: 0.8531 - mse: 1.2223 - val_loss: 13.0265 - val_mae: 1.0628 - val_mse: 2.1710\n",
      "Epoch 388/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 11.8936 - mae: 0.8438 - mse: 1.1896 - val_loss: 12.9714 - val_mae: 1.1920 - val_mse: 2.5668\n",
      "Epoch 389/1000\n",
      "412/412 [==============================] - 0s 53us/sample - loss: 11.9519 - mae: 0.8746 - mse: 1.2690 - val_loss: 12.9293 - val_mae: 1.1273 - val_mse: 2.3235\n",
      "Epoch 390/1000\n",
      "412/412 [==============================] - 0s 63us/sample - loss: 11.9044 - mae: 0.8490 - mse: 1.2098 - val_loss: 12.9703 - val_mae: 1.2134 - val_mse: 2.6078\n",
      "Epoch 391/1000\n",
      "412/412 [==============================] - 0s 70us/sample - loss: 11.9039 - mae: 0.8538 - mse: 1.2280 - val_loss: 12.9196 - val_mae: 1.1398 - val_mse: 2.3542\n",
      "Epoch 392/1000\n",
      "412/412 [==============================] - 0s 56us/sample - loss: 11.9023 - mae: 0.8476 - mse: 1.2127 - val_loss: 12.9363 - val_mae: 1.1808 - val_mse: 2.5050\n",
      "Epoch 393/1000\n",
      "412/412 [==============================] - 0s 70us/sample - loss: 11.9057 - mae: 0.8437 - mse: 1.2021 - val_loss: 13.0646 - val_mae: 1.3721 - val_mse: 3.1119\n",
      "Epoch 394/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 11.9281 - mae: 0.8765 - mse: 1.2969 - val_loss: 13.4072 - val_mae: 1.0737 - val_mse: 2.2402\n",
      "Epoch 395/1000\n",
      "412/412 [==============================] - 0s 55us/sample - loss: 11.9162 - mae: 0.8412 - mse: 1.2057 - val_loss: 12.9924 - val_mae: 1.1147 - val_mse: 2.3247\n",
      "Epoch 396/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 11.9478 - mae: 0.8625 - mse: 1.2441 - val_loss: 12.9532 - val_mae: 1.2661 - val_mse: 2.7545\n",
      "Epoch 397/1000\n",
      "412/412 [==============================] - 0s 53us/sample - loss: 11.9326 - mae: 0.8639 - mse: 1.2724 - val_loss: 13.0055 - val_mae: 1.1329 - val_mse: 2.3842\n",
      "Epoch 398/1000\n",
      "412/412 [==============================] - 0s 65us/sample - loss: 11.8571 - mae: 0.8265 - mse: 1.1554 - val_loss: 13.1651 - val_mae: 1.2814 - val_mse: 2.9149\n",
      "Epoch 399/1000\n",
      "412/412 [==============================] - 0s 70us/sample - loss: 11.9086 - mae: 0.8520 - mse: 1.2555 - val_loss: 12.9638 - val_mae: 1.0904 - val_mse: 2.2065\n",
      "Epoch 400/1000\n",
      "412/412 [==============================] - 0s 78us/sample - loss: 11.9109 - mae: 0.8411 - mse: 1.2082 - val_loss: 13.0012 - val_mae: 1.1680 - val_mse: 2.4993\n",
      "Epoch 401/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 11.8979 - mae: 0.8326 - mse: 1.1909 - val_loss: 13.0161 - val_mae: 1.3420 - val_mse: 2.9835\n",
      "Epoch 402/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 11.9590 - mae: 0.8754 - mse: 1.3106 - val_loss: 12.9977 - val_mae: 1.1197 - val_mse: 2.3452\n",
      "Epoch 403/1000\n",
      "412/412 [==============================] - 0s 75us/sample - loss: 11.9033 - mae: 0.8387 - mse: 1.1931 - val_loss: 12.9781 - val_mae: 1.2387 - val_mse: 2.7034\n",
      "Epoch 404/1000\n",
      "412/412 [==============================] - 0s 76us/sample - loss: 11.8850 - mae: 0.8307 - mse: 1.1987 - val_loss: 12.9455 - val_mae: 1.2888 - val_mse: 2.7908\n",
      "Epoch 405/1000\n",
      "412/412 [==============================] - 0s 73us/sample - loss: 11.9078 - mae: 0.8566 - mse: 1.2354 - val_loss: 13.0767 - val_mae: 1.2207 - val_mse: 2.6785\n",
      "Epoch 406/1000\n",
      "412/412 [==============================] - 0s 54us/sample - loss: 11.9201 - mae: 0.8650 - mse: 1.2644 - val_loss: 13.2281 - val_mae: 1.0396 - val_mse: 2.1387\n",
      "Epoch 407/1000\n",
      "412/412 [==============================] - 0s 102us/sample - loss: 11.9406 - mae: 0.8481 - mse: 1.2273 - val_loss: 13.0856 - val_mae: 1.2089 - val_mse: 2.6445\n",
      "Epoch 408/1000\n",
      "412/412 [==============================] - 0s 84us/sample - loss: 11.8386 - mae: 0.8236 - mse: 1.1449 - val_loss: 12.9314 - val_mae: 1.2625 - val_mse: 2.7043\n",
      "Epoch 409/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412/412 [==============================] - 0s 56us/sample - loss: 11.9205 - mae: 0.8624 - mse: 1.2486 - val_loss: 13.0280 - val_mae: 1.1648 - val_mse: 2.5006\n",
      "Epoch 410/1000\n",
      "412/412 [==============================] - 0s 74us/sample - loss: 11.8661 - mae: 0.8375 - mse: 1.1933 - val_loss: 13.1915 - val_mae: 1.1034 - val_mse: 2.3186\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 64)                1152      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 5,442\n",
      "Trainable params: 5,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 515 samples, validate on 172 samples\n",
      "Epoch 1/1000\n",
      "515/515 [==============================] - 1s 1ms/sample - loss: 269.8637 - mae: 14.5002 - mse: 269.7607 - val_loss: 241.6648 - val_mae: 13.6307 - val_mse: 241.4855\n",
      "Epoch 2/1000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 212.2816 - mae: 12.5290 - mse: 211.8858 - val_loss: 173.8387 - val_mae: 11.0268 - val_mse: 173.0339\n",
      "Epoch 3/1000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 138.7741 - mae: 9.3806 - mse: 137.1983 - val_loss: 103.2887 - val_mae: 7.6785 - val_mse: 100.5961\n",
      "Epoch 4/1000\n",
      "515/515 [==============================] - 0s 52us/sample - loss: 76.4480 - mae: 6.2846 - mse: 72.2480 - val_loss: 55.7307 - val_mae: 5.1586 - val_mse: 49.5878\n",
      "Epoch 5/1000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 44.4698 - mae: 4.6443 - mse: 36.9252 - val_loss: 42.0591 - val_mae: 4.4509 - val_mse: 34.1373\n",
      "Epoch 6/1000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 36.0923 - mae: 4.0831 - mse: 26.9396 - val_loss: 37.5273 - val_mae: 4.1532 - val_mse: 28.9725\n",
      "Epoch 7/1000\n",
      "515/515 [==============================] - 0s 55us/sample - loss: 32.4108 - mae: 3.7758 - mse: 22.7941 - val_loss: 32.6090 - val_mae: 3.7978 - val_mse: 23.0782\n",
      "Epoch 8/1000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 28.6133 - mae: 3.4632 - mse: 18.6445 - val_loss: 29.0554 - val_mae: 3.4502 - val_mse: 20.0923\n",
      "Epoch 9/1000\n",
      "515/515 [==============================] - 0s 54us/sample - loss: 25.1295 - mae: 3.1387 - mse: 15.1941 - val_loss: 25.3046 - val_mae: 3.1243 - val_mse: 15.9990\n",
      "Epoch 10/1000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 22.2887 - mae: 2.8636 - mse: 12.2378 - val_loss: 22.4878 - val_mae: 2.8463 - val_mse: 11.9373\n",
      "Epoch 11/1000\n",
      "515/515 [==============================] - 0s 69us/sample - loss: 19.9648 - mae: 2.5933 - mse: 9.6049 - val_loss: 20.6723 - val_mae: 2.5413 - val_mse: 11.6045\n",
      "Epoch 12/1000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 18.2947 - mae: 2.3461 - mse: 8.0331 - val_loss: 18.4813 - val_mae: 2.2634 - val_mse: 8.6093\n",
      "Epoch 13/1000\n",
      "515/515 [==============================] - 0s 66us/sample - loss: 17.1818 - mae: 2.1670 - mse: 6.7405 - val_loss: 17.7059 - val_mae: 2.0804 - val_mse: 7.6821\n",
      "Epoch 14/1000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 16.6922 - mae: 2.0423 - mse: 6.2116 - val_loss: 17.1404 - val_mae: 2.0618 - val_mse: 7.2028\n",
      "Epoch 15/1000\n",
      "515/515 [==============================] - 0s 65us/sample - loss: 16.4575 - mae: 1.9871 - mse: 5.8733 - val_loss: 16.7954 - val_mae: 1.9183 - val_mse: 6.0923\n",
      "Epoch 16/1000\n",
      "515/515 [==============================] - 0s 58us/sample - loss: 16.2782 - mae: 1.9574 - mse: 5.6764 - val_loss: 16.8585 - val_mae: 1.8821 - val_mse: 5.6854\n",
      "Epoch 17/1000\n",
      "515/515 [==============================] - 0s 68us/sample - loss: 16.1638 - mae: 1.9427 - mse: 5.5512 - val_loss: 16.4403 - val_mae: 1.9208 - val_mse: 5.8738\n",
      "Epoch 18/1000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 16.0219 - mae: 1.9194 - mse: 5.4063 - val_loss: 16.4027 - val_mae: 1.8036 - val_mse: 5.7014\n",
      "Epoch 19/1000\n",
      "515/515 [==============================] - 0s 69us/sample - loss: 15.9888 - mae: 1.8957 - mse: 5.3450 - val_loss: 16.9856 - val_mae: 2.1242 - val_mse: 7.5941\n",
      "Epoch 20/1000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 15.7686 - mae: 1.8659 - mse: 5.2282 - val_loss: 16.1582 - val_mae: 1.9825 - val_mse: 6.2055\n",
      "Epoch 21/1000\n",
      "515/515 [==============================] - 0s 72us/sample - loss: 15.7011 - mae: 1.8635 - mse: 5.1175 - val_loss: 15.9583 - val_mae: 1.7883 - val_mse: 5.6505\n",
      "Epoch 22/1000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 15.5409 - mae: 1.8251 - mse: 4.9296 - val_loss: 15.8545 - val_mae: 1.6926 - val_mse: 4.9035\n",
      "Epoch 23/1000\n",
      "515/515 [==============================] - 0s 68us/sample - loss: 15.4059 - mae: 1.7850 - mse: 4.7247 - val_loss: 15.6495 - val_mae: 1.6876 - val_mse: 4.7199\n",
      "Epoch 24/1000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 15.3026 - mae: 1.7657 - mse: 4.6623 - val_loss: 15.5423 - val_mae: 1.6470 - val_mse: 4.7063\n",
      "Epoch 25/1000\n",
      "515/515 [==============================] - 0s 70us/sample - loss: 15.2208 - mae: 1.7453 - mse: 4.5906 - val_loss: 15.6874 - val_mae: 1.7016 - val_mse: 4.4509\n",
      "Epoch 26/1000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 15.1605 - mae: 1.7542 - mse: 4.4816 - val_loss: 15.1677 - val_mae: 1.6919 - val_mse: 4.7595\n",
      "Epoch 27/1000\n",
      "515/515 [==============================] - 0s 68us/sample - loss: 14.9837 - mae: 1.7029 - mse: 4.3403 - val_loss: 15.2135 - val_mae: 1.5887 - val_mse: 4.0974\n",
      "Epoch 28/1000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 14.8253 - mae: 1.6628 - mse: 4.1358 - val_loss: 15.3231 - val_mae: 1.5787 - val_mse: 3.9502\n",
      "Epoch 29/1000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 14.8034 - mae: 1.6621 - mse: 4.1054 - val_loss: 14.8624 - val_mae: 1.7176 - val_mse: 4.7006\n",
      "Epoch 30/1000\n",
      "515/515 [==============================] - 0s 76us/sample - loss: 14.6327 - mae: 1.6284 - mse: 4.0101 - val_loss: 15.5090 - val_mae: 1.5636 - val_mse: 3.7687\n",
      "Epoch 31/1000\n",
      "515/515 [==============================] - 0s 53us/sample - loss: 14.5664 - mae: 1.5985 - mse: 3.8301 - val_loss: 15.0517 - val_mae: 1.4765 - val_mse: 3.6393\n",
      "Epoch 32/1000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 14.4881 - mae: 1.5726 - mse: 3.7414 - val_loss: 14.7122 - val_mae: 1.4718 - val_mse: 3.5026\n",
      "Epoch 33/1000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 14.3703 - mae: 1.5509 - mse: 3.6425 - val_loss: 14.4031 - val_mae: 1.4944 - val_mse: 3.5832\n",
      "Epoch 34/1000\n",
      "515/515 [==============================] - 0s 54us/sample - loss: 14.2634 - mae: 1.5320 - mse: 3.6017 - val_loss: 14.7948 - val_mae: 1.4723 - val_mse: 3.3672\n",
      "Epoch 35/1000\n",
      "515/515 [==============================] - 0s 63us/sample - loss: 14.1931 - mae: 1.5124 - mse: 3.4540 - val_loss: 14.6704 - val_mae: 1.4183 - val_mse: 3.1903\n",
      "Epoch 36/1000\n",
      "515/515 [==============================] - 0s 54us/sample - loss: 14.1200 - mae: 1.4859 - mse: 3.3668 - val_loss: 14.2974 - val_mae: 1.5250 - val_mse: 4.1081\n",
      "Epoch 37/1000\n",
      "515/515 [==============================] - 0s 55us/sample - loss: 14.0134 - mae: 1.4587 - mse: 3.3712 - val_loss: 13.9893 - val_mae: 1.3646 - val_mse: 3.2233\n",
      "Epoch 38/1000\n",
      "515/515 [==============================] - 0s 68us/sample - loss: 13.8650 - mae: 1.4248 - mse: 3.1661 - val_loss: 14.2837 - val_mae: 1.3288 - val_mse: 2.8684\n",
      "Epoch 39/1000\n",
      "515/515 [==============================] - 0s 57us/sample - loss: 13.7678 - mae: 1.3921 - mse: 3.0286 - val_loss: 14.4757 - val_mae: 1.7590 - val_mse: 4.9007\n",
      "Epoch 40/1000\n",
      "515/515 [==============================] - 0s 67us/sample - loss: 13.7263 - mae: 1.4092 - mse: 3.1512 - val_loss: 15.6461 - val_mae: 1.4707 - val_mse: 3.3252\n",
      "Epoch 41/1000\n",
      "515/515 [==============================] - 0s 56us/sample - loss: 13.7687 - mae: 1.3561 - mse: 2.9033 - val_loss: 13.6511 - val_mae: 1.3597 - val_mse: 3.0891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000\n",
      "515/515 [==============================] - 0s 64us/sample - loss: 13.5839 - mae: 1.3446 - mse: 2.8768 - val_loss: 13.7297 - val_mae: 1.3404 - val_mse: 3.1395\n",
      "Epoch 43/1000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 13.5534 - mae: 1.3288 - mse: 2.8400 - val_loss: 13.5397 - val_mae: 1.3035 - val_mse: 2.8619\n",
      "Epoch 44/1000\n",
      "515/515 [==============================] - 0s 68us/sample - loss: 13.4317 - mae: 1.3019 - mse: 2.7195 - val_loss: 14.6139 - val_mae: 1.2737 - val_mse: 2.6285\n",
      "Epoch 45/1000\n",
      "515/515 [==============================] - 0s 59us/sample - loss: 13.4004 - mae: 1.2686 - mse: 2.5916 - val_loss: 13.6557 - val_mae: 1.4657 - val_mse: 3.4797\n",
      "Epoch 46/1000\n",
      "515/515 [==============================] - 0s 81us/sample - loss: 13.3780 - mae: 1.2831 - mse: 2.6627 - val_loss: 13.4235 - val_mae: 1.2597 - val_mse: 2.6713\n",
      "Epoch 47/1000\n",
      "515/515 [==============================] - 0s 85us/sample - loss: 13.4107 - mae: 1.2865 - mse: 2.6961 - val_loss: 13.6655 - val_mae: 1.1793 - val_mse: 2.3356\n",
      "Epoch 48/1000\n",
      " 32/515 [>.............................] - ETA: 0s - loss: 12.1573 - mae: 1.0492 - mse: 1.9555WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-26e6724310ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Megallen 2.0/Working Directory/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_validation, y_validation)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             callbacks=self.callbacks, validation_data=(X_validation, y_validation))\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             batch_end=step * batch_size + current_batch_size)\n\u001b[1;32m    173\u001b[0m       \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[0;34m(self, step, mode, size)\u001b[0m\n\u001b[1;32m    698\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_exhausted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         self.callbacks._call_batch_hook(\n\u001b[0;32m--> 700\u001b[0;31m             mode, 'end', step, batch_logs)\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     if (self._delta_t_batch > 0. and\n\u001b[1;32m    240\u001b[0m         delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3500\u001b[0m     \"\"\"\n\u001b[1;32m   3501\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3502\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3408\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3410\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3411\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msz\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3554\u001b[0m         \u001b[0;31m# warn and return nans like mean would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3555\u001b[0;31m         \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3556\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_median_nancheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3557\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3257\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mrcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;31m# Make this warning show up first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/loc/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mitems\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for f in range(1, 11, 1):\n",
    "    frac = f / 10.0\n",
    "    sample = data_grouped.sample(frac=frac, random_state=12345)\n",
    "    sample_grouped = sample.groupby([\"location\", pd.Grouper(key=\"time\", freq=\"1s\")]).mean().reset_index()\n",
    "    train, validation, test = train_validation_test_split(sample_grouped)\n",
    "\n",
    "    train.sort_values(\"time\", inplace=True)\n",
    "    validation.sort_values(\"time\", inplace=True)\n",
    "    test.sort_values(\"time\", inplace=True)\n",
    "\n",
    "    train_imputed = train.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    train_imputed.fillna(0, inplace=True)\n",
    "    train_imputed.reset_index(inplace=True)\n",
    "\n",
    "    validation_imputed = validation.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    validation_imputed.fillna(0, inplace=True)\n",
    "    validation_imputed.reset_index(inplace=True)\n",
    "\n",
    "    test_imputed = test.set_index(\"location\").groupby(\"location\").ffill()\n",
    "    test_imputed.fillna(0, inplace=True)\n",
    "    test_imputed.reset_index(inplace=True)\n",
    "\n",
    "    train_imputed[\"X\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "    train_imputed[\"Y\"] = train_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])\n",
    "\n",
    "    validation_imputed[\"X\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "    validation_imputed[\"Y\"] = validation_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])\n",
    "\n",
    "    test_imputed[\"X\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"X\"])\n",
    "    test_imputed[\"Y\"] = test_imputed[\"location\"].apply(lambda x: pin[x][\"Y\"])\n",
    "\n",
    "    X_train, y_train = train_imputed[scanners].values, train_imputed[[\"X\", \"Y\"]].values\n",
    "    X_validation, y_validation = validation_imputed[scanners].values, validation_imputed[[\"X\", \"Y\"]].values\n",
    "    X_test, y_test = test_imputed[scanners].values, test_imputed[[\"X\", \"Y\"]].values\n",
    "\n",
    "    model = MLP()\n",
    "    history = model.fit(X_train, y_train, X_validation, y_validation)\n",
    "    train_loss.append(history.history['loss'][-1])\n",
    "    val_loss.append(history.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0.1, 1.1, 0.1)\n",
    "plt.plot(x, train_loss, label='Training loss')\n",
    "plt.plot(x, val_loss, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Dataset size\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/Small_MLP_Regression_GroupBy_FFill_MinMax.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
